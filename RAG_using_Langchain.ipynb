{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qRjVe1tZhsx"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, you must install the packages and set the necessary environment variables.\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install LangChain's Python library, `langchain`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olK4Ejjzuj76",
        "outputId": "79201a2f-7dac-4577-aff4-98abd9d20539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.2/974.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1CzIZiaurWv"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGBoQhoz3kdy",
        "outputId": "8ca70ae9-50cc-4478-eb32-633d9b4cf618",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiGHSFmZaniK"
      },
      "source": [
        "### Grab an API Key\n",
        "\n",
        "To use Gemini you need an *API key*. You can create an API key with one click in [Google AI Studio](https://makersuite.google.com/).\n",
        "After creating the API key, you can either set an environment variable named `GOOGLE_API_KEY` to your API Key or pass the API key as an argument when using the `ChatGoogleGenerativeAI` class to access Google's `gemini` and `gemini-vision` models or the `GoogleGenerativeAIEmbeddings` class to access Google's Generative AI embedding model using `LangChain`.\n",
        "\n",
        "In this tutorial, you will set the environment variable `GOOGLE_API_KEY` to configure Gemini to use your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xId4sR52utS0",
        "outputId": "8e315cff-e3ca-4c96-8d0d-53b3c55724e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key configured successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Step 1: Set the environment variable for your API key\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCyVoYC9NYaKFXUkplJpDWSAnHK1I5e-mQ'\n",
        "\n",
        "# Step 2: Retrieve the API key from the environment variable\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "# Step 3: Configure the API key for your service\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Step 4: Confirm that the API key is set correctly\n",
        "print(\"API key configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEKMUyVmckWI"
      },
      "source": [
        "## Basic steps\n",
        "LLMs are trained offline on a large corpus of public data. Hence they cannot answer questions based on custom or private data accurately without additional context.\n",
        "\n",
        "If you want to make use of LLMs to answer questions based on private data, you have to provide the relevant documents as context alongside your prompt. This approach is called Retrieval Augmented Generation (RAG).\n",
        "\n",
        "You will use this approach to create a question-answering assistant using the Gemini text model integrated through LangChain. The assistant is expected to answer questions about the Gemini model. To make this possible you will add more context to the assistant using data from a website.\n",
        "\n",
        "In this tutorial, you'll implement the two main components in an RAG-based architecture:\n",
        "\n",
        "1. Retriever\n",
        "\n",
        "    Based on the user's query, the retriever retrieves relevant snippets that add context from the document. In this tutorial, the document is the website data.\n",
        "    The relevant snippets are passed as context to the next stage - \"Generator\".\n",
        "\n",
        "2. Generator\n",
        "\n",
        "    The relevant snippets from the website data are passed to the LLM along with the user's query to generate accurate answers.\n",
        "\n",
        "You'll learn more about these stages in the upcoming sections while implementing the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPhs4mDkjdgY"
      },
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gLEmOViDGkL",
        "outputId": "c70664d3-7746-45d2-e636-06971750952d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.4)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.4 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcvGPVdXu05F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4eafd0-2e3a-47f2-89c4-886cd61a008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain import hub\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.prompt_template import format_document\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4461Jihk_rWq"
      },
      "source": [
        "## Retriever\n",
        "\n",
        "In this stage, you will perform the following steps:\n",
        "\n",
        "1. Read and parse the website data using LangChain.\n",
        "\n",
        "2. Create embeddings of the website data.\n",
        "\n",
        "    Embeddings are numerical representations (vectors) of text. Hence, text with similar meaning will have similar embedding vectors. You'll make use of Gemini's embedding model to create the embedding vectors of the website data.\n",
        "\n",
        "3. Store the embeddings in Chroma's vector store.\n",
        "    \n",
        "    Chroma is a vector database. The Chroma vector store helps in the efficient retrieval of similar vectors. Thus, for adding context to the prompt for the LLM, relevant embeddings of the text matching the user's question can be retrieved easily using Chroma.\n",
        "\n",
        "4. Create a Retriever from the Chroma vector store.\n",
        "\n",
        "    The retriever will be used to pass relevant website embeddings to the LLM along with user queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WomGvIAVjZeI"
      },
      "source": [
        "### Read and parse the website data\n",
        "\n",
        "LangChain provides a wide variety of document loaders. To read the website data as a document, you will use the `WebBaseLoader` from LangChain.\n",
        "\n",
        "To know more about how to read and parse input data from different sources using the document loaders of LangChain, read LangChain's [document loaders guide](https://python.langchain.com/docs/integrations/document_loaders)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAaKjFN7U717",
        "outputId": "e802e70c-5d70-44d0-e297-8fbe2dc602ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tto2nBoHTN-",
        "outputId": "e18af7f1-95fe-46c0-9bb3-36e6a6cd3ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Harry_Potter.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs1 = loader.load()\n",
        "\n",
        "print(len(docs1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsndsnJPTVBy",
        "outputId": "7d492b2d-fba6-4638-dcf4-017d23929e0e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEOZGqjT1Tnr",
        "outputId": "9865227a-9035-4384-ff41-61e96808e166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 0}), Document(page_content=\"1Harry Potter and the Sorcerer's Stone\\nCHAPTER ONE\\nTHE BOY WHO LIVEDMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\\nthat they were perfectly normal, thank you very much. They were the last\\npeople you'd expect to be involved in anything strange or mysterious,because they just didn't hold with such nonsense.\\nMr. Dursley was the director of a firm called Grunnings, which made\\ndrills. He was a big, beefy man with hardly any neck, although he did\\nhave a very large mustache. Mrs. Dursley was thin and blonde and had\\nnearly twice the usual amount of neck, which came in very useful as shespent so much of her time craning over garden fences, spying on theneighbors. The Dursleys had a small son called Dudley and in theiropinion there was no finer boy anywhere.\\nThe Dursleys had everything they wanted, but they also had a secret, and\\ntheir greatest fear was that somebody would discover it. They didn'tthink they could bear it if anyone found out about the Potters. Mrs.Potter was Mrs. Dursley's sister, but they hadn't met for several years;in fact, Mrs. Dursley pretended she didn't have a sister, because hersister and her good-for-nothing husband were as unDursleyish as it waspossible to be. The Dursleys shuddered to think what the neighbors would\\nsay if the Potters arrived in the street. The Dursleys knew that the\\nPotters had a small son, too, but they had never even seen him. This boywas another good reason for keeping the Potters away; they didn't wantDudley mixing with a child like that.\\nWhen Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\\nstarts, there was nothing about the cloudy sky outside to suggest that\\nstrange and mysterious things would soon be happening all over thecountry. Mr. Dursley hummed as he picked out his most boring tie forwork, and Mrs. Dursley gossiped away happily as she wrestled a screamingDudley into his high chair.\\nNone of them noticed a large, tawny owl flutter past the window.\\nAt half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.\\nDursley on the cheek, and tried to kiss Dudley good-bye but missed,\", metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 1}), Document(page_content='2because Dudley was now having a tantrum and throwing his cereal at the\\nwalls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He gotinto his car and backed out of number four\\'s drive.\\nIt was on the corner of the street that he noticed the first sign of\\nsomething peculiar -- a cat reading a map. For a second, Mr. Dursley\\ndidn\\'t realize what he had seen -- then he jerked his head around to\\nlook again. There was a tabby cat standing on the corner of PrivetDrive, but there wasn\\'t a map in sight. What could he have been thinkingof? It must have been a trick of the light. Mr. Dursley blinked andstared at the cat. It stared back. As Mr. Dursley drove around thecorner and up the road, he watched the cat in his mirror. It was nowreading the sign that said Privet Drive -- no, looking at the sign; cats\\ncouldn\\'t read maps or signs. Mr. Dursley gave himself a little shake and\\nput the cat out of his mind. As he drove toward town he thought ofnothing except a large order of drills he was hoping to get that day.\\nBut on the edge of town, drills were driven out of his mind by something\\nelse. As he sat in the usual morning traffic jam, he couldn\\'t help\\nnoticing that there seemed to be a lot of strangely dressed people\\nabout. People in cloaks. Mr. Dursley couldn\\'t bear people who dressed infunny clothes -- the getups you saw on young people! He supposed thiswas some stupid new fashion. He drummed his fingers on the steeringwheel and his eyes fell on a huddle of these weirdos standing quiteclose by. They were whispering excitedly together. Mr. Dursley wasenraged to see that a couple of them weren\\'t young at all; why, that man\\nhad to be older than he was, and wearing an emerald-green cloak! The\\nnerve of him! But then it struck Mr. Dursley that this was probably somesilly stunt -- these people were obviously collecting for something...yes, that would be it. The traffic moved on and a few minutes later, Mr.Dursley arrived in the Grunnings parking lot, his mind back on drills.\\nMr. Dursley always sat with his back to the window in his office on the\\nninth floor. If he hadn\\'t, he might have found it harder to concentrateon drills that morning. He didn\\'t see the owls swoop ing past in broaddaylight, though people down in the street did; they pointed and gazedopen- mouthed as owl after owl sped overhead. Most of them had neverseen an owl even at nighttime. Mr. Dursley, however, had a perfectlynormal, owl-free morning. He yelled at five different people. He made\\nseveral important telephone calls and shouted a bit more. He was in a\\nvery good mood until lunchtime, when he thought he\\'d stretch his legsand walk across the road to buy himself a bun from the bakery.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 2}), Document(page_content='3He\\'d forgotten all about the people in cloaks until he passed a group of\\nthem next to the baker\\'s. He eyed them angrily as he passed. He didn\\'tknow why, but they made him uneasy. This bunch were whisperingexcitedly, too, and he couldn\\'t see a single collecting tin. It was onhis way back past them, clutching a large doughnut in a bag, that hecaught a few words of what they were saying.\\n\"The Potters, that\\'s right, that\\'s what I heard yes, their son, Harry\"\\nMr. Dursley stopped dead. Fear flooded him. He looked back at the\\nwhisperers as if he wanted to say something to them, but thought betterof it.\\nHe dashed back across the road, hurried up to his office, snapped at his\\nsecretary not to disturb him, seized his telephone, and had almostfinished dialing his home number when he changed his mind. He put thereceiver back down and stroked his mustache, thinking... no, he wasbeing stupid. Potter wasn\\'t such an unusual name. He was sure there werelots of people called Potter who had a son called Harry. Come to think\\nof it, he wasn\\'t even sure his nephew was called Harry. He\\'d never even\\nseen the boy. It might have been Harvey. Or Harold. There was no pointin worrying Mrs. Dursley; she always got so upset at any mention of hersister. He didn\\'t blame her -- if he\\'d had a sister like that... but allthe same, those people in cloaks...\\nHe found it a lot harder to concentrate on drills that afternoon and\\nwhen he left the building at five o\\'clock, he was still so worried that\\nhe walked straight into someone just outside the door.\\n\"Sorry,\" he grunted, as the tiny old man stumbled and almost fell. It\\nwas a few seconds before Mr. Dursley realized that the man was wearing aviolet cloak. He didn\\'t seem at all upset at being almost knocked to the\\nground. On the contrary, his face split into a wide smile and he said in\\na squeaky voice that made passersby stare, \"Don\\'t be sorry, my dear sir,for nothing could upset me today! Rejoice, for You-Know-Who has gone atlast! Even Muggles like yourself should be celebrating, this happy,happy day!\"\\nAnd the old man hugged Mr. Dursley around the middle and walked off.\\nMr. Dursley stood rooted to the spot. He had been hugged by a complete\\nstranger. He also thought he had been called a Muggle, whatever thatwas. He was rattled. He hurried to his car and set off for home, hoping', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 3}), Document(page_content='4he was imagining things, which he had never hoped before, because he\\ndidn\\'t approve of imagination.\\nAs he pulled into the driveway of number four, the first thing he saw --\\nand it didn\\'t improve his mood -- was the tabby cat he\\'d spotted thatmorning. It was now sitting on his garden wall. He was sure it was the\\nsame one; it had the same markings around its eyes.\\n\"Shoo!\" said Mr. Dursley loudly. The cat didn\\'t move. It just gave him a\\nstern look. Was this normal cat behavior? Mr. Dursley wondered. Tryingto pull himself together, he let himself into the house. He was stilldetermined not to mention anything to his wife.\\nMrs. Dursley had had a nice, normal day. She told him over dinner all\\nabout Mrs. Next Door\\'s problems with her daughter and how Dudley hadlearned a new word (\"Won\\'t!\"). Mr. Dursley tried to act normally. WhenDudley had been put to bed, he went into the living room in time tocatch the last report on the evening news:\\n\"And finally, bird-watchers everywhere have reported that the nation\\'s\\nowls have been behaving very unusually today. Although owls normallyhunt at night and are hardly ever seen in daylight, there have beenhundreds of sightings of these birds flying in every direction sincesunrise. Experts are unable to explain why the owls have suddenlychanged their sleeping pattern.\" The newscaster allowed himself a grin.\"Most mysterious. And now, over to Jim McGuffin with the weather. Going\\nto be any more showers of owls tonight, Jim?\"\\n\"Well, Ted,\" said the weatherman, \"I don\\'t know about that, but it\\'s not\\nonly the owls that have been acting oddly today. Viewers as far apart asKent, Yorkshire, and Dundee have been phoning in to tell me that insteadof the rain I promised yesterday, they\\'ve had a downpour of shooting\\nstars! Perhaps people have been celebrating Bonfire Night early -- it\\'s\\nnot until next week, folks! But I can promise a wet night tonight.\"\\nMr. Dursley sat frozen in his armchair. Shooting stars all over Britain?\\nOwls flying by daylight? Mysterious people in cloaks all over the place?And a whisper, a whisper about the Potters...\\nMrs. Dursley came into the living room carrying two cups of tea. It was\\nno good. He\\'d have to say something to her. He cleared his throatnervously. \"Er -- Petunia, dear -- you haven\\'t heard from your sisterlately, have you?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 4}), Document(page_content='5As he had expected, Mrs. Dursley looked shocked and angry. After all,\\nthey normally pretended she didn\\'t have a sister.\\n\"No,\" she said sharply. \"Why?\"\\n\"Funny stuff on the news,\" Mr. Dursley mumbled. \"Owls... shooting\\nstars... and there were a lot of funny-looking people in town today...\"\\n\"So?\" snapped Mrs. Dursley.\"Well, I just thought... maybe... it was something to do with... you\\nknow... her crowd.\"\\nMrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered\\nwhether he dared tell her he\\'d heard the name \"Potter.\" He decided hedidn\\'t dare. Instead he said, as casually as he could, \"Their son --he\\'d be about Dudley\\'s age now, wouldn\\'t he?\"\\n\"I suppose so,\" said Mrs. Dursley stiffly.\\n\"What\\'s his name again? Howard, isn\\'t it?\"\"Harry. Nasty, common name, if you ask me.\"\"Oh, yes,\" said Mr. Dursley, his heart sinking horribly. \"Yes, I quite\\nagree.\"\\nHe didn\\'t say another word on the subject as they went upstairs to bed.\\nWhile Mrs. Dursley was in the bathroom, Mr. Dursley crept to the bedroomwindow and peered down into the front garden. The cat was still there.It was staring down Privet Drive as though it were waiting for\\nsomething.\\nWas he imagining things? Could all this have anything to do with the\\nPotters? If it did... if it got out that they were related to a pair of-- well, he didn\\'t think he could bear it.\\nThe Dursleys got into bed. Mrs. Dursley fell asleep quickly but Mr.\\nDursley lay awake, turning it all over in his mind. His last, comforting\\nthought before he fell asleep was that even if the Potters wereinvolved, there was no reason for them to come near him and Mrs.Dursley. The Potters knew very well what he and Petunia thought about', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 5}), Document(page_content='6them and their kind.... He couldn\\'t see how he and Petunia could get\\nmixed up in anything that might be going on -- he yawned and turned over-- it couldn\\'t affect them....\\nHow very wrong he was.\\nMr. Dursley might have been drifting into an uneasy sleep, but the cat\\non the wall outside was showing no sign of sleepiness. It was sitting asstill as a statue, its eyes fixed unblinkingly on the far corner ofPrivet Drive. It didn\\'t so much as quiver when a car door slammed on thenext street, nor when two owls swooped overhead. In fact, it was nearlymidnight before the cat moved at all.\\nA man appeared on the corner the cat had been watching, appeared so\\nsuddenly and silently you\\'d have thought he\\'d just popped out of theground. The cat\\'s tail twitched and its eyes narrowed.\\nNothing like this man had ever been seen on Privet Drive. He was tall,\\nthin, and very old, judging by the silver of his hair and beard, which\\nwere both long enough to tuck into his belt. He was wearing long robes,\\na purple cloak that swept the ground, and high-heeled, buckled boots.His blue eyes were light, bright, and sparkling behind half-moonspectacles and his nose was very long and crooked, as though it had beenbroken at least twice. This man\\'s name was Albus Dumbledore.\\nAlbus Dumbledore didn\\'t seem to realize that he had just arrived in a\\nstreet where everything from his name to his boots was unwelcome. He was\\nbusy rummaging in his cloak, looking for something. But he did seem torealize he was being watched, because he looked up suddenly at the cat,which was still staring at him from the other end of the street. Forsome reason, the sight of the cat seemed to amuse him. He chuckled andmuttered, \"I should have known.\"\\nHe found what he was looking for in his inside pocket. It seemed to be a\\nsilver cigarette lighter. He flicked it open, held it up in the air, andclicked it. The nearest street lamp went out with a little pop. Heclicked it again -- the next lamp flickered into darkness. Twelve timeshe clicked the Put-Outer, until the only lights left on the whole streetwere two tiny pinpricks in the distance, which were the eyes of the cat\\nwatching him. If anyone looked out of their window now, even beady-eyed\\nMrs. Dursley, they wouldn\\'t be able to see anything that was happeningdown on the pavement. Dumbledore slipped the Put-Outer back inside hiscloak and set off down the street toward number four, where he sat down', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 6}), Document(page_content='7on the wall next to the cat. He didn\\'t look at it, but after a moment he\\nspoke to it.\\n\"Fancy seeing you here, Professor McGonagall.\"He turned to smile at the tabby, but it had gone. Instead he was smiling\\nat a rather severe-looking woman who was wearing square glasses exactly\\nthe shape of the markings the cat had had around its eyes. She, too, waswearing a cloak, an emerald one. Her black hair was drawn into a tightbun. She looked distinctly ruffled.\\n\"How did you know it was me?\" she asked.\\n\"My dear Professor, I \\'ve never seen a cat sit so stiffly.\"\\n\"You\\'d be stiff if you\\'d been sitting on a brick wall all day,\" said\\nProfessor McGonagall.\\n\"All day? When you could have been celebrating? I must have passed a\\ndozen feasts and parties on my way here.\"\\nProfessor McGonagall sniffed angrily.\"Oh yes, everyone\\'s celebrating, all right,\" she said impatiently.\\n\"You\\'d think they\\'d be a bit more careful, but no -- even the Muggleshave noticed something\\'s going on. It was on their news.\" She jerked her\\nhead back at the Dursleys\\' dark living-room window. \"I heard it. Flocks\\nof owls... shooting stars.... Well, they\\'re not completely stupid. Theywere bound to notice something. Shooting stars down in Kent -- I\\'ll betthat was Dedalus Diggle. He never had much sense.\"\\n\"You can\\'t blame them,\" said Dumbledore gently. \"We\\'ve had precious\\nlittle to celebrate for eleven years.\"\\n\"I know that,\" said Professor McGonagall irritably. \"But that\\'s no\\nreason to lose our heads. People are being downright careless, out onthe streets in broad daylight, not even dressed in Muggle clothes,swapping rumors.\"\\nShe threw a sharp, sideways glance at Dumbledore here, as though hoping\\nhe was going to tell her something, but he didn\\'t, so she went on. \"Afine thing it would be if, on the very day YouKnow-Who seems to havedisappeared at last, the Muggles found out about us all. I suppose he', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 7}), Document(page_content='8really has gone, Dumbledore?\"\\n\"It certainly seems so,\" said Dumbledore. \"We have much to be thankful\\nfor. Would you care for a lemon drop?\"\\n\"A what?\"\\n\"A lemon drop. They\\'re a kind of Muggle sweet I\\'m rather fond of\"\\n\"No, thank you,\" said Professor McGonagall coldly, as though she didn\\'t\\nthink this was the moment for lemon drops. \"As I say, even ifYou-Know-Who has gone -\"\\n\"My dear Professor, surely a sensible person like yourself can call him\\nby his name? All this \\'You- Know-Who\\' nonsense -- for eleven years Ihave been trying to persuade people to call him by his proper name:Voldemort.\" Professor McGonagall flinched, but Dumbledore, who wasunsticking two lemon drops, seemed not to notice. \"It all gets soconfusing if we keep saying \\'You-Know-Who.\\' I have never seen any reason\\nto be frightened of saying Voldemort\\'s name.\\n\"I know you haven \\'t, said Professor McGonagall, sounding half\\nexasperated, half admiring. \"But you\\'re different. Everyone knows you\\'rethe only one You-Know- oh, all right, Voldemort, was frightened of.\"\\n\"You flatter me,\" said Dumbledore calmly. \"Voldemort had powers I will\\nnever have.\"\\n\"Only because you\\'re too -- well -- noble to use them.\"\"It\\'s lucky it\\'s dark. I haven\\'t blushed so much since Madam Pomfrey\\ntold me she liked my new earmuffs.\"\\nProfessor McGonagall shot a sharp look at Dumbledore and said, \"The owls\\nare nothing next to the rumors that are flying around. You know whateveryone\\'s saying? About why he\\'s disappeared? About what finallystopped him?\"\\nIt seemed that Professor McGonagall had reached the point she was most\\nanxious to discuss, the real reason she had been waiting on a cold, hard\\nwall all day, for neither as a cat nor as a woman had she fixedDumbledore with such a piercing stare as she did now. It was plain thatwhatever \"everyone\" was saying, she was not going to believe it until', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 8}), Document(page_content='9Dumbledore told her it was true. Dumbledore, however, was choosing\\nanother lemon drop and did not answer.\\n\"What they\\'re saying,\" she pressed on, \"is that last night Voldemort\\nturned up in Godric\\'s Hollow. He went to find the Potters. The rumor isthat Lily and James Potter are -- are -- that they\\'re -- dead. \"\\nDumbledore bowed his head. Professor McGonagall gasped.\\n\"Lily and James... I can\\'t believe it... I didn\\'t want to believe it...\\nOh, Albus...\"\\nDumbledore reached out and patted her on the shoulder. \"I know... I\\nknow...\" he said heavily.\\nProfessor McGonagall\\'s voice trembled as she went on. \"That\\'s not all.\\nThey\\'re saying he tried to kill the Potter\\'s son, Harry. But -- hecouldn\\'t. He couldn\\'t kill that little boy. No one knows why, or how,but they\\'re saying that when he couldn\\'t kill Harry Potter, Voldemort\\'s\\npower somehow broke -- and that\\'s why he\\'s gone.\\nDumbledore nodded glumly.\"It\\'s -- it\\'s true?\" faltered Professor McGonagall. \"After all he\\'s\\ndone... all the people he\\'s killed... he couldn\\'t kill a little boy?It\\'s just astounding... of all the things to stop him... but how in the\\nname of heaven did Harry survive?\"\\n\"We can only guess,\" said Dumbledore. \"We may never know.\"Professor McGonagall pulled out a lace handkerchief and dabbed at her\\neyes beneath her spectacles. Dumbledore gave a great sniff as he took a\\ngolden watch from his pocket and examined it. It was a very odd watch.\\nIt had twelve hands but no numbers; instead, little planets were movingaround the edge. It must have made sense to Dumbledore, though, becausehe put it back in his pocket and said, \"Hagrid\\'s late. I suppose it washe who told you I\\'d be here, by the way?\"\\n\"Yes,\" said Professor McGonagall. \"And I don\\'t suppose you\\'re going to\\ntell me why you\\'re here, of all places?\"\\n\"I\\'ve come to bring Harry to his aunt and uncle. They\\'re the only family\\nhe has left now.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 9}), Document(page_content='10\"You don\\'t mean -- you can\\'t mean the people who live here?\" cried\\nProfessor McGonagall, jumping to her feet and pointing at number four.\"Dumbledore -- you can\\'t. I\\'ve been watching them all day. You couldn\\'tfind two people who are less like us. And they\\'ve got this son -- I sawhim kicking his mother all the way up the street, screaming for sweets.\\nHarry Potter come and live here!\"\\n\"It\\'s the best place for him,\" said Dumbledore firmly. \"His aunt and\\nuncle will be able to explain everything to him when he\\'s older. I\\'vewritten them a letter.\"\\n\"A letter?\" repeated Professor McGonagall faintly, sitting back down on\\nthe wall. \"Really, Dumbledore, you think you can explain all this in a\\nletter? These people will never understand him! He\\'ll be famous -- alegend -- I wouldn\\'t be surprised if today was known as Harry Potter dayin the future -- there will be books written about Harry -- every childin our world will know his name!\"\\n\"Exactly,\" said Dumbledore, looking very seriously over the top of his\\nhalf-moon glasses. \"It would be enough to turn any boy\\'s head. Famousbefore he can walk and talk! Famous for something he won\\'t evenremember! CarA you see how much better off he\\'ll be, growing up awayfrom all that until he\\'s ready to take it?\"\\nProfessor McGonagall opened her mouth, changed her mind, swallowed, and\\nthen said, \"Yes -- yes, you\\'re right, of course. But how is the boy\\ngetting here, Dumbledore?\" She eyed his cloak suddenly as though shethought he might be hiding Harry underneath it.\\n\"Hagrid\\'s bringing him.\"\\n\"You think it -- wise -- to trust Hagrid with something as important as\\nthis?\"\\nI would trust Hagrid with my life,\" said Dumbledore.\"I\\'m not saying his heart isn\\'t in the right place,\" said Professor\\nMcGonagall grudgingly, \"but you can\\'t pretend he\\'s not careless. He does\\ntend to -- what was that?\"\\nA low rumbling sound had broken the silence around them. It grew\\nsteadily louder as they looked up and down the street for some sign of a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 10}), Document(page_content='11headlight; it swelled to a roar as they both looked up at the sky -- and\\na huge motorcycle fell out of the air and landed on the road in front ofthem.\\nIf the motorcycle was huge, it was nothing to the man sitting astride\\nit. He was almost twice as tall as a normal man and at least five times\\nas wide. He looked simply too big to be allowed, and so wild - long\\ntangles of bushy black hair and beard hid most of his face, he had handsthe size of trash can lids, and his feet in their leather boots werelike baby dolphins. In his vast, muscular arms he was holding a bundleof blankets.\\n\"Hagrid,\" said Dumbledore, sounding relieved. \"At last. And where did\\nyou get that motorcycle?\"\\n\"Borrowed it, Professor Dumbledore, sit,\" said the giant, climbing\\ncarefully off the motorcycle as he spoke. \"Young Sirius Black lent it tome. I\\'ve got him, sir.\"\\n\"No problems, were there?\"\\n\"No, sir -- house was almost destroyed, but I got him out all right\\nbefore the Muggles started swarmin\\' around. He fell asleep as we wasflyin\\' over Bristol.\"\\nDumbledore and Professor McGonagall bent forward over the bundle of\\nblankets. Inside, just visible, was a baby boy, fast asleep. Under a\\ntuft of jet-black hair over his forehead they could see a curiouslyshaped cut, like a bolt of lightning.\\n\"Is that where -?\" whispered Professor McGonagall.\\n\"Yes,\" said Dumbledore. \"He\\'ll have that scar forever.\"\\n\"Couldn\\'t you do something about it, Dumbledore?\"\"Even if I could, I wouldn\\'t. Scars can come in handy. I have one myself\\nabove my left knee that is a perfect map of the London Underground. Well-- give him here, Hagrid -- we\\'d better get this over with.\"\\nDumbledore took Harry in his arms and turned toward the Dursleys\\' house.\\n\"Could I -- could I say good-bye to him, sir?\" asked Hagrid. He bent his', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 11}), Document(page_content='12great, shaggy head over Harry and gave him what must have been a very\\nscratchy, whiskery kiss. Then, suddenly, Hagrid let out a howl like awounded dog.\\n\"Shhh!\" hissed Professor McGonagall, \"you\\'ll wake the Muggles!\"\\n\"S-s-sorry,\" sobbed Hagrid, taking out a large, spotted handkerchief and\\nburying his face in it. \"But I c-c-can\\'t stand it -- Lily an\\' James dead-- an\\' poor little Harry off ter live with Muggles -\"\\n\"Yes, yes, it\\'s all very sad, but get a grip on yourself, Hagrid, or\\nwe\\'ll be found,\" Professor McGonagall whispered, patting Hagrid gingerlyon the arm as Dumbledore stepped over the low garden wall and walked to\\nthe front door. He laid Harry gently on the doorstep, took a letter out\\nof his cloak, tucked it inside Harry\\'s blankets, and then came back tothe other two. For a full minute the three of them stood and looked atthe little bundle; Hagrid\\'s shoulders shook, Professor McGonagallblinked furiously, and the twinkling light that usually shone fromDumbledore\\'s eyes seemed to have gone out.\\n\"Well,\" said Dumbledore finally, \"that\\'s that. We\\'ve no business staying\\nhere. We may as well go and join the celebrations.\"\\n\"Yeah,\" said Hagrid in a very muffled voice, \"I\\'ll be takin\\' Sirius his\\nbike back. G\\'night, Professor McGonagall -- Professor Dumbledore, sir.\"\\nWiping his streaming eyes on his jacket sleeve, Hagrid swung himself\\nonto the motorcycle and kicked the engine into life; with a roar it roseinto the air and off into the night.\\n\"I shall see you soon, I expect, Professor McGonagall,\" said Dumbledore,\\nnodding to her. Professor McGonagall blew her nose in reply.\\nDumbledore turned and walked back down the street. On the corner he\\nstopped and took out the silver Put-Outer. He clicked it once, andtwelve balls of light sped back to their street lamps so that PrivetDrive glowed suddenly orange and he could make out a tabby cat slinkingaround the corner at the other end of the street. He could just see thebundle of blankets on the step of number four.\\n\"Good luck, Harry,\" he murmured. He turned on his heel and with a swish\\nof his cloak, he was gone.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 12}), Document(page_content='13A breeze ruffled the neat hedges of Privet Drive, which lay silent and\\ntidy under the inky sky, the very last place you would expectastonishing things to happen. Harry Potter rolled over inside hisblankets without waking up. One small hand closed on the letter besidehim and he slept on, not knowing he was special, not knowing he wasfamous, not knowing he would be woken in a few hours\\' time by Mrs.\\nDursley\\'s scream as she opened the front door to put out the milk\\nbottles, nor that he would spend the next few weeks being prodded andpinched by his cousin Dudley... He couldn\\'t know that at this verymoment, people meeting in secret all over the country were holding uptheir glasses and saying in hushed voices: \"To Harry Potter -- the boywho lived!\"\\nCHAPTER TWO\\nTHE VANISHING GLASSNearly ten years had passed since the Dursleys had woken up to find\\ntheir nephew on the front step, but Privet Drive had hardly changed at\\nall. The sun rose on the same tidy front gardens and lit up the brassnumber four on the Dursleys\\' front door; it crept into their livingroom, which was almost exactly the same as it had been on the night whenMr. Dursley had seen that fateful news report about the owls. Only thephotographs on the mantelpiece really showed how much time had passed.Ten years ago, there had been lots of pictures of what looked like a\\nlarge pink beach ball wearing different-colored bonnets -- but Dudley\\nDursley was no longer a baby, and now the photographs showed a largeblond boy riding his first bicycle, on a carousel at the fair, playing acomputer game with his father, being hugged and kissed by his mother.The room held no sign at all that another boy lived in the house, too.\\nYet Harry Potter was still there, asleep at the moment, but not for\\nlong. His Aunt Petunia was awake and it was her shrill voice that madethe first noise of the day.\\n\"Up! Get up! Now!\"Harry woke with a start. His aunt rapped on the door again.\\n\"Up!\" she screeched. Harry heard her walking toward the kitchen and then\\nthe sound of the frying pan being put on the stove. He rolled onto hisback and tried to remember the dream he had been having. It had been a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 13}), Document(page_content='14good one. There had been a flying motorcycle in it. He had a funny\\nfeeling he\\'d had the same dream before.\\nHis aunt was back outside the door.\"Are you up yet?\" she demanded.\\n\"Nearly,\" said Harry.\\n\"Well, get a move on, I want you to look after the bacon. And don\\'t you\\ndare let it burn, I want everything perfect on Duddy\\'s birthday.\"\\nHarry groaned.\\n\"What did you say?\" his aunt snapped through the door.\\n\"Nothing, nothing...\"Dudley\\'s birthday -- how could he have forgotten? Harry got slowly out\\nof bed and started looking for socks. He found a pair under his bed and,\\nafter pulling a spider off one of them, put them on. Harry was used tospiders, because the cupboard under the stairs was full of them, andthat was where he slept.\\nWhen he was dressed he went down the hall into the kitchen. The table\\nwas almost hidden beneath all Dudley\\'s birthday presents. It looked as\\nthough Dudley had gotten the new computer he wanted, not to mention the\\nsecond television and the racing bike. Exactly why Dudley wanted aracing bike was a mystery to Harry, as Dudley was very fat and hatedexercise -- unless of course it involved punching somebody. Dudley\\'sfavorite punching bag was Harry, but he couldn\\'t often catch him. Harrydidn\\'t look it, but he was very fast.\\nPerhaps it had something to do with living in a dark cupboard, but Harry\\nhad always been small and skinny for his age. He looked even smaller andskinnier than he really was because all he had to wear were old clothesof Dudley\\'s, and Dudley was about four times bigger than he was. Harryhad a thin face, knobbly knees, black hair, and bright green eyes. Hewore round glasses held together with a lot of Scotch tape because of\\nall the times Dudley had punched him on the nose. The only thing Harry\\nliked about his own appearance was a very thin scar on his forehead thatwas shaped like a bolt of lightning. He had had it as long as he couldremember, and the first question he could ever remember asking his Aunt', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 14}), Document(page_content='15Petunia was how he had gotten it.\\n\"In the car crash when your parents died,\" she had said. \"And don\\'t ask\\nquestions.\"\\nDon\\'t ask questions -- that was the first rule for a quiet life with the\\nDursleys.\\nUncle Vernon entered the kitchen as Harry was turning over the bacon.\"Comb your hair!\" he barked, by way of a morning greeting.About once a week, Uncle Vernon looked over the top of his newspaper and\\nshouted that Harry needed a haircut. Harry must have had more haircuts\\nthan the rest of the boys in his class put\\ntogether, but it made no difference, his hair simply grew that way --\\nall over the place.\\nHarry was frying eggs by the time Dudley arrived in the kitchen with his\\nmother. Dudley looked a lot like Uncle Vernon. He had a large pink face,not much neck, small, watery blue eyes, and thick blond hair that laysmoothly on his thick, fat head. Aunt Petunia often said that Dudleylooked like a baby angel -- Harry often said that Dudley looked like apig in a wig.\\nHarry put the plates of egg and bacon on the table, which was difficult\\nas there wasn\\'t much room. Dudley, meanwhile, was counting his presents.His face fell.\\n\"Thirty-six,\" he said, looking up at his mother and father. \"That\\'s two\\nless than last year.\"\\n\"Darling, you haven\\'t counted Auntie Marge\\'s present, see, it\\'s here\\nunder this big one from Mommy and Daddy.\"\\n\"All right, thirty-seven then,\" said Dudley, going red in the face.\\nHarry, who could see a huge Dudley tantrum coming on, began wolfing downhis bacon as fast as possible in case Dudley turned the table over.\\nAunt Petunia obviously scented danger, too, because she said quickly,\\n\"And we\\'ll buy you another two presents while we\\'re out today. How\\'sthat, popkin? Two more presents. Is that all right\\'\\'', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 15}), Document(page_content='16Dudley thought for a moment. It looked like hard work. Finally he said\\nslowly, \"So I\\'ll have thirty ... thirty...\"\\n\"Thirty-nine, sweetums,\" said Aunt Petunia.\\n\"Oh.\" Dudley sat down heavily and grabbed the nearest parcel. \"All right\\nthen.\"\\nUncle Vernon chuckled. \"Little tyke wants his money\\'s worth, just like\\nhis father. \\'Atta boy, Dudley!\" He ruffled Dudley\\'s hair.\\nAt that moment the telephone rang and Aunt Petunia went to answer it\\nwhile Harry and Uncle Vernon watched Dudley unwrap the racing bike, a\\nvideo camera, a remote control airplane, sixteen new computer games, anda VCR. He was ripping the paper off a gold wristwatch when Aunt Petuniacame back from the telephone looking both angry and worried.\\n\"Bad news, Vernon,\" she said. \"Mrs. Figg\\'s broken her leg. She can\\'t\\ntake him.\" She jerked her head in Harry\\'s direction.\\nDudley\\'s mouth fell open in horror, but Harry\\'s heart gave a leap. Every\\nyear on Dudley\\'s birthday, his parents took him and a friend out for theday, to adventure parks, hamburger restaurants, or the movies. Everyyear, Harry was left behind with Mrs. Figg, a mad old lady who lived twostreets away. Harry hated it there. The whole house smelled of cabbage\\nand Mrs. Figg made him look at photographs of all the cats she\\'d ever\\nowned.\\n\"Now what?\" said Aunt Petunia, looking furiously at Harry as though he\\'d\\nplanned this. Harry knew he ought to feel sorry that Mrs. Figg hadbroken her leg, but it wasn\\'t easy when he reminded himself it would be\\na whole year before he had to look at Tibbles, Snowy, Mr. Paws, and\\nTufty again.\\n\"We could phone Marge,\" Uncle Vernon suggested.\"Don\\'t be silly, Vernon, she hates the boy.\"\\nThe Dursleys often spoke about Harry like this, as though he wasn\\'t\\nthere -- or rather, as though he was something very nasty that couldn\\'tunderstand them, like a slug.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 16}), Document(page_content='17\"What about what\\'s-her-name, your friend -- Yvonne?\"\\n\"On vacation in Majorca,\" snapped Aunt Petunia.\"You could just leave me here,\" Harry put in hopefully (he\\'d be able to\\nwatch what he wanted on television for a change and maybe even have a go\\non Dudley\\'s computer).\\nAunt Petunia looked as though she\\'d just swallowed a lemon.\"And come back and find the house in ruins?\" she snarled.\"I won\\'t blow up the house,\" said Harry, but they weren\\'t listening.\\n\"I suppose we could take him to the zoo,\" said Aunt Petunia slowly, \"...\\nand leave him in the car....\"\\n\"That car\\'s new, he\\'s not sitting in it alone....\"\\nDudley began to cry loudly. In fact, he wasn\\'t really crying -- it had\\nbeen years since he\\'d really cried -- but he knew that if he screwed uphis face and wailed, his mother would give him anything he wanted.\\n\"Dinky Duddydums, don\\'t cry, Mummy won\\'t let him spoil your special\\nday!\" she cried, flinging her arms around him.\\n\"I... don\\'t... want... him... t-t-to come!\" Dudley yelled between huge,\\npretend sobs. \"He always sp- spoils everything!\" He shot Harry a nastygrin through the gap in his mother\\'s arms.\\nJust then, the doorbell rang -- \"Oh, good Lord, they\\'re here!\" said Aunt\\nPetunia frantically -- and a moment later, Dudley\\'s best friend, Piers\\nPolkiss, walked in with his mother. Piers was a scrawny boy with a face\\nlike a rat. He was usually the one who held people\\'s arms behind theirbacks while Dudley hit them. Dudley stopped pretending to cry at once.\\nHalf an hour later, Harry, who couldn\\'t believe his luck, was sitting in\\nthe back of the Dursleys\\' car with Piers and Dudley, on the way to thezoo for the first time in his life. His aunt and uncle hadn\\'t been able\\nto think of anything else to do with him, but before they\\'d left, Uncle\\nVernon had taken Harry aside.\\n\"I\\'m warning you,\" he had said, putting his large purple face right up', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 17}), Document(page_content='18close to Harry\\'s, \"I\\'m warning you now, boy -- any funny business,\\nanything at all -- and you\\'ll be in that cupboard from now untilChristmas.\"\\n\"I\\'m not going to do anything,\" said Harry, \"honestly..\\nBut Uncle Vernon didn\\'t believe him. No one ever did.\\nThe problem was, strange things often happened around Harry and it was\\njust no good telling the Dursleys he didn\\'t make them happen.\\nOnce, Aunt Petunia, tired of Harry coming back from the barbers looking\\nas though he hadn\\'t been at all, had taken a pair of kitchen scissors\\nand cut his hair so short he was almost bald except for his bangs, which\\nshe left \"to hide that horrible scar.\" Dudley had laughed himself sillyat Harry, who spent a sleepless night imagining school the next day,where he was already laughed at for his baggy clothes and taped glasses.Next morning, however, he had gotten up to find his hair exactly as ithad been before Aunt Petunia had sheared it off He had been given a week\\nin his cupboard for this, even though he had tried to explain that he\\ncouldn\\'t explain how it had grown back so quickly.\\nAnother time, Aunt Petunia had been trying to force him into a revolting\\nold sweater of Dudley\\'s (brown with orange puff balls) -- The harder shetried to pull it over his head, the smaller it seemed to become, untilfinally it might have fitted a hand puppet, but certainly wouldn\\'t fit\\nHarry. Aunt Petunia had decided it must have shrunk in the wash and, to\\nhis great relief, Harry wasn\\'t punished.\\nOn the other hand, he\\'d gotten into terrible trouble for being found on\\nthe roof of the school kitchens. Dudley\\'s gang had been chasing him asusual when, as much to Harry\\'s surprise as anyone else\\'s, there he was\\nsitting on the chimney. The Dursleys had received a very angry letter\\nfrom Harry\\'s headmistress telling them Harry had been climbing schoolbuildings. But all he\\'d tried to do (as he shouted at Uncle Vernonthrough the locked door of his cupboard) was jump behind the big trashcans outside the kitchen doors. Harry supposed that the wind must havecaught him in mid- jump.\\nBut today, nothing was going to go wrong. It was even worth being with\\nDudley and Piers to be spending the day somewhere that wasn\\'t school,his cupboard, or Mrs. Figg\\'s cabbage-smelling living room.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 18}), Document(page_content='19While he drove, Uncle Vernon complained to Aunt Petunia. He liked to\\ncomplain about things: people at work, Harry, the council, Harry, thebank, and Harry were just a few of his favorite subjects. This morning,it was motorcycles.\\n\"... roaring along like maniacs, the young hoodlums,\" he said, as a\\nmotorcycle overtook them.\\nI had a dream about a motorcycle,\" said Harry, remembering suddenly. \"It\\nwas flying.\"\\nUncle Vernon nearly crashed into the car in front. He turned right\\naround in his seat and yelled at Harry, his face like a gigantic beet\\nwith a mustache: \"MOTORCYCLES DON\\'T FLY!\"\\nDudley and Piers sniggered.I know they don\\'t,\" said Harry. \"It was only a dream.\"\\nBut he wished he hadn\\'t said anything. If there was one thing the\\nDursleys hated even more than his asking questions, it was his talkingabout anything acting in a way it shouldn\\'t, no matter if it was in adream or even a cartoon -- they seemed to think he might get dangerousideas.\\nIt was a very sunny Saturday and the zoo was crowded with families. The\\nDursleys bought Dudley and Piers large chocolate ice creams at the\\nentrance and then, because the smiling lady in the van had asked Harrywhat he wanted before they could hurry him away, they bought him a cheaplemon ice pop. It wasn\\'t bad, either, Harry thought, licking it as theywatched a gorilla scratching its head who looked remarkably like Dudley,except that it wasn\\'t blond.\\nHarry had the best morning he\\'d had in a long time. He was careful to\\nwalk a little way apart from the Dursleys so that Dudley and Piers, whowere starting to get bored with the animals by lunchtime, wouldn\\'t fallback on their favorite hobby of hitting him. They ate in the zoorestaurant, and when Dudley had a tantrum because his knickerbockerglory didn\\'t have enough ice cream on top, Uncle Vernon bought him\\nanother one and Harry was allowed to finish the first.\\nHarry felt, afterward, that he should have known it was all too good to\\nlast.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 19}), Document(page_content='20After lunch they went to the reptile house. It was cool and dark in\\nthere, with lit windows all along the walls. Behind the glass, all sortsof lizards and snakes were crawling and slithering over bits of wood andstone. Dudley and Piers wanted to see huge, poisonous cobras and thick,man-crushing pythons. Dudley quickly found the largest snake in the\\nplace. It could have wrapped its body twice around Uncle Vernon\\'s car\\nand crushed it into a trash can -- but at the moment it didn\\'t look inthe mood. In fact, it was fast asleep.\\nDudley stood with his nose pressed against the glass, staring at the\\nglistening brown coils.\\n\"Make it move,\" he whined at his father. Uncle Vernon tapped on the\\nglass, but the snake didn\\'t budge.\\n\"Do it again,\" Dudley ordered. Uncle Vernon rapped the glass smartly\\nwith his knuckles, but the snake just snoozed on.\\n\"This is boring,\" Dudley moaned. He shuffled away.\\nHarry moved in front of the tank and looked intently at the snake. He\\nwouldn\\'t have been surprised if it had died of boredom itself -- nocompany except stupid people drumming their fingers on the glass tryingto disturb it all day long. It was worse than having a cupboard as abedroom, where the only visitor was Aunt Petunia hammering on the door\\nto wake you up; at least he got to visit the rest of the house.\\nThe snake suddenly opened its beady eyes. Slowly, very slowly, it raised\\nits head until its eyes were on a level with Harry\\'s.\\nIt winked.\\nHarry stared. Then he looked quickly around to see if anyone was\\nwatching. They weren\\'t. He looked back at the snake and winked, too.\\nThe snake jerked its head toward Uncle Vernon and Dudley, then raised\\nits eyes to the ceiling. It gave Harry a look that said quite plainly:\\n\"I get that all the time.\\n\"I know,\" Harry murmured through the glass, though he wasn\\'t sure the\\nsnake could hear him. \"It must be really annoying.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 20}), Document(page_content='21The snake nodded vigorously.\\n\"Where do you come from, anyway?\" Harry asked.The snake jabbed its tail at a little sign next to the glass. Harry\\npeered at it.\\nBoa Constrictor, Brazil.\"Was it nice there?\"The boa constrictor jabbed its tail at the sign again and Harry read on:\\nThis specimen was bred in the zoo. \"Oh, I see -- so you\\'ve never been to\\nBrazil?\"\\nAs the snake shook its head, a deafening shout behind Harry made both of\\nthem jump.\\n\"DUDLEY! MR. DURSLEY! COME AND LOOK AT THIS SNAKE! YOU\\nWON\\'T BELIEVEWHAT IT\\'S DOING!\"\\nDudley came waddling toward them as fast as he could.\"Out of the way, you,\" he said, punching Harry in the ribs. Caught by\\nsurprise, Harry fell hard on the concrete floor. What came next happened\\nso fast no one saw how it happened -- one second, Piers and Dudley wereleaning right up close to the glass, the next, they had leapt back withhowls of horror.\\nHarry sat up and gasped; the glass front of the boa constrictor\\'s tank\\nhad vanished. The great snake was uncoiling itself rapidly, slithering\\nout onto the floor. People throughout the reptile house screamed andstarted running for the exits.\\nAs the snake slid swiftly past him, Harry could have sworn a low,\\nhissing voice said, \"Brazil, here I come.... Thanksss, amigo.\"\\nThe keeper of the reptile house was in shock.\\n\"But the glass,\" he kept saying, \"where did the glass go?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 21}), Document(page_content='22The zoo director himself made Aunt Petunia a cup of strong, sweet tea\\nwhile he apologized over and over again. Piers and Dudley could onlygibber. As far as Harry had seen, the snake hadn\\'t done anything exceptsnap playfully at their heels as it passed, but by the time they wereall back in Uncle Vernon\\'s car, Dudley was telling them how it hadnearly bitten off his leg, while Piers was swearing it had tried to\\nsqueeze him to death. But worst of all, for Harry at least, was Piers\\ncalming down enough to say, \"Harry was talking to it, weren\\'t you,Harry?\"\\nUncle Vernon waited until Piers was safely out of the house before\\nstarting on Harry. He was so angry he could hardly speak. He managed tosay, \"Go -- cupboard -- stay -- no meals,\" before he collapsed into a\\nchair, and Aunt Petunia had to run and get him a large brandy.\\nHarry lay in his dark cupboard much later, wishing he had a watch. He\\ndidn\\'t know what time it was and he couldn\\'t be sure the Dursleys wereasleep yet. Until they were, he couldn\\'t risk sneaking to the kitchenfor some food.\\nHe\\'d lived with the Dursleys almost ten years, ten miserable years, as\\nlong as he could remember, ever since he\\'d been a baby and his parentshad died in that car crash. He couldn\\'t remember being in the car whenhis parents had died. Sometimes, when he strained his memory during longhours in his cupboard, he came up with a strange vision: a blindingflash of green light and a burn- ing pain on his forehead. This, he\\nsupposed, was the crash, though he couldn\\'t imagine where all the green\\nlight came from. He couldn\\'t remember his parents at all. His aunt anduncle never spoke about them, and of course he was forbidden to askquestions. There were no photographs of them in the house.\\nWhen he had been younger, Harry had dreamed and dreamed of some unknown\\nrelation coming to take him away, but it had never happened; the\\nDursleys were his only family. Yet sometimes he thought (or maybe hoped)that strangers in the street seemed to know him. Very strange strangersthey were, too. A tiny man in a violet top hat had bowed to him oncewhile out shopping with Aunt Petunia and Dudley. After asking Harryfuriously if he knew the man, Aunt Petunia had rushed them out of theshop without buying anything. A wild-looking old woman dressed all in\\ngreen had waved merrily at him once on a bus. A bald man in a very long\\npurple coat had actually shaken his hand in the street the other day andthen walked away without a word. The weirdest thing about all thesepeople was the way they seemed to vanish the second Harry tried to get a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 22}), Document(page_content='23closer look.\\nAt school, Harry had no one. Everybody knew that Dudley\\'s gang hated\\nthat odd Harry Potter in his baggy old clothes and broken glasses, andnobody liked to disagree with Dudley\\'s gang.\\nCHAPTER THREE\\nTHE LETTERS FROM NO ONEThe escape of the Brazilian boa constrictor earned Harry his\\nlongest-ever punishment. By the time he was allowed out of his cupboard\\nagain, the summer holidays had started and Dudley had already broken his\\nnew video camera, crashed his remote control airplane, and, first timeout on his racing bike, knocked down old Mrs. Figg as she crossed PrivetDrive on her crutches.\\nHarry was glad school was over, but there was no escaping Dudley\\'s gang,\\nwho visited the house every single day. Piers, Dennis, Malcolm, and\\nGordon were all big and stupid, but as Dudley was the biggest andstupidest of the lot, he was the leader. The rest of them were all quitehappy to join in Dudley\\'s favorite sport: Harry Hunting.\\nThis was why Harry spent as much time as possible out of the house,\\nwandering around and thinking about the end of the holidays, where he\\ncould see a tiny ray of hope. When September came he would be going off\\nto secondary school and, for the first time in his life, he wouldn\\'t bewith Dudley. Dudley had been accepted at Uncle Vernon\\'s old privateschool, Smeltings. Piers Polkiss was going there too. Harry, on theother hand, was going to Stonewall High, the local public school. Dudleythought this was very funny.\\n\"They stuff people\\'s heads down the toilet the first day at Stonewall,\"\\nhe told Harry. \"Want to come upstairs and practice?\"\\n\"No, thanks,\" said Harry. \"The poor toilet\\'s never had anything as\\nhorrible as your head down it -- it might be sick.\" Then he ran, beforeDudley could work out what he\\'d said.\\nOne day in July, Aunt Petunia took Dudley to London to buy his Smeltings\\nuniform, leaving Harry at Mrs. Figg\\'s. Mrs. Figg wasn \\'t as bad asusual. It turned out she\\'d broken her leg tripping over one of her cats,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 23}), Document(page_content='24and she didn\\'t seem quite as fond of them as before. She let Harry watch\\ntelevision and gave him a bit of chocolate cake that tasted as thoughshe\\'d had it for several years.\\nThat evening, Dudley paraded around the living room for the family in\\nhis brand-new uniform. Smeltings\\' boys wore maroon tailcoats, orange\\nknickerbockers, and flat straw hats called boaters. They also carried\\nknobbly sticks, used for hitting each other while the teachers weren\\'tlooking. This was supposed to be good training for later life.\\nAs he looked at Dudley in his new knickerbockers, Uncle Vernon said\\ngruffly that it was the proudest moment of his life. Aunt Petunia burstinto tears and said she couldn\\'t believe it was her Ickle Dudleykins, he\\nlooked so handsome and grown-up. Harry didn\\'t trust himself to speak. He\\nthought two of his ribs might already have cracked from trying not tolaugh.\\nThere was a horrible smell in the kitchen the next morning when Harry\\nwent in for breakfast. It seemed to be coming from a large metal tub in\\nthe sink. He went to have a look. The tub was full of what looked like\\ndirty rags swimming in gray water.\\n\"What\\'s this?\" he asked Aunt Petunia. Her lips tightened as they always\\ndid if he dared to ask a question.\\n\"Your new school uniform,\" she said.\\nHarry looked in the bowl again.\\n\"Oh,\" he said, \"I didn\\'t realize it had to be so wet.\"\"DotA be stupid,\" snapped Aunt Petunia. \"I\\'m dyeing some of Dudley\\'s old\\nthings gray for you. It\\'ll look just like everyone else\\'s when I\\'ve\\nfinished.\"\\nHarry seriously doubted this, but thought it best not to argue. He sat\\ndown at the table and tried not to think about how he was going to lookon his first day at Stonewall High -- like he was wearing bits of oldelephant skin, probably.\\nDudley and Uncle Vernon came in, both with wrinkled noses because of the\\nsmell from Harry\\'s new uniform. Uncle Vernon opened his newspaper asusual and Dudley banged his Smelting stick, which he carried everywhere,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 24}), Document(page_content='25on the table.\\nThey heard the click of the mail slot and flop of letters on the\\ndoormat.\\n\"Get the mail, Dudley,\" said Uncle Vernon from behind his paper.\\n\"Make Harry get it.\"\\n\"Get the mail, Harry.\"\"Make Dudley get it.\"\\n\"Poke him with your Smelting stick, Dudley.\"\\nHarry dodged the Smelting stick and went to get the mail. Three things\\nlay on the doormat: a postcard from Uncle Vernon\\'s sister Marge, who wasvacationing on the Isle of Wight, a brown envelope that looked like abill, and -- a letter for Harry.\\nHarry picked it up and stared at it, his heart twanging like a giant\\nelastic band. No one, ever, in his whole life, had written to him. Whowould? He had no friends, no other relatives -- he didn\\'t belong to thelibrary, so he\\'d never even got rude notes asking for books back. Yethere it was, a letter, addressed so plainly there could be no mistake:\\nMr. H. Potter\\nThe Cupboard under the Stairs4 Privet Drive\\nLittle Whinging\\nSurreyThe envelope was thick and heavy, made of yellowish parchment, and the\\naddress was written in emerald-green ink. There was no stamp.\\nTurning the envelope over, his hand trembling, Harry saw a purple wax\\nseal bearing a coat of arms; a lion, an eagle, a badger, and a snakesurrounding a large letter H.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 25}), Document(page_content='26\"Hurry up, boy!\" shouted Uncle Vernon from the kitchen. \"What are you\\ndoing, checking for letter bombs?\" He chuckled at his own joke.\\nHarry went back to the kitchen, still staring at his letter. He handed\\nUncle Vernon the bill and the postcard, sat down, and slowly began toopen the yellow envelope.\\nUncle Vernon ripped open the bill, snorted in disgust, and flipped over\\nthe postcard.\\n\"Marge\\'s ill,\" he informed Aunt Petunia. \"Ate a funny whelk. --.\"\"Dad!\" said Dudley suddenly. \"Dad, Harry\\'s got something!\"\\nHarry was on the point of unfolding his letter, which was written on the\\nsame heavy parchment as the envelope, when it was jerked sharply out ofhis hand by Uncle Vernon.\\n\"That\\'s mine!\" said Harry, trying to snatch it back.\\n\"Who\\'d be writing to you?\" sneered Uncle Vernon, shaking the letter open\\nwith one hand and glancing at it. His face went from red to green fasterthan a set of traffic lights. And it didn\\'t stop there. Within secondsit was the grayish white of old porridge.\\n\"P-P-Petunia!\" he gasped.\\nDudley tried to grab the letter to read it, but Uncle Vernon held it\\nhigh out of his reach. Aunt Petunia took it curiously and read the firstline. For a moment it looked as though she might faint. She clutched herthroat and made a choking noise.\\n\"Vernon! Oh my goodness -- Vernon!\"\\nThey stared at each other, seeming to have forgotten that Harry and\\nDudley were still in the room. Dudley wasn\\'t used to being ignored. Hegave his father a sharp tap on the head with his Smelting stick.\\n\"I want to read that letter,\" he said loudly. want to read it,\" said\\nHarry furiously, \"as it\\'s mine.\"\\n\"Get out, both of you,\" croaked Uncle Vernon, stuffing the letter back\\ninside its envelope.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 26}), Document(page_content='27Harry didn\\'t move.\\nI WANT MY LETTER!\" he shouted.\"Let me see it!\" demanded Dudley.\\n\"OUT!\" roared Uncle Vernon, and he took both Harry and Dudley by the\\nscruffs of their necks and threw them into the hall, slamming thekitchen door behind them. Harry and Dudley promptly had a furious butsilent fight over who would listen at the keyhole; Dudley won, so Harry,his glasses dangling from one ear, lay flat on his stomach to listen atthe crack between door and floor.\\n\"Vernon,\" Aunt Petunia was saying in a quivering voice, \"look at the\\naddress -- how could they possibly know where he sleeps? You don\\'t thinkthey\\'re watching the house?\"\\n\"Watching -- spying -- might be following us,\" muttered Uncle Vernon\\nwildly.\\n\"But what should we do, Vernon? Should we write back? Tell them we don\\'t\\nwant --\"\\nHarry could see Uncle Vernon\\'s shiny black shoes pacing up and down the\\nkitchen.\\n\"No,\" he said finally. \"No, we\\'ll ignore it. If they don\\'t get an\\nanswer... Yes, that\\'s best... we won\\'t do anything....\\n\"But --\"\\n\"I\\'m not having one in the house, Petunia! Didn\\'t we swear when we took\\nhim in we\\'d stamp out that dangerous nonsense?\"\\nThat evening when he got back from work, Uncle Vernon did something he\\'d\\nnever done before; he visited Harry in his cupboard.\\n\"Where\\'s my letter?\" said Harry, the moment Uncle Vernon had squeezed\\nthrough the door. \"Who\\'s writing to me?\"\\n\"No one. it was addressed to you by mistake,\" said Uncle Vernon shortly.\\n\"I have burned it.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 27}), Document(page_content='28\"It was not a mistake,\" said Harry angrily, \"it had my cupboard on it.\"\\n\"SILENCE!\" yelled Uncle Vernon, and a couple of spiders fell from the\\nceiling. He took a few deep breaths and then forced his face into asmile, which looked quite painful.\\n\"Er -- yes, Harry -- about this cupboard. Your aunt and I have been\\nthinking... you\\'re really getting a bit big for it... we think it mightbe nice if you moved into Dudley\\'s second bedroom.\\n\"Why?\" said Harry.\\n\"Don\\'t ask questions!\" snapped his uncle. \"Take this stuff upstairs,\\nnow.\"\\nThe Dursleys\\' house had four bedrooms: one for Uncle Vernon and Aunt\\nPetunia, one for visitors (usually Uncle Vernon\\'s sister, Marge), onewhere Dudley slept, and one where Dudley kept all the toys and things\\nthat wouldn\\'t fit into his first bedroom. It only took Harry one trip\\nupstairs to move everything he owned from the cupboard to this room. Hesat down on the bed and stared around him. Nearly everything in here wasbroken. The month-old video camera was lying on top of a small, workingtank Dudley had once driven over the next door neighbor\\'s dog; in thecorner was Dudley\\'s first-ever television set, which he\\'d put his footthrough when his favorite program had been canceled; there was a large\\nbirdcage, which had once held a parrot that Dudley had swapped at school\\nfor a real air rifle, which was up on a shelf with the end all bentbecause Dudley had sat on it. Other shelves were full of books. Theywere the only things in the room that looked as though they\\'d never beentouched.\\nFrom downstairs came the sound of Dudley bawling at his mother, I don\\'t\\nwant him in there... I need that room... make him get out....\"\\nHarry sighed and stretched out on the bed. Yesterday he\\'d have given\\nanything to be up here. Today he\\'d rather be back in his cupboard withthat letter than up here without it.\\nNext morning at breakfast, everyone was rather quiet. Dudley was in\\nshock. He\\'d screamed, whacked his father with his Smelting stick, beensick on purpose, kicked his mother, and thrown his tortoise through thegreenhouse roof, and he still didn\\'t have his room back. Harry was', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 28}), Document(page_content='29thinking about this time yesterday and bitterly wishing he\\'d opened the\\nletter in the hall. Uncle Vernon and Aunt Petunia kept looking at eachother darkly.\\nWhen the mail arrived, Uncle Vernon, who seemed to be trying to be nice\\nto Harry, made Dudley go and get it. They heard him banging things with\\nhis Smelting stick all the way down the hall. Then he shouted, \"There\\'s\\nanother one! \\'Mr. H. Potter, The Smallest Bedroom, 4 Privet Drive --\\'\"\\nWith a strangled cry, Uncle Vernon leapt from his seat and ran down the\\nhall, Harry right behind him. Uncle Vernon had to wrestle Dudley to theground to get the letter from him, which was made difficult by the factthat Harry had grabbed Uncle Vernon around the neck from behind. After a\\nminute of confused fighting, in which everyone got hit a lot by the\\nSmelting stick, Uncle Vernon straightened up, gasping for breath, withHarry\\'s letter clutched in his hand.\\n\"Go to your cupboard -- I mean, your bedroom,\" he wheezed at Harry.\\n\"Dudley -- go -- just go.\"\\nHarry walked round and round his new room. Someone knew he had moved out\\nof his cupboard and they seemed to know he hadn\\'t received his firstletter. Surely that meant they\\'d try again? And this time he\\'d make surethey didn\\'t fail. He had a plan.\\nThe repaired alarm clock rang at six o\\'clock the next morning. Harry\\nturned it off quickly and dressed silently. He mustn\\'t wake the\\nDursleys. He stole downstairs without turning on any of the lights.\\nHe was going to wait for the postman on the corner of Privet Drive and\\nget the letters for number four first. His heart hammered as he creptacross the dark hall toward the front door --\\nHarry leapt into the air; he\\'d trodden on something big and squashy on\\nthe doormat -- something alive!\\nLights clicked on upstairs and to his horror Harry realized that the\\nbig, squashy something had been his uncle\\'s face. Uncle Vernon had beenlying at the foot of the front door in a sleeping bag, clearly making\\nsure that Harry didn\\'t do exactly what he\\'d been trying to do. He\\nshouted at Harry for about half an hour and then told him to go and makea cup of tea. Harry shuffled miserably off into the kitchen and by thetime he got back, the mail had arrived, right into Uncle Vernon\\'s lap.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 29}), Document(page_content='30Harry could see three letters addressed in green ink.\\nI want --\" he began, but Uncle Vernon was tearing the letters into\\npieces before his eyes. Uncle Vernon didnt go to work that day. Hestayed at home and nailed up the mail slot.\\n\"See,\" he explained to Aunt Petunia through a mouthful of nails, \"if\\nthey can\\'t deliver them they\\'ll just give up.\"\\n\"I\\'m not sure that\\'ll work, Vernon.\"\"Oh, these people\\'s minds work in strange ways, Petunia, they\\'re not\\nlike you and me,\" said Uncle Vernon, trying to knock in a nail with the\\npiece of fruitcake Aunt Petunia had just brought him.\\nOn Friday, no less than twelve letters arrived for Harry. As they\\ncouldn\\'t go through the mail slot they had been pushed under the door,slotted through the sides, and a few even forced through the smallwindow in the downstairs bathroom.\\nUncle Vernon stayed at home again. After burning all the letters, he got\\nout a hammer and nails and boarded up the cracks around the front andback doors so no one could go out. He hummed \"Tiptoe Through the Tulips\"as he worked, and jumped at small noises.\\nOn Saturday, things began to get out of hand. Twenty-four letters to\\nHarry found their way into the house, rolled up and hidden inside each\\nof the two dozen eggs that their very confused milkman had handed AuntPetunia through the living room window. While Uncle Vernon made furioustelephone calls to the post office and the dairy trying to find someoneto complain to, Aunt Petunia shredded the letters in her food processor.\\n\"Who on earth wants to talk to you this badly?\" Dudley asked Harry in\\namazement.\\nOn Sunday morning, Uncle Vernon sat down at the breakfast table looking\\ntired and rather ill, but happy.\\n\"No post on Sundays,\" he reminded them cheerfully as he spread marmalade\\non his newspapers, \"no damn letters today --\"\\nSomething came whizzing down the kitchen chimney as he spoke and caught\\nhim sharply on the back of the head. Next moment, thirty or forty', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 30}), Document(page_content='31letters came pelting out of the fireplace like bullets. The Dursleys\\nducked, but Harry leapt into the air trying to catch one.\\n\"Out! OUT!\"Uncle Vernon seized Harry around the waist and threw him into the hall.\\nWhen Aunt Petunia and Dudley had run out with their arms over their\\nfaces, Uncle Vernon slammed the door shut. They could hear the lettersstill streaming into the room, bouncing off the walls and floor.\\n\"That does it,\" said Uncle Vernon, trying to speak calmly but pulling\\ngreat tufts out of his mustache at the same time. I want you all backhere in five minutes ready to leave. We\\'re going away. Just pack some\\nclothes. No arguments!\"\\nHe looked so dangerous with half his mustache missing that no one dared\\nargue. Ten minutes later they had wrenched their way through theboarded-up doors and were in the car, speeding toward the highway.Dudley was sniffling in the back seat; his father had hit him round the\\nhead for holding them up while he tried to pack his television, VCR, and\\ncomputer in his sports bag.\\nThey drove. And they drove. Even Aunt Petunia didn\\'t dare ask where they\\nwere going. Every now and then Uncle Vernon would take a sharp turn anddrive in the opposite direction for a while. \"Shake\\'em off... shake \\'emoff,\" he would mutter whenever he did this.\\nThey didn\\'t stop to eat or drink all day. By nightfall Dudley was\\nhowling. He\\'d never had such a bad day in his life. He was hungry, he\\'dmissed five television programs he\\'d wanted to see, and he\\'d never goneso long without blowing up an alien on his computer.\\nUncle Vernon stopped at last outside a gloomy-looking hotel on the\\noutskirts of a big city. Dudley and Harry shared a room with twin bedsand damp, musty sheets. Dudley snored but Harry stayed awake, sitting onthe windowsill, staring down at the lights of passing cars andwondering....\\nThey ate stale cornflakes and cold tinned tomatoes on toast for\\nbreakfast the next day. They had just finished when the owner of the\\nhotel came over to their table.\\n\"\\'Scuse me, but is one of you Mr. H. Potter? Only I got about an \\'undred', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 31}), Document(page_content='32of these at the front desk.\"\\nShe held up a letter so they could read the green ink address:Mr. H. Potter\\nRoom 17\\nRailview HotelCokeworthHarry made a grab for the letter but Uncle Vernon knocked his hand out\\nof the way. The woman stared.\\n\"I\\'ll take them,\" said Uncle Vernon, standing up quickly and following\\nher from the dining room.\\nWouldn\\'t it be better just to go home, dear?\" Aunt Petunia suggested\\ntimidly, hours later, but Uncle Vernon didn\\'t seem to hear her. Exactly\\nwhat he was looking for, none of them knew. He drove them into themiddle of a forest, got out, looked around, shook his head, got back inthe car, and off they went again. The same thing happened in the middleof a plowed field, halfway across a suspension bridge, and at the top ofa multilevel parking garage.\\n\"Daddy\\'s gone mad, hasn\\'t he?\" Dudley asked Aunt Petunia dully late that\\nafternoon. Uncle Vernon had parked at the coast, locked them all insidethe car, and disappeared.\\nIt started to rain. Great drops beat on the roof of the car. Dud ley\\nsniveled.\\n\"It\\'s Monday,\" he told his mother. \"The Great Humberto\\'s on tonight. I\\nwant to stay somewhere with a television. \"\\nMonday. This reminded Harry of something. If it was Monday -- and you\\ncould usually count on Dudley to know the days the week, because oftelevision -- then tomorrow, Tuesday, was Harry\\'s eleventh birthday. Of\\ncourse, his birthdays were never exactly fun -- last year, the Dursleys\\nhad given him a coat hanger and a pair of Uncle Vernon\\'s old socks.Still, you weren\\'t eleven every day.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 32}), Document(page_content='33Uncle Vernon was back and he was smiling. He was also carrying a long,\\nthin package and didn\\'t answer Aunt Petunia when she asked what he\\'dbought.\\n\"Found the perfect place!\" he said. \"Come on! Everyone out!\"\\nIt was very cold outside the car. Uncle Vernon was pointing at what\\nlooked like a large rock way out at sea. Perched on top of the rock wasthe most miserable little shack you could imagine. One thing wascertain, there was no television in there.\\n\"Storm forecast for tonight!\" said Uncle Vernon gleefully, clapping his\\nhands together. \"And this gentleman\\'s kindly agreed to lend us his\\nboat!\"\\nA toothless old man came ambling up to them, pointing, with a rather\\nwicked grin, at an old rowboat bobbing in the iron-gray water belowthem.\\n\"I\\'ve already got us some rations,\" said Uncle Vernon, \"so all aboard!\"\\nIt was freezing in the boat. Icy sea spray and rain crept down their\\nnecks and a chilly wind whipped their faces. After what seemed likehours they reached the rock, where Uncle Vernon, slipping and sliding,led the way to the broken-down house.\\nThe inside was horrible; it smelled strongly of seaweed, the wind\\nwhistled through the gaps in the wooden walls, and the fireplace wasdamp and empty. There were only two rooms.\\nUncle Vernon\\'s rations turned out to be a bag of chips each and four\\nbananas. He tried to start a fire but the empty chip bags just smoked\\nand shriveled up.\\n\"Could do with some of those letters now, eh?\" he said cheerfully.He was in a very good mood. Obviously he thought nobody stood a chance\\nof reaching them here in a storm to deliver mail. Harry privatelyagreed, though the thought didn\\'t cheer him up at all.\\nAs night fell, the promised storm blew up around them. Spray from the\\nhigh waves splattered the walls of the hut and a fierce wind rattled thefilthy windows. Aunt Petunia found a few moldy blankets in the second', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 33}), Document(page_content='34room and made up a bed for Dudley on the moth-eaten sofa. She and Uncle\\nVernon went off to the lumpy bed next door, and Harry was left to findthe softest bit of floor he could and to curl up under the thinnest,most ragged blanket.\\nThe storm raged more and more ferociously as the night went on. Harry\\ncouldn\\'t sleep. He shivered and turned over, trying to get comfortable,\\nhis stomach rumbling with hunger. Dudley\\'s snores were drowned by thelow rolls of thunder that started near midnight. The lighted dial ofDudley\\'s watch, which was dangling over the edge of the sofa on his fatwrist, told Harry he\\'d be eleven in ten minutes\\' time. He lay andwatched his birthday tick nearer, wondering if the Dursleys wouldremember at all, wondering where the letter writer was now.\\nFive minutes to go. Harry heard something creak outside. He hoped the\\nroof wasn\\'t going to fall in, although he might be warmer if it did.Four minutes to go. Maybe the house in Privet Drive would be so full ofletters when they got back that he\\'d be able to steal one somehow.\\nThree minutes to go. Was that the sea, slapping hard on the rock like\\nthat? And (two minutes to go) what was that funny crunching noise? Wasthe rock crumbling into the sea?\\nOne minute to go and he\\'d be eleven. Thirty seconds... twenty ... ten...\\nnine -- maybe he\\'d wake Dudley up, just to annoy him -- three... two...one...\\nBOOM.\\nThe whole shack shivered and Harry sat bolt upright, staring at the\\ndoor. Someone was outside, knocking to come in.\\nCHAPTER FOUR\\nTHE KEEPER OF THE KEYSBOOM. They knocked again. Dudley jerked awake. \"Where\\'s the cannon?\" he\\nsaid stupidly.\\nThere was a crash behind them and Uncle Vernon came skidding into the\\nroom. He was holding a rifle in his hands -- now they knew what had beenin the long, thin package he had brought with them.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 34}), Document(page_content='35\"Who\\'s there?\" he shouted. \"I warn you -- I\\'m armed!\"\\nThere was a pause. Then --SMASH!\\nThe door was hit with such force that it swung clean off its hinges and\\nwith a deafening crash landed flat on the floor.\\nA giant of a man was standing in the doorway. His face was almost\\ncompletely hidden by a long, shaggy mane of hair and a wild, tangledbeard, but you could make out his eyes, glinting like black beetles\\nunder all the hair.\\nThe giant squeezed his way into the hut, stooping so that his head just\\nbrushed the ceiling. He bent down, picked up the door, and fitted iteasily back into its frame. The noise of the storm outside dropped alittle. He turned to look at them all.\\n\"Couldn\\'t make us a cup o\\' tea, could yeh? It\\'s not been an easy\\njourney...\"\\nHe strode over to the sofa where Dudley sat frozen with fear.\"Budge up, yeh great lump,\" said the stranger.\\nDudley squeaked and ran to hide behind his mother, who was crouching,\\nterrified, behind Uncle Vernon.\\n\"An\\' here\\'s Harry!\" said the giant.\\nHarry looked up into the fierce, wild, shadowy face and saw that the\\nbeetle eyes were crinkled in a smile.\\n\"Las\\' time I saw you, you was only a baby,\" said the giant. \"Yeh look a\\nlot like yet dad, but yeh\\'ve got yet mom\\'s eyes.\"\\nUncle Vernon made a funny rasping noise.\\nI demand that you leave at once, sit!\" he said. \"You are breaking and\\nentering!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 35}), Document(page_content='36\"Ah, shut up, Dursley, yeh great prune,\" said the giant; he reached over\\nthe back of the sofa, jerked the gun out of Uncle Vernon\\'s hands, bentit into a knot as easily as if it had been made of rubber, and threw itinto a corner of the room.\\nUncle Vernon made another funny noise, like a mouse being trodden on.\\n\"Anyway -- Harry,\" said the giant, turning his back on the Dursleys, \"a\\nvery happy birthday to yeh. Got summat fer yeh here -- I mighta sat onit at some point, but it\\'ll taste all right.\"\\nFrom an inside pocket of his black overcoat he pulled a slightly\\nsquashed box. Harry opened it with trembling fingers. Inside was a\\nlarge, sticky chocolate cake with Happy Birthday Harry written on it in\\ngreen icing.\\nHarry looked up at the giant. He meant to say thank you, but the words\\ngot lost on the way to his mouth, and what he said instead was, \"Who areyou?\"\\nThe giant chuckled.\\n\"True, I haven\\'t introduced meself. Rubeus Hagrid, Keeper of Keys and\\nGrounds at Hogwarts.\"\\nHe held out an enormous hand and shook Harry\\'s whole arm.\\n\"What about that tea then, eh?\" he said, rubbing his hands together.\\n\"I\\'d not say no ter summat stronger if yeh\\'ve got it, mind.\"\\nHis eyes fell on the empty grate with the shriveled chip bags in it and\\nhe snorted. He bent down over the fireplace; they couldn\\'t see what he\\nwas doing but when he drew back a second later, there was a roaring fire\\nthere. It filled the whole damp hut with flickering light and Harry feltthe warmth wash over him as though he\\'d sunk into a hot bath.\\nThe giant sat back down on the sofa, which sagged under his weight, and\\nbegan taking all sorts of things out of the pockets of his coat: acopper kettle, a squashy package of sausages, a poker, a teapot, several\\nchipped mugs, and a bottle of some amber liquid that he took a swig from\\nbefore starting to make tea. Soon the hut was full of the sound andsmell of sizzling sausage. Nobody said a thing while the giant wasworking, but as he slid the first six fat, juicy, slightly burnt', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 36}), Document(page_content='37sausages from the poker, Dudley fidgeted a little. Uncle Vernon said\\nsharply, \"Don\\'t touch anything he gives you, Dudley.\"\\nThe giant chuckled darkly.\"Yet great puddin\\' of a son don\\' need fattenin\\' anymore, Dursley, don\\'\\nworry.\"\\nHe passed the sausages to Harry, who was so hungry he had never tasted\\nanything so wonderful, but he still couldn\\'t take his eyes off thegiant. Finally, as nobody seemed about to explain anything, he said,\"I\\'m sorry, but I still don\\'t really know who you are.\"\\nThe giant took a gulp of tea and wiped his mouth with the back of his\\nhand.\\n\"Call me Hagrid,\" he said, \"everyone does. An\\' like I told yeh, I\\'m\\nKeeper of Keys at Hogwarts -- yeh\\'ll know all about Hogwarts, o\\' course.\\n\"Er -- no,\" said Harry.\\nHagrid looked shocked.\"Sorry,\" Harry said quickly.\"Sony?\" barked Hagrid, turning to stare at the Dursleys, who shrank back\\ninto the shadows. \"It\\' s them as should be sorry! I knew yeh weren\\'t\\ngettin\\' yer letters but I never thought yeh wouldn\\'t even know abou\\'Hogwarts, fer cryin\\' out loud! Did yeh never wonder where yet parentslearned it all?\"\\n\"All what?\" asked Harry.\\n\"ALL WHAT?\" Hagrid thundered. \"Now wait jus\\' one second!\"\\nHe had leapt to his feet. In his anger he seemed to fill the whole hut.\\nThe Dursleys were cowering against the wall.\\n\"Do you mean ter tell me,\" he growled at the Dursleys, \"that this boy --\\nthis boy! -- knows nothin\\' abou\\' -- about ANYTHING?\"\\nHarry thought this was going a bit far. He had been to school, after\\nall, and his marks weren\\'t bad.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 37}), Document(page_content='38\"I know some things,\" he said. \"I can, you know, do math and stuff.\" But\\nHagrid simply waved his hand and said, \"About our world, I mean. Yourworld. My world. Yer parents\\' world.\"\\n\"What world?\"\\nHagrid looked as if he was about to explode.\\n\"DURSLEY!\" he boomed.Uncle Vernon, who had gone very pale, whispered something that sounded\\nlike \"Mimblewimble.\" Hagrid stared wildly at Harry.\\n\"But yeh must know about yet mom and dad,\" he said. \"I mean, they\\'re\\nfamous. You\\'re famous.\"\\n\"What? My -- my mom and dad weren\\'t famous, were they?\"\\n\"Yeh don\\' know... yeh don\\' know...\" Hagrid ran his fingers through his\\nhair, fixing Harry with a bewildered stare.\\n\"Yeh don\\' know what yeh are?\" he said finally.Uncle Vernon suddenly found his voice.\\n\"Stop!\" he commanded. \"Stop right there, sit! I forbid you to tell the\\nboy anything!\"\\nA braver man than Vernon Dursley would have quailed under the furious\\nlook Hagrid now gave him; when Hagrid spoke, his every syllable trembledwith rage.\\n\"You never told him? Never told him what was in the letter Dumbledore\\nleft fer him? I was there! I saw Dumbledore leave it, Dursley! An\\'you\\'ve kept it from him all these years?\"\\n\"Kept what from me?\" said Harry eagerly.\\n\"STOP! I FORBID YOU!\" yelled Uncle Vernon in panic.\\nAunt Petunia gave a gasp of horror.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 38}), Document(page_content='39\"Ah, go boil yet heads, both of yeh,\" said Hagrid. \"Harry -- yet a\\nwizard.\"\\nThere was silence inside the hut. Only the sea and the whistling wind\\ncould be heard.\\n\"-- a what?\" gasped Harry.\\n\"A wizard, o\\' course,\" said Hagrid, sitting back down on the sofa, which\\ngroaned and sank even lower, \"an\\' a thumpin\\' good\\'un, I\\'d say, onceyeh\\'ve been trained up a bit. With a mum an\\' dad like yours, what elsewould yeh be? An\\' I reckon it\\'s abou\\' time yeh read yer letter.\"\\nHarry stretched out his hand at last to take the yellowish envelope,\\naddressed in emerald green to Mr. H. Potter, The Floor, Hut-on-the-Rock,The Sea. He pulled out the letter and read:\\nHOGWARTS SCHOOL of WITCHCRAFT and WIZARDRY\\nHeadmaster: ALBUS DUMBLEDORE\\n(Order of Merlin, First Class, Grand Sorc., Chf. Warlock, Supreme\\nMugwump, International Confed. of Wizards)\\nDear Mr. Potter,\\nWe are pleased to inform you that you have been accepted at Hogwarts\\nSchool of Witchcraft and Wizardry. Please find enclosed a list of allnecessary books and equipment.\\nTerm begins on September 1. We await your owl by no later than July 31.\\nYours sincerely,\\nMinerva McGonagall,\\nDeputy HeadmistressQuestions exploded inside Harry\\'s head like fireworks and he couldn\\'t\\ndecide which to ask first. After a few minutes he stammered, \"What does\\nit mean, they await my owl?\"\\n\"Gallopin\\' Gorgons, that reminds me,\" said Hagrid, clapping a hand to\\nhis forehead with enough force to knock over a cart horse, and from yet', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 39}), Document(page_content='40another pocket inside his overcoat he pulled an owl -- a real, live,\\nrather ruffled-looking owl -- a long quill, and a roll of parchment.With his tongue between his teeth he scribbled a note that Harry couldread upside down:\\nDear Professor Dumbledore,\\nGiven Harry his letter.\\nTaking him to buy his things tomorrow.Weather\\'s horrible. Hope you\\'re Well.\\nHagrid\\nHagrid rolled up the note, gave it to the owl, which clamped it in its\\nbeak, went to the door, and threw the owl out into the storm. Then hecame back and sat down as though this was as normal as talking on thetelephone.\\nHarry realized his mouth was open and closed it quickly.\\n\"Where was I?\" said Hagrid, but at that moment, Uncle Vernon, still\\nashen-faced but looking very angry, moved into the firelight.\\n\"He\\'s not going,\" he said.\\nHagrid grunted.\\n\"I\\'d like ter see a great Muggle like you stop him,\" he said.\"A what?\" said Harry, interested.\\n\"A Muggle,\" said Hagrid, \"it\\'s what we call nonmagic folk like thern.\\nAn\\' it\\'s your bad luck you grew up in a family o\\' the biggest Muggles Iever laid eyes on.\"\\n\"We swore when we took him in we\\'d put a stop to that rubbish,\" said\\nUncle Vernon, \"swore we\\'d stamp it out of him! Wizard indeed!\"\\n\"You knew?\" said Harry. \"You knew I\\'m a -- a wizard?\"\\n\"Knew!\" shrieked Aunt Petunia suddenly. \"Knew! Of course we knew! How', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 40}), Document(page_content='41could you not be, my dratted sister being what she was? Oh, she got a\\nletter just like that and disappeared off to that-that school-and camehome every vacation with her pockets full of frog spawn, turning teacupsinto rats. I was the only one who saw her for what she was -- a freak!But for my mother and father, oh no, it was Lily this and Lily that,they were proud of having a witch in the family!\"\\nShe stopped to draw a deep breath and then went ranting on. It seemed\\nshe had been wanting to say all this for years.\\n\"Then she met that Potter at school and they left and got married and\\nhad you, and of course I knew you\\'d be just the same, just as strange,just as -- as -- abnormal -- and then, if you please, she went and got\\nherself blown up and we got landed with you!\"\\nHarry had gone very white. As soon as he found his voice he said, \"Blown\\nup? You told me they died in a car crash!\"\\n\"CAR CRASH!\" roared Hagrid, jumping up so angrily that the Dursleys\\nscuttled back to their corner. \"How could a car crash kill Lily an\\'\\nJames Potter? It\\'s an outrage! A scandal! Harry Potter not knowin\\' hisown story when every kid in our world knows his name!\" \"But why? Whathappened?\" Harry asked urgently.\\nThe anger faded from Hagrid\\'s face. He looked suddenly anxious.\\n\"I never expected this,\" he said, in a low, worried voice. \"I had no\\nidea, when Dumbledore told me there might be trouble gettin\\' hold ofyeh, how much yeh didn\\'t know. Ah, Harry, I don\\' know if I\\'m the rightperson ter tell yeh -- but someone 3 s gotta -- yeh can\\'t go off terHogwarts not knowin\\'.\"\\nHe threw a dirty look at the Dursleys.\\n\"Well, it\\'s best yeh know as much as I can tell yeh -- mind, I can\\'t\\ntell yeh everythin\\', it\\'s a great myst\\'ry, parts of it....\"\\nHe sat down, stared into the fire for a few seconds, and then said, \"It\\nbegins, I suppose, with -- with a person called -- but it\\'s incredible\\nyeh don\\'t know his name, everyone in our world knows --\"\\n\"Who? \"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 41}), Document(page_content='42\"Well -- I don\\' like sayin\\' the name if I can help it. No one does.\"\\n\"Why not?\"\"Gulpin\\' gargoyles, Harry, people are still scared. Blimey, this is\\ndifficult. See, there was this wizard who went... bad. As bad as you\\ncould go. Worse. Worse than worse. His name was...\"\\nHagrid gulped, but no words came out.\"Could you write it down?\" Harry suggested.\"Nah -can\\'t spell it. All right -- Voldemort. \" Hagrid shuddered. \"Don\\'\\nmake me say it again. Anyway, this -- this wizard, about twenty years\\nago now, started lookin\\' fer followers. Got \\'em, too -- some wereafraid, some just wanted a bit o\\' his power, \\'cause he was gettin\\'himself power, all right. Dark days, Harry. Didn\\'t know who ter trust,didn\\'t dare get friendly with strange wizards or witches... terriblethings happened. He was takin\\' over. \\'Course, some stood up to him --\\nan\\' he killed \\'em. Horribly. One o\\' the only safe places left was\\nHogwarts. Reckon Dumbledore\\'s the only one You-Know-Who was afraid of.Didn\\'t dare try takin\\' the school, not jus\\' then, anyway.\\n\"Now, yer mum an\\' dad were as good a witch an\\' wizard as I ever knew.\\nHead boy an\\' girl at Hogwarts in their day! Suppose the myst\\'ry is whyYou-Know-Who never tried to get \\'em on his side before... probably knew\\nthey were too close ter Dumbledore ter want anythin\\' ter do with the\\nDark Side.\\n\"Maybe he thought he could persuade \\'em... maybe he just wanted \\'em\\noutta the way. All anyone knows is, he turned up in the village whereyou was all living, on Halloween ten years ago. You was just a year old.\\nHe came ter yer house an\\' -- an\\' --\"\\nHagrid suddenly pulled out a very dirty, spotted handkerchief and blew\\nhis nose with a sound like a foghorn.\\n\"Sorry,\" he said. \"But it\\'s that sad -- knew yer mum an\\' dad, an\\' nicer\\npeople yeh couldn\\'t find -- anyway...\"\\n\"You-Know-Who killed \\'em. An\\' then -- an\\' this is the real myst\\'ry of\\nthe thing -- he tried to kill you, too. Wanted ter make a clean job ofit, I suppose, or maybe he just liked killin\\' by then. But he couldn\\'t', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 42}), Document(page_content='43do it. Never wondered how you got that mark on yer forehead? That was no\\nordinary cut. That\\'s what yeh get when a Powerful, evil curse touchesyeh -- took care of yer mum an\\' dad an\\' yer house, even -- but it didn\\'twork on you, an\\' that\\'s why yer famous, Harry. No one ever lived afterhe decided ter kill \\'em, no one except you, an\\' he\\'d killed some o\\' thebest witches an\\' wizards of the age -- the McKinnons, the Bones, the\\nPrewetts -- an\\' you was only a baby, an\\' you lived.\"\\nSomething very painful was going on in Harry\\'s mind. As Hagrid\\'s story\\ncame to a close, he saw again the blinding flash of green light, moreclearly than he had ever remembered it before -- and he rememberedsomething else, for the first time in his life: a high, cold, cruellaugh.\\nHagrid was watching him sadly.\\n\"Took yeh from the ruined house myself, on Dumbledore\\'s orders. Brought\\nyeh ter this lot...\"\\n\"Load of old tosh,\" said Uncle Vernon. Harry jumped; he had almost\\nforgotten that the Dursleys were there. Uncle Vernon certainly seemed tohave got back his courage. He was glaring at Hagrid and his fists wereclenched.\\n\"Now, you listen here, boy,\" he snarled, \"I accept there\\'s something\\nstrange about you, probably nothing a good beating wouldn\\'t have cured\\n-- and as for all this about your parents, well, they were weirdos, no\\ndenying it, and the world\\'s better off without them in my opinion --asked for all they got, getting mixed up with these wizarding types --just what I expected, always knew they\\'d come to a sticky end --\"\\nBut at that moment, Hagrid leapt from the sofa and drew a battered pink\\numbrella from inside his coat. Pointing this at Uncle Vernon like a\\nsword, he said, \"I\\'m warning you, Dursley -I\\'m warning you -- one moreword... \"\\nIn danger of being speared on the end of an umbrella by a bearded giant,\\nUncle Vernon\\'s courage failed again; he flattened himself against thewall and fell silent.\\n\"That\\'s better,\" said Hagrid, breathing heavily and sitting back down on\\nthe sofa, which this time sagged right down to the floor.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 43}), Document(page_content='44Harry, meanwhile, still had questions to ask, hundreds of them.\\n\"But what happened to Vol--, sorry -- I mean, You-Know-Who?\"\"Good question, Harry. Disappeared. Vanished. Same night he tried ter\\nkill you. Makes yeh even more famous. That\\'s the biggest myst\\'ry, see...\\nhe was gettin\\' more an\\' more powerful -- why\\'d he go?\\n\"Some say he died. Codswallop, in my opinion. Dunno if he had enough\\nhuman left in him to die. Some say he\\'s still out there, bidin\\' histime, like, but I don\\' believe it. People who was on his side came backter ours. Some of \\'em came outta kinda trances. Don~ reckon theycould\\'ve done if he was comin\\' back.\\n\"Most of us reckon he\\'s still out there somewhere but lost his powers.\\nToo weak to carry on. \\'Cause somethin\\' about you finished him, Harry.There was somethin\\' goin\\' on that night he hadn\\'t counted on -- I dunnowhat it was, no one does -- but somethin\\' about you stumped him, allright.\"\\nHagrid looked at Harry with warmth and respect blazing in his eyes, but\\nHarry, instead of feeling pleased and proud, felt quite sure there hadbeen a horrible mistake. A wizard? Him? How could he possibly be? He\\'dspent his life being clouted by Dudley, and bullied by Aunt Petunia andUncle Vernon; if he was really a wizard, why hadn\\'t they been turnedinto warty toads every time they\\'d tried to lock him in his cupboard? If\\nhe\\'d once defeated the greatest sorcerer in the world, how come Dudley\\nhad always been able to kick him around like a football?\\n\"Hagrid,\" he said quietly, \"I think you must have made a mistake. I\\ndon\\'t think I can be a wizard.\"\\nTo his surprise, Hagrid chuckled.\\n\"Not a wizard, eh? Never made things happen when you was scared or\\nangry?\"\\nHarry looked into the fire. Now he came to think about it... every odd\\nthing that had ever made his aunt and uncle furious with him had\\nhappened when he, Harry, had been upset or angry... chased by Dudley\\'s\\ngang, he had somehow found himself out of their reach... dreading goingto school with that ridiculous haircut, he\\'d managed to make it growback... and the very last time Dudley had hit him, hadn\\'t he got his', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 44}), Document(page_content='45revenge, without even realizing he was doing it? Hadn\\'t he set a boa\\nconstrictor on him?\\nHarry looked back at Hagrid, smiling, and saw that Hagrid was positively\\nbeaming at him.\\n\"See?\" said Hagrid. \"Harry Potter, not a wizard -- you wait, you\\'ll be\\nright famous at Hogwarts.\"\\nBut Uncle Vernon wasn\\'t going to give in without a fight.\"Haven\\'t I told you he\\'s not going?\" he hissed. \"He\\'s going to Stonewall\\nHigh and he\\'ll be grateful for it. I\\'ve read those letters and he needs\\nall sorts of rubbish -- spell books and wands and --\"\\n\"If he wants ter go, a great Muggle like you won\\'t stop him,\" growled\\nHagrid. \"Stop Lily an\\' James Potter\\' s son goin\\' ter Hogwarts! Yer mad.His name\\'s been down ever since he was born. He\\'s off ter the finestschool of witchcraft and wizardry in the world. Seven years there and he\\nwon\\'t know himself. He\\'ll be with youngsters of his own sort, fer a\\nchange, an\\' he\\'ll be under the greatest headmaster Hogwarts ever hadAlbus Dumbled--\"\\n\"I AM NOT PAYING FOR SOME CRACKPOT OLD FOOL To TEACH HIM\\nMAGIC TRICKS!\"yelled Uncle Vernon.\\nBut he had finally gone too far. Hagrid seized his umbrella and whirled\\nit over his head, \"NEVER,\" he thundered, \"- INSULT- ALBUS- DUMBLEDORE-IN- FRONT- OF- ME!\"\\nHe brought the umbrella swishing down through the air to point at Dudley\\n-- there was a flash of violet light, a sound like a firecracker, a\\nsharp squeal, and the next second, Dudley was dancing on the spot withhis hands clasped over his fat bottom, howling in pain. When he turnedhis back on them, Harry saw a curly pig\\'s tail poking through a hole inhis trousers.\\nUncle Vernon roared. Pulling Aunt Petunia and Dudley into the other\\nroom, he cast one last terrified look at Hagrid and slammed the door\\nbehind them.\\nHagrid looked down at his umbrella and stroked his beard.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 45}), Document(page_content='46\"Shouldn\\'ta lost me temper,\" he said ruefully, \"but it didn\\'t work\\nanyway. Meant ter turn him into a pig, but I suppose he was so much likea pig anyway there wasn\\'t much left ter do.\"\\nHe cast a sideways look at Harry under his bushy eyebrows.\\n\"Be grateful if yeh didn\\'t mention that ter anyone at Hogwarts,\" he\\nsaid. \"I\\'m -- er -- not supposed ter do magic, strictly speakin\\'. I wasallowed ter do a bit ter follow yeh an\\' get yer letters to yeh an\\' stuff-- one o\\' the reasons I was so keen ter take on the job\\n\"Why aren\\'t you supposed to do magic?\" asked Harry.\\n\"Oh, well -- I was at Hogwarts meself but I -- er -- got expelled, ter\\ntell yeh the truth. In me third year. They snapped me wand in half an\\'everything. But Dumbledore let me stay on as gamekeeper. Great man,Dumbledore.\" \"Why were you expelled?\"\\n\"It\\'s gettin\\' late and we\\'ve got lots ter do tomorrow,\" said Hagrid\\nloudly. \"Gotta get up ter town, get all yer books an\\' that.\"\\nHe took off his thick black coat and threw it to Harry.\"You can kip under that,\" he said. \"Don\\' mind if it wriggles a bit, I\\nthink I still got a couple o\\' dormice in one o\\' the pockets.\"\\nCHAPTER FIVE\\nDIAGON ALLEY\\nHarry woke early the next morning. Although he could tell it was\\ndaylight, he kept his eyes shut tight.\\n\"It was a dream, he told himself firmly. \"I dreamed a giant called\\nHagrid came to tell me I was going to a school for wizards. When I openmy eyes I\\'ll be at home in my cupboard.\"\\nThere was suddenly a loud tapping noise.\\nAnd there\\'s Aunt Petunia knocking on the door, Harry thought, his heart\\nsinking. But he still didn\\'t open his eyes. It had been such a good', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 46}), Document(page_content='47dream.\\nTap. Tap. Tap.\"All right,\" Harry mumbled, \"I\\'m getting up.\"\\nHe sat up and Hagrid\\'s heavy coat fell off him. The hut was full of\\nsunlight, the storm was over, Hagrid himself was asleep on the collapsedsofa, and there was an owl rapping its claw on the window, a newspaperheld in its beak.\\nHarry scrambled to his feet, so happy he felt as though a large balloon\\nwas swelling inside him. He went straight to the window and jerked it\\nopen. The owl swooped in and dropped the newspaper on top of Hagrid, who\\ndidn\\'t wake up. The owl then fluttered onto the floor and began toattack Hagrid\\'s coat.\\n\"Don\\'t do that.\"\\nHarry tried to wave the owl out of the way, but it snapped its beak\\nfiercely at him and carried on savaging the coat.\\n\"Hagrid!\" said Harry loudly. \"There\\'s an owl\"Pay him,\" Hagrid grunted into the sofa.\\n\"What?\"\\n\"He wants payin\\' fer deliverin\\' the paper. Look in the pockets.\"\\nHagrid\\'s coat seemed to be made of nothing but pockets -- bunches ofkeys, slug pellets, balls of string, peppermint humbugs, teabags...finally, Harry pulled out a handful of strange-looking coins.\\n\"Give him five Knuts,\" said Hagrid sleepily.\\n\"Knuts?\"\"The little bronze ones.\"\\nHarry counted out five little bronze coins, and the owl held out his leg\\nso Harry could put the money into a small leather pouch tied to it. Thenhe flew off through the open window.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 47}), Document(page_content='48Hagrid yawned loudly, sat up, and stretched.\\n\"Best be Off, Harry, lots ter do today, gotta get up ter London an\\' buy\\nall yer stuff fer school.\"\\nHarry was turning over the wizard coins and looking at them. He had just\\nthought of something that made him feel as though the happy balloon\\ninside him had got a puncture.\\n\"Um -- Hagrid?\"\"Mm?\" said Hagrid, who was pulling on his huge boots.\\n\"I haven\\'t got any money -- and you heard Uncle Vernon last night ... he\\nwon\\'t pay for me to go and learn magic.\"\\n\"Don\\'t worry about that,\" said Hagrid, standing up and scratching his\\nhead. \"D\\'yeh think yer parents didn\\'t leave yeh anything?\"\\n\"But if their house was destroyed --\"\\n\"They didn\\' keep their gold in the house, boy! Nah, first stop fer us is\\nGringotts. Wizards\\' bank. Have a sausage, they\\'re not bad cold -- an\\' Iwouldn\\' say no teh a bit o\\' yer birthday cake, neither.\"\\n\"Wizards have banks?\"\\n\"Just the one. Gringotts. Run by goblins.\"\\nHarry dropped the bit of sausage he was holding.\"Goblins?\"\\n\"Yeah -- so yeh\\'d be mad ter try an\\' rob it, I\\'ll tell yeh that. Never\\nmess with goblins, Harry. Gringotts is the safest place in the world feranything yeh want ter keep safe -- \\'cept maybe Hogwarts. As a matter o\\'fact, I gotta visit Gringotts anyway. Fer Dumbledore. Hogwartsbusiness.\" Hagrid drew himself up proudly. \"He usually gets me ter doimportant stuff fer him. Fetchin\\' you gettin\\' things from Gringotts --\\nknows he can trust me, see.\\n\"Got everythin\\'? Come on, then.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 48}), Document(page_content='49Harry followed Hagrid out onto the rock. The sky was quite clear now and\\nthe sea gleamed in the sunlight. The boat Uncle Vernon had hired wasstill there, with a lot of water in the bottom after the storm.\\n\"How did you get here?\" Harry asked, looking around for another boat.\\n\"Flew,\" said Hagrid.\\n\"Flew?\"\\n\"Yeah -- but we\\'ll go back in this. Not s\\'pposed ter use magic now I\\'ve\\ngot yeh.\"\\nThey settled down in the boat, Harry still staring at Hagrid, trying to\\nimagine him flying.\\n\"Seems a shame ter row, though,\" said Hagrid, giving Harry another of\\nhis sideways looks. \"If I was ter -- er -- speed things up a bit, wouldyeh mind not mentionin\\' it at Hogwarts?\"\\n\"Of course not,\" said Harry, eager to see more magic. Hagrid pulled out\\nthe pink umbrella again, tapped it twice on the side of the boat, andthey sped off toward land.\\n\"Why would you be mad to try and rob Gringotts?\" Harry asked.\"Spells -- enchantments,\" said Hagrid, unfolding his newspaper as he\\nspoke. \"They say there\\'s dragons guardin\\' the highsecurity vaults. And\\nthen yeh gotta find yer way -- Gringotts is hundreds of miles underLondon, see. Deep under the Underground. Yeh\\'d die of hunger tryin\\' terget out, even if yeh did manage ter get yer hands on summat.\"\\nHarry sat and thought about this while Hagrid read his newspaper, the\\nDaily Prophet. Harry had learned from Uncle Vernon that people liked to\\nbe left alone while they did this, but it was very difficult, he\\'d neverhad so many questions in his life.\\n\"Ministry o\\' Magic messin\\' things up as usual,\" Hagrid muttered, turning\\nthe page.\\n\"There\\'s a Ministry of Magic?\" Harry asked, before he could stop\\nhimself.\\n\"\\'Course,\" said Hagrid. \"They wanted Dumbledore fer Minister, 0 \\'', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 49}), Document(page_content='50course, but he\\'d never leave Hogwarts, so old Cornelius Fudge got the\\njob. Bungler if ever there was one. So he pelts Dumbledore with owlsevery morning, askin\\' fer advice.\"\\n\"But what does a Ministry of Magic do?\"\\n\"Well, their main job is to keep it from the Muggles that there\\'s still\\nwitches an\\' wizards up an\\' down the country.\"\\n\"Why?\"\"Why? Blimey, Harry, everyone\\'d be wantin\\' magic solutions to their\\nproblems. Nah, we\\'re best left alone.\"\\nAt this moment the boat bumped gently into the harbor wall. Hagrid\\nfolded up his newspaper, and they clambered up the stone steps onto thestreet.\\nPassersby stared a lot at Hagrid as they walked through the little town\\nto the station. Harry couldn\\'t blame them. Not only was Hagrid twice as\\ntall as anyone else, he kept pointing at perfectly ordinary things likeparking meters and saying loudly, \"See that, Harry? Things these Mugglesdream up, eh?\"\\n\"Hagrid,\" said Harry, panting a bit as he ran to keep up, \"did you say\\nthere are dragons at Gringotts?\"\\n\"Well, so they say,\" said Hagrid. \"Crikey, I\\'d like a dragon.\"\\n\"You\\'d like one?\"\"Wanted one ever since I was a kid -- here we go.\"\\nThey had reached the station. There was a train to London in five\\nminutes\\' time. Hagrid, who didn\\'t understand \"Muggle money,\" as hecalled it, gave the bills to Harry so he could buy their tickets.\\nPeople stared more than ever on the train. Hagrid took up two seats and\\nsat knitting what looked like a canary-yellow circus tent.\\n\"Still got yer letter, Harry?\" he asked as he counted stitches. Harry\\ntook the parchment envelope out of his pocket.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 50}), Document(page_content='51\"Good,\" said Hagrid. \"There\\'s a list there of everything yeh need.\"\\nHarry unfolded a second piece of paper he hadn\\'t noticed the night\\nbefore, and read:\\nHOGWARTS SCHOOL of WITCHCRAFT and WIZARDRY\\nUNIFORM\\nFirst-year students will require:1. Three sets of plain work robes (black)\\n2. One plain pointed hat (black) for day wear\\n3. One pair of protective gloves (dragon hide or similar)4. One winter cloak (black, silver fastenings)\\nPlease note that all pupils\\' clothes should carry name tags\\nCOURSE BOOKSAll students should have a copy of each of the following:The Standard Book of Spells (Grade 1) by Miranda Goshawk\\nA History of Magic by Bathilda Bagshot\\nMagical Theory by Adalbert WafflingA Beginners\\' Guide to Transfiguration by Emetic Switch\\nOne Thousand Magical Herbs and Fungi by Phyllida Spore\\nMagical Drafts and Potions by Arsenius JiggerFantastic Beasts and Where to Find Them by Newt Scamander\\nThe Dark Forces: A Guide to Self-Protection by Quentin Trimble\\nOTHER EQUIPMENT', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 51}), Document(page_content='52wand cauldron (pewter, standard size 2) set\\nglass or crystal phialstelescope set\\nbrass scales\\nStudents may also bring an owl OR a cat OR a toadPARENTS ARE REMINDED THAT FIRST YEARS ARE NOT ALLOWED\\nTHEIR OWNBROOMSTICKS\\n\"Can we buy all this in London?\" Harry wondered aloud.\\n\"If yeh know where to go,\" said Hagrid.Harry had never been to London before. Although Hagrid seemed to know\\nwhere he was going, he was obviously not used to getting there in an\\nordinary way. He got stuck in the ticket barrier on the Underground, andcomplained loudly that the seats were too small and the trains too slow.\\n\"I don\\'t know how the Muggles manage without magic,\" he said as they\\nclimbed a broken-down escalator that led up to a bustling road linedwith shops.\\nHagrid was so huge that he parted the crowd easily; all Harry had to do\\nwas keep close behind him. They passed book shops and music stores,hamburger restaurants and cinemas, but nowhere that looked as if itcould sell you a magic wand. This was just an ordinary street full ofordinary people. Could there really be piles of wizard gold buried miles\\nbeneath them? Were there really shops that sold spell books and\\nbroomsticks? Might this not all be some huge joke that the Dursleys hadcooked up? If Harry hadn\\'t known that the Dursleys had no sense ofhumor, he might have thought so; yet somehow, even though everythingHagrid had told him so far was unbelievable, Harry couldn\\'t helptrusting him.\\n\"This is it,\" said Hagrid, coming to a halt, \"the Leaky Cauldron. It\\'s a\\nfamous place.\"\\nIt was a tiny, grubby-looking pub. If Hagrid hadn\\'t pointed it out,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 52}), Document(page_content='53Harry wouldn\\'t have noticed it was there. The people hurrying by didn\\'t\\nglance at it. Their eyes slid from the big book shop on one side to therecord shop on the other as if they couldn\\'t see the Leaky Cauldron atall. In fact, Harry had the most peculiar feeling that only he andHagrid could see it. Before he could mention this, Hagrid had steeredhim inside.\\nFor a famous place, it was very dark and shabby. A few old women were\\nsitting in a corner, drinking tiny glasses of sherry. One of them wassmoking a long pipe. A little man in a top hat was talking to the oldbartender, who was quite bald and looked like a toothless walnut. Thelow buzz of chatter stopped when they walked in. Everyone seemed to knowHagrid; they waved and smiled at him, and the bartender reached for a\\nglass, saying, \"The usual, Hagrid?\"\\n\"Can\\'t, Tom, I\\'m on Hogwarts business,\" said Hagrid, clapping his great\\nhand on Harry\\'s shoulder and making Harry\\'s knees buckle.\\n\"Good Lord,\" said the bartender, peering at Harry, \"is this -- can this\\nbe --?\"\\nThe Leaky Cauldron had suddenly gone completely still and silent.\\n\"Bless my soul,\" whispered the old bartender, \"Harry Potter... what an\\nhonor.\"\\nHe hurried out from behind the bar, rushed toward Harry and seized his\\nhand, tears in his eyes.\\n\"Welcome back, Mr. Potter, welcome back.\"\\nHarry didn\\'t know what to say. Everyone was looking at him. The old\\nwoman with the pipe was puffing on it without realizing it had gone out.Hagrid was beaming.\\nThen there was a great scraping of chairs and the next moment, Harry\\nfound himself shaking hands with everyone in the Leaky Cauldron.\\n\"Doris Crockford, Mr. Potter, can\\'t believe I\\'m meeting you at last.\"\\n\"So proud, Mr. Potter, I\\'m just so proud.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 53}), Document(page_content='54\"Always wanted to shake your hand -- I\\'m all of a flutter.\"\\n\"Delighted, Mr. Potter, just can\\'t tell you, Diggle\\'s the name, Dedalus\\nDiggle.\"\\n\"I\\'ve seen you before!\" said Harry, as Dedalus Diggle\\'s top hat fell off\\nin his excitement. \"You bowed to me once in a shop.\"\\n\"He remembers!\" cried Dedalus Diggle, looking around at everyone. \"Did\\nyou hear that? He remembers me!\" Harry shook hands again and again --Doris Crockford kept coming back for more.\\nA pale young man made his way forward, very nervously. One of his eyes\\nwas twitching.\\n\"Professor Quirrell!\" said Hagrid. \"Harry, Professor Quirrell will be\\none of your teachers at Hogwarts.\"\\n\"P-P-Potter,\" stammered Professor Quirrell, grasping Harry\\'s hand,\\n\"c-can\\'t t-tell you how p- pleased I am to meet you.\"\\n\"What sort of magic do you teach, Professor Quirrell?\"\"D-Defense Against the D-D-Dark Arts,\" muttered Professor Quirrell, as\\nthough he\\'d rather not think about it. \"N-not that you n-need it, eh,\\nP-P-Potter?\" He laughed nervously. \"You\\'ll be g-getting all your\\nequipment, I suppose? I\\'ve g-got to p-pick up a new b-book on vampires,m-myself.\" He looked terrified at the very thought.\\nBut the others wouldn\\'t let Professor Quirrell keep Harry to himself. It\\ntook almost ten minutes to get away from them all. At last, Hagrid\\nmanaged to make himself heard over the babble.\\n\"Must get on -- lots ter buy. Come on, Harry.\"Doris Crockford shook Harry\\'s hand one last time, and Hagrid led them\\nthrough the bar and out into a small, walled courtyard, where there wasnothing but a trash can and a few weeds.\\nHagrid grinned at Harry.\\n\"Told yeh, didn\\'t I? Told yeh you was famous. Even Professor Quirrell', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 54}), Document(page_content='55was tremblin\\' ter meet yeh -- mind you, he\\'s usually tremblin\\'.\"\\n\"Is he always that nervous?\"\"Oh, yeah. Poor bloke. Brilliant mind. He was fine while he was\\nstudyin\\' outta books but then he took a year off ter get some firsthand\\nexperience.... They say he met vampires in the Black Forest, and therewas a nasty bit o\\' trouble with a hag -- never been the same since.Scared of the students, scared of his own subject now, where\\'s meumbrella?\"\\nVampires? Hags? Harry\\'s head was swimming. Hagrid, meanwhile, was\\ncounting bricks in the wall above the trash can.\\n\"Three up... two across he muttered. \"Right, stand back, Harry.\"He tapped the wall three times with the point of his umbrella.\\nThe brick he had touched quivered -- it wriggled -- in the middle, a\\nsmall hole appeared -- it grew wider and wider -- a second later theywere facing an archway large enough even for Hagrid, an archway onto acobbled street that twisted and turned out of sight.\\n\"Welcome,\" said Hagrid, \"to Diagon Alley.\"\\nHe grinned at Harry\\'s amazement. They stepped through the archway. Harry\\nlooked quickly over his shoulder and saw the archway shrink instantlyback into solid wall.\\nThe sun shone brightly on a stack of cauldrons outside the nearest shop.\\nCauldrons -- All Sizes - Copper, Brass, Pewter, Silver -- Self-Stirring\\n-- Collapsible, said a sign hanging over them.\\n\"Yeah, you\\'ll be needin\\' one,\" said Hagrid, \"but we gotta get yer money\\nfirst.\"\\nHarry wished he had about eight more eyes. He turned his head in every\\ndirection as they walked up the street, trying to look at everything at\\nonce: the shops, the things outside them, the people doing their\\nshopping. A plump woman outside an Apothecary was shaking her head asthey passed, saying, \"Dragon liver, seventeen Sickles an ounce, they\\'remad....\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 55}), Document(page_content='56A low, soft hooting came from a dark shop with a sign saying Eeylops Owl\\nEmporium -- Tawny, Screech, Barn, Brown, and Snowy. Several boys ofabout Harry\\'s age had their noses pressed against a window withbroomsticks in it. \"Look,\" Harry heard one of them say, \"the new NimbusTwo Thousand -- fastest ever --\" There were shops selling robes, shops\\nselling telescopes and strange silver instruments Harry had never seen\\nbefore, windows stacked with barrels of bat spleens and eels\\' eyes,tottering piles of spell books, quills, and rolls of parchment, potionbottles, globes of the moon....\\n\"Gringotts,\" said Hagrid.\\nThey had reached a snowy white building that towered over the other\\nlittle shops. Standing beside its burnished bronze doors, wearing auniform of scarlet and gold, was -\\n\"Yeah, that\\'s a goblin,\" said Hagrid quietly as they walked up the white\\nstone steps toward him. The goblin was about a head shorter than Harry.\\nHe had a swarthy, clever face, a pointed beard and, Harry noticed, very\\nlong fingers and feet. He bowed as they walked inside. Now they werefacing a second pair of doors, silver this time, with words engravedupon them:\\nEnter, stranger, but take heed\\nOf what awaits the sin of greed,\\nFor those who take, but do not earn,Must pay most dearly in their turn.\\nSo if you seek beneath our floors\\nA treasure that was never yours,Thief, you have been warned, bewareOf finding more than treasure there.\\n\"Like I said, Yeh\\'d be mad ter try an\\' rob it,\" said Hagrid.\\nA pair of goblins bowed them through the silver doors and they were in a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 56}), Document(page_content='57vast marble hall. About a hundred more goblins were sitting on high\\nstools behind a long counter, scribbling in large ledgers, weighingcoins in brass scales, examining precious stones through eyeglasses.There were too many doors to count leading off the hall, and yet moregoblins were showing people in and out of these. Hagrid and Harry madefor the counter.\\n\"Morning,\" said Hagrid to a free goblin. \"We\\'ve come ter take some money\\noutta Mr. Harry Potter\\'s safe.\"\\n\"You have his key, Sir?\"\"Got it here somewhere,\" said Hagrid, and he started emptying his\\npockets onto the counter, scattering a handful of moldy dog biscuits\\nover the goblin\\'s book of numbers. The goblin wrinkled his nose. Harrywatched the goblin on their right weighing a pile of rubies as big asglowing coals.\\n\"Got it,\" said Hagrid at last, holding up a tiny golden key.\\nThe goblin looked at it closely.\\n\"That seems to be in order.\"\"An\\' I\\'ve also got a letter here from Professor Dumbledore,\" said Hagrid\\nimportantly, throwing out his chest. \"It\\'s about the YouKnow-What in\\nvault seven hundred and thirteen.\"\\nThe goblin read the letter carefully.\"Very well,\" he said, handing it back to Hagrid, \"I will have Someone\\ntake you down to both vaults. Griphook!\"\\nGriphook was yet another goblin. Once Hagrid had crammed all the dog\\nbiscuits back inside his pockets, he and Harry followed Griphook towardone of the doors leading off the hall.\\n\"What\\'s the You-Know-What in vault seven hundred and thirteen?\" Harry\\nasked.\\n\"Can\\'t tell yeh that,\" said Hagrid mysteriously. \"Very secret. Hogwarts\\nbusiness. Dumbledore\\'s trusted me. More\\'n my job\\'s worth ter tell yehthat.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 57}), Document(page_content='58Griphook held the door open for them. Harry, who had expected more\\nmarble, was surprised. They were in a narrow stone passageway lit withflaming torches. It sloped steeply downward and there were littlerailway tracks on the floor. Griphook whistled and a small cart camehurtling up the tracks toward them. They climbed in -- Hagrid with some\\ndifficulty -- and were off.\\nAt first they just hurtled through a maze of twisting passages. Harry\\ntried to remember, left, right, right, left, middle fork, right, left,but it was impossible. The rattling cart seemed to know its own way,because Griphook wasn\\'t steering.\\nHarry\\'s eyes stung as the cold air rushed past them, but he kept them\\nwide open. Once, he thought he saw a burst of fire at the end of apassage and twisted around to see if it was a dragon, but too late - -they plunged even deeper, passing an underground lake where hugestalactites and stalagmites grew from the ceiling and floor.\\nI never know,\" Harry called to Hagrid over the noise of the cart,\\n\"what\\'s the difference between a stalagmite and a stalactite?\"\\n\"Stalagmite\\'s got an \\'m\\' in it,\" said Hagrid. \"An\\' don\\' ask me questions\\njust now, I think I\\'m gonna be sick.\"\\nHe did look very green, and when the cart stopped at last beside a small\\ndoor in the passage wall, Hagrid got out and had to lean against the\\nwall to stop his knees from trembling.\\nGriphook unlocked the door. A lot of green smoke came billowing out, and\\nas it cleared, Harry gasped. Inside were mounds of gold coins. Columnsof silver. Heaps of little bronze Knuts.\\n\"All yours,\" smiled Hagrid.\\nAll Harry\\'s -- it was incredible. The Dursleys couldn\\'t have known about\\nthis or they\\'d have had it from him faster than blinking. How often hadthey complained how much Harry cost them to keep? And all the time therehad been a small fortune belonging to him, buried deep under London.\\nHagrid helped Harry pile some of it into a bag.\\n\"The gold ones are Galleons,\" he explained. \"Seventeen silver Sickles to', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 58}), Document(page_content='59a Galleon and twenty-nine Knuts to a Sickle, it\\'s easy enough. Right,\\nthat should be enough fer a couple o\\' terms, we\\'ll keep the rest safefor yeh.\" He turned to Griphook. \"Vault seven hundred and thirteen now,please, and can we go more slowly?\"\\n\"One speed only,\" said Griphook.\\nThey were going even deeper now and gathering speed. The air became\\ncolder and colder as they hurtled round tight corners. They wentrattling over an underground ravine, and Harry leaned over the side totry to see what was down at the dark bottom, but Hagrid groaned andpulled him back by the scruff of his neck.\\nVault seven hundred and thirteen had no keyhole.\\n\"Stand back,\" said Griphook importantly. He stroked the door gently with\\none of his long fingers and it simply melted away.\\n\"If anyone but a Gringotts goblin tried that, they\\'d be sucked through\\nthe door and trapped in there,\" said Griphook.\\n\"How often do you check to see if anyone\\'s inside?\" Harry asked.\"About once every ten years,\" said Griphook with a rather nasty grin.Something really extraordinary had to be inside this top security vault,\\nHarry was sure, and he leaned forward eagerly, expecting to see fabulous\\njewels at the very least -- but at first he thought it was empty. Thenhe noticed a grubby little package wrapped up in brown paper lying onthe floor. Hagrid picked it up and tucked it deep inside his coat. Harrylonged to know what it was, but knew better than to ask.\\n\"Come on, back in this infernal cart, and don\\'t talk to me on the way\\nback, it\\'s best if I keep me mouth shut,\" said Hagrid.\\nOne wild cart ride later they stood blinking in the sunlight outside\\nGringotts. Harry didn\\'t know where to run first now that he had a bagfull of money. He didn\\'t have to know how many Galleons there were to apound to know that he was holding more money than he\\'d had in his whole\\nlife -- more money than even Dudley had ever had.\\n\"Might as well get yer uniform,\" said Hagrid, nodding toward Madam\\nMalkin\\'s Robes for All Occasions. \"Listen, Harry, would yeh mind if I', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 59}), Document(page_content='60slipped off fer a pick-me-up in the Leaky Cauldron? I hate them\\nGringotts carts.\" He did still look a bit sick, so Harry entered MadamMalkin\\'s shop alone, feeling nervous.\\nMadam Malkin was a squat, smiling witch dressed all in mauve.\\n\"Hogwarts, clear?\" she said, when Harry started to speak. \"Got the lot\\nhere -- another young man being fitted up just now, in fact. \"\\nIn the back of the shop, a boy with a pale, pointed face was standing on\\na footstool while a second witch pinned up his long black robes. MadamMalkin stood Harry on a stool next to him) slipped a long robe over hishead, and began to pin it to the right length.\\n\"Hello,\" said the boy, \"Hogwarts, too?\"\\n\"Yes,\" said Harry.\"My father\\'s next door buying my books and mother\\'s up the street\\nlooking at wands,\" said the boy. He had a bored, drawling voice. \"Then\\nI\\'m going to drag them off to took at racing brooms. I don\\'t see whyfirst years can\\'t have their own. I think I\\'ll bully father into gettingme one and I\\'ll smuggle it in somehow.\"\\nHarry was strongly reminded of Dudley.\\n\"Have you got your own broom?\" the boy went on.\\n\"No,\" said Harry.\"Play Quidditch at all?\"\\n\"No,\" Harry said again, wondering what on earth Quidditch could be.\\n\"I do -- Father says it\\'s a crime if I\\'m not picked to play for my\\nhouse, and I must say, I agree. Know what house you\\'ll be in yet?\"\\n\"No,\" said Harry, feeling more stupid by the minute.\\n\"Well, no one really knows until they get there, do they, but I know\\nI\\'ll be in Slytherin, all our family have been -- imagine being inHufflepuff, I think I\\'d leave, wouldn\\'t you?\" \"Mmm,\" said Harry, wishinghe could say something a bit more interesting.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 60}), Document(page_content='61\"I say, look at that man!\" said the boy suddenly, nodding toward the\\nfront window. Hagrid was standing there, grinning at Harry and pointingat two large ice creams to show he couldn\\'t come in.\\n\"That\\'s Hagrid,\" said Harry, pleased to know something the boy didn\\'t.\\n\"He works at Hogwarts.\"\\n\"Oh,\" said the boy, \"I\\'ve heard of him. He\\'s a sort of servant, isn\\'t\\nhe?\"\\n\"He\\'s the gamekeeper,\" said Harry. He was liking the boy less and less\\nevery second.\\n\"Yes, exactly. I heard he\\'s a sort of savage -- lives in a hut on the\\nschool grounds and every now and then he gets drunk, tries to do magic,and ends up setting fire to his bed.\"\\n\"I think he\\'s brilliant,\" said Harry coldly.\\n\"Do you?\" said the boy, with a slight sneer. \"Why is he with you? Where\\nare your parents?\"\\n\"They\\'re dead,\" said Harry shortly. He didn\\'t feel much like going into\\nthe matter with this boy.\\n\"Oh, sorry,\" said the other,. not sounding sorry at all. \"But they were\\nour kind, weren\\'t they?\"\\n\"They were a witch and wizard, if that\\'s what you mean.\"\"I really don\\'t think they should let the other sort in, do you? They\\'re\\njust not the same, they\\'ve never been brought up to know our ways. Some\\nof them have never even heard of Hogwarts until they get the letter,imagine. I think they should keep it in the old wizarding families.What\\'s your surname, anyway?\"\\nBut before Harry could answer, Madam Malkin said, \"That\\'s you done, my\\ndear,\" and Harry, not sorry for an excuse to stop talking to the boy,\\nhopped down from the footstool.\\n\"Well, I\\'ll see you at Hogwarts, I suppose,\" said the drawling boy.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 61}), Document(page_content='62Harry was rather quiet as he ate the ice cream Hagrid had bought him\\n(chocolate and raspberry with chopped nuts).\\n\"What\\'s up?\" said Hagrid.\"Nothing,\" Harry lied. They stopped to buy parchment and quills. Harry\\ncheered up a bit when he found a bottle of ink that changed color as you\\nwrote. When they had left the shop, he said, \"Hagrid, what\\'s Quidditch?\"\\n\"Blimey, Harry, I keep forgettin\\' how little yeh know -- not knowin\\'\\nabout Quidditch!\"\\n\"Don\\'t make me feel worse,\" said Harry. He told Hagrid about the pate\\nboy in Madam Malkin\\'s.\\n\"--and he said people from Muggle families shouldn\\'t even be allowed\\nin.\"\\n\"Yer not from a Muggle family. If he\\'d known who yeh were -- he\\'s grown\\nup knowin\\' yer name if his parents are wizardin\\' folk. You saw what\\neveryone in the Leaky Cauldron was like when they saw yeh. Anyway, whatdoes he know about it, some o\\' the best I ever saw were the only oneswith magic in \\'em in a long line 0\\' Muggles -- look at yer mum! Lookwhat she had fer a sister!\"\\n\"So what is Quidditch?\"\\n\"It\\'s our sport. Wizard sport. It\\'s like -- like soccer in the Muggle\\nworld -- everyone follows Quidditch -- played up in the air onbroomsticks and there\\'s four balls -- sorta hard ter explain the rules.\"\"And what are Slytherin and Hufflepuff?\"\\n\"School houses. There\\'s four. Everyone says Hufflepuff are a lot o\\'\\nduffers, but --\"\\n\"I bet I\\'m in Hufflepuff\" said Harry gloomily.\"Better Hufflepuff than Slytherin,\" said Hagrid darkly. \"There\\'s not a\\nsingle witch or wizard who went bad who wasn\\'t in Slytherin.\\nYou-Know-Who was one.\"\\n\"Vol-, sorry - You-Know-Who was at Hogwarts?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 62}), Document(page_content='63\"Years an\\' years ago,\" said Hagrid.\\nThey bought Harry\\'s school books in a shop called Flourish and Blotts\\nwhere the shelves were stacked to the ceiling with books as large aspaving stones bound in leather; books the size of postage stamps incovers of silk; books full of peculiar symbols and a few books with\\nnothing in them at all. Even Dudley, who never read anything, would have\\nbeen wild to get his hands on some of these. Hagrid almost had to dragHarry away from Curses and Countercurses (Bewitch Your Friends andBefuddle Your Enemies with the Latest Revenges: Hair Loss, Jelly-Legs,Tongue- Tying and Much, Much More) by Professor Vindictus Viridian.\\n\"I was trying to find out how to curse Dudley.\"\\n\"I\\'m not sayin\\' that\\'s not a good idea, but yer not ter use magic in the\\nMuggle world except in very special circumstances,\" said Hagrid. \"An\\'anyway, yeh couldn\\' work any of them curses yet, yeh\\'ll need a lot morestudy before yeh get ter that level.\"\\nHagrid wouldn\\'t let Harry buy a solid gold cauldron, either (\"It says\\npewter on yer list\"), but they got a nice set of scales for weighingpotion ingredients and a collapsible brass telescope. Then they visitedthe Apothecary, which was fascinating enough to make up for its horriblesmell, a mixture of bad eggs and rotted cabbages. Barrels of slimy stuffstood on the floor; jars of herbs, dried roots, and bright powders linedthe walls; bundles of feathers, strings of fangs, and snarled claws hung\\nfrom the ceiling. While Hagrid asked the man behind the counter for a\\nsupply of some basic potion ingredients for Harry, Harry himselfexamined silver unicorn horns at twenty-one Galleons each and minuscule,glittery-black beetle eyes (five Knuts a scoop).\\nOutside the Apothecary, Hagrid checked Harry\\'s list again.\\n\"Just yer wand left - A yeah, an\\' I still haven\\'t got yeh a birthday\\npresent.\"\\nHarry felt himself go red.\"You don\\'t have to --\"\\n\"I know I don\\'t have to. Tell yeh what, I\\'ll get yer animal. Not a toad,\\ntoads went outta fashion years ago, yeh\\'d be laughed at - an\\' I don\\'like cats, they make me sneeze. I\\'ll get yer an owl. All the kids want', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 63}), Document(page_content='64owls, they\\'re dead useful, carry yer mail an\\' everythin\\'.\"\\nTwenty minutes later, they left Eeylops Owl Emporium, which had been\\ndark and full of rustling and flickering, jewel-bright eyes. Harry nowcarried a large cage that held a beautiful snowy owl, fast asleep withher head under her wing. He couldn\\'t stop stammering his thanks,\\nsounding just like Professor Quirrell.\\n\"Don\\' mention it,\" said Hagrid gruffly. \"Don\\' expect you\\'ve had a lotta\\npresents from them Dursleys. Just Ollivanders left now - only place ferwands, Ollivanders, and yeh gotta have the best wand.\"\\nA magic wand... this was what Harry had been really looking forward to.\\nThe last shop was narrow and shabby. Peeling gold letters over the door\\nread Ollivanders: Makers of Fine Wands since 382 B.C. A single wand layon a faded purple cushion in the dusty window.\\nA tinkling bell rang somewhere in the depths of the shop as they stepped\\ninside. It was a tiny place, empty except for a single, spindly chair\\nthat Hagrid sat on to wait. Harry felt strangely as though he hadentered a very strict library; he swallowed a lot of new questions thathad just occurred to him and looked instead at the thousands of narrowboxes piled neatly right up to the ceiling. For some reason, the back ofhis neck prickled. The very dust and silence in here seemed to tinglewith some secret magic.\\n\"Good afternoon,\" said a soft voice. Harry jumped. Hagrid must have\\njumped, too, because there was a loud crunching noise and he got quicklyoff the spindly chair.\\nAn old man was standing before them, his wide, pale eyes shining like\\nmoons through the gloom of the shop.\\n\"Hello,\" said Harry awkwardly.\"Ah yes,\" said the man. \"Yes, yes. I thought I\\'d be seeing you soon.\\nHarry Potter.\" It wasn\\'t a question. \"You have your mother\\'s eyes. Itseems only yesterday she was in here herself, buying her first wand. Ten\\nand a quarter inches long, swishy, made of willow. Nice wand for charm\\nwork.\"\\nMr. Ollivander moved closer to Harry. Harry wished he would blink. Those', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 64}), Document(page_content='65silvery eyes were a bit creepy.\\n\"Your father, on the other hand, favored a mahogany wand. Eleven inches.\\nPliable. A little more power and excellent for transfiguration. Well, Isay your father favored it -- it\\'s really the wand that chooses thewizard, of course.\"\\nMr. Ollivander had come so close that he and Harry were almost nose to\\nnose. Harry could see himself reflected in those misty eyes.\\n\"And that\\'s where...\"Mr. Ollivander touched the lightning scar on Harry\\'s forehead with a\\nlong, white finger.\\n\"I\\'m sorry to say I sold the wand that did it,\" he said softly.\\n\"Thirteen-and-a-half inches. Yew. Powerful wand, very powerful, and inthe wrong hands... well, if I\\'d known what that wand was going out intothe world to do....\"\\nHe shook his head and then, to Harry\\'s relief, spotted Hagrid.\\n\"Rubeus! Rubeus Hagrid! How nice to see you again.... Oak, sixteen\\ninches, rather bendy, wasn\\'t it?\"\\n\"It was, sir, yes,\" said Hagrid.\\n\"Good wand, that one. But I suppose they snapped it in half when you got\\nexpelled?\" said Mr. Ollivander, suddenly stern.\\n\"Er -- yes, they did, yes,\" said Hagrid, shuffling his feet. \"I\\'ve still\\ngot the pieces, though,\" he added brightly.\\n\"But you don\\'t use them?\" said Mr. Ollivander sharply.\\n\"Oh, no, sit,\" said Hagrid quickly. Harry noticed he gripped his pink\\numbrella very tightly as he spoke.\\n\"Hmmm,\" said Mr. Ollivander, giving Hagrid a piercing look. \"Well, now\\n-- Mr. Potter. Let me see.\" He pulled a long tape measure with silver\\nmarkings out of his pocket. \"Which is your wand arm?\"\\n\"Er -- well, I\\'m right-handed,\" said Harry.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 65}), Document(page_content='66\"Hold out your arm. That\\'s it.\" He measured Harry from shoulder to\\nfinger, then wrist to elbow, shoulder to floor, knee to armpit and roundhis head. As he measured, he said, \"Every Ollivander wand has a core ofa powerful magical substance, Mr. Potter. We use unicorn hairs, phoenixtail feathers, and the heartstrings of dragons. No two Ollivander wands\\nare the same, just as no two unicorns, dragons, or phoenixes are quite\\nthe same. And of course, you will never get such good results withanother wizard\\'s wand.\"\\nHarry suddenly realized that the tape measure, which was measuring\\nbetween his nostrils, was doing this on its own. Mr. Ollivander wasflitting around the shelves, taking down boxes.\\n\"That will do,\" he said, and the tape measure crumpled into a heap on\\nthe floor. \"Right then, Mr. Potter. Try this one. Beechwood and dragonheartstring. Nine inches. Nice and flexible. just take it and give it awave.\"\\nHarry took the wand and (feeling foolish) waved it around a bit, but Mr.\\nOllivander snatched it out of his hand almost at once.\\n\"Maple and phoenix feather. Seven inches. Quite whippy. Try --\"Harry tried -- but he had hardly raised the wand when it, too, was\\nsnatched back by Mr. Ollivander.\\n\"No, no -here, ebony and unicorn hair, eight and a half inches, springy.\\nGo on, go on, try it out.\"\\nHarry tried. And tried. He had no idea what Mr. Ollivander was waiting\\nfor. The pile of tried wands was mounting higher and higher on the\\nspindly chair, but the more wands Mr. Ollivander pulled from the\\nshelves, the happier he seemed to become.\\n\"Tricky customer, eh? Not to worry, we\\'ll find the perfect match here\\nsomewhere -- I wonder, now - - yes, why not -- unusual combination --holly and phoenix feather, eleven inches, nice and supple.\"\\nHarry took the wand. He felt a sudden warmth in his fingers. He raised\\nthe wand above his head, brought it swishing down through the dusty airand a stream of red and gold sparks shot from the end like a firework,throwing dancing spots of light on to the walls. Hagrid whooped and', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 66}), Document(page_content='67clapped and Mr. Ollivander cried, \"Oh, bravo! Yes, indeed, oh, very\\ngood. Well, well, well... how curious... how very curious... \"\\nHe put Harry\\'s wand back into its box and wrapped it in brown paper,\\nstill muttering, \"Curious... curious..\\n\"Sorry,\" said Harry, \"but what\\'s curious?\"\\nMr. Ollivander fixed Harry with his pale stare.\"I remember every wand I\\'ve ever sold, Mr. Potter. Every single wand. It\\nso happens that the phoenix whose tail feather is in your wand, gaveanother feather -- just one other. It is very curious indeed that you\\nshould be destined for this wand when its brother why, its brother gave\\nyou that scar.\"\\nHarry swallowed.\"Yes, thirteen-and-a-half inches. Yew. Curious indeed how these things\\nhappen. The wand chooses the wizard, remember.... I think we must expect\\ngreat things from you, Mr. Potter.... After all, He-Who-Must-Not-Be-Named did great things -- terrible, yes, but great.\"\\nHarry shivered. He wasn\\'t sure he liked Mr. Ollivander too much. He paid\\nseven gold Galleons for his wand, and Mr. Ollivander bowed them from hisshop.\\nThe late afternoon sun hung low in the sky as Harry and Hagrid made\\ntheir way back down Diagon Alley, back through the wall, back throughthe Leaky Cauldron, now empty. Harry didn\\'t speak at all as they walkeddown the road; he didn\\'t even notice how much people were gawking atthem on the Underground, laden as they were with all their funny-shaped\\npackages, with the snowy owl asleep in its cage on Harry\\'s lap. Up\\nanother escalator, out into Paddington station; Harry only realizedwhere they were when Hagrid tapped him on the shoulder.\\n\"Got time fer a bite to eat before yer train leaves,\" he said.He bought Harry a hamburger and they sat down on plastic seats to eat\\nthem. Harry kept looking around. Everything looked so strange, somehow.\\n\"You all right, Harry? Yer very quiet,\" said Hagrid.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 67}), Document(page_content='68Harry wasn\\'t sure he could explain. He\\'d just had the best birthday of\\nhis life -- and yet -- he chewed his hamburger, trying to find thewords.\\n\"Everyone thinks I\\'m special,\" he said at last. \"All those people in the\\nLeaky Cauldron, Professor Quirrell, Mr. Ollivander... but I don\\'t know\\nanything about magic at all. How can they expect great things? I\\'m\\nfamous and I can\\'t even remember what I\\'m famous for. I don\\'t know whathappened when Vol-, sorry -- I mean, the night my parents died.\"\\nHagrid leaned across the table. Behind the wild beard and eyebrows he\\nwore a very kind smile.\\n\"Don\\' you worry, Harry. You\\'ll learn fast enough. Everyone starts at the\\nbeginning at Hogwarts, you\\'ll be just fine. just be yerself. I know it\\'shard. Yeh\\'ve been singled out, an\\' that\\'s always hard. But yeh\\'ll have agreat time at Hogwarts -- I did -- still do, \\'smatter of fact.\"\\nHagrid helped Harry on to the train that would take him back to the\\nDursleys, then handed him an envelope.\\n\"Yer ticket fer Hogwarts, \" he said. \"First o\\' September -- King\\'s Cross\\n-- it\\'s all on yer ticket. Any problems with the Dursleys, send me aletter with yer owl, she\\'ll know where to find me.... See yeh soon,Harry.\"\\nThe train pulled out of the station. Harry wanted to watch Hagrid until\\nhe was out of sight; he rose in his seat and pressed his nose againstthe window, but he blinked and Hagrid had gone.\\nCHAPTER SIX\\nTHE JOURNEY FROM PLATFORM NINE AND THREE-QUARTERS\\nHarry\\'s last month with the Dursleys wasn\\'t fun. True, Dudley was now so\\nscared of Harry he wouldn\\'t stay in the same room, while Aunt Petuniaand Uncle Vernon didn\\'t shut Harry in his cupboard, force him to doanything, or shout at him -- in fact, they didn\\'t speak to him at all.\\nHalf terrified, half furious, they acted as though any chair with Harry\\nin it were empty. Although this was an improvement in many ways, it didbecome a bit depressing after a while.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 68}), Document(page_content='69Harry kept to his room, with his new owl for company. He had decided to\\ncall her Hedwig, a name he had found in A History of Magic. His schoolbooks were very interesting. He lay on his bed reading late into thenight, Hedwig swooping in and out of the open window as she pleased. Itwas lucky that Aunt Petunia didn\\'t come in to vacuum anymore, becauseHedwig kept bringing back dead mice. Every night before he went to\\nsleep, Harry ticked off another day on the piece of paper he had pinned\\nto the wall, counting down to September the first.\\nOn the last day of August he thought he\\'d better speak to his aunt and\\nuncle about getting to King\\'s Cross station the next day, so he wentdown to the living room where they were watching a quiz show ontelevision. He cleared his throat to let them know he was there, and\\nDudley screamed and ran from the room.\\n\"Er -- Uncle Vernon?\"Uncle Vernon grunted to show he was listening.\\n\"Er -- I need to be at King\\'s Cross tomorrow to -- to go to Hogwarts.\"\\nUncle Vernon grunted again.\"Would it be all right if you gave me a lift?\"Grunt. Harry supposed that meant yes.\\n\"Thank you.\"\\nHe was about to go back upstairs when Uncle Vernon actually spoke.\"Funny way to get to a wizards\\' school, the train. Magic carpets all got\\npunctures, have they?\"\\nHarry didn\\'t say anything.\"Where is this school, anyway?\"\"I don\\'t know,\" said Harry, realizing this for the first time. He pulled\\nthe ticket Hagrid had given him out of his pocket.\\n\"I just take the train from platform nine and three-quarters at eleven\\no\\'clock,\" he read.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 69}), Document(page_content='70His aunt and uncle stared.\\n\"Platform what?\"\"Nine and three-quarters.\"\\n\"Don\\'t talk rubbish,\" said Uncle Vernon. \"There is no platform nine and\\nthree-quarters.\"\\n\"It\\'s on my ticket.\"\"Barking,\" said Uncle Vernon, \"howling mad, the lot of them. You\\'ll see.\\nYou just wait. All right, we\\'ll take you to King\\'s Cross. We\\'re going up\\nto London tomorrow anyway, or I wouldn\\'t bother.\"\\n\"Why are you going to London?\" Harry asked, trying to keep things\\nfriendly.\\n\"Taking Dudley to the hospital,\" growled Uncle Vernon. \"Got to have that\\nruddy tail removed before he goes to Smeltings.\"\\nHarry woke at five o\\'clock the next morning and was too excited and\\nnervous to go back to sleep. He got up and pulled on his jeans becausehe didn\\'t want to walk into the station in his wizard\\'s robes -- he\\'dchange on the train. He checked his Hogwarts list yet again to make sure\\nhe had everything he needed, saw that Hedwig was shut safely in her\\ncage, and then paced the room, waiting for the Dursleys to get up. Twohours later, Harry\\'s huge, heavy trunk had been loaded into theDursleys\\' car, Aunt Petunia had talked Dudley into sitting next toHarry, and they had set off.\\nThey reached King\\'s Cross at half past ten. Uncle Vernon dumped Harry\\'s\\ntrunk onto a cart and wheeled it into the station for him. Harry thoughtthis was strangely kind until Uncle Vernon stopped dead, facing theplatforms with a nasty grin on his face.\\n\"Well, there you are, boy. Platform nine -- platform ten. Your platform\\nshould be somewhere in the middle, but they don\\'t seem to have built it\\nyet, do they?\"\\nHe was quite right, of course. There was a big plastic number nine over\\none platform and a big plastic number ten over the one next to it, and', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 70}), Document(page_content='71in the middle, nothing at all.\\n\"Have a good term,\" said Uncle Vernon with an even nastier smile. He\\nleft without another word. Harry turned and saw the Dursleys drive away.All three of them were laughing. Harry\\'s mouth went rather dry. What onearth was he going to do? He was starting to attract a lot of funny\\nlooks, because of Hedwig. He\\'d have to ask someone.\\nHe stopped a passing guard, but didn\\'t dare mention platform nine and\\nthree-quarters. The guard had never heard of Hogwarts and when Harrycouldn\\'t even tell him what part of the country it was in, he started toget annoyed, as though Harry was being stupid on purpose. Gettingdesperate, Harry asked for the train that left at eleven o\\'clock, but\\nthe guard said there wasn\\'t one. In the end the guard strode away,\\nmuttering about time wasters. Harry was now trying hard not to panic.According to the large clock over the arrivals board, he had ten minutesleft to get on the train to Hogwarts and he had no idea how to do it; hewas stranded in the middle of a station with a trunk he could hardlylift, a pocket full of wizard money, and a large owl.\\nHagrid must have forgotten to tell him something you had to do, like\\ntapping the third brick on the left to get into Diagon Alley. Hewondered if he should get out his wand and start tapping the ticketinspector\\'s stand between platforms nine and ten.\\nAt that moment a group of people passed just behind him and he caught a\\nfew words of what they were saying.\\n\"-- packed with Muggles, of course --\"Harry swung round. The speaker was a plump woman who was talking to four\\nboys, all with flaming red hair. Each of them was pushing a trunk like\\nHarry\\'s in front of him -- and they had an owl.\\nHeart hammering, Harry pushed his cart after them. They stopped and so\\ndid he, just near enough to hear what they were saying.\\n\"Now, what\\'s the platform number?\" said the boys\\' mother.\\n\"Nine and three-quarters!\" piped a small girl, also red-headed, who was\\nholding her hand, \"Mom, can\\'t I go... \"\\n\"You\\'re not old enough, Ginny, now be quiet. All right, Percy, you go', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 71}), Document(page_content='72first.\"\\nWhat looked like the oldest boy marched toward platforms nine and ten.\\nHarry watched, careful not to blink in case he missed it -- but just asthe boy reached the dividing barrier between the two platforms, a largecrowd of tourists came swarming in front of him and by the time the last\\nbackpack had cleared away, the boy had vanished.\\n\"Fred, you next,\" the plump woman said.\"I\\'m not Fred, I\\'m George,\" said the boy. \"Honestly, woman, you call\\nyourself our mother? CarA you tell I\\'m George?\"\\n\"Sorry, George, dear.\"\\n\"Only joking, I am Fred,\" said the boy, and off he went. His twin called\\nafter him to hurry up, and he must have done so, because a second later,he had gone -- but how had he done it?\\nNow the third brother was walking briskly toward the barrier he was\\nalmost there -- and then, quite suddenly, he wasn\\'t anywhere.\\nThere was nothing else for it.\"Excuse me,\" Harry said to the plump woman.\\n\"Hello, dear,\" she said. \"First time at Hogwarts? Ron\\'s new, too.\"\\nShe pointed at the last and youngest of her sons. He was tall, thin, and\\ngangling, with freckles, big hands and feet, and a long nose.\\n\"Yes,\" said Harry. \"The thing is -- the thing is, I don\\'t know how to\\n--\"\\n\"How to get onto the platform?\" she said kindly, and Harry nodded.\"Not to worry,\" she said. \"All you have to do is walk straight at the\\nbarrier between platforms nine and ten. Don\\'t stop and don\\'t be scaredyou\\'ll crash into it, that\\'s very important. Best do it at a bit of a\\nrun if you\\'re nervous. Go on, go now before Ron.\"\\n\"Er -- okay,\" said Harry.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 72}), Document(page_content='73He pushed his trolley around and stared at the barrier. It looked very\\nsolid.\\nHe started to walk toward it. People jostled him on their way to\\nplatforms nine and ten. Harry walked more quickly. He was going to smashright into that barrier and then he\\'d be in trouble -- leaning forward\\non his cart, he broke into a heavy run -- the barrier was coming nearer\\nand nearer -- he wouldn\\'t be able to stop -- the cart was out of control-- he was a foot away -- he closed his eyes ready for the crash --\\nIt didn\\'t come... he kept on running... he opened his eyes. A scarlet\\nsteam engine was waiting next to a platform packed with people. A signoverhead said Hogwarts Express, eleven O\\'clock. Harry looked behind him\\nand saw a wrought-iron archway where the barrier had been, with the\\nwords Platform Nine and Three-Quarters on it, He had done it.\\nSmoke from the engine drifted over the heads of the chattering crowd,\\nwhile cats of every color wound here and there between their legs. Owlshooted to one another in a disgruntled sort of way over the babble and\\nthe scraping of heavy trunks.\\nThe first few carriages were already packed with students, some hanging\\nout of the window to talk to their families, some fighting over seats.Harry pushed his cart off down the platform in search of an empty seat.He passed a round-faced boy who was saying, \"Gran, I\\'ve lost my toadagain.\"\\n\"Oh, Neville,\" he heard the old woman sigh.\\nA boy with dreadlocks was surrounded by a small crowd.\"Give us a look, Lee, go on.\"\\nThe boy lifted the lid of a box in his arms, and the people around him\\nshrieked and yelled as something inside poked out a long, hairy leg.\\nHarry pressed on through the crowd until he found an empty compartment\\nnear the end of the train. He put Hedwig inside first and then startedto shove and heave his trunk toward the train door. He tried to lift it\\nup the steps but could hardly raise one end and twice he dropped it\\npainfully on his foot.\\n\"Want a hand?\" It was one of the red-haired twins he\\'d followed through', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 73}), Document(page_content='74the barrier.\\n\"Yes, please,\" Harry panted.\"Oy, Fred! C\\'mere and help!\"\\nWith the twins\\' help, Harry\\'s trunk was at last tucked away in a corner\\nof the compartment.\\n\"Thanks,\" said Harry, pushing his sweaty hair out of his eyes.\"What\\'s that?\" said one of the twins suddenly, pointing at Harry\\'s\\nlightning scar.\\n\"Blimey,\" said the other twin. \"Are you\\n\"He is,\" said the first twin. \"Aren\\'t you?\" he added to Harry.\"What?\" said Harry.\\n\"Harry Potter, \"chorused the twins.\\n\"Oh, him,\" said Harry. \"I mean, yes, I am.\"The two boys gawked at him, and Harry felt himself turning red. Then, to\\nhis relief, a voice came floating in through the train\\'s open door.\\n\"Fred? George? Are you there?\"\\n\"Coming, Mom.\"With a last look at Harry, the twins hopped off the train.\\nHarry sat down next to the window where, half hidden, he could watch the\\nred-haired family on the platform and hear what they were saying. Theirmother had just taken out her handkerchief.\\n\"Ron, you\\'ve got something on your nose.\"\\nThe youngest boy tried to jerk out of the way, but she grabbed him and\\nbegan rubbing the end of his nose.\\n\"Mom -- geroff\" He wriggled free.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 74}), Document(page_content='75\"Aaah, has ickle Ronnie got somefink on his nosie?\" said one of the\\ntwins.\\n\"Shut up,\" said Ron.\\n\"Where\\'s Percy?\" said their mother.\\n\"He\\'s coming now.\"The oldest boy came striding into sight. He had already changed into his\\nbillowing black Hogwarts robes, and Harry noticed a shiny silver badgeon his chest with the letter P on it.\\n\"Can\\'t stay long, Mother,\" he said. \"I\\'m up front, the prefects have got\\ntwo compartments to themselves --\"\\n\"Oh, are you a prefect, Percy?\" said one of the twins, with an air of\\ngreat surprise. \"You should have said something, we had no idea.\"\\n\"Hang on, I think I remember him saying something about it,\" said the\\nother twin. \"Once --\"\\n\"Or twice --\"\"A minute --\"\\n\"All summer --\"\\n\"Oh, shut up,\" said Percy the Prefect.\"How come Percy gets new robes, anyway?\" said one of the twins.\\n\"Because he\\'s a prefect,\" said their mother fondly. \"All right, dear,\\nwell, have a good term -- send me an owl when you get there.\"\\nShe kissed Percy on the cheek and he left. Then she turned to the twins.\"Now, you two -- this year, you behave yourselves. If I get one more owl\\ntelling me you\\'ve -- you\\'ve blown up a toilet or --\"\\n\"Blown up a toilet? We\\'ve never blown up a toilet.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 75}), Document(page_content='76\"Great idea though, thanks, Mom.\"\\n\"It\\'s not funny. And look after Ron.\"\"Don\\'t worry, ickle Ronniekins is safe with us.\"\\n\"Shut up,\" said Ron again. He was almost as tall as the twins already\\nand his nose was still pink where his mother had rubbed it.\\n\"Hey, Mom, guess what? Guess who we just met on the train?\"Harry leaned back quickly so they couldn\\'t see him looking.\\n\"You know that black-haired boy who was near us in the station? Know who\\nhe is?\"\\n\"Who?\"\"Harry Potter!\"\\nHarry heard the little girl\\'s voice.\\n\"Oh, Mom, can I go on the train and see him, Mom, eh please....\"\"You\\'ve already seen him, Ginny, and the poor boy isn\\'t something you\\ngoggle at in a zoo. Is he really, Fred? How do you know?\"\\n\"Asked him. Saw his scar. It\\'s really there - like lightning.\"\\n\"Poor dear - no wonder he was alone, I wondered. He was ever so polite\\nwhen he asked how to get onto the platform.\"\\n\"Never mind that, do you think he remembers what You-Know-Who looks\\nlike?\"\\nTheir mother suddenly became very stern.\"I forbid you to ask him, Fred. No, don\\'t you dare. As though he needs\\nreminding of that on his first day at school.\"\\n\"All right, keep your hair on.\"\\nA whistle sounded.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 76}), Document(page_content='77\"Hurry up!\" their mother said, and the three boys clambered onto the\\ntrain. They leaned out of the window for her to kiss them good-bye, andtheir younger sister began to cry.\\n\"Don\\'t, Ginny, we\\'ll send you loads of owls.\"\\n\"We\\'ll send you a Hogwarts toilet seat.\"\\n\"George!\"\"Only joking, Mom.\"\\nThe train began to move. Harry saw the boys\\' mother waving and their\\nsister, half laughing, half crying, running to keep up with the trainuntil it gathered too much speed, then she fell back and waved.\\nHarry watched the girl and her mother disappear as the train rounded the\\ncorner. Houses flashed past the window. Harry felt a great leap of\\nexcitement. He didn\\'t know what he was going to but it had to be better\\nthan what he was leaving behind.\\nThe door of the compartment slid open and the youngest redheaded boy\\ncame in.\\n\"Anyone sitting there?\" he asked, pointing at the seat opposite Harry.\\n\"Everywhere else is full.\"\\nHarry shook his head and the boy sat down. He glanced at Harry and then\\nlooked quickly out of the window, pretending he hadn\\'t looked. Harry sawhe still had a black mark on his nose.\\n\"Hey, Ron.\"\\nThe twins were back.\"Listen, we\\'re going down the middle of the train -- Lee Jordan\\'s got a\\ngiant tarantula down there.\"\\n\"Right,\" mumbled Ron.\\n\"Harry,\" said the other twin, \"did we introduce ourselves? Fred and\\nGeorge Weasley. And this is Ron, our brother. See you later, then.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 77}), Document(page_content='78\"Bye,\" said Harry and Ron. The twins slid the compartment door shut\\nbehind them.\\n\"Are you really Harry Potter?\" Ron blurted out.\\nHarry nodded.\\n\"Oh -well, I thought it might be one of Fred and George\\'s jokes,\" said\\nRon. \"And have you really got -- you know...\"\\nHe pointed at Harry\\'s forehead.\\nHarry pulled back his bangs to show the lightning scar. Ron stared.\\n\"So that\\'s where You-Know-Who\"Yes,\" said Harry, \"but I can\\'t remember it.\"\\n\"Nothing?\" said Ron eagerly.\\n\"Well -- I remember a lot of green light, but nothing else.\"\"Wow,\" said Ron. He sat and stared at Harry for a few moments, then, as\\nthough he had suddenly realized what he was doing, he looked quickly outof the window again.\\n\"Are all your family wizards?\" asked Harry, who found Ron just as\\ninteresting as Ron found him.\\n\"Er -- Yes, I think so,\" said Ron. \"I think Mom\\'s got a second cousin\\nwho\\'s an accountant, but we never talk about him.\"\\n\"So you must know loads of magic already.\"\\nThe Weasleys were clearly one of those old wizarding families the pale\\nboy in Diagon Alley had talked about.\\n\"I heard you went to live with Muggles,\" said Ron. \"What are they like?\"\\n\"Horrible -well, not all of them. My aunt and uncle and cousin are,\\nthough. Wish I\\'d had three wizard brothers.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 78}), Document(page_content='79\"Five,\" said Ron. For some reason, he was looking gloomy. \"I\\'m the sixth\\nin our family to go to Hogwarts. You could say I\\'ve got a lot to live upto. Bill and Charlie have already left -- Bill was head boy and Charliewas captain of Quidditch. Now Percy\\'s a prefect. Fred and George messaround a lot, but they still get really good marks and everyone thinksthey\\'re really funny. Everyone expects me to do as well as the others,\\nbut if I do, it\\'s no big deal, because they did it first. You never get\\nanything new, either, with five brothers. I\\'ve got Bill\\'s old robes,Charlie\\'s old wand, and Percy\\'s old rat.\"\\nRon reached inside his jacket and pulled out a fat gray rat, which was\\nasleep.\\n\"His name\\'s Scabbers and he\\'s useless, he hardly ever wakes up. Percy\\ngot an owl from my dad for being made a prefect, but they couldn\\'t aff-- I mean, I got Scabbers instead.\"\\nRon\\'s ears went pink. He seemed to think he\\'d said too much, because he\\nwent back to staring out of the window.\\nHarry didn\\'t think there was anything wrong with not being able to\\nafford an owl. After all, he\\'d never had any money in his life until amonth ago, and he told Ron so, all about having to wear Dudley\\'s oldclothes and never getting proper birthday presents. This seemed to cheerRon up.\\n\"... and until Hagrid told me, I didn\\'t know anything about be ing a\\nwizard or about my parents or Voldemort\"\\nRon gasped.\"What?\" said Harry.\\n\"You said You-Know-Who\\'s name!\" said Ron, sounding both shocked and\\nimpressed. \"I\\'d have thought you, of all people --\"\\n\"I\\'m not trying to be brave or anything, saying the name,\" said Harry, I\\njust never knew you shouldn\\'t. See what I mean? I\\'ve got loads tolearn.... I bet,\" he added, voicing for the first time something that\\nhad been worrying him a lot lately, \"I bet I\\'m the worst in the class.\"\\n\"You won\\'t be. There\\'s loads of people who come from Muggle families and\\nthey learn quick enough.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 79}), Document(page_content='80While they had been talking, the train had carried them out of London.\\nNow they were speeding past fields full of cows and sheep. They werequiet for a time, watching the fields and lanes flick past.\\nAround half past twelve there was a great clattering outside in the\\ncorridor and a smiling, dimpled woman slid back their door and said,\\n\"Anything off the cart, dears?\"\\nHarry, who hadn\\'t had any breakfast, leapt to his feet, but Ron\\'s ears\\nwent pink again and he muttered that he\\'d brought sandwiches. Harry wentout into the corridor.\\nHe had never had any money for candy with the Dursleys, and now that he\\nhad pockets rattling with gold and silver he was ready to buy as manyMars Bars as he could carry -- but the woman didn\\'t have Mars Bars. Whatshe did have were Bettie Bott\\'s Every Flavor Beans, Drooble\\'s BestBlowing Gum, Chocolate Frogs. Pumpkin Pasties, Cauldron Cakes, LicoriceWands, and a number of other strange things Harry had never seen in his\\nlife. Not wanting to miss anything, he got some of everything and paid\\nthe woman eleven silver Sickles and seven bronze Knuts.\\nRon stared as Harry brought it all back in to the compartment and tipped\\nit onto an empty seat.\\n\"Hungry, are you?\"\\n\"Starving,\" said Harry, taking a large bite out of a pumpkin pasty.\\nRon had taken out a lumpy package and unwrapped it. There were four\\nsandwiches inside. He pulled one of them apart and said, \"She alwaysforgets I don\\'t like corned beef.\"\\n\"Swap you for one of these,\" said Harry, holding up a pasty. \"Go on --\"\\n\"You don\\'t want this, it\\'s all dry,\" said Ron. \"She hasn\\'t got much\\ntime,\" he added quickly, \"you know, with five of us.\"\\n\"Go on, have a pasty,\" said Harry, who had never had anything to share\\nbefore or, indeed, anyone to share it with. It was a nice feeling,\\nsitting there with Ron, eating their way through all Harry\\'s pasties,cakes, and candies (the sandwiches lay forgotten).', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 80}), Document(page_content='81\"What are these?\" Harry asked Ron, holding up a pack of Chocolate Frogs.\\n\"They\\'re not really frogs, are they?\" He was starting to feel thatnothing would surprise him.\\n\"No,\" said Ron. \"But see what the card is. I\\'m missing Agrippa.\"\\n\"What?\"\\n\"Oh, of course, you wouldn\\'t know -- Chocolate Frogs have cards, inside\\nthem, you know, to collect -- famous witches and wizards. I\\'ve got aboutfive hundred, but I haven\\'t got Agrippa or Ptolemy.\"\\nHarry unwrapped his Chocolate Frog and picked up the card. It showed a\\nman\\'s face. He wore half- moon glasses, had a long, crooked nose, and\\nflowing silver hair, beard, and mustache. Underneath the picture was thename Albus Dumbledore.\\n\"So this is Dumbledore!\" said Harry.\\n\"Don\\'t tell me you\\'d never heard of Dumbledore!\" said Ron. \"Can I have a\\nfrog? I might get Agrippa -- thanks\\nHarry turned over his card and read:ALBUS DUMBLEDORE\\nCURRENTLY HEADMASTER OF HOGWARTS\\nConsidered by many the greatest wizard of modern times, Dumbledore is\\nparticularly famous for his defeat of the dark wizard Grindelwald in1945, for the discovery of the twelve uses of dragon\\'s blood, and hiswork on alchemy with his partner, Nicolas Flamel. Professor Dumbledore\\nenjoys chamber music and tenpin bowling.\\nHarry turned the card back over and saw, to his astonishment, that\\nDumbledore\\'s face had disappeared.\\n\"He\\'s gone!\"\\n\"Well, you can\\'t expect him to hang around all day,\" said Ron. \"He\\'ll be\\nback. No, I\\'ve got Morgana again and I\\'ve got about six of her... do youwant it? You can start collecting.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 81}), Document(page_content='82Ron\\'s eyes strayed to the pile of Chocolate Frogs waiting to be\\nunwrapped.\\n\"Help yourself,\" said Harry. \"But in, you know, the Muggle world, people\\njust stay put in photos.\"\\n\"Do they? What, they don\\'t move at all?\" Ron sounded amazed. \"weird!\"\\nHarry stared as Dumbledore sidled back into the picture on his card and\\ngave him a small smile. Ron was more interested in eating the frogs thanlooking at the Famous Witches and Wizards cards, but Harry couldn\\'t keephis eyes off them. Soon he had not only Dumbledore and Morgana, butHengist of Woodcroft, Alberic Grunnion, Circe, Paracelsus, and Merlin.\\nHe finally tore his eyes away from the druidess Cliodna, who was\\nscratching her nose, to open a bag of Bertie Bott\\'s Every Flavor Beans.\\n\"You want to be careful with those,\" Ron warned Harry. \"When they say\\nevery flavor, they mean every flavor -- you know, you get all theordinary ones like chocolate and peppermint and mar- malade, but then\\nyou can get spinach and liver and tripe. George reckons he had a booger-\\nflavored one once.\"\\nRon picked up a green bean, looked at it carefully, and bit into a\\ncorner.\\n\"Bleaaargh -- see? Sprouts.\"\\nThey had a good time eating the Every Flavor Beans. Harry got toast,\\ncoconut, baked bean, strawberry, curry, grass, coffee, sardine, and waseven brave enough to nibble the end off a funny gray one Ron wouldn\\'ttouch, which turned out to be pepper.\\nThe countryside now flying past the window was becoming wilder. The neat\\nfields had gone. Now there were woods, twisting rivers, and dark greenhills.\\nThere was a knock on the door of their compartment and the round-faced\\nboy Harry had passed on platform nine and threequarters came in. Helooked tearful.\\n\"Sorry,\" he said, \"but have you seen a toad at all?\"\\nWhen they shook their heads, he wailed, \"I\\'ve lost him! He keeps getting', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 82}), Document(page_content='83away from me!\"\\n\"He\\'ll turn up,\" said Harry.\"Yes,\" said the boy miserably. \"Well, if you see him...\"\\nHe left.\\n\"Don\\'t know why he\\'s so bothered,\" said Ron. \"If I\\'d brought a toad I\\'d\\nlose it as quick as I could. Mind you, I brought Scabbers, so I can\\'ttalk.\"\\nThe rat was still snoozing on Ron\\'s lap.\\n\"He might have died and you wouldn\\'t know the difference,\" said Ron in\\ndisgust. \"I tried to turn him yellow yesterday to make him moreinteresting, but the spell didn\\'t work. I\\'ll show you, look...\"\\nHe rummaged around in his trunk and pulled out a very battered-looking\\nwand. It was chipped in places and something white was glinting at the\\nend.\\n\"Unicorn hair\\'s nearly poking out. AnywayHe had just raised his \\'wand when the compartment door slid open again.\\nThe toadless boy was back, but this time he had a girl with him. She was\\nalready wearing her new Hogwarts robes.\\n\"Has anyone seen a toad? Neville\\'s lost one,\" she said. She had a bossy\\nsort of voice, lots of bushy brown hair, and rather large front teeth.\\n\"We\\'ve already told him we haven\\'t seen it,\" said Ron, but the girl\\nwasn\\'t listening, she was looking at the wand in his hand.\\n\"Oh, are you doing magic? Let\\'s see it, then.\"She sat down. Ron looked taken aback.\"Er -- all right.\"\\nHe cleared his throat.\\n\"Sunshine, daisies, butter mellow, Turn this stupid, fat rat yellow.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 83}), Document(page_content='84He waved his wand, but nothing happened. Scabbers stayed gray and fast\\nasleep.\\n\"Are you sure that\\'s a real spell?\" said the girl. \"Well, it\\'s not very\\ngood, is it? I\\'ve tried a few simple spells just for practice and it\\'s\\nall worked for me. Nobody in my family\\'s magic at all, it was ever such\\na surprise when I got my letter, but I was ever so pleased, of course, Imean, it\\'s the very best school of witchcraft there is, I\\'ve heard --I\\'ve learned all our course books by heart, of course, I just hope itwill be enough -- I\\'m Hermione Granger, by the way, who are you.\\nShe said all this very fast.\\nHarry looked at Ron, and was relieved to see by his stunned face that he\\nhadn\\'t learned all the course books by heart either.\\n\"I\\'m Ron Weasley,\" Ron muttered.\\n\"Harry Potter,\" said Harry.\\n\"Are you really?\" said Hermione. \"I know all about you, of course -- I\\ngot a few extra books. for background reading, and you\\'re in ModernMagical History and The Rise and Fall of the Dark Arts and GreatWizarding Events of the Twentieth Century.\\n\"Am I?\" said Harry, feeling dazed.\\n\"Goodness, didn\\'t you know, I\\'d have found out everything I could if it\\nwas me,\" said Hermione. \"Do either of you know what house you\\'ll be in?I\\'ve been asking around, and I hope I\\'m in Gryffindor, it sounds by farthe best; I hear Dumbledore himself was in it, but I suppose Ravenclaw\\nwouldn\\'t be too bad.... Anyway, we\\'d better go and look for Neville\\'s\\ntoad. You two had better change, you know, I expect we\\'ll be theresoon.\"\\nAnd she left, taking the toadless boy with her.\"Whatever house I\\'m in, I hope she\\'s not in it,\" said Ron. He threw his\\nwand back into his trunk. \"Stupid spell -- George gave it to me, bet he\\nknew it was a dud.\"\\n\"What house are your brothers in?\" asked Harry.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 84}), Document(page_content='85\"Gryffindor,\" said Ron. Gloom seemed to be settling on him again. \"Mom\\nand Dad were in it, too. I don\\'t know what they\\'ll say if I\\'m not. Idon\\'t suppose Ravenclaw would be too bad, but imagine if they put me inSlytherin.\"\\n\"That\\'s the house Vol-, I mean, You-Know-Who was in?\"\\n\"Yeah,\" said Ron. He flopped back into his seat, looking depressed.\"You know, I think the ends of Scabbers\\' whiskers are a bit lighter,\"\\nsaid Harry, trying to take Ron\\'s mind off houses. \"So what do youroldest brothers do now that they\\'ve left, anyway?\"\\nHarry was wondering what a wizard did once he\\'d finished school.\\n\"Charlie\\'s in Romania studying dragons, and Bill\\'s in Africa doing\\nsomething for Gringotts,\" said Ron. \"Did you hear about\\nGringotts? It\\'s been all over the Daily Prophet, but I don\\'t suppose you\\nget that with the Muggles -- someone tried to rob a high securityvault.\"\\nHarry stared.\"Really? What happened to them?\"\\n\"Nothing, that\\'s why it\\'s such big news. They haven\\'t been caught. My\\ndad says it must\\'ve been a powerful Dark wizard to get round Gringotts,but they don\\'t think they took anything, that\\'s what\\'s odd. \\'Course,everyone gets scared when something like this happens in caseYou-Know-Who\\'s behind it.\"\\nHarry turned this news over in his mind. He was starting to get a\\nprickle of fear every time You- Know-Who was mentioned. He supposed thiswas all part of entering the magical world, but it had been a lot morecomfortable saying \"Voldemort\" without worrying.\\n\"What\\'s your Quidditch team?\" Ron asked.\\n\"Er -- I don\\'t know any,\" Harry confessed.\\n\"What!\" Ron looked dumbfounded. \"Oh, you wait, it\\'s the best game in the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 85}), Document(page_content='86world --\" And he was off, explaining all about the four balls and the\\npositions of the seven players, describing famous games he\\'d been towith his brothers and the broomstick he\\'d like to get if he had themoney. He was just taking Harry through the finer points of the gamewhen the compartment door slid open yet again, but it wasn\\'t Neville thetoadless boy, or Hermione Granger this time.\\nThree boys entered, and Harry recognized the middle one at once: it was\\nthe pale boy from Madam Malkin\\'s robe shop. He was looking at Harry witha lot more interest than he\\'d shown back in Diagon Alley.\\n\"Is it true?\" he said. \"They\\'re saying all down the train that Harry\\nPotter\\'s in this compartment. So it\\'s you, is it?\"\\n\"Yes,\" said Harry. He was looking at the other boys. Both of them were\\nthickset and looked extremely mean. Standing on either side of the paleboy, they looked like bodyguards.\\n\"Oh, this is Crabbe and this is Goyle,\" said the pale boy carelessly,\\nnoticing where Harry was looking. \"And my name\\'s Malfoy, Draco Malfoy.\"\\nRon gave a slight cough, which might have been hiding a snigget. Draco\\nMalfoy looked at him.\\n\"Think my name\\'s funny, do you? No need to ask who you are. My father\\ntold me all the Weasleys have red hair, freckles, and more children than\\nthey can afford.\"\\nHe turned back to Harry. \"You\\'ll soon find out some wizarding families\\nare much better than others, Potter. You don\\'t want to go making friendswith the wrong sort. I can help you there.\"\\nHe held out his hand to shake Harry\\'s, but Harry didn\\'t take it.\\n\"I think I can tell who the wrong sort are for myself, thanks,\" he said\\ncoolly.\\nDraco Malfoy didn\\'t go red, but a pink tinge appeared in his pale\\ncheeks.\\n\"I\\'d be careful if I were you, Potter,\" he said slowly. \"Unless you\\'re a\\nbit politer you\\'ll go the same way as your parents. They didn\\'t knowwhat was good for them, either. You hang around with riffraff like the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 86}), Document(page_content='87Weasleys and that Hagrid, and it\\'ll rub off on you.\"\\nBoth Harry and Ron stood up.\"Say that again,\" Ron said, his face as red as his hair.\\n\"Oh, you\\'re going to fight us, are you?\" Malfoy sneered.\\n\"Unless you get out now,\" said Harry, more bravely than he felt, because\\nCrabbe and Goyle were a lot bigger than him or Ron.\\n\"But we don\\'t feet like leaving, do we, boys? We\\'ve eaten all our food\\nand you still seem to have some.\"\\nGoyle reached toward the Chocolate Frogs next to Ron - Ron leapt\\nforward, but before he\\'d so much as touched Goyle, Goyle let out ahorrible yell.\\nScabbers the rat was hanging off his finger, sharp little teeth sunk\\ndeep into Goyle\\'s knuckle - Crabbe and Malfoy backed away as Goyle swung\\nScabbers round and round, howling, and when Scabbets finally flew offand hit the window, all three of them disappeared at once. Perhaps theythought there were more rats lurking among the sweets, or perhaps they\\'dheard footsteps, because a second later, Hermione Granger had come in.\\n\"What has been going on?\" she said, looking at the sweets all over the\\nfloor and Ron picking up Scabbers by his tail.\\nI think he\\'s been knocked out,\" Ron said to Harry. He looked closer at\\nScabbers. \"No -- I don\\'t believe it -- he\\'s gone back to sleep-\"\\nAnd so he had.\\n\"You\\'ve met Malfoy before?\"\\nHarry explained about their meeting in Diagon Alley.\"I\\'ve heard of his family,\" said Ron darkly. \"They were some of the\\nfirst to come back to our side after You-Know-Who disappeared. Said\\nthey\\'d been bewitched. My dad doesn\\'t believe it. He says Malfoy\\'s\\nfather didn\\'t need an excuse to go over to the Dark Side.\" He turned toHermione. \"Can we help you with something?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 87}), Document(page_content='88\"You\\'d better hurry up and put your robes on, I\\'ve just been up to the\\nfront to ask the conductor, and he says we\\'re nearly there. You haven\\'tbeen fighting, have you? You\\'ll be in trouble before we even get there!\"\\n\"Scabbers has been fighting, not us,\" said Ron, scowling at her. \"Would\\nyou mind leaving while we change?\"\\n\"All right -- I only came in here because people outside are behaving\\nvery childishly, racing up and down the corridors,\" said Hermione in asniffy voice. \"And you\\'ve got dirt on your nose, by the way, did youknow?\"\\nRon glared at her as she left. Harry peered out of the window. It was\\ngetting dark. He could see mountains and forests under a deep purple\\nsky. The train did seem to be slowing down.\\nHe and Ron took off their jackets and pulled on their long black robes.\\nRon\\'s were a bit short for him, you could see his sneakers underneaththem.\\nA voice echoed through the train: \"We will be reaching Hogwarts in five\\nminutes\\' time. Please leave your luggage on the train, it will be takento the school separately.\"\\nHarry\\'s stomach lurched with nerves and Ron, he saw, looked pale under\\nhis freckles. They crammed their pockets with the last of the sweets and\\njoined the crowd thronging the corridor.\\nThe train slowed right down and finally stopped. People pushed their way\\ntoward the door and out on to a tiny, dark platform. Harry shivered inthe cold night air. Then a lamp came bobbing over the heads of thestudents, and Harry heard a familiar voice: \"Firs\\' years! Firs\\' years\\nover here! All right there, Harry?\"\\nHagrid\\'s big hairy face beamed over the sea of heads.\"C\\'mon, follow me -- any more firs\\' years? Mind yer step, now! Firs\\'\\nyears follow me!\"\\nSlipping and stumbling, they followed Hagrid down what seemed to be a\\nsteep, narrow path. It was so dark on either side of them that Harrythought there must be thick trees there. Nobody spoke much. Neville, theboy who kept losing his toad, sniffed once or twice.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 88}), Document(page_content='89\"Ye\\' all get yer firs\\' sight o\\' Hogwarts in a sec,\" Hagrid called over\\nhis shoulder, \"jus\\' round this bend here.\"\\nThere was a loud \"Oooooh!\"\\nThe narrow path had opened suddenly onto the edge of a great black take.\\nPerched atop a high mountain on the other side, its windows sparkling inthe starry sky, was a vast castle with many turrets and towers.\\n\"No more\\'n four to a boat!\" Hagrid called, pointing to a fleet of little\\nboats sitting in the water by the shore. Harry and Ron were followedinto their boat by Neville and Hermione. \"Everyone in?\" shouted Hagrid,\\nwho had a boat to himself. \"Right then -- FORWARD!\"\\nAnd the fleet of little boats moved off all at once, gliding across the\\nlake, which was as smooth as glass. Everyone was silent, staring up atthe great castle overhead. It towered over them as they sailed nearerand nearer to the cliff on which it stood.\\n\"Heads down!\" yelled Hagrid as the first boats reached the cliff; they\\nall bent their heads and the little boats carried them through a curtainof ivy that hid a wide opening in the cliff face. They were carriedalong a dark tunnel, which seemed to be taking them right underneath thecastle, until they reached a kind of underground harbor, where theyclambered out onto rocks and pebbles.\\n\"Oy, you there! Is this your toad?\" said Hagrid, who was checking the\\nboats as people climbed out of them.\\n\"Trevor!\" cried Neville blissfully, holding out his hands. Then they\\nclambered up a passageway in the rock after Hagrid\\'s lamp, coming out at\\nlast onto smooth, damp grass right in the shadow of the castle.\\nThey walked up a flight of stone steps and crowded around the huge, Oak\\nfront door.\\n\"Everyone here? You there, still got yer toad?\"\\nHagrid raised a gigantic fist and knocked three times on the castle\\ndoor.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 89}), Document(page_content='90CHAPTER SEVEN\\nTHE SORTING HATThe door swung open at once. A tall, black-haired witch in emerald-green\\nrobes stood there. She had a very stern face and Harry\\'s first thought\\nwas that this was not someone to cross.\\n\"The firs\\' years, Professor McGonagall,\" said Hagrid.\"Thank you, Hagrid. I will take them from here.\"She pulled the door wide. The entrance hall was so big you could have\\nfit the whole of the Dursleys\\' house in it. The stone walls were lit\\nwith flaming torches like the ones at Gringotts, the ceiling was toohigh to make out, and a magnificent marble staircase facing them led tothe upper floors.\\nThey followed Professor McGonagall across the flagged stone floor. Harry\\ncould hear the drone of hundreds of voices from a doorway to the right\\n-the rest of the school must already be here -- but Professor McGonagallshowed the first years into a small, empty chamber off the hall. Theycrowded in, standing rather closer together than they would usually havedone, peering about nervously.\\n\"Welcome to Hogwarts,\" said Professor McGonagall. \"The start-of-term\\nbanquet will begin shortly, but before you take your seats in the Great\\nHall, you will be sorted into your houses. The Sorting is a veryimportant ceremony because, while you are here, your house will besomething like your family within Hogwarts. You will have classes withthe rest of your house, sleep in your house dormitory, and spend freetime in your house common room.\\n\"The four houses are called Gryffindor, Hufflepuff, Ravenclaw, and\\nSlytherin. Each house has its own noble history and each has producedoutstanding witches and wizards. While you are at Hogwarts, yourtriumphs will earn your house points, while any rulebreaking will losehouse points. At the end of the year, the house with the most points isawarded the house cup, a great honor. I hope each of you will be a\\ncredit to whichever house becomes yours.\\n\"The Sorting Ceremony will take place in a few minutes in front of the\\nrest of the school. I suggest you all smarten yourselves up as much as', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 90}), Document(page_content='91you can while you are waiting.\"\\nHer eyes lingered for a moment on Neville\\'s cloak, which was fastened\\nunder his left ear, and on Ron\\'s smudged nose. Harry nervously tried toflatten his hair.\\n\"I shall return when we are ready for you,\" said Professor McGonagall.\\n\"Please wait quietly.\"\\nShe left the chamber. Harry swallowed.\"How exactly do they sort us into houses?\" he asked Ron.\\n\"Some sort of test, I think. Fred said it hurts a lot, but I think he\\nwas joking.\"\\nHarry\\'s heart gave a horrible jolt. A test? In front of the whole\\nschool? But he didn\\'t know any magic yet -- what on earth would he haveto do? He hadn\\'t expected something like this the moment they arrived.\\nHe looked around anxiously and saw that everyone else looked terrified,\\ntoo. No one was talking much except Hermione Granger, who was whisperingvery fast about all the spells she\\'d learned and wondering which oneshe\\'d need. Harry tried hard not to listen to her. He\\'d never been morenervous, never, not even when he\\'d had to take a school report home tothe Dursleys saying that he\\'d somehow turned his teacher\\'s wig blue. Hekept his eyes fixed on the door. Any second now, Professor McGonagall\\nwould come back and lead him to his doom.\\nThen something happened that made him jump about a foot in the air --\\nseveral people behind him screamed.\\n\"What the --?\"\\nHe gasped. So did the people around him. About twenty ghosts had just\\nstreamed through the back wall. Pearly-white and slightly transparent,they glided across the room talking to one another and hardly glancingat the first years. They seemed to be arguing. What looked like a fatlittle monk was saying: \"Forgive and forget, I say, we ought to give hima second chance --\"\\n\"My dear Friar, haven\\'t we given Peeves all the chances he deserves? He\\ngives us all a bad name and you know, he\\'s not really even a ghost -- Isay, what are you all doing here?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 91}), Document(page_content='92A ghost wearing a ruff and tights had suddenly noticed the first years.\\nNobody answered.\"New students!\" said the Fat Friar, smiling around at them. \"About to be\\nSorted, I suppose?\"\\nA few people nodded mutely.\"Hope to see you in Hufflepuff!\" said the Friar. \"My old house, you\\nknow.\"\\n\"Move along now,\" said a sharp voice. \"The Sorting Ceremony\\'s about to\\nstart.\"\\nProfessor McGonagall had returned. One by one, the ghosts floated away\\nthrough the opposite wall.\\n\"Now, form a line,\" Professor McGonagall told the first years, \"and\\nfollow me.\"\\nFeeling oddly as though his legs had turned to lead, Harry got into line\\nbehind a boy with sandy hair, with Ron behind him, and they walked outof the chamber, back across the hall, and through a pair of double doorsinto the Great Hall.\\nHarry had never even imagined such a strange and splendid place. It was\\nlit by thousands and thousands of candles that were floating in midairover four long tables, where the rest of the students were sitting.These tables were laid with glittering golden plates and goblets. At thetop of the hall was another long table where the teachers were sitting.\\nProfessor McGonagall led the first years up here, so that they came to a\\nhalt in a line facing the other students, with the teachers behind them.The hundreds of faces staring at them looked like pale lanterns in theflickering candlelight. Dotted here and there among the students, theghosts shone misty silver. Mainly to avoid all the staring eyes, Harrylooked upward and saw a velvety black ceiling dotted with stars. Heheard\\nHermione whisper, \"Its bewitched to look like the sky outside. I read\\nabout it in Hogwarts, A History.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 92}), Document(page_content='93It was hard to believe there was a ceiling there at all, and that the\\nGreat Hall didn\\'t simply open on to the heavens.\\nHarry quickly looked down again as Professor McGonagall silently placed\\na four-legged stool in front of the first years. On top of the stool sheput a pointed wizard\\'s hat. This hat was patched and frayed and\\nextremely dirty. Aunt Petunia wouldn\\'t have let it in the house.\\nMaybe they had to try and get a rabbit out of it, Harry thought wildly,\\nthat seemed the sort of thing -- noticing that everyone in the hall wasnow staring at the hat, he stared at it, too. For a few seconds, therewas complete silence. Then the hat twitched. A rip near the brim openedwide like a mouth -- and the hat began to sing:\\n\"Oh, you may not think I\\'m pretty,\\nBut don\\'t judge on what you see,I\\'ll eat myself if you can find\\nA smarter hat than me.\\nYou can keep your bowlers black,Your top hats sleek and tall,\\nFor I\\'m the Hogwarts Sorting Hat\\nAnd I can cap them all.There\\'s nothing hidden in your head\\nThe Sorting Hat can\\'t see,\\nSo try me on and I will tell youWhere you ought to be.You might belong in Gryffindor,\\nWhere dwell the brave at heart,\\nTheir daring, nerve, and chivalry Set Gryffindors apart;', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 93}), Document(page_content='94You might belong in Hufflepuff,\\nWhere they are just and loyal,Those patient Hufflepuffis are true And unafraid of toil;\\nOr yet in wise old Ravenclaw,\\nif you\\'ve a ready mind,Where those of wit and learning,\\nWill always find their kind;\\nOr perhaps in SlytherinYou\\'ll make your real friends,\\nThose cunning folk use any means\\nTo achieve their ends.So put me on! Don\\'t be afraid!And don\\'t get in a flap!\\nYou\\'re in safe hands (though I have none)\\nFor I\\'m a Thinking Cap!\"The whole hall burst into applause as the hat finished its song. It\\nbowed to each of the four tables and then became quite still again.\\n\"So we\\'ve just got to try on the hat!\" Ron whispered to Harry. \"I\\'ll\\nkill Fred, he was going on about wrestling a troll.\"\\nHarry. smiled weakly. Yes, trying on the hat was a lot better than\\nhaving to do a spell, but he did wish they could have tried it on\\nwithout everyone watching. The hat seemed to be asking rather alot;\\nHarry didn\\'t feel brave or quick-witted or any of it at the moment. Ifonly the hat had mentioned a house for people who felt a bit queasy,that would have been the one for him.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 94}), Document(page_content='95Professor McGonagall now stepped forward holding a long roll of\\nparchment.\\n\"When I call your name, you will put on the hat and sit on the stool to\\nbe sorted,\" she said. \"Abbott, Hannah!\"\\nA pink-faced girl with blonde pigtails stumbled out of line, put on the\\nhat, which fell right down over her eyes, and sat down. A moments pause--\\n\"HUFFLEPUFF!\" shouted the hat.\\nThe table on the right cheered and clapped as Hannah went to sit down at\\nthe Hufflepuff table. Harry saw the ghost of the Fat Friar wavingmerrily at her.\\n\"Bones, Susan!\"\\n\"HUFFLEPUFF!\" shouted the hat again, and Susan scuttled off to sit next\\nto Hannah.\\n\"Boot, Terry!\"\"RAVENCLAW!\"\\nThe table second from the left clapped this time; several Ravenclaws\\nstood up to shake hands with Terry as he joined them.\\n\" Brocklehurst, Mandy\" went to Ravenclaw too, but \"Brown, Lavender\"\\nbecame the first new Gryffindor, and the table on the far left explodedwith cheers; Harry could see Ron\\'s twin brothers catcalling.\\n\"Bulstrode, Millicent\" then became a Slytherin. Perhaps it was Harry\\'s\\nimagination, after all he\\'d heard about Slytherin, but he thought theylooked like an unpleasant lot. He was starting to feel definitely sicknow. He remembered being picked for teams during gym at his old school.He had always been last to be chosen, not because he was no good, butbecause no one wanted Dudley to think they liked him.\\n\"Finch-Fletchley, Justin!\"\\n\"HUFFLEPUFF!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 95}), Document(page_content='96Sometimes, Harry noticed, the hat shouted out the house at once, but at\\nothers it took a little while to decide. \"Finnigan, Seamus,\" thesandy-haired boy next to Harry in the line, sat on the stool for almosta whole minute before the hat declared him a Gryffindor.\\n\"Granger, Hermione!\"\\nHermione almost ran to the stool and jammed the hat eagerly on her head.\"GRYFFINDOR!\" shouted the hat. Ron groaned.A horrible thought struck Harry, as horrible thoughts always do when\\nyou\\'re very nervous. What if he wasn\\'t chosen at all? What if he just\\nsat there with the hat over his eyes for ages, until ProfessorMcGonagall jerked it off his head and said there had obviously been amistake and he\\'d better get back on the train?\\nWhen Neville Longbottom, the boy who kept losing his toad, was called,\\nhe fell over on his way to the stool. The hat took a long time to decide\\nwith Neville. When it finally shouted, \"GRYFFINDOR,\" Neville ran offstill wearing it, and had to jog back amid gales of laughter to give itto \"MacDougal, Morag.\"\\nMalfoy swaggered forward when his name was called and got his wish at\\nonce: the hat had barely touched his head when it screamed, \"SLYTHERIN!\"\\nMalfoy went to join his friends Crabbe and Goyle, looking pleased with\\nhimself.\\nThere weren\\'t many people left now. \"Moon\" \"Nott\" \"Parkinson\" then a\\npair of twin girls, \"Patil\" and \"Patil\" then \"Perks, Sally-Anne\" and\\nthen, at last -- \"Potter, Harry!\"\\nAs Harry stepped forward, whispers suddenly broke out like little\\nhissing fires all over the hall.\\n\"Potter, did she say?\"\\nThe Harry Potter?\"\\nThe last thing Harry saw before the hat dropped over his eyes was the\\nhall full of people craning to get a good look at him. Next second he', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 96}), Document(page_content='97was looking at the black inside of the hat. He waited.\\nHmm,\" said a small voice in his ear. \"Difficult. Very difficult. Plenty\\nof courage, I see. Not a bad mind either. There\\'s talent, A my goodness,yes -- and a nice thirst to prove yourself, now that\\'s interesting....So where shall I put you?\"\\nHarry gripped the edges of the stool and thought, Not Slytherin, not\\nSlytherin.\\n\"Not Slytherin, eh?\" said the small voice. \"Are you sure? You could be\\ngreat, you know, it\\'s all here in your head, and Slytherin will help youon the way to greatness, no doubt about that -- no? Well, if you\\'re sure\\n-- better be GRYFFINDOR!\"\\nHarry heard the hat shout the last word to the whole hall. He took off\\nthe hat and walked shakily toward the Gryffindor table. He was sorelieved to have been chosen and not put in Slytherin, he hardly noticedthat he was getting the loudest cheer yet. Percy the Prefect got up and\\nshook his hand vigorously, while the Weasley twins yelled, \"We got\\nPotter! We got Potter!\" Harry sat down opposite the ghost in the ruffhe\\'d seen earlier. The ghost patted his arm, giving Harry the sudden,horrible feeling he\\'d just plunged it into a bucket of ice-cold water.\\nHe could see the High Table properly now. At the end nearest him sat\\nHagrid, who caught his eye and gave him the thumbs up. Harry grinned\\nback. And there, in the center of the High Table, in a large gold chair,\\nsat Albus Dumbledore. Harry recognized him at once from the card he\\'dgotten out of the Chocolate Frog on the train. Dumbledore\\'s silver hairwas the only thing in the whole hall that shone as brightly as theghosts. Harry spotted Professor Quirtell, too, the nervous young manfrom the Leaky Cauldron. He was looking very peculiar in a large purple\\nturban.\\nAnd now there were only three people left to be sorted. \"Thomas, Dean,\"\\na Black boy even taller than Ron, joined Harry at the Gryffindor table.\"Turpin, Lisa,\" became a Ravenclaw and then it was Ron\\'s turn. He waspale green by now. Harry crossed his fingers under the table and asecond later the hat had shouted, \"GRYFFINDOR!\"\\nHarry clapped loudly with the rest as Ron collapsed into the chair next\\nto him.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 97}), Document(page_content='98\"Well done, Ron, excellent,\" said Percy Weasley Pompously across Harry\\nas \"Zabini, Blaise,\" was made a Slytherin. Professor McGonagall rolledup her scroll and took the Sorting Hat away.\\nHarry looked down at his empty gold plate. He had only just realized how\\nhungry he was. The pumpkin pasties seemed ages ago.\\nAlbus Dumbledore had gotten to his feet. He was beaming at the students,\\nhis arms opened wide, as if nothing could have pleased him more than tosee them all there.\\n\"Welcome,\" he said. \"Welcome to a new year at Hogwarts! Before we begin\\nour banquet, I would like to say a few words. And here they are: Nitwit!\\nBlubber! Oddment! Tweak!\\n\"Thank you!\"He sat back down. Everybody clapped and cheered. Harry didn\\'t know\\nwhether to laugh or not.\\n\"Is he -- a bit mad?\" he asked Percy uncertainly.\\n\"Mad?\" said Percy airily. \"He\\'s a genius! Best wizard in the world! But\\nhe is a bit mad, yes. Potatoes, Harry?\"\\nHarry\\'s mouth fell open. The dishes in front of him were now piled with\\nfood. He had never seen so many things he liked to eat on one table:\\nroast beef, roast chicken, pork chops and lamb chops, sausages, baconand steak, boiled potatoes, roast potatoes, fries, Yorkshire pudding,peas, carrots, gravy, ketchup, and, for some strange reason, pepperminthumbugs.\\nThe Dursleys had never exactly starved Harry, but he\\'d never been\\nallowed to eat as much as he liked. Dudley had always taken anythingthat Harry really wanted, even if It made him sick. Harry piled hisplate with a bit of everything except the peppermints and began to eat.It was all delicious.\\n\"That does look good,\" said the ghost in the ruff sadly, watching Harry\\ncut up his steak,\\n\"Can\\'t you --?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 98}), Document(page_content='99I haven\\'t eaten for nearly four hundred years,\" said the ghost. \"I don\\'t\\nneed to, of course, but one does miss it. I don\\'t think I\\'ve in troducedmyself? Sir Nicholas de Mimsy-Porpington at your service. Resident ghostof Gryffindor Tower.\"\\n\"I know who you are!\" said Ron suddenly. \"My brothers told me about you\\n-- you\\'re Nearly Headless Nick!\"\\n\"I would prefer you to call me Sir Nicholas de Mimsy --\" the ghost began\\nstiffly, but sandy-haired Seamus Finnigan interrupted.\\n\"Nearly Headless? How can you be nearly headless?\"\\nSir Nicholas looked extremely miffed, as if their little chat wasn\\'t\\ngoing at all the way he wanted.\\n\"Like this,\" he said irritably. He seized his left ear and pulled. His\\nwhole head swung off his neck and fell onto his shoulder as if it was ona hinge. Someone had obviously tried to behead him, but not done it\\nproperly. Looking pleased at the stunned looks on their faces, Nearly\\nHeadless Nick flipped his head back onto his neck, coughed, and said,\"So -- new Gryffindors! I hope you\\'re going to help us win the housechampionship this year? Gryffindors have never gone so long withoutwinning. Slytherins have got the cup six years in a row! The BloodyBaron\\'s becoming almost unbearable -- he\\'s the Slytherin ghost.\"\\nHarry looked over at the Slytherin table and saw a horrible ghost\\nsitting there, with blank staring eyes, a gaunt face, and robes stainedwith silver blood. He was right next to Malfoy who, Harry was pleased tosee, didn\\'t look too pleased with the seating arrangements.\\n\"How did he get covered in blood?\" asked Seamus with great interest.\\n\"I\\'ve never asked,\" said Nearly Headless Nick delicately.\\nWhen everyone had eaten as much as they could, the remains of the food\\nfaded from the plates, leaving them sparkling clean as before. A momentlater the desserts appeared. Blocks of ice cream in every flavor youcould think of, apple pies, treacle tarts, chocolate eclairs and jam\\ndoughnuts, trifle, strawberries, Jell-O, rice pudding -- \"\\nAs Harry helped himself to a treacle tart, the talk turned to their\\nfamilies.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 99}), Document(page_content='100\"I\\'m half-and-half,\" said Seamus. \"Me dad\\'s a Muggle. Mom didn\\'t tell\\nhim she was a witch \\'til after they were married. Bit of a nasty shockfor him.\"\\nThe others laughed.\\n\"What about you, Neville?\" said Ron.\\n\"Well, my gran brought me up and she\\'s a witch,\" said Neville, \"but the\\nfamily thought I was all- Muggle for ages. My Great Uncle Algie kepttrying to catch me off my guard and force some magic out of me -- hepushed me off the end of Blackpool pier once, I nearly drowned -- but\\nnothing happened until I was eight. Great Uncle Algie came round for\\ndinner, and he was hanging me out of an upstairs window by the ankleswhen my Great Auntie Enid offered him a meringue and he accidentally letgo. But I bounced -- all the way down the garden and into the road. Theywere all really pleased, Gran was crying, she was so happy. And youshould have seen their faces when I got in here -- they thought I might\\nnot be magic enough to come, you see. Great Uncle Algie was so pleased\\nhe bought me my toad.\"\\nOn Harry\\'s other side, Percy Weasley and Hermione were talking about\\nlessons (\"I do hope they start right away, there\\'s so much to learn, I\\'mparticularly interested in Transfiguration, you know, turning somethinginto something else, of course, it\\'s supposed to be very difficult-\";\\n\"You\\'ll be starting small, just matches into needles and that sort of\\nthing -- \").\\nHarry, who was starting to feel warm and sleepy, looked up atthe High Table again. Hagrid was drinking deeply from his goblet.\\nProfessor McGonagall was talking to Professor Dumbledore. Professor\\nQuirrell, in his absurd turban, was talking to a teacher with greasyblack hair, a hooked nose, and sallow skin.\\nIt happened very suddenly. The hook-nosed teacher looked past Quirrell\\'s\\nturban straight into Harry\\'s eyes -- and a sharp, hot pain shot acrossthe scar on Harry\\'s forehead.\\n\"Ouch!\" Harry clapped a hand to his head.\\n\"What is it?\" asked Percy.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 100}), Document(page_content='101\"N-nothing.\"\\nThe pain had gone as quickly as it had come. Harder to shake off was the\\nfeeling Harry had gotten from the teacher\\'s look -- a feeling that hedidn\\'t like Harry at all.\\n\"Who\\'s that teacher talking to Professor Quirrell?\" he asked Percy.\\n\"Oh, you know Quirrell already, do you? No wonder he\\'s looking so\\nnervous, that\\'s Professor Snape. He teaches Potions, but he doesn\\'t wantto -- everyone knows he\\'s after Quirrell\\'s job. Knows an awful lot aboutthe Dark Arts, Snape.\"\\nHarry watched Snape for a while, but Snape didn\\'t look at him again.\\nAt last, the desserts too disappeared, and Professor Dumbledore got to\\nhis feet again. The hall fell silent.\\n\"Ahern -- just a few more words now that we are all fed and watered. I\\nhave a few start-of-term notices to give you.\\n\"First years should note that the forest on the grounds is forbidden to\\nall pupils. And a few of our older students would do well to rememberthat as well.\"\\nDumbledore\\'s twinkling eyes flashed in the direction of the Weasley\\ntwins.\\n\"I have also been asked by Mr. Filch, the caretaker, to remind you all\\nthat no magic should be used between classes in the corridors.\\n\"Quidditch trials will be held in the second week of the term. Anyone\\ninterested in playing for their house teams should contact Madam Hooch.\\n\"And finally, I must tell you that this year, the third-floor corridor\\non the right-hand side is out of bounds to everyone who does not wish todie a very painful death.\"\\nHarry laughed, but he was one of the few who did.\\n\"He\\'s not serious?\" he muttered to Percy.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 101}), Document(page_content='102\"Must be,\" said Percy, frowning at Dumbledore. \"It\\'s odd, because he\\nusually gives us a reason why we\\'re not allowed to go somewhere -- theforest\\'s full of dangerous beasts, everyone knows that. I do think hemight have told us prefects, at least.\"\\n\"And now, before we go to bed, let us sing the school song!\" cried\\nDumbledore. Harry noticed that the other teachers\\' smiles had become\\nrather fixed.\\nDumbledore gave his wand a little flick, as if he was trying to get a\\nfly off the end, and a long golden ribbon flew out of it, which rosehigh above the tables and twisted itself, snakelike, into words.\\n\"Everyone pick their favorite tune,\" said Dumbledore, \"and off we go!\"\\nAnd the school bellowed:\\n\"Hogwarts, Hogwarts, Hoggy Warty Hogwarts,Teach us something please,\\nWhether we be old and bald\\nOr young with scabby knees,Our heads could do with filling\\nWith some interesting stuff,\\nFor now they\\'re bare and full of air,Dead flies and bits of fluff,\\nSo teach us things worth knowing,\\nBring back what we\\'ve forgot,just do your best, we\\'ll do the rest,And learn until our brains all rot.\\nEverybody finished the song at different times. At last, only the\\nWeasley twins were left singing along to a very slow funeral march.Dumbledore conducted their last few lines with his wand and when they', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 102}), Document(page_content='103had finished, he was one of those who clapped loudest.\\n\"Ah, music,\" he said, wiping his eyes. \"A magic beyond all we do here!\\nAnd now, bedtime. Off you trot!\"\\nThe Gryffindor first years followed Percy through the chattering crowds,\\nout of the Great Hall, and up the marble staircase. Harry\\'s legs were\\nlike lead again, but only because he was so tired and full of food. Hewas too sleepy even to be surprised that the people in the portraitsalong the corridors whispered and pointed as they passed, or that twicePercy led them through doorways hidden behind sliding panels and hangingtapestries. They climbed more staircases, yawning and dragging theirfeet, and Harry was just wondering how much farther they had to go when\\nthey came to a sudden halt.\\nA bundle of walking sticks was floating in midair ahead of them, and as\\nPercy took a step toward them they started throwing themselves at him.\\n\"Peeves,\" Percy whispered to the first years. \"A poltergeist.\" He raised\\nhis voice, \"Peeves -- show yourself\"\\nA loud, rude sound, like the air being let out of a balloon, answered.\"Do you want me to go to the Bloody Baron?\"There was a pop, and a little man with wicked, dark eyes and a wide\\nmouth appeared, floating cross- legged in the air, clutching the walking\\nsticks.\\n\"Oooooooh!\" he said, with an evil cackle. \"Ickle Firsties! What fun!\"He swooped suddenly at them. They all ducked.\\n\"Go away, Peeves, or the Baron\\'ll hear about this, I mean it!\" barked\\nPercy.\\nPeeves stuck out his tongue and vanished, dropping the walking sticks on\\nNeville\\'s head. They heard him zooming away, rattling coats of armor ashe passed.\\n\"You want to watch out for Peeves,\" said Percy, as they set off again.\\n\"The Bloody Baron\\'s the only one who can control him, he won\\'t evenlisten to us prefects. Here we are.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 103}), Document(page_content='104At the very end of the corridor hung a portrait of a very fat woman in a\\npink silk dress.\\n\"Password?\" she said. \"Caput Draconis,\" said Percy, and the portrait\\nswung forward to reveal a round hole in the wall. They all scrambled\\nthrough it -- Neville needed a leg up -- and found themselves in the\\nGryffindor common room, a cozy, round room full of squashy armchairs.\\nPercy directed the girls through one door to their dormitory and the\\nboys through another. At the top of a spiral staircase -- they wereobviously in one of the towers -- they found their beds at last: fivefour-posters hung with deep red, velvet curtains. Their trunks had\\nalready been brought up. Too tired to talk much, they pulled on their\\npajamas and fell into bed.\\n\" Great food, isn\\'t it?\" Ron muttered to Harry through the hangings.\\n\"Get off, Scabbers! He\\'s chewing my sheets.\"\\nHarry was going to ask Ron if he\\'d had any of the treacle tart, but he\\nfell asleep almost at once.\\nPerhaps Harry had eaten a bit too much, because he had a very strange\\ndream. He was wearing Professor Quirrell\\'s turban, which kept talking tohim, telling him he must transfer to Slytherin at once, because it washis destiny. Harry told the turban he didn\\'t want to be in Slytherin; it\\ngot heavier and heavier; he tried to pull it off but it tightened\\npainfully -- and there was Malfoy, laughing at him as he struggled withit -then Malfoy turned into the hook-nosed teacher, Snape, whose laughbecame high and cold -- there was a burst of green light and Harry woke,sweating and shaking.\\nHe rolled over and fell asleep again, and when he woke next day, he\\ndidn\\'t remember the dream at all.\\nCHAPTER EIGHT\\nTHE POTIONS MASTER\\nThere, look.\"\\n\"Where?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 104}), Document(page_content='105\"Next to the tall kid with the red hair.\"\\n\"Wearing the glasses?\"\"Did you see his face?\"\\n\"Did you see his scar?\"\\nWhispers followed Harry from the moment he left his dormitory the next\\nday. People lining up outside classrooms stood on tiptoe to get a lookat him, or doubled back to pass him in the corridors again, staring.Harry wished they wouldn\\'t, because he was trying to concentrate on\\nfinding his way to classes.\\nThere were a hundred and forty-two staircases at Hogwarts: wide,\\nsweeping ones; narrow, rickety ones; some that led somewhere differenton a Friday; some with a vanishing step halfway up that you had toremember to jump. Then there were doors that wouldn\\'t open unless you\\nasked politely, or tickled them in exactly the right place, and doors\\nthat weren\\'t really doors at all, but solid walls just pretending. Itwas also very hard to remember where anything was, because it all seemedto move around a lot. The people in the portraits kept going to visiteach other, and Harry was sure the coats of armor could walk.\\nThe ghosts didn\\'t help, either. It was always a nasty shock when one of\\nthem glided suddenly through a door you were trying to open. Nearly\\nHeadless Nick was always happy to point new Gryffindors in the rightdirection, but Peeves the Poltergeist was worth two locked doors and atrick staircase if you met him when you were late for class. He woulddrop wastepaper baskets on your head, pull rugs from under your feet,pelt you with bits of chalk, or sneak up behind you, invisible, grab\\nyour nose, and screech, \"GOT YOUR CONK!\"\\nEven worse than Peeves, if that was possible, was the caretaker, Argus\\nFilch. Harry and Ron managed to get on the wrong side of him on theirvery first morning. Filch found them trying to force their way through adoor that unluckily turned out to be the entrance to the out-of-boundscorridor on the third floor. He wouldn\\'t believe they were lost, was\\nsure they were trying to break into it on purpose, and was threatening\\nto lock them in the dungeons when they were rescued by ProfessorQuirrell, who was passing.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 105}), Document(page_content='106Filch owned a cat called Mrs. Norris, a scrawny, dust-colored creature\\nwith bulging, lamp like eyes just like Filch\\'s. She patrolled thecorridors alone. Break a rule in front of her, put just one toe out ofline, and she\\'d whisk off for Filch, who\\'d appear, wheezing, two secondslater. Filch knew the secret passageways of the school better thananyone (except perhaps the Weasley twins) and could pop up as suddenly\\nas any of the ghosts. The students all hated him, and it was the dearest\\nambition of many to give Mrs. Norris a good kick.\\nAnd then, once you had managed to find them, there were the classes\\nthemselves. There was a lot more to magic, as Harry quickly found out,than waving your wand and saying a few funny words.\\nThey had to study the night skies through their telescopes every\\nWednesday at midnight and learn the names of different stars and themovements of the planets. Three times a week they went out to thegreenhouses behind the castle to study Herbology, with a dumpy littlewitch called Professor Sprout, where they learned how to take care ofall the strange plants and fungi, and found out what they were used for.\\nEasily the most boring class was History of Magic, which was the only\\none taught by a ghost. Professor Binns had been very old\\nindeed when he had fallen asleep in front of the staff room fire and got\\nup next morning to teach, leaving his body behind him. Binns droned onand on while they scribbled down names and dates, and got Emetic the\\nEvil and Uric the Oddball mixed up.\\nProfessor Flitwick, the Charms teacher, was a tiny little wizard who had\\nto stand on a pile of books to see over his desk. At the start of theirfirst class he took the roll call, and when he reached Harry\\'s name hegave an excited squeak and toppled out of sight.\\nProfessor McGonagall was again different. Harry had been quite right to\\nthink she wasn\\'t a teacher to cross. Strict and clever, she gave them atalking-to the moment they sat down in her first class.\\n\"Transfiguration is some of the most complex and dangerous magic you\\nwill learn at Hogwarts,\" she said. \"Anyone messing around in my class\\nwill leave and not come back. You have been warned.\"\\nThen she changed her desk into a pig and back again. They were all very\\nimpressed and couldn\\'t wait to get started, but soon realized they', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 106}), Document(page_content='107weren\\'t going to be changing the furniture into animals for a long time.\\nAfter taking a lot of complicated notes, they were each given a matchand started trying to turn it into a needle. By the end of the lesson,only Hermione Granger had made any difference to her match; ProfessorMcGonagall showed the class how it had gone all silver and pointy andgave Hermione a rare smile.\\nThe class everyone had really been looking forward to was Defense\\nAgainst the Dark Arts, but Quirrell\\'s lessons turned out to be a bit ofa joke. His classroom smelled strongly of garlic, which everyone saidwas to ward off a vampire he\\'d met in Romania and was afraid would becoming back to get him one of these days. His turban, he told them, hadbeen given to him by an African prince as a thank-you for getting rid of\\na troublesome zombie, but they weren\\'t sure they believed this story.\\nFor one thing, when Seamus Finnigan asked eagerly to hear how Quirrellhad fought off the zombie, Quirrell went pink and started talking aboutthe weather; for another, they had noticed that a funny smell hungaround the turban, and the Weasley twins insisted that it was stuffedfull of garlic as well, so that Quirrell was protected wherever he went.\\nHarry was very relieved to find out that he wasn\\'t miles behind everyone\\nelse. Lots of people had come from Muggle families and, like him, hadn\\'thad any idea that they were witches and wizards. There was so much tolearn that even people like Ron didn\\'t have much of a head start.\\nFriday was an important day for Harry and Ron. They finally managed to\\nfind their way down to the Great Hall for breakfast without getting lost\\nonce.\\n\"What have we got today?\" Harry asked Ron as he poured sugar on his\\nporridge.\\n\"Double Potions with the Slytherins,\" said Ron. \"Snape\\'s Head of\\nSlytherin House. They say he always favors them -- we\\'ll be able to seeif it\\'s true.\"\\n\"Wish McGonagall favored us, \" said Harry. Professor McGonagall was head\\nof Gryffindor House, but it hadn\\'t stopped her from giving them a hugepile of homework the day before.\\nJust then, the mail arrived. Harry had gotten used to this by now, but\\nit had given him a bit of a shock on the first morning, when about ahundred owls had suddenly streamed into the Great Hall during breakfast,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 107}), Document(page_content='108circling the tables until they saw their owners, and dropping letters\\nand packages onto their laps.\\nHedwig hadn\\'t brought Harry anything so far. She sometimes flew in to\\nnibble his ear and have a bit of toast before going off to sleep in theowlery with the other school owls. This morning, however, she fluttered\\ndown between the marmalade and the sugar bowl and dropped a note onto\\nHarry\\'s plate. Harry tore it open at once. It said, in a very untidyscrawl:\\nDear Harry,\\nI know you get Friday afternoons off, so would you like to come and have\\na cup of tea with me around three?\\nI want to hear all about your first week. Send us an answer back with\\nHedwig.\\nHagrid\\nHarry borrowed Ron\\'s quill, scribbled Yes, please, see you later on the\\nback of the note, and sent Hedwig off again.\\nIt was lucky that Harry had tea with Hagrid to look forward to, because\\nthe Potions lesson turned out to be the worst thing that had happened to\\nhim so far.\\nAt the start-of-term banquet, Harry had gotten the idea that Professor\\nSnape disliked him. By the end of the first Potions lesson, he knew he\\'dbeen wrong. Snape didn\\'t dislike Harry -- he hated him.\\nPotions lessons took place down in one of the dungeons. It was colder\\nhere than up in the main castle, and would have been quite creepy enoughwithout the pickled animals floating in glass jars all around the walls.\\nSnape, like Flitwick, started the class by taking the roll call, and\\nlike Flitwick, he paused at Harry\\'s name.\\n\"Ah, Yes,\" he said softly, \"Harry Potter. Our new -- celebrity.\"\\nDraco Malfoy and his friends Crabbe and Goyle sniggered behind their', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 108}), Document(page_content='109hands. Snape finished calling the names and looked up at the class. His\\neyes were black like Hagrid\\'s, but they had none of Hagrid\\'s warmth.They were cold and empty and made you think of dark tunnels.\\n\"You are here to learn the subtle science and exact art of\\npotionmaking,\" he began. He spoke in barely more than a whisper, but\\nthey caught every word -- like Professor McGonagall, Snape had y caught\\nevery word -- like Professor McGonagall, Snape had the gift of keeping aclass silent without effort. \"As there is little foolish wand-wavinghere, many of you will hardly believe this is magic. I don\\'t expect youwill really understand the beauty of the softly simmering cauldron withits shimmering fumes, the delicate power of liquids that creep throughhuman veins, bewitching the mind, ensnaring the senses.... I can teach\\nyou how to bottle fame, brew glory, even stopper death -- if you aren\\'t\\nas big a bunch of dunderheads as I usually have to teach.\"\\nMore silence followed this little speech. Harry and Ron exchanged looks\\nwith raised eyebrows. Hermione Granger was on the edge of her seat andlooked desperate to start proving that she wasn\\'t a dunderhead.\\n\"Potter!\" said Snape suddenly. \"What would I get if I added powdered\\nroot of asphodel to an infusion of wormwood?\"\\nPowdered root of what to an infusion of what? Harry glanced at Ron, who\\nlooked as stumped as he was; Hermione\\'s hand had shot into the air.\\n\"I don\\'t know, sit,\" said Harry.\\nSnape\\'s lips curled into a sneer.\"Tut, tut -- fame clearly isn\\'t everything.\"\\nHe ignored Hermione\\'s hand.\\n\"Let\\'s try again. Potter, where would you look if I told you to find me\\na bezoar?\"\\nHermione stretched her hand as high into the air as it would go without\\nher leaving her seat, but Harry didn\\'t have the faintest idea what a\\nbezoar was. He tried not to look at Malfoy, Crabbe, and Goyle, who were\\nshaking with laughter.\\n\"I don\\'t know, sit.\" \"Thought you wouldn\\'t open a book before coming,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 109}), Document(page_content='110eh, Potter?\" Harry forced himself to keep looking straight into those\\ncold eyes. He had looked through his books at the Dursleys\\', but didSnape expect him to remember everything in One Thousand Magical Herbsand Fungi?\\nSnape was still ignoring Hermione\\'s quivering hand.\\n\"What is the difference, Potter, between monkshood and wolfsbane?\"\\nAt this, Hermione stood up, her hand stretching toward the dungeon\\nceiling.\\n\"I don\\'t know,\" said Harry quietly. \"I think Hermione does, though, why\\ndon\\'t you try her?\"\\nA few people laughed; Harry caught Seamus\\'s eye, and Seamus winked.\\nSnape, however, was not pleased.\\n\"Sit down,\" he snapped at Hermione. \"For your information, Potter,\\nasphodel and wormwood make a sleeping potion so powerful it is known as\\nthe Draught of Living Death. A bezoar is a stone taken from the stomachof a goat and it will save you from most poisons. As for monkshood andwolfsbane, they are the same plant, which also goes by the name ofaconite. Well? Why aren\\'t you all copying that down?\"\\nThere was a sudden rummaging for quills and parchment. Over the noise,\\nSnape said, \"And a point will be taken from Gryffindor House for your\\ncheek, Potter.\"\\nThings didn\\'t improve for the Gryffindors as the Potions lesson\\ncontinued. Snape put them all into pairs and set them to mixing up asimple potion to cure boils. He swept around in his long black cloak,\\nwatching them weigh dried nettles and crush snake fangs, criticizing\\nalmost everyone except Malfoy, whom he seemed to like. He was justtelling everyone to look at the perfect way Malfoy had stewed his hornedslugs when clouds of acid green smoke and a loud hissing filled thedungeon. Neville had somehow managed to melt Seamus\\'s cauldron into atwisted blob, and their potion was seeping across the stone floor,burning holes in people\\'s shoes. Within seconds, the whole class was\\nstanding on their stools while Neville, who had been drenched in the\\npotion when the cauldron collapsed, moaned in pain as angry red boilssprang up all over his arms and legs.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 110}), Document(page_content='111\"Idiot boy!\" snarled Snape, clearing the spilled potion away with one\\nwave of his wand. \"I suppose you added the porcupine quills beforetaking the cauldron off the fire?\"\\nNeville whimpered as boils started to pop up all over his nose.\\n\"Take him up to the hospital wing,\" Snape spat at Seamus. Then he\\nrounded on Harry and Ron, who had been working next to Neville.\\n\"You -- Potter -- why didn\\'t you tell him not to add the quills? Thought\\nhe\\'d make you look good if he got it wrong, did you? That\\'s anotherpoint you\\'ve lost for Gryffindor.\"\\nThis was so unfair that Harry opened his mouth to argue, but Ron kicked\\nhim behind their cauldron.\\n\"Doi* push it,\" he muttered, \"I\\'ve heard Snape can turn very nasty.\"As they climbed the steps out of the dungeon an hour later, Harry\\'s mind\\nwas racing and his spirits were low. He\\'d lost two points for Gryffindor\\nin his very first week -- why did Snape hate him so much? \"Cheer up,\"said Ron, \"Snape\\'s always taking points off Fred and George. Can I comeand meet Hagrid with you?\"\\nAt five to three they left the castle and made their way across the\\ngrounds. Hagrid lived in a small wooden house on the edge of the\\nforbidden forest. A crossbow and a pair of galoshes were outside the\\nfront door.\\nWhen Harry knocked they heard a frantic scrabbling from inside and\\nseveral booming barks. Then Hagrid\\'s voice rang out, saying, \"Back, Fang-- back.\"\\nHagrid\\'s big, hairy face appeared in the crack as he pulled the door\\nopen.\\n\"Hang on,\" he said. \"Back, Fang.\"He let them in, struggling to keep a hold on the collar of an enormous\\nblack boarhound.\\nThere was only one room inside. Hams and pheasants were hanging from the\\nceiling, a copper kettle was boiling on the open fire, and in the corner', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 111}), Document(page_content='112stood a massive bed with a patchwork quilt over it.\\n\"Make yerselves at home,\" said Hagrid, letting go of Fang, who bounded\\nstraight at Ron and started licking his ears. Like Hagrid, Fang wasclearly not as fierce as he looked.\\n\"This is Ron,\" Harry told Hagrid, who was pouring boiling water into a\\nlarge teapot and putting rock cakes onto a plate.\\n\"Another Weasley, eh?\" said Hagrid, glancing at Ron\\'s freckles. I spent\\nhalf me life chasin\\' yer twin brothers away from the forest.\"\\nThe rock cakes were shapeless lumps with raisins that almost broke their\\nteeth, but Harry and Ron pretended to be enjoying them as they told\\nHagrid all about their first -lessons. Fang rested his head on Harry\\'sknee and drooled all over his robes.\\nHarry and Ron were delighted to hear Hagrid call Fitch \"that old git.\"\\n\"An\\' as fer that cat, Mrs. Norris, I\\'d like ter introduce her to Fang\\nsometime. D\\'yeh know, every time I go up ter the school, she follows meeverywhere? Can\\'t get rid of her -- Fitch puts her up to it.\"\\nHarry told Hagrid about Snape\\'s lesson. Hagrid, like Ron, told Harry not\\nto worry about it, that Snape liked hardly any of the students.\\n\"But he seemed to really hate me.\"\\n\"Rubbish!\" said Hagrid. \"Why should he?\"Yet Harry couldn\\'t help thinking that Hagrid didn\\'t quite meet his eyes\\nwhen he said that.\\n\"How\\'s yer brother Charlie?\" Hagrid asked Ron. \"I liked him a lot --\\ngreat with animals.\"\\nHarry wondered if Hagrid had changed the subject on purpose. While Ron\\ntold Hagrid all about Charlie\\'s work with dragons, Harry picked up apiece of paper that was lying on the table under the tea cozy. It was a\\ncutting from the Daily Prophet:\\nGRINGOTTS BREAK-IN LATEST', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 112}), Document(page_content='113Investigations continue into the break-in at Gringotts on 31 July,\\nwidely believed to be the work of Dark wizards or witches unknown.\\nGringotts goblins today insisted that nothing had been taken. The vault\\nthat was searched had in fact been emptied the same day.\\n\"But we\\'re not telling you what was in there, so keep your noses out if\\nyou know what\\'s good for you,\" said a Gringotts spokesgoblin thisafternoon.\\nHarry remembered Ron telling him on the train that someone had tried to\\nrob Gringotts, but Ron hadn\\'t mentioned the date.\\n\"Hagrid!\" said Harry, \"that Gringotts break-in happened on my birthday!\\nIt might\\'ve been happening while we were there!\"\\nThere was no doubt about it, Hagrid definitely didn\\'t meet Harry\\'s eyes\\nthis time. He grunted and offered him another rock cake. Harry read thestory again. The vault that was searched had in fact been emptied\\nearlier that same day. Hagrid had emptied vault seven hundred and\\nthirteen, if you could call it emptying, taking out that grubby littlepackage. Had that been what the thieves were looking for?\\nAs Harry and Ron walked back to the castle for dinner, their pockets\\nweighed down with rock cakes they\\'d been too polite to refuse, Harrythought that none of the lessons he\\'d had so far had given him as much\\nto think about as tea with Hagrid. Had Hagrid collected that package\\njust in time? Where was it now? And did Hagrid know something aboutSnape that he didn\\'t want to tell Harry?\\nCHAPTER NINE\\nTHE MIDNIGHT DUEL\\nHarry had never believed he would meet a boy he hated more than Dudley,\\nbut that was before he met Draco Malfoy. Still, first-yearGryffindors only had Potions with the Slytherins, so they didn\\'t have toput up with Malfoy much. Or at least, they didn\\'t until they spotted a\\nnotice pinned up in the Gryffindor common room that made them all groan.\\nFlying lessons would be starting on Thursday -- and Gryffindor andSlytherin would be learning together.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 113}), Document(page_content='114\"Typical,\" said Harry darkly. \"Just what I always wanted. To make a fool\\nof myself on a broomstick in front of Malfoy.\"\\nHe had been looking forward to learning to fly more than anything else.\"You don\\'t know that you\\'ll make a fool of yourself,\" said Ron\\nreasonably. \"Anyway, I know Malfoy\\'s always going on about how good he\\nis at Quidditch, but I bet that\\'s all talk.\"\\nMalfay certainly did talk about flying a lot. He complained loudly about\\nfirst years never getting on the house Quidditch teams and told long,boastful stories that always seemed to end with him narrowly escapingMuggles in helicopters. He wasn\\'t the only one, though: the way Seamus\\nFinnigan told it, he\\'d spent most of his childhood zooming around the\\ncountryside on his broomstick. Even Ron would tell anyone who\\'d listenabout the time he\\'d almost hit a hang glider on Charlie\\'s old broom.Everyone from wizarding families talked about Quidditch constantly. Ronhad already had a big argument with Dean Thomas, who shared theirdormitory, about soccer. Ron couldn\\'t see what was exciting about a game\\nwith only one ball where no one was allowed to fly. Harry had caught Ron\\nprodding Dean\\'s poster of West Ham soccer team, trying to make theplayers move.\\nNeville had never been on a broomstick in his life, because his\\ngrandmother had never let him near one. Privately, Harry felt she\\'d hadgood reason, because Neville managed to have an extraordinary number of\\naccidents even with both feet on the ground.\\nHermione Granger was almost as nervous about flying as Neville was. This\\nwas something you couldn\\'t learn by heart out of a book -- not that shehadn\\'t tried. At breakfast on Thursday she bored them all stupid withflying tips she\\'d gotten out of a library book called Quidditch Through\\nthe Ages. Neville was hanging on to her every word, desperate for\\nanything that might help him hang on to his broomstick later, buteverybody else was very pleased when Hermione\\'s lecture was interruptedby the arrival of the mail.\\nHarry hadn\\'t had a single letter since Hagrid\\'s note, something that\\nMalfoy had been quick to notice, of course. Malfoy\\'s eagle owl was\\nalways bringing him packages of sweets from home, which he opened\\ngloatingly at the Slytherin table.\\nA barn owl brought Neville a small package from his grandmother. He', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 114}), Document(page_content='115opened it excitedly and showed them a glass ball the size of a large\\nmarble, which seemed to be full of white smoke.\\n\"It\\'s a Remembrall!\" he explained. \"Gran knows I forget things -- this\\ntells you if there\\'s something you\\'ve forgotten to do. Look, you hold ittight like this and if it turns red -- oh...\" His face fell, because the\\nRemembrall had suddenly glowed scarlet,\\n\"You\\'ve forgotten something...\"Neville was trying to remember what he\\'d forgotten when Draco Malfoy,\\nwho was passing the Gryffindor table, snatched the Remembrall out of hishand.\\nHarry and Ron jumped to their feet. They were half hoping for a reason\\nto fight Malfay, but Professor McGonagall, who could spot troublequicker than any teacher in the school, was there in a flash.\\n\"What\\'s going on?\"\\n\"Malfoy\\'s got my Remembrall, Professor.\"\\nScowling, Malfoy quickly dropped the Remembrall back on the table.\"Just looking,\" he said, and he sloped away with Crabbe and Goyle behind\\nhim.\\nAt three-thirty that afternoon, Harry, Ron, and the other Gryffindors\\nhurried down the front steps onto the grounds for their first flyinglesson. It was a clear, breezy day, and the grass rippled under theirfeet as they marched down the sloping lawns toward a smooth, flat lawnon the opposite side of the grounds to the forbidden forest, whose trees\\nwere swaying darkly in the distance.\\nThe Slytherins were already there, and so were twenty broomsticks lying\\nin neat lines on the ground. Harry had heard Fred and George Weasleycomplain about the school brooms, saying that some of them started tovibrate if you flew too high, or always flew slightly to the left.\\nTheir teacher, Madam Hooch, arrived. She had short, gray hair, and\\nyellow eyes like a hawk.\\n\"Well, what are you all waiting for?\" she barked. \"Everyone stand by a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 115}), Document(page_content='116broomstick. Come on, hurry up.\"\\nHarry glanced down at his broom. It was old and some of the twigs stuck\\nout at odd angles.\\n\"Stick out your right hand over your broom,\" called Madam Hooch at the\\nfront, \"and say \\'Up!\"\\'\\n\"UPF everyone shouted.Harry\\'s broom jumped into his hand at once, but it was one of the few\\nthat did. Hermione Granger\\'s had simply rolled over on the ground, andNeville\\'s hadn\\'t moved at all. Perhaps brooms, like horses, could tell\\nwhen you were afraid, thought Harry; there was a quaver in Neville\\'s\\nvoice that said only too clearly that he wanted to keep his feet on theground.\\nMadam Hooch then showed them how to mount their brooms without sliding\\noff the end, and walked up and down the rows correcting their grips.\\nHarry and Ron were delighted when she told Malfoy he\\'d been doing it\\nwrong for years.\\n\"Now, when I blow my whistle, you kick off from the ground, hard,\" said\\nMadam Hooch. \"Keep your brooms steady, rise a few feet, and then comestraight back down by leaning forward slightly. On my whistle -- three-- two --\"\\nBut Neville, nervous and jumpy and frightened of being left on the\\nground, pushed off hard before the whistle had touched Madam Hooch\\'slips.\\n\"Come back, boy!\" she shouted, but Neville was rising straight up like a\\ncork shot out of a bottle -- twelve feet -- twenty feet. Harry saw his\\nscared white face look down at the ground falling away, saw him gasp,slip sideways off the broom and --\\nWHAM -- a thud and a nasty crack and Neville lay facedown on the grass\\nin a heap. His broomstick was still rising higher and higher, andstarted to drift lazily toward the forbidden forest and out of sight.\\nMadam Hooch was bending over Neville, her face as white as his.\\n\"Broken wrist,\" Harry heard her mutter. \"Come on, boy -- it\\'s all right,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 116}), Document(page_content='117up you get.\".\\nShe turned to the rest of the class.\"None of you is to move while I take this boy to the hospital wing! You\\nleave those brooms where they are or you\\'ll be out of Hogwarts before\\nyou can say \\'Quidditch.\\' Come on, dear.\"\\nNeville, his face tear-streaked, clutching his wrist, hobbled off with\\nMadam Hooch, who had her arm around him.\\nNo sooner were they out of earshot than Malfoy burst into laughter.\\n\"Did you see his face, the great lump?\"\\nThe other Slytherins joined in.\"Shut up, Malfoy,\" snapped Parvati Patil.\\n\"Ooh, sticking up for Longbottom?\" said Pansy Parkinson, a hard-faced\\nSlytherin girl. \"Never thought you\\'d like fat little crybabies,Parvati.\"\\n\"Look!\" said Malfoy, darting forward and snatching something out of the\\ngrass. \"It\\'s that stupid thing Longbottom\\'s gran sent him.\"\\nThe Remembrall glittered in the sun as he held it up.\\n\"Give that here, Malfoy,\" said Harry quietly. Everyone stopped talking\\nto watch.\\nMalfoy smiled nastily.\\n\"I think I\\'ll leave it somewhere for Longbottom to find -- how about --\\nup a tree?\"\\n\"Give it here!\" Harry yelled, but Malfoy had leapt onto his broomstick\\nand taken off. He hadn\\'t been lying, he could fly well. Hovering levelwith the topmost branches of an oak he called, \"Come and get it,\\nPotter!\"\\nHarry grabbed his broom.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 117}), Document(page_content='118\"No!\" shouted Hermione Granger. \"Madam Hooch told us not to move --\\nyou\\'ll get us all into trouble.\"\\nHarry ignored her. Blood was pounding in his ears. He mounted the broom\\nand kicked hard against the ground and up, up he soared; air rushedthrough his hair, and his robes whipped out behind him -and in a rush of\\nfierce joy he realized he\\'d found something he could do without being\\ntaught -- this was easy, this was wonderful. He pulled his broomstick upa little to take it even higher, and heard screams and gasps of girlsback on the ground and an admiring whoop from Ron.\\nHe turned his broomstick sharply to face Malfoy in midair. Malfoy looked\\nstunned.\\n\"Give it here,\" Harry called, \"or I\\'ll knock you off that broom!\" \"Oh,\\nyeah?\" said Malfoy, trying to sneer, but looking worried.\\nHarry knew, somehow, what to do. He leaned forward and grasped the broom\\ntightly in both hands, and it shot toward Malfay like a javelin. Malfoy\\nonly just got out of the way in time; Harry made a sharp about-face and\\nheld the broom steady. A few people below were clapping.\\n\"No Crabbe and Goyle up here to save your neck, Malfoy,\" Harry called.The same thought seemed to have struck Malfoy.\\n\"Catch it if you can, then!\" he shouted, and he threw the glass ball\\nhigh into the air and streaked back toward the ground.\\nHarry saw, as though in slow motion, the ball rise up in the air and\\nthen start to fall. He leaned forward and pointed his broom handle down-- next second he was gathering speed in a steep dive, racing the ball\\n-- wind whistled in his ears, mingled with the screams of people\\nwatching -- he stretched out his hand -- a foot from the ground hecaught it, just in time to pull his broom straight, and he toppledgently onto the grass with the Remembrall clutched safely in his fist.\\n\"HARRY POTTER!\"\\nHis heart sank faster than he\\'d just dived. Professor McGonagall was\\nrunning toward them. He got to his feet, trembling.\\n\"Never -- in all my time at Hogwarts --\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 118}), Document(page_content='119Professor McGonagall was almost speechless with shock, and her glasses\\nflashed furiously, \"-- how dare you -- might have broken your neck --\"\\n\"It wasn\\'t his fault, Professor --\"\\n\"Be quiet, Miss Patil\\n\"But Malfoy --\"\"That\\'s enough, Mr. Weasley. Potter, follow me, now.\"Harry caught sight of Malfoy, Crabbe, and Goyle\\'s triumphant faces as he\\nleft, walking numbly in Professor McGonagall\\'s wake as she strode toward\\nthe castle. He was going to be expelled, he just knew it. He wanted tosay something to defend himself, but there seemed to be something wrongwith his voice. Professor McGonagall was sweeping along without evenlooking at him; he had to jog to keep up. Now he\\'d done it. He hadn\\'teven lasted two weeks. He\\'d be packing his bags in ten minutes. What\\nwould the Dursleys say when he turned up on the doorstep?\\nUp the front steps, up the marble staircase inside, and still Professor\\nMcGonagall didn\\'t say a word to him. She wrenched open doors and marchedalong corridors with Harry trotting miserably behind her. Maybe she wastaking him to Dumbledore. He thought of Hagrid, expelled but allowed tostay on as gamekeeper. Perhaps he could be Hagrid\\'s assistant. His\\nstomach twisted as he imagined it, watching Ron and the others becoming\\nwizards, while he stumped around the grounds carrying Hagrid\\'s bag.\\nProfessor McGonagall stopped outside a classroom. She opened the door\\nand poked her head inside.\\n\"Excuse me, Professor Flitwick, could I borrow Wood for a moment?\"\\nWood? thought Harry, bewildered; was Wood a cane she was going to use on\\nhim?\\nBut Wood turned out to be a person, a burly fifth-year boy who came out\\nof Flitwicles class looking confused.\\n\"Follow me, you two,\" said Professor McGonagall, and they marched on up\\nthe corridor, Wood looking curiously at Harry.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 119}), Document(page_content='120\"In here.\"\\nProfessor McGonagall pointed them into a classroom that was empty except\\nfor Peeves, who was busy writing rude words on the blackboard.\\n\"Out, Peeves!\" she barked. Peeves threw the chalk into a bin, which\\nclanged loudly, and he swooped out cursing. Professor McGonagall slammed\\nthe door behind him and turned to face the two boys.\\n\"Potter, this is Oliver Wood. Wood -- I\\'ve found you a Seeker.\"Wood\\'s expression changed from puzzlement to delight.\\n\"Are you serious, Professor?\"\\n\"Absolutely,\" said Professor McGonagall crisply. \"The boy\\'s a natural.\\nI\\'ve never seen anything like it. Was that your first time on abroomstick, Potter?\"\\nHarry nodded silently. He didn\\'t have a clue what was going on, but he\\ndidn\\'t seem to be being expelled, and some of the feeling started comingback to his legs.\\n\"He caught that thing in his hand after a fifty-foot dive,\" Professor\\nMcGonagall told Wood. \"Didn\\'t even scratch himself. Charlie Weasleycouldn\\'t have done it.\"\\nWood was now looking as though all his dreams had come true at once.\\n\"Ever seen a game of Quidditch, Potter?\" he asked excitedly.\"Wood\\'s captain of the Gryffindor team,\" Professor McGonagall explained.\\n\"He\\'s just the build for a Seeker, too,\" said Wood, now walking around\\nHarry and staring at him. \"Light -- speedy -- we\\'ll have to get him adecent broom, Professor -- a Nimbus Two Thousand or a Cleansweep Seven,I\\'d say.\"\\nI shall speak to Professor Dumbledore and see if we can\\'t bend the\\nfirst-year rule. Heaven knows, we need a better team than last year.\\nFlattened in that last match by Slytherin, I couldn\\'t look Severus Snapein the face for weeks....\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 120}), Document(page_content='121Professor McGonagall peered sternly over her glasses at Harry.\\n\"I want to hear you\\'re training hard, Potter, or I may change my mind\\nabout punishing you.\"\\nThen she suddenly smiled.\\n\"Your father would have been proud,\" she said. \"He was an excellent\\nQuidditch player himself.\"\\n\"You\\'re joking.\"It was dinnertime. Harry had just finished telling Ron what had happened\\nwhen he\\'d left the grounds with Professor McGonagall. Ron had a piece of\\nsteak and kidney pie halfway to his mouth, but he\\'d forgotten all aboutit.\\n\"Seeker?\" he said. \"But first years never -- you must be the youngest\\nhouse player in about a century, said Harry, shoveling pie into his\\nmouth. He felt particularly hungry after the excitement of the\\nafternoon. \"Wood told me.\"\\nRon was so amazed, so impressed, he just sat and gaped at Harry.\"I start training next week,\" said Harry. \"Only don\\'t tell anyone, Wood\\nwants to keep it a secret.\"\\nFred and George Weasley now came into the hall, spotted Harry, and\\nhurried over.\\n\"Well done,\" said George in a low voice. \"Wood told us. We\\'re on the\\nteam too -- Beaters.\"\\n\"I tell you, we\\'re going to win that Quidditch cup for sure this year,\"\\nsaid Fred. \"We haven\\'t won since Charlie left, but this year\\'s team isgoing to be brilliant. You must be good, Harry, Wood was almost skippingwhen he told us.\"\\n\"Anyway, we\\'ve got to go, Lee Jordan reckons he\\'s found a new secret\\npassageway out of the school.\"\\n\"Bet it\\'s that one behind the statue of Gregory the Smarmy that we found\\nin our first week. See you.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 121}), Document(page_content='122Fred and George had hardly disappeared when someone far less welcome\\nturned up: Malfoy, flanked by Crabbe and Goyle.\\n\"Having a last meal, Potter? When are you getting the train back to the\\nMuggles?\"\\n\"You\\'re a lot braver now that you\\'re back on the ground and you\\'ve got\\nyour little friends with you,\" said Harry coolly. There was of coursenothing at all little about Crabbe and Goyle, but as the High Table wasfull of teachers, neither of them could do more than crack theirknuckles and scowl.\\n\"I\\'d take you on anytime on my own,\" said Malfoy. \"Tonight, if you want.\\nWizard\\'s duel. Wands only -- no contact. What\\'s the matter? Never heardof a wizard\\'s duel before, I suppose?\"\\n\"Of course he has,\" said Ron, wheeling around. \"I\\'m his second, who\\'s\\nyours?\"\\nMalfoy looked at Crabbe and Goyle, sizing them up.\\n\"Crabbe,\" he said. \"Midnight all right? We\\'ll meet you in the trophy\\nroom; that\\'s always unlocked.\"\\nWhen Malfoy had gone, Ron and Harry looked at each other. \"What is a\\nwizard\\'s duel?\" said Harry. \"And what do you mean, you\\'re my second?\"\\n\"Well, a second\\'s there to take over if you die,\" said Ron casually,\\ngetting started at last on his cold pie. Catching the look on Harry\\'sface, he added quickly, \"But people only die in proper duels, you know,with real wizards. The most you and Malfoy\\'ll be able to do is send\\nsparks at each other. Neither of you knows enough magic to do any real\\ndamage. I bet he expected you to refuse, anyway.\"\\n\"And what if I wave my wand and nothing happens?\"\"Throw it away and punch him on the nose,\" Ron suggested. \"Excuse me.\"\\nThey both looked up. It was Hermione Granger.\\n\"Can\\'t a person eat in peace in this place?\" said Ron.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 122}), Document(page_content='123Hermione ignored him and spoke to Harry.\\n\"I couldn\\'t help overhearing what you and Malfoy were saying --\"\"Bet you could,\" Ron muttered.\\n\"--and you mustn\\'t go wandering around the school at night, think of the\\npoints you\\'ll lose Gryffindor if you\\'re caught, and you\\'re bound to be.It\\'s really very selfish of you.\"\\n\"And it\\'s really none of your business,\" said Harry.\"Good-bye,\" said Ron.\\nAll the same, it wasn\\'t what you\\'d call the perfect end to the day,\\nHarry thought, as he lay awake much later listening to Dean and Seamusfalling asleep (Neville wasn\\'t back from the hospital wing). Ron hadspent all evening giving him advice such as \"If he tries to curse you,you\\'d better dodge it, because I can\\'t remember how to block them.\"\\nThere was a very good chance they were going to get caught by Filch or\\nMrs. Norris, and Harry felt he was pushing his luck, breaking anotherschool rule today. On the other hand, Malfoys sneering face kept loomingup out of the darkness - this was his big chance to beat Malfoyface-to-face. He couldn\\'t miss it.\\n\"Half-past eleven,\" Ron muttered at last, \"we\\'d better go.\"\\nThey pulled on their bathrobes, picked up their wands, and crept across\\nthe tower room, down the spiral staircase, and into the Gryffindorcommon room. A few embers were still glowing in the fireplace, turningall the armchairs into hunched black shadows. They had almost reachedthe portrait hole when a voice spoke from the chair nearest them, \"I\\ncan\\'t believe you\\'re going to do this, Harry.\"\\nA lamp flickered on. It was Hermione Granger, wearing a pink bathrobe\\nand a frown.\\n\"You!\" said Ron furiously. \"Go back to bed!\"\\n\"I almost told your brother,\" Hermione snapped, \"Percy -- he\\'s a\\nprefect, he\\'d put a stop to this.\"\\nHarry couldn\\'t believe anyone could be so interfering.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 123}), Document(page_content='124\"Come on,\" he said to Ron. He pushed open the portrait of the Fat Lady\\nand climbed through the hole.\\nHermione wasn\\'t going to give up that easily. She followed Ron through\\nthe portrait hole, hissing at them like an angry goose.\\n\"Don\\'t you care about Gryffindor, do you only care about yourselves, I\\ndon\\'t want Slytherin to win the house cup, and you\\'ll lose all thepoints I got from Professor McGonagall for knowing about SwitchingSpells.\"\\n\"Go away.\" \"All right, but I warned you, you just remember what I said\\nwhen you\\'re on the train home tomorrow, you\\'re so --\"\\nBut what they were, they didn\\'t find out. Hermione had turned to the\\nportrait of the Fat Lady to get back inside and found herself facing anempty painting. The Fat Lady had gone on a nighttime visit and Hermionewas locked out of Gryffindor tower.\\n\"Now what am I going to do?\" she asked shrilly.\\n\"That\\'s your problem,\" said Ron. \"We\\'ve got to go, we 3 re going to be\\nlate.\"\\nThey hadn\\'t even reached the end of the corridor when Hermione caught up\\nwith them.\\n\"I\\'m coming with you,\" she said.\"You are not.\"\\n\"D\\'you think I\\'m going to stand out here and wait for Filch to catch me?\\nIf he finds all three of us I\\'ll tell him the truth, that I was tryingto stop you, and you can back me up.\"\\n\"You\\'ve got some nerve --\" said Ron loudly.\"Shut up, both of you!\" said Harry sharply. I heard something.\"\\nIt was a sort of snuffling.\\n\"Mrs. Norris?\" breathed Ron, squinting through the dark.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 124}), Document(page_content='125It wasn\\'t Mrs. Norris. It was Neville. He was curled up on the floor,\\nfast asleep, but jerked suddenly awake as they crept nearer.\\n\"Thank goodness you found me! I\\'ve been out here for hours, I couldn\\'t\\nremember the new password to get in to bed.\"\\n\"Keep your voice down, Neville. The password\\'s \\'Pig snout\\' but it won\\'t\\nhelp you now, the Fat Lady\\'s gone off somewhere.\"\\n\"How\\'s your arm?\" said Harry.\"Fine,\" said Neville, showing them. \"Madam Pomfrey mended it in about a\\nminute.\"\\n\"Good - well, look, Neville, we\\'ve got to be somewhere, we\\'ll see you\\nlater --\"\\n\"Don\\'t leave me!\" said Neville, scrambling to his feet, \"I don\\'t want to\\nstay here alone, the Bloody Baron\\'s been past twice already.\"\\nRon looked at his watch and then glared furiously at Hermione and\\nNeville.\\n\"If either of you get us caught, I\\'ll never rest until I\\'ve learned that\\nCurse of the Bogies Quirrell told us about, and used it on you.\\nHermione opened her mouth, perhaps to tell Ron exactly how to use the\\nCurse of the Bogies, but Harry hissed at her to be quiet and beckonedthem all forward.\\nThey flitted along corridors striped with bars of moonlight from the\\nhigh windows. At every turn Harry expected to run into Filch or Mrs.\\nNorris, but they were lucky. They sped up a staircase to the third floorand tiptoed toward the trophy room.\\nMalfoy and Crabbe weren\\'t there yet. The crystal trophy cases glimmered\\nwhere the moonlight caught them. Cups, shields, plates, and statueswinked silver and gold in the darkness. They edged along the walls,\\nkeeping their eyes on the doors at either end of the room. Harry took\\nout his wand in case Malfoy leapt in and started at once. The minutescrept by.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 125}), Document(page_content='126\"He\\'s late, maybe he\\'s chickened out,\" Ron whispered.\\nThen a noise in the next room made them jump. Harry had only just raised\\nhis wand when they heard someone speak -and it wasn\\'t Malfoy.\\n\"Sniff around, my sweet, they might be lurking in a corner.\"\\nIt was Filch speaking to Mrs. Norris. Horror-struck, Harry waved madly\\nat the other three to follow him as quickly as possible; they scurriedsilently toward the door, away from Filch\\'s voice. Neville\\'s robes hadbarely whipped round the corner when they heard Filch enter the trophyroom.\\n\"They\\'re in here somewhere,\" they heard him mutter, \"probably hiding.\"\\n\"This way!\" Harry mouthed to the others and, petrified, they began to\\ncreep down a long gallery full of suits of armor. They could hear Filchgetting nearer. Neville suddenly let out a frightened squeak and brokeinto a run -he tripped, grabbed Ron around the waist, and the pair of\\nthem toppled right into a suit of armor.\\nThe clanging and crashing were enough to wake the whole castle.\"RUN!\" Harry yelled, and the four of them sprinted down the gallery, not\\nlooking back to see whether Filch was following -- they swung around thedoorpost and galloped down one corridor then another, Harry in the lead,\\nwithout any idea where they were or where they were going -- they ripped\\nthrough a tapestry and found themselves in a hidden passageway, hurtledalong it and came out near their Charms classroom, which they knew wasmiles from the trophy room.\\n\"I think we\\'ve lost him,\" Harry panted, leaning against the cold wall\\nand wiping his forehead. Neville was bent double, wheezing and\\nspluttering.\\nI -- told -you,\" Hermione gasped, clutching at the stitch in her chest,\\n\"I -- told -- you.\"\\n\"We\\'ve got to get back to Gryffindor tower,\" said Ron, \"quickly as\\npossible.\"\\n\"Malfoy tricked you,\" Hermione said to Harry. \"You realize that, don\\'t\\nyou? He was never going to meet you -- Filch knew someone was going to', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 126}), Document(page_content='127be in the trophy room, Malfoy must have tipped him off.\"\\nHarry thought she was probably right, but he wasn\\'t going to tell her\\nthat.\\n\"Let\\'s go.\"\\nIt wasn\\'t going to be that simple. They hadn\\'t gone more than a dozen\\npaces when a doorknob rattled and something came shooting out of aclassroom in front of them.\\nIt was Peeves. He caught sight of them and gave a squeal of delight.\\n\"Shut up, Peeves -- please -- you\\'ll get us thrown out.\"\\nPeeves cackled.\"Wandering around at midnight, Ickle Firsties? Tut, tut, tut. Naughty,\\nnaughty, you\\'ll get caughty.\"\\n\"Not if you don\\'t give us away, Peeves, please.\"\\n\"Should tell Filch, I should,\" said Peeves in a saintly voice, but his\\neyes glittered wickedly. \"It\\'s for your own good, you know.\"\\n\"Get out of the way,\" snapped Ron, taking a swipe at Peeves this was a\\nbig mistake.\\n\"STUDENTS OUT OF BED!\" Peeves bellowed, \"STUDENTS OUT OF BED\\nDOWN THECHARMS CORRIDOR\"\\nDucking under Peeves, they ran for their lives, right to the end of the\\ncorridor where they slammed into a door -- and it was locked.\\n\"This is it!\" Ron moaned, as they pushed helplessly at the door, \"We\\'re\\ndone for! This is the end!\" They could hear footsteps, Filch running asfast as he could toward Peeves\\'s shouts.\\n\"Oh, move over,\" Hermione snarled. She grabbed Harry\\'s wand, tapped the\\nlock, and whispered, \\'Alohomora!\"\\nThe lock clicked and the door swung open -- they piled through it, shut', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 127}), Document(page_content='128it quickly, and pressed their ears against it, listening.\\n\"Which way did they go, Peeves?\" Filch was saying. \"Quick, tell me.\"\"Say \\'please.\"\\'\\n\"Don\\'t mess with me, Peeves, now where did they go?\"\\n\"Shan\\'t say nothing if you don\\'t say please,\" said Peeves in his\\nannoying singsong voice.\\n\"All right -please.\"\\n\"NOTHING! Ha haaa! Told you I wouldn\\'t say nothing if you didn\\'t say\\nplease! Ha ha! Haaaaaa!\" And they heard the sound of Peeves whooshingaway and Filch cursing in rage.\\n\"He thinks this door is locked,\" Harry whispered. \"I think we\\'ll be okay\\n-- get off, Neville!\" For Neville had been tugging on the sleeve of\\nHarry\\'s bathrobe for the last minute. \"What?\"\\nHarry turned around -- and saw, quite clearly, what. For a moment, he\\nwas sure he\\'d walked into a nightmare -- this was too much, on top ofeverything that had happened so far.\\nThey weren\\'t in a room, as he had supposed. They were in a corridor. The\\nforbidden corridor on the third floor. And now they knew why it was\\nforbidden.\\nThey were looking straight into the eyes of a monstrous dog, a dog that\\nfilled the whole space between ceiling and floor. It had three heads.Three pairs of rolling, mad eyes; three noses, twitching\\nand quivering in their direction; three drooling mouths, saliva hanging\\nin slippery ropes from yellowish fangs.\\nIt was standing quite still, all six eyes staring at them, and Harry\\nknew that the only reason they weren\\'t already dead was that theirsudden appearance had taken it by surprise, but it was quickly getting\\nover that, there was no mistaking what those thunderous growls meant.\\nHarry groped for the doorknob -- between Filch and death, he\\'d take\\nFilch.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 128}), Document(page_content='129They fell backward -- Harry slammed the door shut, and they ran, they\\nalmost flew, back down the corridor. Filch must have hurried off to lookfor them somewhere else, because they didn\\'t see him anywhere, but theyhardly cared -- all they wanted to do was put as much space as possiblebetween them and that monster. They didn\\'t stop running until they\\nreached the portrait of the Fat Lady on the seventh floor.\\n\"Where on earth have you all been?\" she asked, looking at their\\nbathrobes hanging off their shoulders and their flushed, sweaty faces.\\n\"Never mind that -- pig snout, pig snout,\" panted Harry, and the\\nportrait swung forward. They scrambled into the common room and\\ncollapsed, trembling, into armchairs.\\nIt was a while before any of them said anything. Neville, indeed, looked\\nas if he\\'d never speak again.\\n\"What do they think they\\'re doing, keeping a thing like that locked up\\nin a school?\" said Ron finally. \"If any dog needs exercise, that one\\ndoes.\"\\nHermione had got both her breath and her bad temper back again. \"You\\ndon\\'t use your eyes, any of you, do you?\" she snapped. \"Didn\\'t you seewhat it was standing on.\\n\"The floor?\" Harry suggested. \"I wasn\\'t looking at its feet, I was too\\nbusy with its heads.\"\\n\"No, not the floor. It was standing on a trapdoor. It\\'s obviously\\nguarding something.\"\\nShe stood up, glaring at them.\\nI hope you\\'re pleased with yourselves. We could all have been killed --\\nor worse, expelled. Now, if you don\\'t mind, I\\'m going to bed.\"\\nRon stared after her, his mouth open.\\n\"No, we don\\'t mind,\" he said. \"You\\'d think we dragged her along,\\nwouldn\\'t you.\\nBut Hermione had given Harry something else to think about as he climbed', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 129}), Document(page_content='130back into bed. The dog was guarding something.... What had Hagrid said?\\nGringotts was the safest place in the world for something you wanted tohide -- except perhaps Hogwarts.\\nIt looked as though Harry had found out where the grubby littie package\\nfrom vault seven hundred and thirteen was.\\nCHAPTER TEN\\nHALLOWEENMalfoy couldn\\'t believe his eyes when he saw that Harry and Ron were\\nstill at Hogwarts the next day, looking tired but perfectly cheerful.\\nIndeed, by the next morning Harry and Ron thought that meeting thethree-headed dog had been an excellent adventure, and they were quitekeen to have another one. In the meantime, Harry filled Ron in about thepackage that seemed to have been moved from Gringotts to Hogwarts, andthey spent a lot of time wondering what could possibly need such heavy\\nprotection. \"It\\'s either really valuable or really dangerous,\" said Ron.\\n\"Or both,\" said Harry.\\nBut as all they knew for sure about the mysterious object was that it\\nwas about two inches long, they didn\\'t have much chance of guessing whatit was without further clues.\\nNeither Neville nor Hermione showed the slightest interest in what lay\\nunderneath the dog and the trapdoor. All Neville cared about was nevergoing near the dog again.\\nHermione was now refusing to speak to Harry and Ron, but she was such a\\nbossy know-it-all that they saw this as an added bonus. All they really\\nwanted now was a way of getting back at Malfoy, and to their greatdelight, just such a thing arrived in the mail about a week later.\\nAs the owls flooded into the Great Hall as usual, everyone\\'s attention\\nwas caught at once by a long, thin package carried by six large screechowls. Harry was just as interested as everyone else to see what was in\\nthis large parcel, and was amazed when the owls soared down and dropped\\nit right in front of him, knocking his bacon to the floor. They hadhardly fluttered out of the way when another owl dropped a letter on topof the parcel.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 130}), Document(page_content='131Harry ripped open the letter first, which was lucky, because it said:\\nDO NOT OPEN THE PARCEL AT THE TABLE.\\nIt contains your new Nimbus Two Thousand, but I don\\'t want everybody\\nknowing you\\'ve got a broomstick or they\\'ll all want one. Oliver Woodwill meet you tonight on the Quidditch field at seven o\\'clock for yourfirst training session.\\nProfessor McGonagall\\nHarry had difficulty hiding his glee as he handed the note to Ron to\\nread.\\n\"A Nimbus Two Thousand!\" Ron moaned enviously. \"I\\'ve never even touched\\none.\"\\nThey left the hall quickly, wanting to unwrap the broomstick in private\\nbefore their first class, but halfway across the entrance hall theyfound the way upstairs barred by Crabbe and Goyle. Malfoy seized thepackage from Harry and felt it.\\n\"That\\'s a broomstick,\" he said, throwing it back to Harry with a mixture\\nof jealousy and spite on his face. \"You\\'ll be in for it this time,\\nPotter, first years aren\\'t allowed them.\"\\nRon couldn\\'t resist it.\"It\\'s not any old broomstick,\" he said, \"it\\'s a Nimbus Two Thousand.\\nWhat did you say you\\'ve got at home, Malfoy, a Comet Two Sixty?\" Ron\\ngrinned at Harry. \"Comets look flashy, but they\\'re not in the same\\nleague as the Nimbus.\"\\n\"What would you know about it, Weasley, you couldn\\'t afford half the\\nhandle,\" Malfoy snapped back. \"I suppose you and your brothers have tosave up twig by twig.\"\\nBefore Ron could answer, Professor Flitwick appeared at Malfoy\\'s elbow.\\n\"Not arguing, I hope, boys?\" he squeaked.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 131}), Document(page_content='132\"Potter\\'s been sent a broomstick, Professor,\" said Malfoy quickly.\\n\"Yes, yes, that\\'s right,\" said Professor Flitwick, beaming at Harry.\\n\"Professor McGonagall told me all about the special circumstances,Potter. And what model is it?\"\\n\"A Nimbus Two Thousand, sit,\" said Harry, fighting not to laugh at the\\nlook of horror on Malfoy\\'s face. \"And it\\'s really thanks to Malfoy herethat I\\'ve got it,\" he added.\\nHarry and Ron headed upstairs, smothering their laughter at Malfoy\\'s\\nobvious rage and confusion. \"Well, it\\'s true,\" Harry chortled as theyreached the top of the marble staircase, \"If he hadn\\'t stolen Neville\\'s\\nRemembrall I wouln\\'t be on the team....\"\\n\"So I suppose you think that\\'s a reward for breaking rules?\" came an\\nangry voice from just behind them. Hermione was stomping up the stairs,looking disapprovingly at the package in Harry\\'s hand.\\n\"I thought you weren\\'t speaking to us?\" said Harry.\\n\"Yes, don\\'t stop now,\" said Ron, \"it\\'s doing us so much good.\"Hermione marched away with her nose in the air.Harry had a lot of trouble keeping his mind on his lessons that day. It\\nkept wandering up to the dormitory where his new broomstick was lying\\nunder his bed, or straying off to the Quidditch field where he\\'d belearning to play that night. He bolted his dinner that evening withoutnoticing what he was eating, and then rushed upstairs with Ron to unwrapthe Nimbus Two Thousand at last.\\n\"Wow,\" Ron sighed, as the broomstick rolled onto Harry\\'s bedspread.\\nEven Harry, who knew nothing about the different brooms, thought it\\nlooked wonderful. Sleek and shiny, with a mahogany handle, it had a longtail of neat, straight twigs and Nimbus Two Thousand written in goldnear the top.\\nAs seven o\\'clock drew nearer, Harry left the castle and set off in the\\ndusk toward the Quidditch field. Held never been inside the stadiumbefore. Hundreds of seats were raised in stands around the field so thatthe spectators were high enough to see what was going on. At either end', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 132}), Document(page_content='133of the field were three golden poles with hoops on the end. They\\nreminded Harry of the little plastic sticks Muggle\\nchildren blew bubbles through, except that they were fifty feet high.Too eager to fly again to wait for Wood, Harry mounted his broomstick\\nand kicked off from the ground. What a feeling -- he swooped in and out\\nof the goal posts and then sped up and down the field. The Nimbus TwoThousand turned wherever he wanted at his lightest touch.\\n\"Hey, Potter, come down!\\'Oliver Wood had arrived. fie was carrying a large wooden crate under his\\narm. Harry landed next to him.\\n\"Very nice,\" said Wood, his eyes glinting. \"I see what McGonagall\\nmeant... you really are a natural. I\\'m just going to teach you the rulesthis evening, then you\\'ll be joining team practice three times a week.\"\\nHe opened the crate. Inside were four different-sized balls.\\n\"Right,\" said Wood. \"Now, Quidditch is easy enough to understand, even\\nif it\\'s not too easy to play. There are seven players on each side.Three of them are called Chasers.\"\\n\"Three Chasers,\" Harry repeated, as Wood took out a bright red ball\\nabout the size of a soccer ball.\\n\"This ball\\'s called the Quaffle,\" said Wood. \"The Chasers throw the\\nQuaffle to each other and try and get it through one of the hoops toscore a goal. Ten points every time the Quaffle goes through one of thehoops. Follow me?\"\\n\"The Chasers throw the Quaffle and put it through the hoops to score,\"\\nHarry recited. \"So -- that\\'s sort of like basketball on broomsticks withsix hoops, isn\\'t it?\"\\n\"What\\'s basketball?\" said Wood curiously. \"Never mind,\" said Harry\\nquickly.\\n\"Now, there\\'s another player on each side who\\'s called the Keeper -I\\'m\\nKeeper for Gryffindor. I have to fly around our hoops and stop the otherteam from scoring.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 133}), Document(page_content='134\"Three Chasers, one Keeper,\" said Harry, who was determined to remember\\nit all. \"And they play with the Quaffle. Okay, got that. So what arethey for?\" He pointed at the three balls left inside the box.\\n\"I\\'ll show you now,\" said Wood. \"Take this.\"\\nHe handed Harry a small club, a bit like a short baseball bat.\\n\"I\\'m going to show you what the Bludgers do,\" Wood said. \"These two are\\nthe Bludgers.\"\\nHe showed Harry two identical balls, jet black and slightly smaller than\\nthe red Quaffle. Harry noticed that they seemed to be straining to\\nescape the straps holding them inside the box.\\n\"Stand back,\" Wood warned Harry. He bent down and freed one of the\\nBludgers.\\nAt once, the black ball rose high in the air and then pelted straight at\\nHarry\\'s face. Harry swung at it with the bat to stop it from breakinghis nose, and sent it zigzagging away into the air -- it zoomed aroundtheir heads and then shot at Wood, who dived on top of it and managed topin it to the ground.\\n\"See?\" Wood panted, forcing the struggling Bludger back into the crate\\nand strapping it down safely. \"The Bludgers rocket around, trying to\\nknock players off their brooms. That\\'s why you have two Beaters on eachteam -- the Weasley twins are ours -- it\\'s their job to protect theirside from the Bludgers and try and knock them toward the other team. So-- think you\\'ve got all that?\"\\n\"Three Chasers try and score with the Quaffle; the Keeper guards the\\ngoal posts; the Beaters keep the Bludgers away from their team,\" Harryreeled off.\\n\"Very good,\" said Wood.\"Er -- have the Bludgers ever killed anyone?\" Harry asked, hoping he\\nsounded offhand.\\n\"Never at Hogwarts. We\\'ve had a couple of broken jaws but nothing worse\\nthan that. Now, the last member of the team is the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 134}), Document(page_content='135Seeker. That\\'s you. And you don\\'t have to worry about the Quaffle or the\\nBludgers unless they crack my head open.\"\\n\"Don\\'t worry, the Weasleys are more than a match for the Bludgers -- I\\nmean, they\\'re like a pair of human Bludgers themselves.\"\\nWood reached into the crate and took out the fourth and last ball.\\nCompared with the Quaffle and the Bludgers, it was tiny, about the sizeof a large walnut. It was bright gold and had little fluttering silverwings.\\n\"This,\" said Wood, \"is the Golden Snitch, and it\\'s the most important\\nball of the lot. It\\'s very hard to catch because it\\'s so fast and\\ndifficult to see. It\\'s the Seeker\\'s job to catch it. You\\'ve got to weavein and out of the Chasers, Beaters, Bludgers, and Quaffle to get itbefore the other team\\'s Seeker, because whichever Seeker catches theSnitch wins his team an extra hundred and fifty points, so they\\nnearly always win. That\\'s why Seekers get fouled so much. A game of\\nQuidditch only ends when the Snitch is caught, so it can go on for ages-- I think the record is three months, they had to keep bringing onsubstitutes so the players could get some sleep. \"Well, that\\'s it -- anyquestions?\"\\nHarry shook his head. He understood what he had to do all right, it was\\ndoing it that was going to be the problem.\\n\"We won\\'t practice with the Snitch yet,\" said Wood, carefully shutting\\nit back inside the crate, \"it\\'s too dark, we might lose it. Let\\'s tryyou out with a few of these.\"\\nHe pulled a bag of ordinary golf balls out of his pocket and a few\\nminutes later, he and Harry were up in the air, Wood throwing the golfballs as hard as he could in every direction for Harry to catch.\\nHarry didn\\'t miss a single one, and Wood was delighted. After half an\\nhour, night had really fallen and they couldn\\'t carry on.\\n\"That Quidditch cup\\'ll have our name on it this year,\" said Wood happily\\nas they trudged back up to the castle. \"I wouldn\\'t be surprised if youturn out better than Charlie Weasley, and he could have played forEngland if he hadn\\'t gone off chasing dragons.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 135}), Document(page_content='136Perhaps it was because he was now so busy, what with Quidditch practice\\nthree evenings a week on top of all his homework, but Harry could hardlybelieve it when he realized that he\\'d already been at Hogwarts twomonths. The castle felt more like home than Privet Drive ever had. Hislessons, too, were becoming more and more interesting now that they had\\nmastered the basics.\\nOn Halloween morning they woke to the delicious smell of baking pumpkin\\nwafting through the corridors. Even better, Professor Flitwick announcedin Charms that he thought they were ready to start making objects fly,something they had all been dying to try since they\\'d seen him makeNeville\\'s toad zoom around the classroom. Professor Flitwick put the\\nclass into pairs to practice. Harry\\'s partner was Seamus Finnigan (which\\nwas a relief, because Neville had been trying to catch his eye). Ron,however, was to be working with Hermione Granger. It was hard to tellwhether Ron or Hermione was angrier about this. She hadn\\'t spoken toeither of them since the day Harry\\'s broomstick had arrived.\\n\"Now, don\\'t forget that nice wrist movement we\\'ve been practicing!\"\\nsqueaked Professor Flitwick, perched on top of his pile of books asusual. \"Swish and flick, remember, swish and flick. And saying the magicwords properly is very important, too -- never forget Wizard Baruffio,who said \\'s\\' instead of \\'f\\' and found himself on the floor with abuffalo on his chest.\"\\nIt was very difficult. Harry and Seamus swished and flicked, but the\\nfeather they were supposed to be sending skyward just lay on thedesktop. Seamus got so impatient that he prodded it with his wand andset fire to it -- Harry had to put it out with his hat.\\nRon, at the next table, wasn\\'t having much more luck.\\n\"Wingardium Leviosa!\" he shouted, waving his long arms like a windmill.\\n\"You\\'re saying it wrong,\" Harry heard Hermione snap. \"It\\'s Wing-gar-dium\\nLevi-o-sa, make the \\'gar\\' nice and long.\"\\n\"You do it, then, if you\\'re so clever,\" Ron snarled.\\nHermione rolled up the sleeves of her gown, flicked her wand, and said,\\n\"Wingardium Leviosa!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 136}), Document(page_content='137Their feather rose off the desk and hovered about four feet above their\\nheads.\\n\"Oh, well done!\" cried Professor Flitwick, clapping. \"Everyone see here,\\nMiss Granger\\'s done it!\"\\nRon was in a very bad mood by the end of the class. \"It\\'s no wonder no\\none can stand her,\" he said to Harry as they pushed their way into thecrowded corridor, \"she\\'s a nightmare, honestly. \"\\nSomeone knocked into Harry as they hurried past him. It was Hermione.\\nHarry caught a glimpse of her face -- and was startled to see that she\\nwas in tears.\\n\"I think she heard you.\"\"So?\" said Ron, but he looked a bit uncomfortable. \"She must\\'ve noticed\\nshe\\'s got no friends.\"\\nHermione didn\\'t turn up for the next class and wasn\\'t seen all\\nafternoon. On their way down to the Great Hall for the Halloween feast,Harry and Ron overheard Parvati Patil telling her friend Lavender thatHermione was crying in the girls\\' bathroom and wanted to be left alone.Ron looked still more awkward at this, but a moment later they hadentered the Great Hall, where the Halloween decorations put Hermione out\\nof their minds.\\nA thousand live bats fluttered from the walls and ceiling while a\\nthousand more swooped over the tables in low black clouds, making thecandles in the pumpkins stutter. The feast appeared suddenly on thegolden plates, as it had at the start-of-term banquet.\\nHarry was just helping himself to a baked potato when Professor Quirrell\\ncame sprinting into the hall, his turban askew and terror on his face.Everyone stared as he reached Professor Dumbledore\\'s chair, slumpedagainst the table, and gasped, \"Troll -- in the dungeons -- thought youought to know.\"\\nHe then sank to the floor in a dead faint.\\nThere was an uproar. It took several purple firecrackers exploding from\\nthe end of Professor Dumbledore\\'s wand to bring silence.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 137}), Document(page_content='138\"Prefects,\" he rumbled, \"lead your Houses back to the dormitories\\nimmediately!\"\\nPercy was in his element.\\n\"Follow me! Stick together, first years! No need to fear the troll if\\nyou follow my orders! Stay close behind me, now. Make way, first yearscoming through! Excuse me, I\\'m a prefect!\"\\n\"How could a troll get in?\" Harry asked as they climbed the stairs.\"Don\\'t ask me, they\\'re supposed to be really stupid,\" said Ron. \"Maybe\\nPeeves let it in for a Halloween joke.\"\\nThey passed different groups of people hurrying in different directions.\\nAs they jostled their way through a crowd of confused Hufflepuffs, Harrysuddenly grabbed Ron\\'s arm.\\n\"I\\'ve just thought -- Hermione.\"\\n\"What about her?\"\"She doesn\\'t know about the troll.\"Ron bit his lip.\\n\"Oh, all right,\" he snapped. \"But Percy\\'d better not see us.\"\\nDucking down, they joined the Hufflepuffs going the other way, slipped\\ndown a deserted side corridor, and hurried off toward the girls\\'bathroom. They had just turned the corner when they heard quick\\nfootsteps behind them.\\n\"Percy!\" hissed Ron, pulling Harry behind a large stone griffin.Peering around it, however, they saw not Percy but Snape. He crossed the\\ncorridor and disappeared from view.\\n\"What\\'s he doing?\" Harry whispered. \"Why isn\\'t he down in the dungeons\\nwith the rest of the teachers?\"\\n\"Search me.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 138}), Document(page_content='139Quietly as possible, they crept along the next corridor after Snape\\'s\\nfading footsteps.\\n\"He\\'s heading for the third floor,\" Harry said, but Ron held up his\\nhand.\\n\"Can you smell something?\"\\nHarry sniffed and a foul stench reached his nostrils, a mixture of old\\nsocks and the kind of public toilet no one seems to clean.\\nAnd then they heard it -- a low grunting, and the shuffling footfalls of\\ngigantic feet. Ron pointed -- at the end of a passage to the left,\\nsomething huge was moving toward them. They shrank into the shadows andwatched as it emerged into a patch of moonlight.\\nIt was a horrible sight. Twelve feet tall, its skin was a dull, granite\\ngray, its great lumpy body like a boulder with its small bald head\\nperched on top like a coconut. It had short legs thick as tree trunks\\nwith flat, horny feet. The smell coming from it was incredible. It washolding a huge wooden club, which dragged along the floor because itsarms were so long.\\nThe troll stopped next to a doorway and peered inside. It waggled its\\nlong ears, making up its tiny mind, then slouched slowly into the room.\\n\"The keys in the lock,\" Harry muttered. \"We could lock it in.\"\\n\"Good idea,\" said Ron nervously.They edged toward the open door, mouths dry, praying the troll wasn\\'t\\nabout to come out of it. With one great leap, Harry managed to grab the\\nkey, slam the door, and lock it.\\n\\'Yes!\"Flushed with their victory, they started to run back up the passage, but\\nas they reached the corner they heard something that made their hearts\\nstop -- a high, petrified scream -- and it was coming from the chamber\\nthey\\'d just chained up.\\n\"Oh, no,\" said Ron, pale as the Bloody Baron.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 139}), Document(page_content='140\"It\\'s the girls\\' bathroom!\" Harry gasped.\\n\"Hermione!\" they said together.It was the last thing they wanted to do, but what choice did they have?\\nWheeling around, they sprinted back to the door and turned the key,\\nfumbling in their panic. Harry pulled the door open and they ran inside.\\nHermione Granger was shrinking against the wall opposite, looking as if\\nshe was about to faint. The troll was advancing on her, knocking thesinks off the walls as it went.\\n\"Confuse it!\" Harry said desperately to Ron, and, seizing a tap, he\\nthrew it as hard as he could against the wall.\\nThe troll stopped a few feet from Hermione. It lumbered around, blinking\\nstupidly, to see what had made the noise. Its mean little eyes sawHarry. It hesitated, then made for him instead, lifting its club as it\\nwent.\\n\"Oy, pea-brain!\" yelled Ron from the other side of the chamber, and he\\nthrew a metal pipe at it. The troll didn\\'t even seem to notice the pipehitting its shoulder, but it heard the yell and paused again, turningits ugly snout toward Ron instead, giving Harry time to run around it.\\n\"Come on, run, run!\" Harry yelled at Hermione, trying to pull her toward\\nthe door, but she couldn\\'t move, she was still flat against the wall,her mouth open with terror.\\nThe shouting and the echoes seemed to be driving the troll berserk. It\\nroared again and started toward Ron, who was nearest and had no way to\\nescape.\\nHarry then did something that was both very brave and very stupid: He\\ntook a great running jump and managed to fasten his arms around thetroll\\'s neck from behind. The troll couldn\\'t feel Harry hanging there,but even a troll will notice if you stick a long bit of wood up itsnose, and Harry\\'s wand had still been in his hand when he\\'d jumped -- it\\nhad gone straight up one of the troll\\'s nostrils.\\nHowling with pain, the troll twisted and flailed its club, with Harry\\nclinging on for dear life; any second, the troll was going to rip him', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 140}), Document(page_content='141off or catch him a terrible blow with the club.\\nHermione had sunk to the floor in fright; Ron pulled out his own wand --\\nnot knowing what he was going to do he heard himself cry the first spellthat came into his head: \"Wingardium Leviosa!\"\\nThe club flew suddenly out of the troll\\'s hand, rose high, high up into\\nthe air, turned slowly over -- and dropped, with a sickening crack, ontoits owner\\'s head. The troll swayed on the spot and then fell flat on itsface, with a thud that made the whole room tremble.\\nHarry got to his feet. He was shaking and out of breath. Ron was\\nstanding there with his wand still raised, staring at what he had done.\\nIt was Hermione who spoke first.\\n\"Is it -- dead?\"I don\\'t think so,\" said Harry, I think it\\'s just been knocked out.\"\\nHe bent down and pulled his wand out of the troll\\'s nose. It was covered\\nin what looked like lumpy gray glue.\\n\"Urgh -- troll boogers.\"He wiped it on the troll\\'s trousers.\\nA sudden slamming and loud footsteps made the three of them look up.\\nThey hadn\\'t realized what a racket they had been making, but of course,someone downstairs must have heard the crashes and the troll\\'s roars. Amoment later, Professor McGonagall had come bursting into the room,closely followed by Snape, with Quirrell bringing up the rear. Quirrell\\ntook one look at the troll, let out a faint whimper, and sat quickly\\ndown on a toilet, clutching his heart.\\nSnape bent over the troll. Professor McGonagall was looking at Ron and\\nHarry. Harry had never seen her look so angry. Her lips were white.Hopes of winning fifty points for Gryffindor faded quickly from Harry\\'smind.\\n\"What on earth were you thinking of?\" said Professor McGonagall, with\\ncold fury in her voice. Harry looked at Ron, who was still standing withhis wand in the air. \"You\\'re lucky you weren\\'t killed. Why aren\\'t you in', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 141}), Document(page_content='142your dormitory?\"\\nSnape gave Harry a swift, piercing look. Harry looked at the floor. He\\nwished Ron would put his wand down.\\nThen a small voice came out of the shadows.\\n\"Please, Professor McGonagall -- they were looking for me.\"\\n\"Miss Granger!\"Hermione had managed to get to her feet at last.\\nI went looking for the troll because I -- I thought I could deal with it\\non my own -- you know, because I\\'ve read all about them.\"\\nRon dropped his wand. Hermione Granger, telling a downright lie to a\\nteacher? \"If they hadn\\'t found me, I\\'d be dead now. Harry stuck his wandup its nose and Ron knocked it out with its own club. They didn\\'t have\\ntime to come and fetch anyone. It was about to finish me off when they\\narrived.\"\\nHarry and Ron tried to look as though this story wasn\\'t new to them.\"Well -- in that case...\" said Professor McGonagall, staring at the\\nthree of them, \"Miss Granger, you foolish girl, how could you think of\\ntackling a mountain troll on your own?\"\\nHermione hung her head. Harry was speechless. Hermione was the last\\nperson to do anything against the rules, and here she was, pretendingshe had, to get them out of trouble. It was as if Snape had startedhanding out sweets.\\n\"Miss Granger, five points will be taken from Gryffindor for this,\" said\\nProfessor McGonagall. \"I\\'m very disappointed in you. If you\\'re not hurtat all, you\\'d better get off to Gryffindor tower. Students are finishingthe feast in their houses.\"\\nHermione left.\\nProfessor McGonagall turned to Harry and Ron.\\n\"Well, I still say you were lucky, but not many first years could have', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 142}), Document(page_content='143taken on a full-grown mountain troll. You each win Gryffindor five\\npoints. Professor Dumbledore will be informed of this. You may go.\"\\nThey hurried out of the chamber and didn\\'t speak at all until they had\\nclimbed two floors up. It was a relief to be away from the smell of thetroll, quite apart from anything else.\\n\"We should have gotten more than ten points,\" Ron grumbled.\\n\"Five, you mean, once she\\'s taken off Hermione\\'s.\"\"Good of her to get us out of trouble like that,\" Ron admitted. \"Mind\\nyou, we did save her.\"\\n\"She might not have needed saving if we hadn\\'t locked the thing in with\\nher,\" Harry reminded him.\\nThey had reached the portrait of the Fat Lady.\\n\"Pig snout,\" they said and entered.\\nThe common room was packed and noisy. Everyone was eating the food that\\nhad been sent up. Hermione, however, stood alone by the door, waitingfor them. There was a very embarrassed pause. Then, none of them lookingat each other, they all said \"Thanks,\" and hurried off to get plates.\\nBut from that moment on, Hermione Granger became their friend. There are\\nsome things you can\\'t share without ending up liking each other, andknocking out a twelve-foot mountain troll is one of them.\\nCHAPTER ELEVEN\\nQUIDDITCH\\nAs they entered November, the weather turned very cold. The mountains\\naround the school became icy gray and the lake like chilled steel. Everymorning the ground was covered in frost. Hagrid could be seen from theupstairs windows defrosting broomsticks on the Quidditch field, bundled\\nup in a long moleskin overcoat, rabbit fur gloves, and enormous\\nbeaverskin boots.\\nThe Quidditch season had begun. On Saturday, Harry would be playing in', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 143}), Document(page_content='144his first match after weeks of training: Gryffindor versus Slytherin. If\\nGryffindor won, they would move up into second place in the housechampionship.\\nHardly anyone had seen Harry play because Wood had decided that, as\\ntheir secret weapon, Harry should be kept, well, secret. But the news\\nthat he was playing Seeker had leaked out somehow, and Harry didn\\'t know\\nwhich was worse -- people telling him he\\'d be brilliant or peopletelling him they\\'d be running around underneath him holding a mattress.\\nIt was really lucky that Harry now had Hermlone as a friend. He didn\\'t\\nknow how he\\'d have gotten through all his homework without her, whatwith all the last-minute Quidditch practice Wood was making them do. She\\nhad also tent him Quidditch Through the Ages, which turned out to be a\\nvery interesting read.\\nHarry learned that there were seven hundred ways of committing a\\nQuidditch foul and that all of them had happened during a World Cupmatch in 1473; that Seekers were usually the smallest and fastest\\nplayers, and that most serious Quidditch accidents seemed to happen to\\nthem; that although people rarely died playing Quidditch, referees hadbeen known to vanish and turn up months later in the Sahara Desert.\\nHermione had become a bit more relaxed about breaking rules since Harry\\nand Ron had saved her from the mountain troll, and she was much nicerfor it. The day before Harry\\'s first Quidditch match the three of them\\nwere out in the freezing courtyard during break, and she had conjured\\nthem up a bright blue fire that could be carried around in a jam jar.They were standing with their backs to it, getting warm, when Snapecrossed the yard. Harry noticed at once that Snape was limping. Harry,Ron, and Hermione moved closer together to block the fire from view;they were sure it wouldn\\'t be allowed. Unfortunately, something about\\ntheir guilty faces caught Snape\\'s eye. He limped over. He hadn\\'t seen\\nthe fire, but he seemed to be looking for a reason to tell them offanyway.\\n\"What\\'s that you\\'ve got there, Potter?\"It was Quidditch Through the Ages. Harry showed him.\\n\"Library books are not to be taken outside the school,\" said Snape.\\n\"Give it to me. Five points from Gryffindor.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 144}), Document(page_content='145\"He\\'s just made that rule up,\" Harry muttered angrily as Snape limped\\naway. \"Wonder what\\'s wrong with his leg?\"\\n\"Dunno, but I hope it\\'s really hurting him,\" said Ron bitterly.The Gryffindor common room was very noisy that evening. Harry, Ron, and\\nHermione sat together next to a window. Hermione was checking Harry and\\nRon\\'s Charms homework for them. She would never let them copy (\"How willyou learn?\"), but by asking her to read it through, they got the rightanswers anyway.\\nHarry felt restless. He wanted Quidditch Through the Ages back, to take\\nhis mind off his nerves about tomorrow. Why should he be afraid of\\nSnape? Getting up, he told Ron and Hermione he was going to ask Snape if\\nhe could have it.\\n\"Better you than me,\" they said together, but Harry had an idea that\\nSnape wouldn\\'t refuse if there were other teachers listening.\\nHe made his way down to the staffroom and knocked. There was no answer.\\nHe knocked again. Nothing.\\nPerhaps Snape had left the book in there? It was worth a try. He pushed\\nthe door ajar and peered inside -- and a horrible scene met his eyes.\\nSnape and Filch were inside, alone. Snape was holding his robes above\\nhis knees. One of his legs was bloody and mangled. Filch was handing\\nSnape bandages.\\n\"Blasted thing*,\" Snape was saying. \"How are you supposed to keep your\\neyes on all three heads at once?\"\\nHarry tried to shut the door quietly, but --\\n\"POTTER!\"Snape\\'s face was twisted with fury as he dropped his robes quickly to\\nhide his leg. Harry gulped.\\n\"I just wondered if I could have my book back.\"\\n\"GET OUT! OUT!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 145}), Document(page_content='146Harry left, before Snape could take any more points from Gryffindor. He\\nsprinted back upstairs.\\n\"Did you get it?\" Ron asked as Harry joined them. \"What\\'s the matter?\"In a low whisper, Harry told them what he\\'d seen.\\n\"You know what this means?\" he finished breathlessly. \"He tried to get\\npast that three-headed dog at Halloween! That\\'s where he was going whenwe saw him -- he\\'s after whatever it\\'s guarding! And Id bet mybroomstick he let that troll in, to make a diversion!\"\\nHermione\\'s eyes were wide.\\n\"No -- he wouldn\\'t, she said. \"I know he\\'s not very nice, but he\\nwouldn\\'t try and steal something Dumbledore was keeping safe.\"\\n\"Honestly, Hermione, you think all teachers are saints or something,\"\\nsnapped Ron. \"I\\'m with Harry. I wouldn\\'t put anything past Snape. But\\nwhat\\'s he after? What\\'s that dog guarding?\"\\nHarry went to bed with his head buzzing with the same question. Neville\\nwas snoring loudly, but Harry couldn\\'t sleep. He tried to empty his mind-- he needed to sleep, he had to, he had his first Quidditch match in afew hours -- but the expression on Snape\\'s face when Harry had seen hisleg wasn\\'t easy to forget.\\nThe next morning dawned very bright and cold. The Great Hall was full of\\nthe delicious smell of fried sausages and the cheer ful chatter ofeveryone looking forward to a good Quidditch match.\\n\"You\\'ve got to eat some breakfast.\"\\n\"I don\\'t want anything.\"\\n\"Just a bit of toast,\" wheedled Hermione.\"I\\'m not hungry.\"\\nHarry felt terrible. In an hour\\'s time he\\'d be walking onto the field.\\n\"Harry, you need your strength,\" said Seamus Finnigan. \"Seekers are\\nalways the ones who get clobbered by the other team.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 146}), Document(page_content='147\"Thanks, Seamus,\" said Harry, watching Seamus pile ketchup on his\\nsausages.\\nBy eleven o\\'clock the whole school seemed to be out in the stands around\\nthe Quidditch pitch. Many students had binoculars. The seats might be\\nraised high in the air, but it was still difficult to see what was going\\non sometimes.\\nRon and Hermione joined Neville, Seamus, and Dean the West Ham fan up in\\nthe top row. As a surprise for Harry, they had painted a large banner onone of the sheets Scabbers had ruined. It said Potter for President, andDean, who was good at drawing, had done a large Gryffindor lion\\nunderneath. Then Hermione had performed a tricky little charm so that\\nthe paint flashed different colors.\\nMeanwhile, in the locker room, Harry and the rest of the team were\\nchanging into their scarlet Quidditch robes (Slytherin would be playingin green).\\nWood cleared his throat for silence.\\n\"Okay, men,\" he said.\"And women,\" said Chaser Angelina Johnson.\\n\"And women,\" Wood agreed. \"This is it.\"\\n\"The big one,\" said Fred Weasley.\"The one we\\'ve all been waiting for,\" said George.\\n\"We know Oliver\\'s speech by heart,\" Fred told Harry, \"we were on the\\nteam last year.\"\\n\"Shut up, you two,\" said Wood. \"This is the best team Gryffindor\\'s had\\nin years. We\\'re going to win. I know it.\"\\nHe glared at them all as if to say, \"Or else.\"\\n\"Right. It\\'s time. Good luck, all of you.\"\\nHarry followed Fred and George out of the locker room and, hoping his', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 147}), Document(page_content='148knees weren\\'t going to give way, walked onto the field to loud cheers.\\nMadam Hooch was refereeing. She stood in the middle of the field waiting\\nfor the two teams, her broom in her hand.\\n\"Now, I want a nice fair game, all of you,\" she said, once they were all\\ngathered around her. Harry noticed that she seemed to be speaking\\nparticularly to the Slytherin Captain, Marcus Flint, a sixth year. Harrythought Flint looked as if he had some troll blood in him. Out of thecorner of his eye he saw the fluttering banner high above, flashingPotter for President over the crowd. His heart skipped. He felt braver.\\n\"Mount your brooms, please.\"\\nHarry clambered onto his Nimbus Two Thousand.\\nMadam Hooch gave a loud blast on her silver whistle.Fifteen brooms rose up, high, high into the air. They were off. \"And the\\nQuaffle is taken immediately by Angelina Johnson of Gryffindor -- what\\nan excellent Chaser that girl is, and rather attractive, too --\"\\n\"JORDAN!\"\"Sorry, Professor.\"\\nThe Weasley twins\\' friend, Lee Jordan, was doing the commentary for the\\nmatch, closely watched by Professor McGonagall.\\n\"And she\\'s really belting along up there, a neat pass to Alicia Spinnet,\\na good find of Oliver Wood\\'s, last year only a reserve -- back toJohnson and -- no, the Slytherins have taken the Quaffle, Slytherin\\nCaptain Marcus Flint gains the Quaffle and off he goes -- Flint flying\\nlike an eagle up there -- he\\'s going to sc- no, stopped by an excellentmove by Gryffindor Keeper Wood and the Gryffindors take the Quaffle --that\\'s Chaser Katie Bell of Gryffindor there, nice dive around Flint,off up the field and -- OUCH -- that must have hurt, hit in the back ofthe head by a Bludger -- Quaffle taken by the Slytherins -- that\\'sAdrian Pucey speeding off toward the goal posts, but he\\'s blocked by a\\nsecond Bludger -- sent his way by Fred or George Weasley, can\\'t tell\\nwhich -- nice play by the Gryffindor Beater, anyway, and Johnson back inpossession of the Quaffle, a clear field ahead and off she goes -- she\\'sreally flying -- dodges a speeding Bludger -- the goal posts are ahead', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 148}), Document(page_content='149-- come on, now, Angelina -- Keeper Bletchley dives -- misses --\\nGRYFFINDORS SCORE!\"\\nGryffindor cheers filled the cold air, with howls and moans from the\\nSlytherins.\\n\"Budge up there, move along.\"\\n\"Hagrid!\"Ron and Hermione squeezed together to give Hagrid enough space to join\\nthem.\\n\"Bin watchin\\' from me hut,\" said Hagrid, patting a large pair of\\nbinoculars around his neck, \"But it isn\\'t the same as bein\\' in thecrowd. No sign of the Snitch yet, eh?\"\\n\"Nope,\" said Ron. \"Harry hasn\\'t had much to do yet.\"\\n\"Kept outta trouble, though, that\\'s somethin\\',\" said Hagrid, raising his\\nbinoculars and peering skyward at the speck that was Harry.\\nWay up above them, Harry was gliding over the game, squinting about for\\nsome sign of the Snitch. This was part of his and Wood\\'s game plan.\\n\"Keep out of the way until you catch sight of the Snitch,\" Wood had\\nsaid. \"We don\\'t want you attacked before you have to be.\"\\nWhen Angelina had scored, Harry had done a couple of loop-the-loops to\\nlet off his feelings. Now he was back to staring around for the Snitch.Once he caught sight of a flash of gold, but it was just a reflectionfrom one of the Weasleys\\' wristwatches, and once a Bludger decided to\\ncome pelting his way, more like a cannonball than anything, but Harry\\ndodged it and Fred Weasley came chasing after it.\\n\"All right there, Harry?\" he had time to yell, as he beat the Bludger\\nfuriously toward Marcus Flint.\\n\"Slytherin in possession,\" Lee Jordan was saying, \"Chaser Pucey ducks\\ntwo Bludgers, two Weasleys, and Chaser Bell, and speeds toward the --\\nwait a moment -- was that the Snitch?\"\\nA murmur ran through the crowd as Adrian Pucey dropped the Quaffle, too', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 149}), Document(page_content='150busy looking over his shoulder at the flash of gold that had passed his\\nleft ear.\\nHarry saw it. In a great rush of excitement he dived downward after the\\nstreak of gold. Slytherin Seeker Terence Higgs had seen it, too. Neckand neck they hurtled toward the Snitch -all the Chasers seemed to have\\nforgotten what they were supposed to be doing as they hung in midair to\\nwatch.\\nHarry was faster than Higgs -- he could see the little round ball, wings\\nfluttering, darting up ahead - - he put on an extra spurt of speed --\\nWHAM! A roar of rage echoed from the Gryffindors below -- Marcus Flint\\nhad blocked Harry on purpose, and Harry\\'s broom spun off course, Harry\\nholding on for dear life.\\n\"Foul!\" screamed the Gryffindors.Madam Hooch spoke angrily to Flint and then ordered a free shot at the\\ngoal posts for Gryffindor. But in all the confusion, of course, the\\nGolden Snitch had disappeared from sight again.\\nDown in the stands, Dean Thomas was yelling, \"Send him off, ref! Red\\ncard!\"\\n\"What are you talking about, Dean?\" said Ron.\\n\"Red card!\" said Dean furiously. \"In soccer you get shown the red card\\nand you\\'re out of the game!\"\\n\"But this isn\\'t soccer, Dean,\" Ron reminded him.\\nHagrid, however, was on Dean\\'s side.\\n\"They oughta change the rules. Flint coulda knocked Harry outta the\\nair.\"\\nLee Jordan was finding it difficult not to take sides.\\n\"So -- after that obvious and disgusting bit of cheating\\n\"Jordan!\" growled Professor McGonagall.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 150}), Document(page_content='151\"I mean, after that open and revolting foul\\n\\'Jordan, I\\'m warning you --\"\"All right, all right. Flint nearly kills the Gryffindor Seeker, which\\ncould happen to anyone, I\\'m sure, so a penalty to Gryffindor, taken by\\nSpinner, who puts it away, no trouble, and we continue play, Gryffindor\\nstill in possession.\"\\nIt was as Harry dodged another Bludger, which went spinning dangerously\\npast his head, that it happened. His broom gave a sudden, frighteninglurch. For a split second, he thought he was going to fall. He grippedthe broom tightly with both his hands and knees. He\\'d never felt\\nanything like that.\\nIt happened again. It was as though the broom was trying to buck him\\noff. But Nimbus Two Thousands did not suddenly decide to buck theirriders off. Harry tried to turn back toward the Gryffindor goal- posts-- he had half a mind to ask Wood to call time-out -- and then he\\nrealized that his broom was completely out of his control. He couldn\\'t\\nturn it. He couldn\\'t direct it at all. It was zigzagging through theair, and every now and then making violent swishing movements thatalmost unseated him.\\nLee was still commentating.\\n\"Slytherin in possession -- Flint with the Quaffle -- passes Spinnet --\\npasses Bell -- hit hard in the face by a Bludger, hope it broke his nose-- only joking, Professor -- Slytherins score -- A no...\\nThe Slytherins were cheering. No one seemed to have noticed that Harry\\'s\\nbroom was behaving strangely. It was carrying- him slowly higher, away\\nfrom the game, jerking and twitching as it went.\\n\"Dunno what Harry thinks he\\'s doing,\" Hagrid mumbled. He stared through\\nhis binoculars. \"If I didn\\' know better, I\\'d say he\\'d lost control ofhis broom... but he can\\'t have....\"\\nSuddenly, people were pointing up at Harry all over the stands. His\\nbroom had started to roll over and over, with him only just managing to\\nhold on. Then the whole crowd gasped. Harry\\'s broom had given a wildjerk and Harry swung off it. He was now dangling from it, holding onwith only one hand.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 151}), Document(page_content='152\"Did something happen to it when Flint blocked him?\" Seamus whispered.\\n\"Can\\'t have,\" Hagrid said, his voice shaking. \"Can\\'t nothing interfere\\nwith a broomstick except powerful Dark magic -- no kid could do that toa Nimbus Two Thousand.\"\\nAt these words, Hermione seized Hagrid\\'s binoculars, but instead of\\nlooking up at Harry, she started looking frantically at the crowd.\\n\"What are you doing?\" moaned Ron, gray-faced.\"I knew it,\" Hermione gasped, \"Snape -- look.\"\\nRon grabbed the binoculars. Snape was in the middle of the stands\\nopposite them. He had his eyes fixed on Harry and was muttering nonstopunder his breath.\\n\"He\\'s doing something -- jinxing the broom,\" said Hermione.\\n\"What should we do?\"\\n\"Leave it to me.\"Before Ron could say another word, Hermione had disappeared. Ron turned\\nthe binoculars back on Harry. His broom was vibrating so hard, it was\\nalmost impossible for him to hang on much longer. The whole crowd was on\\nits feet, watching, terrified, as the Weasleys flew up to try and pullHarry safely onto one of their brooms, but it was no good -- every timethey got near him, the broom would jump higher still. They dropped lowerand circled beneath him, obviously hoping to catch him if he fell.Marcus\\nFlint seized the Quaffle and scored five times without anyone noticing.\\n\"Come on, Hermione,\" Ron muttered desperately.Hermione had fought her way across to the stand where Snape stood, and\\nwas now racing along the row behind him; she didn\\'t even stop to say\\nsorry as she knocked Professor Quirrell headfirst into the row in front.\\nReaching Snape, she crouched down, pulled out her wand, and whispered afew, well- chosen words. Bright blue flames shot from her wand onto thehem of Snape\\'s robes.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 152}), Document(page_content='153It took perhaps thirty seconds for Snape to realize that he was on fire.\\nA sudden yelp told her she had done her job. Scooping the fire off himinto a little jar in her pocket, she scrambled back along the row --Snape would never know what had happened.\\nIt was enough. Up in the air, Harry was suddenly able to clamber back on\\nto his broom.\\n\"Neville, you can look!\" Ron said. Neville had been sobbing into\\nHagrid\\'s jacket for the last five minutes.\\nHarry was speeding toward the ground when the crowd saw him clap his\\nhand to his mouth as though he was about to be sick -- he hit the field\\non all fours -- coughed -- and something gold fell into his hand.\\n\"I\\'ve got the Snitch!\" he shouted, waving it above his head, and the\\ngame ended in complete confusion.\\n\"He didn\\'t catch it, he nearly swallowed it,\" Flint was still howling\\ntwenty minutes later, but it made no difference -- Harry hadn\\'t brokenany rules and Lee Jordan was still happily shouting the results --Gryffindor had won by one hundred and seventy points to sixty. Harryheard none of this, though. He was being made a cup of strong tea backin Hagrid\\'s hut, with Ron and Hermione.\\n\"It was Snape,\" Ron was explaining, \"Hermione and I saw him. He was\\ncursing your broomstick, muttering, he wouldn\\'t take his eyes off you.\"\\n\"Rubbish,\" said Hagrid, who hadn\\'t heard a word of what had gone on next\\nto him in the stands. \"Why would Snape do somethin\\' like that?\"\\nHarry, Ron, and Hermione looked at one another, wondering what to tell\\nhim. Harry decided on the truth.\\n\"I found out something about him,\" he told Hagrid. \"He tried to get past\\nthat three-headed dog on Halloween. It bit him. We think he was tryingto steal whatever it\\'s guarding.\"\\nHagrid dropped the teapot.\\n\"How do you know about Fluffy?\" he said.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 153}), Document(page_content='154\"Fluffy?\"\\n\"Yeah -- he\\'s mine -- bought him off a Greek chappie I met in the pub\\nlas\\' year -- I lent him to Dumbledore to guard the\\n\"Yes?\" said Harry eagerly.\\n\"Now, don\\'t ask me anymore,\" said Hagrid gruffly. \"That\\'s top secret,\\nthat is.\"\\n\"But Snape\\'s trying to steal it.\"\"Rubbish,\" said Hagrid again. \"Snape\\'s a Hogwarts teacher, he\\'d do\\nnothin\\' of the sort.\"\\n\"So why did he just try and kill Harry?\" cried Hermione.The afternoon\\'s events certainly seemed to have changed her mind about\\nSnape.\\nI know a jinx when I see one, Hagrid, I\\'ve read all about them!\\nYou\\'ve got to keep eye contact, and Snape wasn\\'t blinking at all, I saw\\nhim!\"\\n\"I\\'m tellin\\' yeh, yer wrong!\" said Hagrid hotly. \"I don\\' know why\\nHarry\\'s broom acted like that, but Snape wouldn\\' try an\\' kill a student!\\nNow, listen to me, all three of yeh -- yer meddlin\\' in things that don\\'concern yeh. It\\'s dangerous. You forget that dog, an\\' you forget whatit\\'s guardin\\', that\\'s between Professor Dumbledore an\\' Nicolas Flamel--\"\\n\"Aha!\" said Harry, \"so there\\'s someone called Nicolas Flamel involved,\\nis there?\"\\nHagrid looked furious with himself.\\nCHAPTER TWELVE\\nTHE MIRROR OF ERISED\\nChristmas was coming. One morning in mid-December, Hogwarts woke to find', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 154}), Document(page_content='155itself covered in several feet of snow. The lake froze solid and the\\nWeasley twins were punished for bewitching several snowballs so thatthey followed Quirrell around, bouncing off the back of his turban. Thefew owls that managed to battle their way through the stormy sky todeliver mail had to be nursed back to health by Hagrid before they couldfly off again.\\nNo one could wait for the holidays to start. While the Gryffindor common\\nroom and the Great Hall had roaring fires, the drafty corridors hadbecome icy and a bitter wind rattled the windows in the classrooms.Worst of all were Professor Snape\\'s classes down in the dungeons, wheretheir breath rose in a mist before them and they kept as close aspossible to their hot cauldrons.\\n\"I do feel so sorry,\" said Draco Malfoy, one Potions class, \"for all\\nthose people who have to stay at Hogwarts for Christmas because they\\'renot wanted at home.\"\\nHe was looking over at Harry as he spoke. Crabbe and Goyle chuckled.\\nHarry, who was measuring out powdered spine of lionfish, ignored them.\\nMalfoy had been even more unpleasant than usual since the Quidditchmatch. Disgusted that the Slytherins had lost, he had tried to geteveryone laughing at how a wide-mouthed tree frog would be replacingHarry as Seeker next. Then he\\'d realized that nobody found this funny,because they were all so impressed at the way Harry had managed to stayon his bucking broomstick. So Malfoy, jealous and angry, had gone back\\nto taunting Harry about having no proper family.\\nIt was true that Harry wasn\\'t going back to Privet Drive for Christmas.\\nProfessor McGonagall had come around the week before, making a list ofstudents who would be staying for the holidays, and Harry had signed upat once. He didn\\'t feel sorry for himself at all; this would probably be\\nthe best Christmas he\\'d ever had. Ron and his brothers were staying,\\ntoo, because Mr. and Mrs. Weasley were going to Romania to visitCharlie.\\nWhen they left the dungeons at the end of Potions, they found a large\\nfir tree blocking the corridor ahead. Two enormous feet sticking out atthe bottom and a loud puffing sound told them that Hagrid was behind it.\\n\"Hi, Hagrid, want any help?\" Ron asked, sticking his head through the\\nbranches.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 155}), Document(page_content='156\"Nah, I\\'m all right, thanks, Ron.\"\\n\"Would you mind moving out of the way?\" came Malfoys cold drawl from\\nbehind them. \"Are you trying to earn some extra money, Weasley? Hopingto be gamekeeper yourself when you leave Hogwarts, I suppose -- that hutof Hagrid\\'s must seem like a palace compared to what your family\\'s used\\nto.\"\\nRon dived at Malfoy just as Snape came up the stairs.\"WEASLEY!\"Ron let go of the front of Malfoy\\'s robes.\\n\"He was provoked, Professor Snape,\" said Hagrid, sticking his huge hairy\\nface out from behind the tree. \"Malfoy was insultin\\' his family.\"\\n\"Be that as it may, fighting is against Hogwarts rules, Hagrid,\" said\\nSnape silkily. \"Five points from Gryffindor, Weasley, and be grateful it\\nisn\\'t more. Move along, all of you.\"\\nMalfoy, Crabbe, and Goyle pushed roughly past the tree, scattering\\nneedles everywhere and smirking.\\n\"I\\'ll get him,\" said Ron, grinding his teeth at Malfoy\\'s back, \"one of\\nthese days, I\\'ll get him --\"\\n\"I hate them both,\" said Harry, \"Malfoy and Snape.\"\\n\"Come on, cheer up, it\\'s nearly Christmas,\" said Hagrid. \"Tell yeh what,\\ncome with me an\\' see the Great Hall, looks a treat.\"\\nSo the three of them followed Hagrid and his tree off to -the Great\\nHall, where Professor McGonagall and Professor Flitwick were busy withthe Christmas decorations.\\n\"Ah, Hagrid, the last tree -- put it in the far corner, would you?\"The hall looked spectacular. Festoons of holly and mistletoe hung all\\naround the walls, and no less than twelve towering Christmas trees stood\\naround the room, some sparkling with tiny icicles, some glittering withhundreds of candles.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 156}), Document(page_content='157\"How many days you got left until yer holidays?\" Hagrid asked.\\n\"Just one,\" said Hermione. \"And that reminds me -Harry, Ron, we\\'ve got\\nhalf an hour before lunch, we should be in the library.\"\\n\"Oh yeah, you\\'re right,\" said Ron, tearing his eyes away from Professor\\nFlitwick, who had golden bubbles blossoming out of his wand and was\\ntrailing them over the branches of the new tree.\\n\"The library?\" said Hagrid, following them out of the hall. \"Just before\\nthe holidays? Bit keen, aren\\'t yeh?\"\\n\"Oh, we\\'re not working,\" Harry told him brightly. \"Ever since you\\nmentioned Nicolas Flamel we\\'ve been trying to find out who he is.\"\\n\"You what?\" Hagrid looked shocked. \"Listen here -- I\\'ve told yeh -- drop\\nit. It\\'s nothin\\' to you what that dog\\'s guardin\\'.\"\\n\"We just want to know who Nicolas Flamel is, that\\'s all,\" said Hermione.\\n\"Unless you\\'d like to tell us and save us the trouble?\" Harry added. \"We\\nmust\\'ve been through hundreds of books already and we can\\'t find himanywhere -- just give us a hint -- I know I\\'ve read his name somewhere.\"\\n\"I\\'m sayin\\' nothin, said Hagrid flatly.\\n\"Just have to find out for ourselves, then,\" said Ron, and they left\\nHagrid looking disgruntled and hurried off to the library.\\nThey had indeed been searching books for Flamel\\'s name ever since Hagrid\\nhad let it slip, because how else were they going to find out what Snapewas trying to steal? The trouble was, it was very hard to know where to\\nbegin, not knowing what Flamel might have done to get himself into a\\nbook. He wasn\\'t in Great Wizards of the Twentieth Century, or NotableMagical Names of Our Time; he was missing, too, from Important ModernMagical Discoveries, and A Study of Recent Developments in Wizardry. Andthen, of course, there was the sheer size of the library; tens ofthousands of books; thousands of shelves; hundreds of narrow rows.\\nHermione took out a list of subjects and titles she had decided to\\nsearch while Ron strode off down a row of books and started pulling themoff the shelves at random. Harry wandered over to the RestrictedSection. He had been wondering for a while if Flamel wasn\\'t somewhere in', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 157}), Document(page_content='158there. Unfortunately, you needed a specially signed note from one of the\\nteachers to look in any of the restricted books, and he knew he\\'d neverget one. These were the books containing powerful Dark Magic nevertaught at Hogwarts, and only read by older students studying advancedDefense Against the Dark Arts.\\n\"What are you looking for, boy?\"\\n\"Nothing,\" said Harry.Madam Pince the librarian brandished a feather duster at him.\"You\\'d better get out, then. Go on -- out!\"\\nWishing he\\'d been a bit quicker at thinking up some story, Harry left\\nthe library. He, Ron, and Hermione had already agreed they\\'d better notask Madam Pince where they could find Flamel. They were sure she\\'d beable to tell them, but they couldn\\'t risk Snape hearing what they wereup to.\\nHarry waited outside in the corridor to see if the other two had found\\nanything, but he wasn\\'t very hopeful. They had been looking for twoweeks, after A, but as they only had odd moments between lessons itwasn\\'t surprising they\\'d found nothing. What they really needed was anice long search without Madam Pince breathing down their necks.\\nFive minutes later, Ron and Hermione joined him, shaking their heads.\\nThey went off to lunch.\\n\"You will keep looking while I\\'m away, won\\'t you?\" said Hermione. \"And\\nsend me an owl if you find anything.\"\\n\"And you could ask your parents if they know who Flamel is,\" said Ron.\\n\"It\\'d be safe to ask them.\"\\n\"Very safe, as they\\'re both dentists,\" said Hermione.Once the holidays had started, Ron and Harry were having too good a time\\nto think much about Flamel. They had the dormitory to themselves and the\\ncommon room was far emptier than usual, so they were able to get the\\ngood armchairs by the fire. They sat by the hour eating anything theycould spear on a toasting fork -- bread, English muffins, marshmallows-- and plotting ways of getting Malfoy expelled, which were fun to talk', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 158}), Document(page_content='159about even if they wouldn\\'t work.\\nRon also started teaching Harry wizard chess. This was exactly like\\nMuggle chess except that the figures were alive, which made it a lotlike directing troops in battle. Ron\\'s set was very old and battered.Like everything else he owned, it had once belonged to someone else in\\nhis family -- in this case, his grandfather. However, old chessmen\\nweren\\'t a drawback at all. Ron knew them so well he never had troublegetting them to do what he wanted.\\nHarry played with chessmen Seamus Finnigan had lent him, and they didn\\'t\\ntrust him at all. He wasn\\'t a very good player yet and they keptshouting different bits of advice at him, which was confusing. \"Don\\'t\\nsend me there, can\\'t you see his knight? Send him, we can afford to lose\\nhim.\" On Christmas Eve, Harry went to bed looking forward to the nextday for the food and the fun, but not expecting any presents at all.When he woke early in the morning, however, the first thing he saw was asmall pile of packages at the foot of his bed.\\n\"Merry Christmas,\" said Ron sleepily as Harry scrambled out of bed and\\npulled on his bathrobe.\\n\"You, too,\" said Harry. \"Will you look at this? I\\'ve got some presents!\"\"What did you expect, turnips?\" said Ron, turning to his own pile, which\\nwas a lot bigger than Harry\\'s.\\nHarry picked up the top parcel. It was wrapped in thick brown paper and\\nscrawled across it was To Harry, from Hagrid. Inside was a roughly cutwooden flute. Hagrid had obviously whittled it himself. Harry blew it --it sounded a bit like an owl.\\nA second, very small parcel contained a note.\\nWe received your message and enclose your Christmas present. From Uncle\\nVernon and Aunt Petunia. Taped to the note was a fifty-pence piece.\\n\"That\\'s friendly,\" said Harry.\\nRon was fascinated by the fifty pence.\\n\"Weird!\" he said, \\'NMat a shape! This is money?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 159}), Document(page_content='160\"You can keep it,\" said Harry, laughing at how pleased Ron was. \"Hagrid\\nand my aunt and uncle -- so who sent these?\"\\n\"I think I know who that one\\'s from,\" said Ron, turning a bit pink and\\npointing to a very lumpy parcel. \"My mom. I told her you didn\\'t expectany presents and -- oh, no,\" he groaned, \"she\\'s made you a Weasley\\nsweater.\"\\nHarry had torn open the parcel to find a thick, hand-knitted sweater in\\nemerald green and a large box of homemade fudge.\\n\"Every year she makes us a sweater,\" said Ron, unwrapping his own, \"and\\nmine\\'s always maroon.\"\\n\"That\\'s really nice of her,\" said Harry, trying the fudge, which was\\nvery tasty.\\nHis next present also contained candy -- a large box of Chocolate Frogs\\nfrom Hermione.\\nThis only left one parcel. Harry picked it up and felt it. It was very\\nlight. He unwrapped it.\\nSomething fluid and silvery gray went slithering to the floor where it\\nlay in gleaming folds. Ron gasped.\\n\"I\\'ve heard of those,\" he said in a hushed voice, dropping the box of\\nEvery Flavor Beans he\\'d gotten from Hermione. \"If that\\'s what I think itis -- they\\'re really rare, and really valuable.\"\\n\"What is it?\"\\nHarry picked the shining, silvery cloth off the floor. It was strange to\\nthe touch, like water woven into material.\\n\"It\\'s an invisibility cloak,\" said Ron, a look of awe on his face. \"I\\'m\\nsure it is -- try it on.\"\\nHarry threw the cloak around his shoulders and Ron gave a yell.\\n\"It is! Look down!\"\\nHarry looked down at his feet, but they were gone. He dashed to the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 160}), Document(page_content='161mirror. Sure enough, his reflection looked back at him, just his head\\nsuspended in midair, his body completely invisible. He pulled the cloakover his head and his reflection vanished completely.\\n\"There\\'s a note!\" said Ron suddenly. \"A note fell out of it!\"\\nHarry pulled off the cloak and seized the letter. Written in narrow,\\nloopy writing he had never seen before were the following words: Yourfather left this in my possession before he died. It is time it wasreturned to you. Use it well.\\nA Very Merry Christmas to you.\\nThere was no signature. Harry stared at the note. Ron was admiring the\\ncloak.\\n\"I\\'d give anything for one of these,\" he said. \"Anything. What\\'s the\\nmatter?\"\\n\"Nothing,\" said Harry. He felt very strange. Who had sent the cloak? Had\\nit really once belonged to his father?\\nBefore he could say or think anything else, the dormitory door was flung\\nopen and Fred and George Weasley bounded in. Harry stuffed the cloakquickly out of sight. He didn\\'t feel like sharing it with anyone else\\nyet.\\n\"Merry Christmas!\"\"Hey, look -- Harry\\'s got a Weasley sweater, too!\"\\nFred and George were wearing blue sweaters, one with a large yellow F on\\nit, the other a G.\\n\"Harry\\'s is better than ours, though,\" said Fred, holding up Harry\\'s\\nsweater. \"She obviously makes more of an effort if you\\'re not family.\"\\n\"Why aren\\'t you wearing yours, Ron?\" George demanded. \"Come on, get it\\non, they\\'re lovely and warm.\"\\n\"I hate maroon,\" Ron moaned halfheartedly as he pulled it over his head.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 161}), Document(page_content='162\"You haven\\'t got a letter on yours,\" George observed. \"I suppose she\\nthinks you don\\'t forget your name. But we\\'re not stupid -- we know we\\'recalled Gred and Forge.\"\\n\"What\\'s all th is noise.\\nPercy Weasley stuck his head through the door, looking disapproving. He\\nhad clearly gotten halfway through unwrapping his presents as he, too,carried a lumpy sweater over his arm, which\\nFred seized.\"P for prefect! Get it on, Percy, come on, we\\'re all wearing ours, even\\nHarry got one.\"\\n\"I -- don\\'t -- want said Percy thickly, as the twins forced the sweater\\nover his head, knocking his glasses askew.\\n\"And you\\'re not sitting with the prefects today, either,\" said\\nGeorge. \"Christmas is a time for family.\"\\nThey frog-marched Percy from the room, his arms pinned to his side by\\nhis sweater.\\nHarry had never in all his life had such a Christmas dinner. A hundred\\nfat, roast turkeys; mountains of roast and boiled potatoes; platters of\\nchipolatas; tureens of buttered peas, silver boats of thick, rich gravyand cranberry sauce -- and stacks of wizard crackers every few feetalong the table. These fantastic party favors were nothing like thefeeble Muggle ones the Dursleys usually bought, with their littleplastic toys and their flimsy paper hats inside. Harry pulled a wizard\\ncracker with Fred and it didn\\'t just bang, it went off with a blast like\\na cannon and engulfed them all in a cloud of blue smoke, while from theinside exploded a rear admiral\\'s hat and several live, white mice. Up atthe High Table, Dumbledore had swapped his pointed wizard\\'s hat for aflowered bonnet, and was chuckling merrily at a joke Professor Flitwickhad just read him.\\nFlaming Christmas puddings followed the turkey. Percy nearly broke his\\nteeth on a silver sickle embedded in his slice. Harry watched Hagridgetting redder and redder in the face as he called for more wine,finally kissing Professor McGonagall on the cheek, who, to Harry\\'s', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 162}), Document(page_content=\"163amazement, giggled and blushed, her top hat lopsided.\\nWhen Harry finally left the table, he was laden down with a stack of\\nthings out of the crackers, including a pack of nonexplodable, luminousballoons, a Grow-Your-Own-Warts kit, and his own new wizard chess set.The white mice had disappeared and Harry had a nasty feeling they were\\ngoing to end up as Mrs. Norris's Christmas dinner.\\nHarry and the Weasleys spent a happy afternoon having a furious snowball\\nfight on the grounds. Then, cold, wet, and gasping for breath, theyreturned to the fire in the Gryffindor common room, where Harry broke inhis new chess set by losing spectacularly to Ron. He suspected hewouldn't have lost so badly if Percy hadn't tried to help him so much.\\nAfter a meal of turkey sandwiches, crumpets, trifle, and Christmas cake,\\neveryone felt too full and sleepy to do much before bed except sit andwatch Percy chase Fred and George all over Gryffindor tower becausethey'd stolen his prefect badge.\\nIt had been Harry's best Christmas day ever. Yet something had been\\nnagging at the back of his mind all day. Not until he climbed into bedwas he free to think about it: the invisibility cloak and whoever hadsent it.\\nRon, full of turkey and cake and with nothing mysterious to bother him,\\nfell asleep almost as soon as he'd drawn the curtains of his\\nfour-poster. Harry leaned over the side of his own bed and pulled the\\ncloak out from under it.\\nHis father's... this had been his father's. He let the material flow\\nover his hands, smoother than silk, light as air. Use it well, the notehad said.\\nHe had to try it, now. He slipped out of bed and wrapped the cloak\\naround himself. Looking down at his legs, he saw only moonlight andshadows. It was a very funny feeling.\\nUse it well.\\nSuddenly, Harry felt wide-awake. The whole of Hogwarts was open to him\\nin this cloak. Excitement flooded through him as he stood there in thedark and silence. He could go anywhere in this, anywhere, and Filchwould never know.\", metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 163}), Document(page_content='164Ron grunted in his sleep. Should Harry wake him? Something held him back\\n-- his father\\'s cloak -- he felt that this time -- the first time -- hewanted to use it alone.\\nHe crept out of the dormitory, down the stairs, across the common room,\\nand climbed through the portrait hole.\\n\"Who\\'s there?\" squawked the Fat Lady. Harry said nothing. He walked\\nquickly down the corridor.\\nWhere should he go? He stopped, his heart racing, and thought. And then\\nit came to him. The Restricted Section in the library. He\\'d be able to\\nread as long as he liked, as long as it took to find out who Flamel was.\\nHe set off, drawing the invisibility cloak tight around him as hewalked.\\nThe library was pitch-black and very eerie. Harry lit a lamp to see his\\nway along the rows of books. The lamp looked as if it was floating along\\nin midair, and even though Harry could feel his arm supporting it, the\\nsight gave him the creeps.\\nThe Restricted Section was right at the back of the library. Step ping\\ncarefully over the rope that separated these books from the rest of thelibrary, he held up his lamp to read the titles.\\nThey didn\\'t tell him much. Their peeling, faded gold letters spelled\\nwords in languages Harry couldn\\'t understand. Some had no title at all.One book had a dark stain on it that looked horribly like blood. Thehairs on the back of Harry\\'s neck prickled. Maybe he was imagining it,maybe not, but he thought a faint whispering was coming from the books,as though they knew someone was there who shouldn\\'t be.\\nHe had to start somewhere. Setting the lamp down carefully on the floor,\\nhe looked along the bottom shelf for an interestinglooking book. A largeblack and silver volume caught his eye. He pulled it out withdifficulty, because it was very heavy, and, balancing it on his knee,let it fall open.\\nA piercing, bloodcurdling shriek split the silence -- the book was\\nscreaming! Harry snapped it shut, but the shriek went on and on, onehigh, unbroken, earsplitting note. He stumbled backward and knocked overhis lamp, which went out at once. Panicking, he heard footsteps coming', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 164}), Document(page_content='165down the corridor outside -- stuffing the shrieking book back on the\\nshelf, he ran for it. He passed Filch in the doorway; Filch\\'s pale, wildeyes looked straight through him, and Harry slipped under Filch\\'soutstretched arm and streaked off up the corridor, the book\\'s shrieksstill ringing in his ears.\\nHe came to a sudden halt in front of a tall suit of armor. He had been\\nso busy getting away from the library, he hadn\\'t paid attention to wherehe was going. Perhaps because it was dark, he didn\\'t recognize where hewas at all. There was a suit of armor near the kitchens, he knew, but hemust be five floors above there.\\n\"You asked me to come directly to you, Professor, if anyone was\\nwandering around at night, and somebody\\'s been in the library Restricted\\nSection.\"\\nHarry felt the blood drain out of his face. Wherever he was, Filch must\\nknow a shortcut, because his soft, greasy voice was getting nearer, andto his horror, it was Snape who replied, \"The Restricted Section? Well,\\nthey can\\'t be far, we\\'ll catch them.\"\\nHarry stood rooted to the spot as Filch and Snape came around the corner\\nahead. They couldn\\'t see him, of course, but it was a narrow corridorand if they came much nearer they\\'d knock right into him -- the cloakdidn\\'t stop him from being solid.\\nHe backed away as quietly as he could. A door stood ajar to his left. It\\nwas his only hope. He squeezed through it, holding his breath, tryingnot to move it, and to his relief he managed to get inside the roomwithout their noticing anything. They walked straight past, and Harryleaned against the wall, breathing deeply, listening to their footstepsdying away. That had been close, very close. It was a few seconds before\\nhe noticed anything about the room he had hidden in.\\nIt looked like an unused classroom. The dark shapes of desks and chairs\\nwere piled against the walls, and there was an upturned wastepaperbasket -- but propped against the wall facing him was something thatdidn\\'t look as if it belonged there, something that looked as if someonehad just put it there to keep it out of the way.\\nIt was a magnificent mirror, as high as the ceiling, with an ornate gold\\nframe, standing on two clawed feet. There was an inscription carvedaround the top: Erised stra ehru oyt ube cafru oyt on wohsi. His panic', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 165}), Document(page_content='166fading now that there was no sound of Filch and Snape, Harry moved\\nnearer to the mirror, wanting to look at himself but see no reflectionagain. He stepped in front of it.\\nHe had to clap his hands to his mouth to stop himself from screaming. He\\nwhirled around. His heart was pounding far more furiously than when the\\nbook had screamed -- for he had seen not only himself in the mirror, but\\na whole crowd of people standing right behind him.\\nBut the room was empty. Breathing very fast, he turned slowly back to\\nthe mirror.\\nThere he was, reflected in it, white and scared-looking, and there,\\nreflected behind him, were at least ten others. Harry looked over his\\nshoulder -- but still, no one was there. Or were they all invisible,too? Was he in fact in a room full of invisible people and this mirror\\'strick was that it reflected them, invisible or not?\\nHe looked in the mirror again. A woman standing right behind his\\nreflection was smiling at him and waving. He reached out a hand and felt\\nthe air behind him. If she was really there, he\\'d touch her, theirreflections were so close together, but he felt only air -- she and theothers existed only in the mirror.\\nShe was a very pretty woman. She had dark red hair and her eyes -- her\\neyes are just like mine, Harry thought, edging a little closer to the\\nglass. Bright green -- exactly the same shape, but then he noticed that\\nshe was crying; smiling, but crying at the same time. The tall, thin,black-haired man standing next to her put his arm around her. He woreglasses, and his hair was very untidy. It stuck up at the back, just asHarry\\'s did.\\nHarry was so close to the mirror now that his nose was nearly touching\\nthat of his reflection.\\n\"Mom?\" he whispered. \"Dad?\"They just looked at him, smiling. And slowly, Harry looked into the\\nfaces of the other people in the mirror, and saw other pairs of green\\neyes like his, other noses like his, even a little old man who looked as\\nthough he had Harry\\'s knobbly knees -- Harry was looking at his family,for the first time in his life.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 166}), Document(page_content='167The Potters smiled and waved at Harry and he stared hungrily back at\\nthem, his hands pressed flat against the glass as though he was hopingto fall right through it and reach them. He had a powerful kind of acheinside him, half joy, half terrible sadness.\\nHow long he stood there, he didn\\'t know. The reflections did not fade\\nand he looked and looked until a distant noise brought him back to his\\nsenses. He couldn\\'t stay here, he had to find his way back to bed. Hetore his eyes away from his mother\\'s face, whispered, \"I\\'ll come back,\"and hurried from the room.\\n\"You could have woken me up,\" said Ron, crossly.\\n\"You can come tonight, I\\'m going back, I want to show you the mirror.\\n\"I\\'d like to see your mom and dad,\" Ron said eagerly.\"And I want to see all your family, all the Weasleys, you\\'ll be able to\\nshow me your other brothers and everyone.\"\\n\"You can see them any old time,\" said Ron. \"Just come round my house\\nthis summer. Anyway, maybe it only shows dead people. Shame about notfinding Flamel, though. Have some bacon or something, why aren\\'t youeating anything?\"\\nHarry couldn\\'t eat. He had seen his parents and would be seeing them\\nagain tonight. He had almost forgotten about Flamel. It didn\\'t seem very\\nimportant anymore. Who cared what the three headed dog was guarding?What did it matter if Snape stole it, really?\\n\"Are you all right?\" said Ron. \"You look odd.\"\\nWhat Harry feared most was that he might not be able to find the mirror\\nroom again. With Ron covered in the cloak, too, they had to walk muchmore slowly the next night. They tried retracing Harry\\'s route from thelibrary, wandering around the dark passageways for nearly an hour.\\n\"I\\'m freezing,\" said Ron. \"Let\\'s forget it and go back.\"\\n\"No!\" Harry hissed. I know it\\'s here somewhere.\"\\nThey passed the ghost of a tall witch gliding in the opposite direction,\\nbut saw no one else. just as Ron started moaning that his feet were dead', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 167}), Document(page_content='168with cold, Harry spotted the suit of armor.\\n\"It\\'s here -- just here -- yes!\"They pushed the door open. Harry dropped the cloak from around his\\nshoulders and ran to the mirror.\\nThere they were. His mother and father beamed at the sight of him.\\n\"See?\" Harry whispered.\"I can\\'t see anything.\"\\n\"Look! Look at them all... there are loads of them....\"\\n\"I can only see you.\"\"Look in it properly, go on, stand where I am.\"\\nHarry stepped aside, but with Ron in front of the mirror, he couldn\\'t\\nsee his family anymore, just Ron in his paisley pajamas.\\nRon, though, was staring transfixed at his image.\"Look at me!\" he said.\\n\"Can you see all your family standing around you?\"\\n\"No -- I\\'m alone -- but I\\'m different -- I look older -- and I\\'m head\\nboy!\"\\n\"What?\"\\n\"I am -- I\\'m wearing the badge like Bill used to -- and I\\'m holding the\\nhouse cup and the Quidditch cup -- I\\'m Quidditch captain, too.\\nRon tore his eyes away from this splendid sight to look excitedly at\\nHarry.\\n\"Do you think this mirror shows the future?\"\\n\"How can it? All my family are dead -- let me have another look --\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 168}), Document(page_content='169\"You had it to yourself all last night, give me a bit more time.\"\\n\"You\\'re only holding the Quidditch cup, what\\'s interesting about that? I\\nwant to see my parents.\"\\n\"Don\\'t push me --\"\\nA sudden noise outside in the corridor put an end to their discussion.\\nThey hadn\\'t realized how loudly they had been talking.\\n\"Quick!\"Ron threw the cloak back over them as the luminous eyes of Mrs. Norris\\ncame round the door. Ron and Harry stood quite still, both thinking the\\nsame thing -- did the cloak work on cats? After what seemed an age, sheturned and left.\\n\"This isn\\'t safe -- she might have gone for Filch, I bet she heard us.\\nCome on.\"\\nAnd Ron pulled Harry out of the room.\\nThe snow still hadn\\'t melted the next morning.\"Want to play chess, Harry?\" said Ron.\\n\"No.\"\\n\"Why don\\'t we go down and visit Hagrid?\"\"No... you go...\"\\n\"I know what you\\'re thinking about, Harry, that mirror. Don\\'t go back\\ntonight.\"\\n\"Why not?\"\"I dunno, I\\'ve just got a bad feeling about it -- and anyway, you\\'ve had\\ntoo many close shaves already. Filch, Snape, and Mrs. Norris are\\nwandering around. So what if they can\\'t see you? What if they walk into\\nyou? What if you knock something over?\"\\n\"You sound like Hermione.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 169}), Document(page_content='170\"I\\'m serious, Harry, don\\'t go.\"\\nBut Harry only had one thought in his head, which was to get back in\\nfront of the mirror, and Ron wasn\\'t going to stop him.\\nThat third night he found his way more quickly than before. He was\\nwalking so fast he knew he was making more noise than was wise, but hedidn\\'t meet anyone.\\nAnd there were his mother and father smiling at him again, and one of\\nhis grandfathers nodding happily. Harry sank down to sit on the floor infront of the mirror. There was nothing to stop him from staying here all\\nnight with his family. Nothing at all.\\nExcept --\"So -- back again, Harry?\"\\nHarry felt as though his insides had turned to ice. He looked behind\\nhim. Sitting on one of the desks by the wall was none other than AlbusDumbledore. Harry must have walked straight past him, so desperate toget to the mirror he hadn\\'t noticed him.\\n\" -- I didn\\'t see you, sir.\"\\n\"Strange how nearsighted being invisible can make you,\" said Dumbledore,\\nand Harry was relieved to see that he was smiling.\\n\"So,\" said Dumbledore, slipping off the desk to sit on the floor with\\nHarry, \"you, like hundreds before you, have discovered the delights ofthe Mirror of Erised.\"\\n\"I didn\\'t know it was called that, Sir.\"\\n\"But I expect you\\'ve realized by now what it does?\"\"It -- well -- it shows me my family --\"\\n\"And it showed your friend Ron himself as head boy.\"\\n\"How did you know --?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 170}), Document(page_content='171\"I don\\'t need a cloak to become invisible,\" said Dumbledore gently.\\n\"Now, can you think what the Mirror of Erised shows us all?\"\\nHarry shook his head.\"Let me explain. The happiest man on earth would be able to use the\\nMirror of Erised like a normal mirror, that is, he would look into it\\nand see himself exactly as he is. Does that help?\"\\nHarry thought. Then he said slowly, \"It shows us what we want...\\nwhatever we want...\"\\n\"Yes and no,\" said Dumbledore quietly. \"It shows us nothing more or less\\nthan the deepest, most desperate desire of our hearts. You, who have\\nnever known your family, see them standing around you. Ronald Weasley,who has always been overshadowed by his brothers, sees himself standingalone, the best of all of them. However, this mirror will give usneither knowledge or truth. Men have wasted away before it, entranced bywhat they have seen, or been driven mad, not knowing if what it shows is\\nreal or even possible.\\n\"The Mirror will be moved to a new home tomorrow, Harry, and I ask you\\nnot to go looking for it again. If you ever do run across it, you willnow be prepared. It does not do to dwell on dreams and forget to live,remember that. Now, why don\\'t you put that admirable cloak back on andget off to bed?\"\\nHarry stood up.\\n\"Sir -- Professor Dumbledore? Can I ask you something?\"\"Obviously, you\\'ve just done so,\" Dumbledore smiled. \"You may ask me one\\nmore thing, however.\"\\n\"What do you see when you look in the mirror?\"\"I? I see myself holding a pair of thick, woolen socks.\"Harry stared.\\n\"One can never have enough socks,\" said Dumbledore. \"Another Christmas\\nhas come and gone and I didn\\'t get a single pair. People will insist ongiving me books.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 171}), Document(page_content='172It was only when he was back in bed that it struck Harry that Dumbledore\\nmight not have been quite truthful. But then, he thought, as he shovedScabbers off his pillow, it had been quite a personal question.\\nCHAPTER THIRTEEN\\nNICOLAS FLAMELDumbledore had convinced Harry not to go looking for the Mirror of\\nErised again, and for the rest of the Christmas holidays theinvisibility cloak stayed folded at the bottom of his trunk. Harry\\nwished he could forget what he\\'d seen in the mirror as easily, but he\\ncouldn\\'t. He started having nightmares. Over and over again he dreamedabout his parents disappearing in a flash of green light, while a highvoice cackled with laughter.\\n\"You see, Dumbledore was right, that mirror could drive you mad,\" said\\nRon, when Harry told him about these drearns.\\nHermione, who came back the day before term started, took a different\\nview of things. She was torn between horror at the idea of Harry beingout of bed, roaming the school three nights in a row (\"If Filch hadcaught you!\"), and disappointment that he hadn\\'t at least found out whoNicolas Flamel was.\\nThey had almost given up hope of ever finding Flamel in a li- brary\\nbook, even though Harry was still sure he\\'d read the name somewhere.Once term had started, they were back to skimming through books for tenminutes during their breaks. Harry had even less time than the othertwo, because Quidditch practice had started again.\\nWood was working the team harder than ever. Even the endless rain that\\nhad replaced the snow couldn\\'t dampen his spirits. The Weasleyscomplained that Wood was becoming a fanatic, but Harry was on Wood\\'sside. If they won their next match, against Hufflepuff, they wouldovertake Slytherin in the house championship for the first time in sevenyears. Quite apart from wanting to win, Harry found that he had fewer\\nnightmares when he was tired out after training.\\nThen, during one particularly wet and muddy practice session, Wood gave\\nthe team a bit of bad news. He\\'d just gotten very angry with the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 172}), Document(page_content='173Weasleys, who kept dive-bombing each other and pretending to fall off\\ntheir brooms.\\n\"Will you stop messing around!\" he yelled. \"That\\'s exactly the sort of\\nthing that\\'ll lose us the match! Snape\\'s refereeing this time, and he\\'llbe looking for any excuse to knock points off Gryffindor!\"\\nGeorge Weasley really did fall off his broom at these words.\\n\"Snape\\'s refereeing?\" he spluttered through a mouthful of mud. \"When\\'s\\nhe ever refereed a Quidditch match? He\\'s not going to be fair if wemight overtake Slytherin.\"\\nThe rest of the team landed next to George to complain, too.\\n\"It\\'s not my fault,\" said Wood. \"We\\'ve just got to make sure we play a\\nclean game, so Snape hasn\\'t got an excuse to pick on us.\"\\nWhich was all very well, thought Harry, but he had another reason for\\nnot wanting Snape near him while he was playing Quidditch....\\nThe rest of the team hung back to talk to one another as usual at the\\nend of practice, but Harry headed straight back to the Gryffindor commonroom, where he found Ron and Hermione playing chess. Chess was the onlything Hermione ever lost at, something Harry and Ron thought was verygood for her.\\n\"Don\\'t talk to me for a moment,\" said Ron when Harry sat down next to\\nhim, \"I need to concen --\" He caught sight of Harry\\'s face. \"What\\'s thematter with you? You look terrible.\"\\nSpeaking quietly so that no one else would hear, Harry told the other\\ntwo about Snape\\'s sudden, sinister desire to be a Quidditch referee.\\n\"Don\\'t play,\" said Hermione at once.\"Say you\\'re ill,\" said Ron.\"Pretend to break your leg,\" Hermione suggested.\\n\"Really break your leg,\" said Ron.\\n\"I can\\'t,\" said Harry. \"There isn\\'t a reserve Seeker. If I back out,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 173}), Document(page_content='174Gryffindor can\\'t play at all.\"\\nAt that moment Neville toppled into the common room. How he had managed\\nto climb through the portrait hole was anyone\\'s guess, because his legshad been stuck together with what they recognized at once as theLeg-Locker Curse. He must have had to bunny hop all the way up to\\nGryffindor tower.\\nEveryone fell over laughing except Hermione, who leapt up and performed\\nthe countercurse. Neville\\'s legs sprang apart and he got to his feet,trembling. \"What happened?\" Hermione asked him, leading him over to sitwith Harry and Ron.\\n\"Malfoy,\" said Neville shakily. \"I met him outside the library. He said\\nhe\\'d been looking for someone to practice that on.\"\\n\"Go to Professor McGonagall!\" Hermione urged Neville. \"Report him!\"Neville shook his head.\\n\"I don\\'t want more trouble,\" he mumbled.\\n\"You\\'ve got to stand up to him, Neville!\" said Ron. \"He\\'s used to\\nwalking all over people, but that\\'s no reason to lie down in front ofhim and make it easier.\"\\n\"There\\'s no need to tell me I\\'m not brave enough to be in Gryffindor,\\nMalfoy\\'s already done that,\" Neville choked out.\\nHarry felt in the pocket of his robes and pulled out a Chocolate Frog,\\nthe very last one from the box Hermione had given him for Christmas. Hegave it to Neville, who looked as though he might cry.\\n\"You\\'re worth twelve of Malfoy,\" Harry said. \"The Sorting Hat chose you\\nfor Gryffindor, didn\\'t it? And where\\'s Malfoy? In stinking Slytherin.\"\\nNeville\\'s lips twitched in a weak smile as he unwrapped the frog.\"Thanks, Harry... I think I\\'ll go to bed.... D\\'you want the card, you\\ncollect them, don\\'t you?\"\\nAs Neville walked away, Harry looked at the Famous Wizard card.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 174}), Document(page_content='175\"Dumbledore again,\" he said, \"He was the first one I ever-\"\\nHe gasped. He stared at the back of the card. Then he looked up at Ron\\nand Hermione.\\n\"I\\'ve found him!\" he whispered. \"I\\'ve found Flamel! I told you I\\'d read\\nthe name somewhere before, I read it on the train coming here -- listen\\nto this: \\'Dumbledore is particularly famous for his defeat of the darkwizard Grindelwald in 1945, for the discovery of the twelve uses ofdragon\\'s blood, and his work on alchemy with his partner, NicolasFlamel\\'!\"\\nHermione jumped to her feet. She hadn\\'t looked so excited since they\\'d\\ngotten back the marks for their very first piece of homework.\\n\"Stay there!\" she said, and she sprinted up the stairs to the girls\\'\\ndormitories. Harry and Ron barely had time to exchange mystified looksbefore she was dashing back, an enormous old book in her arms.\\n\"I never thought to look in here!\" she whispered excitedly. \"I got this\\nout of the library weeks ago for a bit of light reading.\"\\n\"Light?\" said Ron, but Hermione told him to be quiet until she\\'d looked\\nsomething up, and started flicking frantically through the pages,muttering to herself.\\nAt last she found what she was looking for.\\n\"I knew it! I knew it!\"\"Are we allowed to speak yet?\" said Ron grumpily. Hermione ignored him.\\n\"Nicolas Flamel,\" she whispered dramatically, \"is the only known maker\\nof the Sorcerer\\'s Stone!\"\\nThis didn\\'t have quite the effect she\\'d expected.\"The what?\" said Harry and Ron.\\n\"Oh, honestly, don\\'t you two read? Look -- read that, there.\"\\nShe pushed the book toward them, and Harry and Ron read: The ancient\\nstudy of alchemy is concerned with making the Sorcerer\\'s Stone, a', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 175}), Document(page_content='176legendary substance with astonishing powers. The stone will transform\\nany metal into pure gold. It also produces the Elixir of Life, whichwill make the drinker immortal.\\nThere have been many reports of the Sorcerer\\'s Stone over the centuries,\\nbut the only Stone currently in existence belongs to Mr. Nicolas Flamel,\\nthe noted alchemist and opera lover. Mr. Flamel, who celebrated his six\\nhundred and sixty-fifth birthday last year, enjoys a quiet life in Devonwith his wife, Perenelle (six hundred and fifty-eight).\\n\"See?\" said Hermione, when Harry and Ron had finished. \"The dog must be\\nguarding Flamel\\'s Sorcerer\\'s Stone! I bet he asked Dumbledore to keep itsafe for him, because they\\'re friends and he knew someone was after it,\\nthat\\'s why he wanted the Stone moved out of Gringotts!\"\\n\"A stone that makes gold and stops you from ever dying!\" said Harry. \"No\\nwonder Snape\\'s after it! Anyone would want it.\"\\n\"And no wonder we couldn\\'t find Flamel in that Study of Recent\\nDevelopments in Wizardry,\" said Ron. \"He\\'s not exactly recent if he\\'s\\nsix hundred and sixty-five, is he?\"\\nThe next morning in Defense Against the Dark Arts, while copying down\\ndifferent ways of treating werewolf bites, Harry and Ron were stilldiscussing what they\\'d do with a Sorcerer\\'s Stone if they had one. Itwasn\\'t until Ron said he\\'d buy his own Quidditch team that Harry\\nremembered about Snape and the coming match.\\n\"I\\'m going to play,\" he told Ron and Hermione. \"If I don\\'t, all the\\nSlytherins will think I\\'m just too scared to face Snape. I\\'ll showthem... it\\'ll really wipe the smiles off their faces if we win.\"\\n\"Just as long as we\\'re not wiping you off the field,\" said Hermione.\\nAs the match drew nearer, however, Harry became more and more nervous,\\nwhatever he told Ron and Hermione. The rest of the team wasn\\'t too calm,either. The idea of overtaking Slytherin in the house championship waswonderful, no one had done it for seven years, but would they be allowedto, with such a biased referee?\\nHarry didn\\'t know whether he was imagining it or not, but he seemed to\\nkeep running into Snape wherever he went. At times, he even wonderedwhether Snape was following him, trying to catch him on his own. Potions', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 176}), Document(page_content='177lessons were turning into a sort of weekly torture, Snape was so\\nhorrible to Harry. Could Snape possibly know they\\'d found out about theSorcerer\\'s Stone? Harry didn\\'t see how he could -- yet he sometimes hadthe horrible feeling that Snape could read minds.\\nHarry knew, when they wished him good luck outside the locker rooms the\\nnext afternoon, that Ron and Hermione were wondering whether they\\'d ever\\nsee him alive again. This wasn\\'t what you\\'d call comforting. Harryhardly heard a word of Wood\\'s pep talk as he pulled on his Quidditchrobes and picked up his Nimbus Two Thousand.\\nRon and Hermione, meanwhile, had found a place in the stands next to\\nNeville, who couldn\\'t understand why they looked so grim and worried, or\\nwhy they had both brought their wands to the match. Little did Harry\\nknow that Ron and Hermione had been secretly practicing the Leg-LockerCurse. They\\'d gotten the idea from Malfoy using it on Neville, and wereready to use it on Snape if he showed any sign of wanting to hurt Harry.\\n\"Now, don\\'t forget, it\\'s Locomotor Mortis,\" Hermione muttered as Ron\\nslipped his wand up his sleeve.\\n\"I know,\" Ron snapped. \"Don\\'t nag.\"Back in the locker room, Wood had taken Harry aside.\"Don\\'t want to pressure you, Potter, but if we ever need an early\\ncapture of the Snitch it\\'s now. Finish the game before Snape can favor\\nHufflepuff too much.\"\\n\"The whole school\\'s out there!\" said Fred Weasley, peering out of the\\ndoor. \"Even -- blimey -- Dumbledore\\'s come to watch!\"\\nHarry\\'s heart did a somersault.\\n\"Dumbledore?\" he said, dashing to the door to make sure. Fred was right.\\nThere was no mistaking that silver beard.\\nHarry could have laughed out loud with relief He was safe. There was\\nsimply no way that Snape would dare to try to hurt him if Dumbledore was\\nwatching.\\nPerhaps that was why Snape was looking so angry as the teams marched\\nonto the field, something that Ron noticed, too.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 177}), Document(page_content='178\"I\\'ve never seen Snape look so mean,\" he told Hermione. \"Look -they\\'re\\noff Ouch!\"\\nSomeone had poked Ron in the back of the head. It was Malfoy.\\n\"Oh, sorry, Weasley, didn\\'t see you there.\"\\nMalfoy grinned broadly at Crabbe and Goyle.\"Wonder how long Potter\\'s going to stay on his broom this time? Anyone\\nwant a bet? What about you, Weasley?\"\\nRon didn\\'t answer; Snape had just awarded Hufflepuff a penalty because\\nGeorge Weasley had hit a Bludger at him. Hermione, who had all herfingers crossed in her lap, was squinting fixedly at Harry, who wascircling the game like a hawk, looking for the Snitch.\\n\"You know how I think they choose people for the Gryffindor team?\" said\\nMalfoy loudly a few minutes later, as Snape awarded Hufflepuff another\\npenalty for no reason at all. \"It\\'s people they feel sorry for. See,there\\'s Potter, who\\'s got no parents, then there\\'s the Weasleys, who\\'vegot no money -- you should be on the team, Longbottom, you\\'ve got nobrains.\"\\nNeville went bright red but turned in his seat to face Malfoy.\\n\"I\\'m worth twelve of you, Malfoy,\" he stammered.\\nMalfoy, Crabbe, and Goyle howled with laughter, but Ron, still not\\ndaring to take his eyes from the game, said, \"You tell him, Neville.\"\\n\"Longbottom, if brains were gold you\\'d be poorer than Weasley, and\\nthat\\'s saying something.\"\\nRon\\'s nerves were already stretched to the breaking point with anxiety\\nabout Harry.\\n\"I\\'m warning you, Malfoy -- one more word\\n\"Ron!\" said Hermione suddenly, \"Harry --\"\\n\"What? Where?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 178}), Document(page_content='179Harry had suddenly gone into a spectacular dive, which drew gasps and\\ncheers from the crowd. Hermione stood up, her crossed fingers in hermouth, as Harry streaked toward the ground like a bullet.\\n\"You\\'re in luck, Weasley, Potter\\'s obviously spotted some money on the\\nground!\" said Malfoy.\\nRon snapped. Before Malfoy knew what was happening, Ron was on top of\\nhim, wrestling him to the ground. Neville hesitated, then clambered overthe back of his seat to help.\\n\"Come on, Harry!\" Hermione screamed, leaping onto her seat to watch as\\nHarry sped straight at Snape -- she didn\\'t even notice Malfoy and Ron\\nrolling around under her seat, or the scuffles and yelps coming from thewhirl of fists that was Neville, Crabbe, and Goyle.\\nUp in the air, Snape turned on his broomstick just in time to see\\nsomething scarlet shoot past him, missing him by inches -- the next\\nsecond, Harry had pulled out of the dive, his arm raised in triumph, the\\nSnitch clasped in his hand.\\nThe stands erupted; it had to be a record, no one could ever remember\\nthe Snitch being caught so quickly.\\n\"Ron! Ron! Where are you? The game\\'s over! Harry\\'s won! We\\'ve won!\\nGryffindor is in the lead!\" shrieked Hermione, dancing up and down on\\nher seat and hugging Parvati Patil in the row in front.\\nHarry jumped off his broom, a foot from the ground. He couldn\\'t believe\\nit. He\\'d done it -- the game was over; it had barely lasted fiveminutes. As Gryffindors came spilling onto the field, he saw Snape land\\nnearby, white-faced and tight-lipped -- then Harry felt a hand on his\\nshoulder and looked up into Dumbledore\\'s smiling face.\\n\"Well done,\" said Dumbledore quietly, so that only Harry could hear.\\n\"Nice to see you haven\\'t been brooding about that mirror... been keepingbusy... excellent...\"\\nSnape spat bitterly on the ground.\\nHarry left the locker room alone some time later, to take his Nimbus Two\\nThousand back to the broomshed. He couldn\\'t ever remember feeling', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 179}), Document(page_content='180happier. He\\'d really done something to be proud of now -- no one could\\nsay he was just a famous name any more. The evening air had neversmelled so sweet. He walked over the damp grass, reliving the last hourin his head, which was a happy blur: Gryffindors running to lift himonto their shoulders; Ron and Hermione in the distance, jumping up anddown, Ron cheering through a heavy nosebleed.\\nHarry had reached the shed. He leaned against the wooden door and looked\\nup at Hogwarts, with its windows glowing red in the setting sun.Gryffindor in the lead. He\\'d done it, he\\'d shown Snape....\\nAnd speaking of Snape...\\nA hooded figure came swiftly down the front steps of the castle. Clearly\\nnot wanting to be seen, it walked as fast as possible toward theforbidden forest. Harry\\'s victory faded from his mind as he watched. Herecognized the figure\\'s prowling walk. Snape, sneaking into the forestwhile everyone else was at dinner -- what was going on?\\nHarry jumped back on his Nimbus Two Thousand and took off. Gliding\\nsilently over the castle he saw Snape enter the forest at a run. Hefollowed.\\nThe trees were so thick he couldn\\'t see where Snape had gone. He flew in\\ncircles, lower and lower, brushing the top branches of trees until heheard voices. He glided toward them and landed noiselessly in a towering\\nbeech tree.\\nHe climbed carefully along one of the branches, holding tight to his\\nbroomstick, trying to see through the leaves. Below, in a shadowyclearing, stood Snape, but he wasn\\'t alone. Quirrell was there, too.Harry couldn\\'t make out the look on his face, but he was stuttering\\nworse than ever. Harry strained to catch what they were saying.\\n\"... d-don\\'t know why you wanted t-t-to meet here of all p-places,\\nSeverus...\"\\n\"Oh, I thought we\\'d keep this private,\" said Snape, his voice icy.\\n\"Students aren\\'t supposed to know about the Sorcerer\\'s Stone, after\\nall.\"\\nHarry leaned forward. Quirrell was mumbling something. Snape interrupted\\nhim.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 180}), Document(page_content='181\"Have you found out how to get past that beast of Hagrid\\'s yet?\"\\n\"B-b-but Severus, I --\"\"You don\\'t want me as your enemy, Quirrell,\" said Snape, taking a step\\ntoward him.\\n\"I-I don\\'t know what you\"You know perfectly well what I mean.\"An owl hooted loudly, and Harry nearly fell out of the tree. He steadied\\nhimself in time to hear Snape say, \"-- your little bit of hocus-pocus.\\nI\\'m waiting.\"\\n\"B-but I d-d-don\\'t --\"\"Very well,\" Snape cut in. \"We\\'ll have another little chat soon, when\\nyou\\'ve had time to think things over and decided where your loyalties\\nlie.\"\\nHe threw his cloak over his head and strode out of the clearing. It was\\nalmost dark now, but Harry could see Quirrell, standing quite still asthough he was petrified.\\n\"Harry, where have you been?\" Hermione squeaked.\\n\"We won! You won! We won!\" shouted Ron, thumping Harry on the back. \"And\\nI gave Malfoy a black eye, and Neville tried to take on Crabbe and Goylesingle-handed! He\\'s still out cold but Madam Pomftey says he\\'ll be allright - talk about showing Slytherin! Everyone\\'s waiting for you in the\\ncommon room, we\\'re having a party, Fred and George stole some cakes and\\nstuff from the kitchens.\"\\n\"Never mind that now,\" said Harry breathlessly. \"Let\\'s find an empty\\nroom, you wait \\'til you hear this....\"\\nHe made sure Peeves wasn\\'t inside before shutting the door behind them,\\nthen he told them what he\\'d seen and heard.\\n\"So we were right, it is the Sorcerer\\'s Stone, and Snape\\'s trying to\\nforce Quirrell to help him get it. He asked if he knew how to get past', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 181}), Document(page_content='182Fluffy - and he said something about Quirrell\\'s \\'hocus pocuss-- I reckon\\nthere are other things guarding the stone apart from Fluffy, loads ofenchantments, probably, and Quirrell would have done some anti-Dark Artsspell that Snape needs to break through --\"\\n\"So you mean the Stone\\'s only safe as long as Quirrell stands up to\\nSnape?\" said Hermione in alarm.\\n\"It\\'ll be gone by next Tuesday,\" said Ron.\\nCHAPTER FOURTEEN\\nNORBERT THE NORWEGIAN RIDGEBACK\\nQuirrell, however, must have been braver than they\\'d thought. In the\\nweeks that followed he did seem to be getting paler and thinner, but itdidn\\'t look as though he\\'d cracked yet.\\nEvery time they passed the third-floor corridor, Harry, Ron, and\\nHermione would press their ears to the door to check that Fluffy wasstill growling inside. Snape was sweeping about in his usual bad temper,which surely meant that the Stone was still safe. Whenever Harry passedQuirrell these days he gave him an encouraging sort of smile, and Ronhad started telling people off for laughing at Quirrell\\'s stutter.\\nHermione, however, had more on her mind than the Sorcerer\\'s Stone. She\\nhad started drawing up study schedules and colorcoding all her notes.Harry and Ron wouldn\\'t have minded, but she kept nagging them to do thesame.\\n\"Hermione, the exams are ages away.\"\\n\"Ten weeks,\" Hermione snapped. \"That\\'s not ages, that\\'s like a second to\\nNicolas Flamel.\"\\n\"But we\\'re not six hundred years old,\" Ron reminded her. \"Anyway, what\\nare you studying for, you already know it A.\"\\n\"What am I studying for? Are you crazy? You realize we need to pass\\nthese exams to get into the second year? They\\'re very important, Ishould have started studying a month ago, I don\\'t know what\\'s gotteninto me....\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 182}), Document(page_content='183Unfortunately, the teachers seemed to be thinking along the same lines\\nas Hermione. They piled so much homework on them that the Easterholidays weren\\'t nearly as much fun as the Christmas ones. It was hardto relax with Hermione next to you reciting the twelve uses of dragon\\'sblood or practicing wand movements. Moaning and yawning, Harry and Ron\\nspent most of their free time in the library with her, trying to get\\nthrough all their extra work.\\n\"I\\'ll never remember this,\" Ron burst out one afternoon, throwing down\\nhis quill and looking longingly out of the library window. It was thefirst really fine day they\\'d had in months. The sky was a clear,forget-me-not blue, and there was a feeling in the air of summer coming.\\nHarry, who was looking up \"Dittany\" in One Thousand Magical Herbs and\\nFungi, didn\\'t look up until he heard Ron say, \"Hagrid! What are youdoing in the library?\"\\nHagrid shuffled into view, hiding something behind his back. He looked\\nvery out of place in his moleskin overcoat.\\n\"Jus\\' lookin\\',\" he said, in a shifty voice that got their interest at\\nonce. \"An\\' what\\'re you lot up ter?\" He looked suddenly suspicious. \"Yernot still lookin\\' fer Nicolas Flamel, are yeh?\" \"Oh, we found out who heis ages ago,\" said Ron impressively. \"And we know what that dog\\'sguarding, it\\'s a Sorcerer\\'s St --\"\\n\"Shhhh!\" Hagrid looked around quickly to see if anyone was listening.\\n\"Don\\' go shoutin\\' about it, what\\'s the matter with yeh?\"\\n\"There are a few things we wanted to ask you, as a matter of fact,\" said\\nHarry, \"about what\\'s guarding the Stone apart from Fluffy --\"\\n\"SHHHH!\" said Hagrid again. \"Listen - come an\\' see me later, I\\'m not\\npromisin\\' I\\'ll tell yeh anythin\\', mind, but don\\' go rabbitin\\' about itin here, students aren\\' s\\'pposed ter know. They\\'ll think I\\'ve told yeh--\"\\n\"See you later, then,\" said Harry.\\nHagrid shuffled off.\\n\"What was he hiding behind his back?\" said Hermione thoughtfully.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 183}), Document(page_content='184\"Do you think it had anything to do with the Stone?\"\\n\"I\\'m going to see what section he was in,\" said Ron, who\\'d had enough of\\nworking. He came back a minute later with a pile of books in his armsand slammed them down on the table.\\n\"Dragons!\" he whispered. \"Hagrid was looking up stuff about dragons!\\nLook at these: Dragon Species of Great Britain and Ireland; From Egg toInferno, A Dragon Keeper\\'s Guide.\"\\n\"Hagrid\\'s always wanted a dragon, he told me so the first time I ever\\nmet him, \" said Harry.\\n\"But it\\'s against our laws,\" said Ron. \"Dragon breeding was outlawed by\\nthe Warlocks\\' Convention of 1709, everyone knows that. It\\'s hard to stopMuggles from noticing us if we\\'re keeping dragons in the back garden -anyway, you can\\'t tame dragons, it\\'s dangerous. You should see the burnsCharlie\\'s got off wild ones in Romania.\"\\n\"But there aren\\'t wild dragons in Britain?\" said Harry.\\n\"Of course there are,\" said Ron. \"Common Welsh Green and Hebridean\\nBlacks. The Ministry of Magic has a job hushing them up, I can tell you.Our kind have to keep putting spells on Muggles who\\'ve spotted them, tomake them forget.\"\\n\"So what on earths Hagrid up to?\" said Hermione.\\nWhen they knocked on the door of the gamekeeper\\'s hut an hour later,\\nthey were surprised to see that all the curtains were closed. Hagridcalled \"Who is it?\" before he let them in, and then shut the door\\nquickly behind them.\\nIt was stifling hot inside. Even though it was such a warm day, there\\nwas a blazing fire in the grate. Hagrid made them tea and offered themstoat sandwiches, which they refused.\\n\"So -- yeh wanted to ask me somethin\\'?\"\\n\"Yes,\" said Harry. There was no point beating around the bush. \"We were\\nwondering if you could tell us what\\'s guarding the Sorcerer\\'s Stoneapart from Fluffy.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 184}), Document(page_content='185Hagrid frowned at him.\\n\"0\\' course I cant, he said. \"Number one, I don\\' know meself. Number two,\\nyeh know too much already, so I wouldn\\' tell yeh if I could. ThatStone\\'s here fer a good reason. It Was almost stolen outta Gringotts - I\\ns\\'ppose yeh\\'ve worked that out an\\' all? Beats me how yeh even know abou\\'\\nFluffy.\"\\n\"Oh, come on, Hagrid, you might not want to tell us, but you do know,\\nyou know everything that goes on round here,\" said Hermione in a warm,flattering voice. Hagrid\\'s beard twitched and they could tell he wassmiling. \"We only wondered who had done the guarding, really.\" Hermione\\nwent on. \"We wondered who Dumbledore had trusted enough to help him,\\napart from you.\"\\nHagrid\\'s chest swelled at these last words. Harry and Ron beamed at\\nHermione.\\n\"Well, I don\\' s\\'pose it could hurt ter tell yeh that... let\\'s see... he\\nborrowed Fluffy from me... then some o\\' the teachers did enchantments...Professor Sprout -- Professor Flitwick -- Professor McGonagall --\" heticked them off on his fingers, \"Professor Quirrell -- an\\' Dumbledorehimself did somethin\\', o\\' course. Hang on, I\\'ve forgotten someone. Ohyeah, Professor Snape.\"\\n\"Snape?\"\\n\"Yeah -- yer not still on abou\\' that, are yeh? Look, Snape helped\\nprotect the Stone, he\\'s not about ter steal it.\"\\nHarry knew Ron and Hermione were thinking the same as he was. If Snape\\nhad been in on protecting the Stone, it must have been easy to find out\\nhow the other teachers had guarded it. He probably knew everything --except, it seemed, Quirrell\\'s spell and how to get past Fluffy.\\n\"You\\'re the only one who knows how to get past Fluffy. aren\\'t you,\\nHagrid?\" said Harry anxiously. \"And you wouldn\\'t tell anyone, would you?Not even one of the teachers?\"\\n\"Not a soul knows except me an\\' Dumbledore,\" said Hagrid proudly.\\n\"Well, that\\'s something,\" Harry muttered to the others. \"Hagrid, can we', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 185}), Document(page_content='186have a window open? I\\'m boiling.\"\\n\"Can\\'t, Harry, sorry,\" said Hagrid. Harry noticed him glance at the\\nfire. Harry looked at it, too.\\n\"Hagrid -- what\\'s that?\"\\nBut he already knew what it was. In the very heart of the fire,\\nunderneath the kettle, was a huge, black egg.\\n\"Ah,\" said Hagrid, fiddling nervously with his beard, \"That\\'s er...\"\"Where did you get it, Hagrid?\" said Ron, crouching over the fire to get\\na closer look at the egg. \"It must\\'ve cost you a fortune.\"\\n\"Won it,\" said Hagrid. \"Las\\' night. I was down in the village havin\\' a\\nfew drinks an\\' got into a game o\\' cards with a stranger. Think he wasquite glad ter get rid of it, ter be honest.\"\\n\"But what are you going to do with it when it\\'s hatched?\" said Hermione.\\n\"Well, I\\'ve bin doin\\' some readin\\' , said Hagrid, pulling a large book\\nfrom under his pillow. \"Got this outta the library -- Dragon Breedingfor Pleasure and Profit -- it\\'s a bit outta date, o\\' course, but it\\'sall in here. Keep the egg in the fire, \\'cause their mothers breathe on Iem, see, an\\' when it hatches, feed it on a bucket o\\' brandy mixed with\\nchicken blood every half hour. An\\' see here -- how ter recognize\\ndiff\\'rent eggs -- what I got there\\'s a Norwegian Ridgeback. They\\'rerare, them.\"\\nHe looked very pleased with himself, but Hermione didn\\'t.\\n\"Hagrid, you live in a wooden house,\" she said.\\nBut Hagrid wasn\\'t listening. He was humming merrily as he stoked the\\nfire.\\nSo now they had something else to worry about: what might happen to\\nHagrid if anyone found out he was hiding an illegal dragon in his hut.\\n\"Wonder what it\\'s like to have a peaceful life,\" Ron sighed, as evening\\nafter evening they struggled through all the extra homework they weregetting. Hermione had now started making study schedules for Harry andRon, too. It was driving them nuts.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 186}), Document(page_content='187Then, one breakfast time, Hedwig brought Harry another note from Hagrid.\\nHe had written only two words: It\\'s hatching.\\nRon wanted to skip Herbology and go straight down to the hut. Hermione\\nwouldn\\'t hear of it.\\n\"Hermione, how many times in our lives are we going to see a dragon\\nhatching?\"\\n\"We\\'ve got lessons, we\\'ll get into trouble, and that\\'s nothing to what\\nHagrid\\'s going to be in when someone finds out what he\\'s doing --\"\\n\"Shut up!\" Harry whispered.\\nMalfoy was only a few feet away and he had stopped dead to listen. How\\nmuch had he heard? Harry didn\\'t like the look on Malfoy\\'s face at all.\\nRon and Hermione argued all the way to Herbology and in the end,\\nHermione agreed to run down to Hagrid\\'s with the other two during\\nmorning break. When the bell sounded from the castle at the end of theirlesson, the three of them dropped their trowels at once and hurriedthrough the grounds to the edge of the forest. Hagrid greeted them,looking flushed and excited.\\n\"It\\'s nearly out.\" He ushered them inside.\\nThe egg was lying on the table. There were deep cracks in it. Something\\nwas moving inside; a funny clicking noise was coming from it.\\nThey all drew their chairs up to the table and watched with bated\\nbreath.\\nAll at once there was a scraping noise and the egg split open. The baby\\ndragon flopped onto the table. It wasn\\'t exactly pretty; Harry thoughtit looked like a crumpled, black umbrella. Its spiny wings were hugecompared to its skinny jet body, it had a long snout with wide nostrils,the stubs of horns and bulging, orange eyes.\\nIt sneezed. A couple of sparks flew out of its snout.\\n\"Isn\\'t he beautiful?\" Hagrid murmured. He reached out a hand to stroke\\nthe dragon\\'s head. It snapped at his fingers, showing pointed fangs.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 187}), Document(page_content='188\"Bless him, look, he knows his mommy!\" said Hagrid.\\n\"Hagrid,\" said Hermione, \"how fast do Norwegian Ridgebacks grow,\\nexactly?\"\\nHagrid was about to answer when the color suddenly drained from his face\\n-- he leapt to his feet and ran to the window.\\n\"What\\'s the matter?\"\"Someone was lookin\\' through the gap in the curtains -- it\\'s a kid --\\nhe\\'s runnin\\' back up ter the school.\"\\nHarry bolted to the door and looked out. Even at a distance there was no\\nmistaking him.\\nMalfoy had seen the dragon.\\nSomething about the smile lurking on Malfoy\\'s face during the next week\\nmade Harry, Ron, and Hermione very nervous. They spent most of theirfree time in Hagrid\\'s darkened hut, trying to reason with him.\\n\"Just let him go,\" Harry urged. \"Set him free.\"\"I can\\'t,\" said Hagrid. \"He\\'s too little. He\\'d die.\"\\nThey looked at the dragon. It had grown three times in length in just a\\nweek. Smoke kept furling out of its nostrils. Hagrid hadn\\'t been doinghis gamekeeping duties because the dragon was keeping him so busy. Therewere empty brandy bottles and chicken feathers all over the floor.\\n\"I\\'ve decided to call him Norbert,\" said Hagrid, looking at the dragon\\nwith misty eyes. \"He really knows me now, watch. Norbert! Norbert!Where\\'s Mommy?\"\\n\"He\\'s lost his marbles,\" Ron muttered in Harry\\'s ear.\"Hagrid,\" said Harry loudly, \"give it two weeks and Norbert\\'s going to\\nbe as long as your house. Malfoy could go to Dumbledore at any moment.\"\\nHagrid bit his lip.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 188}), Document(page_content='189\"I -- I know I can\\'t keep him forever, but I can\\'t jus\\' dump him, I\\ncan\\'t.\"\\nHarry suddenly turned to Ron. Charlie, he said.\"You\\'re losing it, too,\" said Ron. \"I\\'m Ron, remember?\"\\n\"No -- Charlie -- your brother, Charlie. In Romania. Studying dragons.\\nWe could send Norbert to him. Charlie can take care of him and then puthim back in the wild!\"\\n\"Brilliant!\" said Ron. \"How about it, Hagrid?\"\\nAnd in the end, Hagrid agreed that they could send -an owl to Charlie to\\nask him.\\nThe following week dragged by. Wednesday night found Hermione and Harry\\nsitting alone in the common room, long after everyone else had gone tobed. The clock on the wall had just\\nchimed midnight when the portrait hole burst open. Ron appeared out of\\nnowhere as he pulled off Harry\\'s invisibility cloak. He had been down atHagrid\\'s hut, helping him feed Norbert, who was now eating dead rats bythe crate.\\n\"It bit me!\" he said, showing them his hand, which was wrapped in a\\nbloody handkerchief. \"I\\'m not going to be able to hold a quill for a\\nweek. I tell you, that dragon\\'s the most horrible animal I\\'ve ever met,but the way Hagrid goes on about it, you\\'d think it was a fluffy littlebunny rabbit. When it bit me he told me off for frightening it. And whenI left, he was singing it a lullaby.\"\\nThere was a tap on the dark window.\\n\"It\\'s Hedwig!\" said Harry, hurrying to let her in. \"She\\'ll have\\nCharlie\\'s answer!\"\\nThe three of them put their heads together to read the note.\\nDear Ron,\\nHow are you? Thanks for the letter -- I\\'d be glad to take the Norwegian\\nRidgeback, but it won\\'t be easy getting him here. I think the best thing', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 189}), Document(page_content='190will be to send him over with some friends of mine who are coming to\\nvisit me next week. Trouble is, they mustn\\'t be seen carrying an illegaldragon.\\nCould you get the Ridgeback up the tallest tower at midnight on\\nSaturday? They can meet you there and take him away while it\\'s still\\ndark.\\nSend me an answer as soon as possible.Love,Charlie\\nThey looked at one another.\\n\"We\\'ve got the invisibility cloak,\" said Harry. \"It shouldn\\'t be too\\ndifficult -- I think the cloaks big enough to cover two of us andNorbert.\"\\nIt was a mark of how bad the last week had been that the other two\\nagreed with him. Anything to get rid of Norbert -- and Malfoy.\\nThere was a hitch. By the next morning, Ron\\'s bitten hand had swollen to\\ntwice its usual size. He didn\\'t know whether it was safe to go to MadamPomfrey -- would she recognize a dragon bite? By the afternoon, though,\\nhe had no choice. The cut had turned a nasty shade of green. It looked\\nas if Norbert\\'s fangs were poisonous.\\nHarry and Hermione rushed up to the hospital wing at the end of the day\\nto find Ron in a terrible state in bed.\\n\"It\\'s not just my hand,\" he whispered, \"although that feels like it\\'s\\nabout to fall off. Malfoy told Madam Pomfrey he wanted to borrow one ofmy books so he could come and have a good laugh at me. He keptthreatening to tell her what really bit me -- I\\'ve told her it was adog, but I don\\'t think she believes me -I shouldn\\'t have hit him at theQuidditch match, that\\'s why he\\'s doing this.\"\\nHarry and Hermione tried to calm Ron down.\\n\"It\\'ll all be over at midnight on Saturday,\" said Hermione, but this\\ndidn\\'t soothe Ron at all. On the contrary, he sat bolt upright and broke', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 190}), Document(page_content='191into a sweat.\\n\"Midnight on Saturday!\" he said in a hoarse voice. \"Oh no oh no -- I\\'ve\\njust remembered -- Charlie\\'s letter was in that book Malfoy took, he\\'sgoing to know we\\'re getting rid of Norbert.\"\\nHarry and Hermione didn\\'t get a chance to answer. Madam Pomfrey came\\nover at that moment and made them leave, saying Ron needed sleep.\\n\"It\\'s too late to change the plan now,\" Harry told Hermione. \"We haven\\'t\\ngot time to send Charlie another owl, and this could be our only chanceto get rid of Norbert. We\\'ll have to risk it. And we have got theinvisibility cloak, Malfoy doesn\\'t know about that.\"\\nThey found Fang, the boarhound, sitting outside with a bandaged tail\\nwhen they went to tell Hagrid, who opened a window to talk to them.\\n\"I won\\'t let you in,\" he puffed. \"Norbert\\'s at a tricky stage -- nothin\\'\\nI can\\'t handle.\"\\nWhen they told him about Charlie\\'s letter, his eyes filled with tears,\\nalthough that might have been because Norbert had just bitten him on theleg.\\n\"Aargh! It\\'s all right, he only got my boot -- jus\\' playin\\' -- he\\'s only\\na baby, after all.\"\\nThe baby banged its tail on the wall, making the windows rattle. Harry\\nand Hermione walked back to the castle feeling Saturday couldn\\'t comequickly enough.\\nThey would have felt sorry for Hagrid when the time came for him to say\\ngood-bye to Norbert if they hadn\\'t been so worried about what they had\\nto do. It was a very dark, cloudy night, and they were a bit latearriving at Hagrid\\'s hut because they\\'d had to wait for Peeves to getout of their way in the entrance hall, where he\\'d been playing tennisagainst the wall. Hagrid had Norbert packed and ready in a large crate.\\n\"He\\'s got lots o\\' rats an\\' some brandy fer the journey,\" said Hagrid in\\na muffled voice. \"An\\' I\\'ve packed his teddy bear in case he gets\\nlonely.\"\\nFrom inside the crate came ripping noises that sounded to Harry as', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 191}), Document(page_content='192though the teddy was having his head torn off.\\n\"Bye-bye, Norbert!\" Hagrid sobbed, as Harry and Hermione covered the\\ncrate with the invisibility cloak and stepped underneath it themselves.\"Mommy will never forget you!\"\\nHow they managed to get the crate back up to the castle, they never\\nknew. Midnight ticked nearer as they heaved Norbert up the marblestaircase in the entrance hall and along the dark corridors. UP anotherstaircase, then another -- even one of Harry\\'s shortcuts didn\\'t make thework much easier.\\n\"Nearly there!\" Harry panted as they reached the corridor beneath the\\ntallest tower.\\nThen a sudden movement ahead of them made them almost drop the crate.\\nForgetting that they were already invisible, they shrank into theshadows, staring at the dark outlines of two people grappling with eachother ten feet away. A lamp flared.\\nProfessor McGonagall, in a tartan bathrobe and a hair net, had Malfoy by\\nthe ear.\\n\"Detention!\" she shouted. \"And twenty points from Slytherin! Wandering\\naround in the middle of the night, how dare you --\"\\n\"You don\\'t understand, Professor. Harry Potter\\'s coming -- he\\'s got a\\ndragon!\"\\n\"What utter rubbish! How dare you tell such lies! Come on -- I shall see\\nProfessor Snape about you, Malfoy!\"\\nThe steep spiral staircase up to the top of the tower seemed the easiest\\nthing in the world after that. Not until they\\'d stepped out into thecold night air did they throw off the cloak, glad to be able to breatheproperly again. Hermione did a sort of jig.\\n\"Malfoy\\'s got detention! I could sing!\"\\n\"Don\\'t,\" Harry advised her.\\nChuckling about Malfoy, they waited, Norbert thrashing about in his\\ncrate. About ten minutes later, four broomsticks came swooping down out', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 192}), Document(page_content='193of the darkness.\\nCharlie\\'s friends were a cheery lot. They showed Harry and Hermione the\\nharness they\\'d rigged up, so they could suspend Norbert between them.They all helped buckle Norbert safely into it and then Harry andHermione shook hands with the others and thanked them very much.\\nAt last, Norbert was going... going... gone.\\nThey slipped back down the spiral staircase, their hearts as light as\\ntheir hands, now that Norbert was off them. No more dragon -- Malfoy indetention -- what could spoil their happiness?\\nThe answer to that was waiting at the foot of the stairs. As they\\nstepped into the corridor, Filch\\'s face loomed suddenly out of thedarkness.\\n\"Well, well, well,\" he whispered, \"we are in trouble.\"\\nThey\\'d left the invisibility cloak on top of the tower.\\nCHAPTER FIFTEEN\\nTHE FORIBIDDEN FOREST\\nThings couldn\\'t have been worse.\\nFilch took them down to Professor McGonagall\\'s study on the first floor,\\nwhere they sat and waited without saying a word to each other. Hermionewas trembling. Excuses, alibis, and wild cover- up stories chased eachother around Harry\\'s brain, each more feeble than the last. He couldn\\'t\\nsee how they were going to get out of trouble this time. They were\\ncornered. How could they have been so stupid as to forget the cloak?There was no reason on earth that Professor McGonagall would accept fortheir being out of bed and creeping around the school in the dead ofnight, let alone being up the tallest astronomy tower, which wasout-of-bounds except for classes. Add Norbert and the invisibilitycloak, and they might as well be packing their bags already.\\nHad Harry thought that things couldn\\'t have been worse? He was wrong.\\nWhen Professor McGonagall appeared, she was leading Neville.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 193}), Document(page_content='194\"Harry!\" Neville burst Out, the moment he saw the other two. \"I was\\ntrying to find you to warn you, I heard Malfoy saying he was going tocatch you, he said you had a drag --\"\\nHarry shook his head violently to shut Neville up, but Professor\\nMcGonagall had seen. She looked more likely to breathe fire than Norbert\\nas she towered over the three of them.\\n\"I would never have believed it of any of you. Mr. Filch says you were\\nup in the astronomy tower. It\\'s one o\\'clock in the morning. Explainyourselves.\"\\nIt was the first time Hermione had ever failed to answer a teacher\\'s\\nquestion. She was staring at her slippers, as still as a statue.\\n\"I think I\\'ve got a good idea of what\\'s been going on,\" said Professor\\nMcGonagall. \"It doesn\\'t take a genius to work it out. You fed DracoMalfoy some cock-and-bull story about a dragon, trying to get him out ofbed and into trouble. I\\'ve already caught him. I suppose you think it\\'s\\nfunny that Longbottom here heard the story and believed it, too?\"\\nHarry caught Neville\\'s eye and tried to tell him without words that this\\nwasn\\'t true, because Neville was looking stunned and hurt. Poor,blundering Neville -- Harry knew what it must have cost him to try andfind them in the dark, to warn them.\\n\"I\\'m disgusted,\" said Professor McGonagall. \"Four students out of bed in\\none night! I\\'ve never heard of such a thing before! You, Miss Granger, Ithought you had more sense. As for you, Mr. Potter, I thought Gryffindormeant more to you than this. All three of you will receive detentions --yes, you too, Mr. Longbottom, nothing gives you the right to walk aroundschool at night, especially these days, it\\'s very dangerous -- and fifty\\npoints will be taken from Gryffindor.\"\\n\"Fifty?\" Harry gasped -- they would lose the lead, the lead he\\'d won in\\nthe last Quidditch match.\\n\"Fifty points each,\" said Professor McGonagall, breathing heavily\\nthrough her long, pointed nose.\\n\"Professor -- please\\n\"You can\\'t --\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 194}), Document(page_content='195\"Don\\'t tell me what I can and can\\'t do, Potter. Now get back to bed, all\\nof you. I\\'ve never been more ashamed of Gryffindor students.\"\\nA hundred and fifty points lost. That put Gryffindor in last place. In\\none night, they\\'d ruined any chance Gryffindor had had for the house\\ncup. Harry felt as though the bottom had dropped out of his stomach. How\\ncould they ever make up for this?\\nHarry didn\\'t sleep all night. He could hear Neville sobbing into his\\npillow for what seemed like hours. Harry couldn\\'t think of anything tosay to comfort him. He knew Neville, like himself, was dreading thedawn. What would happen when the rest of Gryffindor found out what\\nthey\\'d done?\\nAt first, Gryffindors passing the giant hourglasses that recorded the\\nhouse points the next day thought there\\'d been a mistake. How could theysuddenly have a hundred and fifty points fewer than yesterday? And thenthe story started to spread: Harry Potter, the famous Harry Potter,\\ntheir hero of two Quidditch matches, had lo st them all those points,\\nhim and a couple of other stupid first years.\\nFrom being one of the most popular and admired people at the school,\\nHarry was suddenly the most hated. Even Ravenclaws and Hufflepuffsturned on him, because everyone had been longing to see Slytherin losethe house cup. Everywhere Harry went, people pointed and didn\\'t trouble\\nto lower their voices as they insulted him. Slytherins, on the other\\nhand, clapped as he walked past them, whistling and cheering, \"ThanksPotter, we owe you one!\"\\nOnly Ron stood by him.\\n\"They\\'ll all forget this in a few weeks. Fred and George have lost loads\\nof points in all the time they\\'ve been here, and people still likethem.\"\\n\"They\\'ve never lost a hundred and fifty points in one go, though, have\\nthey?\" said Harry miserably.\\n\"Well -- no,\" Ron admitted.\\nIt was a bit late to repair the damage, but Harry swore to himself not\\nto meddle in things that weren\\'t his business from now on. He\\'d had it', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 195}), Document(page_content='196with sneaking around and spying. He felt so ashamed of himself that he\\nwent to Wood and offered to resign from the Quidditch team.\\n\"Resign?\" Wood thundered. \"What good\\'ll that do? How are we going to get\\nany points back if we can\\'t win at Quidditch?\"\\nBut even Quidditch had lost its fun. The rest of the team wouldn\\'t speak\\nto Harry during practice, and if they had to speak about him, theycalled him \"the Seeker.\"\\nHermione and Neville were suffering, too. They didn\\'t have as bad a time\\nas Harry, because they weren\\'t as well-known, but nobody would speak tothem, either. Hermione had stopped drawing attention to herself in\\nclass, keeping her head down and working in silence.\\nHarry was almost glad that the exams weren\\'t far away. All the studying\\nhe had to do kept his mind off his misery. He, Ron, and Hermione kept tothemselves, working late into the night, trying to remember theingredients in complicated potions, learn charms and spells by heart,\\nmemorize the dates of magical discoveries and goblin rebellions....\\nThen, about a week before the exams were due to start, Harry\\'s new\\nresolution not to interfere in anything that didn\\'t concern him was putto an unexpected test. Walking back from the library on his own oneafternoon, he heard somebody whimpering from a classroom up ahead. As hedrew closer, he heard Quirrell\\'s voice.\\n\"No -- no -- not again, please --\"\\nIt sounded as though someone was threatening him. Harry moved closer.\"All right -- all right --\" he heard Quirrell sob.\\nNext second, Quirrell came hurrying out of the classroom straightening\\nhis turban. He was pale and looked as though he was about to cry. Hestrode out of sight; Harry didn\\'t think Quirrell had even noticed him.He waited until Quirrell\\'s footsteps had disappeared, then peered intothe classroom. It was empty, but a door stood ajar at the other end.Harry was halfway toward it before he remembered what he\\'d promised\\nhimself about not meddling.\\nAll the same, he\\'d have gambled twelve Sorcerer\\'s Stones that Snape had\\njust left the room, and from what Harry had just heard, Snape would be', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 196}), Document(page_content='197walking with a new spring in his step -- Quirrell seemed to have given\\nin at last.\\nHarry went back to the library, where Hermione was testing Ron on\\nAstronomy. Harry told them what he\\'d heard.\\n\"Snape\\'s done it, then!\" said Ron. \"If Quirrell\\'s told him how to break\\nhis Anti-Dark Force spell --\"\\n\"There\\'s still Fluffy, though,\" said Hermione.\"Maybe Snape\\'s found out how to get past him without asking Hagrid,\"\\nsaid Ron, looking up at the thousands of books surrounding them. \"I bet\\nthere\\'s a book somewhere in here telling you how to get past a giant\\nthree-headed dog. So what do we do, Harry?\"\\nThe light of adventure was kindling again in Ron\\'s eyes, but Hermione\\nanswered before Harry could.\\n\"Go to Dumbledore. That\\'s what we should have done ages ago. If we try\\nanything ourselves we\\'ll be thrown out for sure.\"\\n\"But we\\'ve got no proof!\" said Harry. \"Quirrell\\'s too scared to back us\\nup. Snape\\'s only got to say he doesn\\'t know how the troll got in atHalloween and that he was nowhere near the third floor -- who do youthink they\\'ll believe, him or us? It\\'s not exactly a secret we hate him,\\nDumbledore\\'ll think we made it up to get him sacked. Filch wouldn\\'t help\\nus if his life depended on it, he\\'s too friendly with Snape, and themore students get thrown out, the better, he\\'ll think. And don\\'t forget,we\\'re not supposed to know about the Stone or Fluffy. That\\'ll take a lotof explaining.\"\\nHermione looked convinced, but Ron didn\\'t.\\n\"If we just do a bit of poking around --\"\"No,\" said Harry flatly, \"we\\'ve done enough poking around.\"He pulled a map of Jupiter toward him and started to learn the names of\\nits moons.\\nThe following morning, notes were delivered to Harry, Hermione, and\\nNeville at the breakfast table. They were all the same:', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 197}), Document(page_content='198Your detention will take place at eleven o\\'clock tonight. Meet Mr. Filch\\nin the entrance hall.\\nProfessor McGonagall Harry had forgotten they still had detentions to do\\nin the furor over the points they\\'d lost. He half expected Hermione to\\ncomplain that this was a whole night of studying lost, but she didn\\'t\\nsay a word. Like Harry, she felt they deserved what they\\'d got.\\nAt eleven o\\'clock that night, they said good-bye to Ron in the common\\nroom and went down to the entrance hall with Neville. Filch was alreadythere -- and so was Malfoy. Harry had also forgotten that Malfoy hadgotten a detention, too.\\n\"Follow me,\" said Filch, lighting a lamp and leading them outside.\\nI bet you\\'ll think twice about breaking a school rule again, won\\'t you,\\neh?\" he said, leering at them. \"Oh yes... hard work and pain are thebest teachers if you ask me.... It\\'s just a pity they let the old\\npunishments die out... hang you by your wrists from the ceiling for a\\nfew days, I\\'ve got the chains still in my office, keep \\'em well oiled incase they\\'re ever needed.... Right, off we go, and don\\'t think ofrunning off, now, it\\'ll be worse for you if you do.\"\\nThey marched off across the dark grounds. Neville kept sniffing. Harry\\nwondered what their punishment was going to be. It must be something\\nreally horrible, or Filch wouldn\\'t be sounding so delighted.\\nThe moon was bright, but clouds scudding across it kept throwing them\\ninto darkness. Ahead, Harry could see the lighted windows of Hagrid\\'shut. Then they heard a distant shout.\\n\"Is that you, Filch? Hurry up, I want ter get started.\"\\nHarry\\'s heart rose; if they were going to be working with Hagrid it\\nwouldn\\'t be so bad. His relief must have showed in his -face, becauseFilch said, \"I suppose you think you\\'ll be enjoying yourself with thatoaf? Well, think again, boy -- it\\'s into the forest you\\'re going and I\\'mmuch mistaken if you\\'ll all come out in one piece.\"\\nAt this, Neville let out a little moan, and Malfoy stopped dead in his\\ntracks.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 198}), Document(page_content='199\"The forest?\" he repeated, and he didn\\'t sound quite as cool as usual.\\n\"We can\\'t go in there at night -- there\\'s all sorts of things in there-- werewolves, I heard.\"\\nNeville clutched the sleeve of Harry\\'s robe and made a choking noise.\\n\"That\\'s your problem, isn\\'t it?\" said Filch, his voice cracking with\\nglee. \"Should\\'ve thought of them werewolves before you got in trouble,shouldn\\'t you?\"\\nHagrid came striding toward them out of the dark, Fang at his heel. He\\nwas carrying his large crossbow, and a quiver of arrows hung over hisshoulder.\\n\"Abou\\' time,\" he said. \"I bin waitin\\' fer half an hour already. All\\nright, Harry, Hermione?\"\\n\"I shouldn\\'t be too friendly to them, Hagrid,\" said Filch coldly,\\nthey\\'re here to be punished, after all.\"\\n\"That\\'s why yer late, is it?\" said Hagrid, frowning at Filch. \"Bin\\nlecturin\\' them, eh? \\'Snot your place ter do that. Yeh\\'ve done yer bit,I\\'ll take over from here.\"\\n\"I\\'ll be back at dawn,\" said Filch, \"for what\\'s left of them,\" he added\\nnastily, and he turned and started back toward the castle, his lamp\\nbobbing away in the darkness.\\nMalfoy now turned to Hagrid.\"I\\'m not going in that forest, he said, and Harry was pleased to hear\\nthe note of panic in his voice.\\n\"Yeh are if yeh want ter stay at Hogwarts,\" said Hagrid fiercely.\\n\"Yeh\\'ve done wrong an\\' now yehve got ter pay fer it.\"\\n\"But this is servant stuff, it\\'s not for students to do. I thought we\\'d\\nbe copying lines or something, if my father knew I was doing this, he\\'d\\ntell yer that\\'s how it is at Hogwarts,\" Hagrid growled. \"Copyin\\' lines!\\nWhat good\\'s that ter anyone? Yeh\\'ll do summat useful or Yeh\\'ll get out.If yeh think yer father\\'d rather you were expelled, then get back offter the castle an\\' pack. Go on\"\\'', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 199}), Document(page_content='200Malfoy didn\\'t move. He looked at Hagrid furiously, but then dropped his\\ngaze.\\n\"Right then,\" said Hagrid, \"now, listen carefully, \\'cause it\\'s dangerous\\nwhat we\\'re gonna do tonight, an\\' I don\\' want no one takin\\' risks. Follow\\nme over here a moment.\"\\nHe led them to the very edge of the forest. Holding his lamp up high, he\\npointed down a narrow, winding earth track that disappeared into thethick black trees. A light breeze lifted their hair as they looked intothe forest.\\n\"Look there,\" said Hagrid, \"see that stuff shinin\\' on the ground?\\nSilvery stuff? That\\'s unicorn blood. There\\'s a unicorn in there bin hurtbadly by summat. This is the second time in a week. I found one deadlast Wednesday. We\\'re gonna try an\\' find the poor thing. We might haveter put it out of its misery.\"\\n\"And what if whatever hurt the unicorn finds us first?\" said Malfoy,\\nunable to keep the fear out of his voice.\\n\"There\\'s nothin\\' that lives in the forest that\\'ll hurt yeh if yer with\\nme or Fang,\" said Hagrid. \"An\\' keep ter the path. Right, now, we\\'regonna split inter two parties an\\' follow the trail in diff\\'rentdirections. There\\'s blood all over the place, it must\\'ve bin staggerin\\'\\naround since last night at least.\"\\n\"I want Fang,\" said Malfoy quickly, looking at Fang\\'s long teeth.\"All right, but I warn yeh, he\\'s a coward,\" said Hagrid. \" So me, Harry,\\nan\\' Hermione\\'ll go one way an\\' Draco, Neville, an\\' Fang\\'ll go the other.\\nNow, if any of us finds the unicorn, we\\'ll send up green sparks, right?\\nGet yer wands out an\\' practice now -- that\\'s it -- an\\' if anyone gets introuble, send up red sparks, an\\' we\\'ll all come an\\' find yeh -- so, becareful -- let\\'s go.\"\\nThe forest was black and silent. A little way into it they reached a\\nfork in the earth path, and Harry, Hermione, and Hagrid took the left\\npath while Malfoy, Neville, and Fang took the right.\\nThey walked in silence, their eyes on the ground. Every now and then a\\nray of moonlight through the branches above lit a spot of silver-blue', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 200}), Document(page_content='201blood on the fallen leaves.\\nHarry saw that Hagrid looked very worried.\"Could a werewolf be killing the unicorns?\" Harry asked.\\n\"Not fast enough,\" said Hagrid. \"It\\'s not easy ter catch a unicorn,\\nthey\\'re powerful magic creatures. I never knew one ter be hurt before.\"\\nThey walked past a mossy tree stump. Harry could hear running water;\\nthere must be a stream somewhere close by. There were still spots ofunicorn blood here and there along the winding path.\\n\"You all right, Hermione?\" Hagrid whispered. \"Don\\' worry, it can\\'t\\'ve\\ngone far if it\\'s this badly hurt, an\\' then we\\'ll be able ter -- GETBEHIND THAT TREE!\"\\nHagrid seized Harry and Hermione and hoisted them off the path behind a\\ntowering oak. He pulled out an arrow and fitted it into his crossbow,\\nraising it, ready to fire. The three of them listened. Something was\\nslithering over dead leaves nearby: it sounded like a cloak trailingalong the ground. Hagrid was squinting up the dark path, but after a fewseconds, the sound faded away.\\n\"I knew it, \" he murmured. \"There\\'s summat in here that shouldn\\' be.\"\\n\"A werewolf?\" Harry suggested.\\n\"That wasn\\' no werewolf an\\' it wasn\\' no unicorn, neither,\" said Hagrid\\ngrimly. \"Right, follow me, but careful, now.\"\\nThey walked more slowly, ears straining for the faintest sound.\\nSuddenly, in a clearing ahead, something definitely moved.\\n\"Who\\'s there?\" Hagrid called. \"Show yerself -- I\\'m armed!\"And into the clearing came -- was it a man, or a horse? To the waist, a\\nman, with red hair and beard, but below that was a horse\\'s gleamingchestnut body with a long, reddish tail. Harry and Hermione\\'s jaws\\ndropped.\\n\"Oh, it\\'s you, Ronan,\" said Hagrid in relief. \"How are yeh?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 201}), Document(page_content='202He walked forward and shook the centaur\\'s hand.\\n\"Good evening to you, Hagrid,\" said Ronan. He had a deep, sorrowful\\nvoice. \"Were you going to shoot me?\"\\n\"Can\\'t be too careful, Ronan,\" said Hagrid, patting his crossbow.\\n\"There\\'s summat bad loose in this forest. This is Harry Potter an\\'\\nHermione Granger, by the way. Students up at the school. An\\' this isRonan, you two. He\\'s a centaur.))\\n\"We\\'d noticed,\" said Hermione faintly.\"Good evening,\" said Ronan. \"Students, are you? And do you learn much,\\nup at the school?\"\\n\"Erm --\"\"A bit,\" said Hermione timidly.\\n\"A bit. Well, that\\'s something.\" Ronan sighed. He flung back his head\\nand stared at the sky. \"Mars is bright tonight.\"\\n\"Yeah,\" said Hagrid, glancing up, too. \"Listen, I\\'m glad we\\'ve run inter\\nyeh, Ronan, \\'cause there\\'s a unicorn bin hurt -- you seen anythin\\'?\"\\nRonan didn\\'t answer immediately. He stared unblinkingly upward, then\\nsighed again.\\n\"Always the innocent are the first victims,\" he said. \"So it has been\\nfor ages past, so it is now.\"\\n\"Yeah,\" said Hagrid, \"but have yeh seen anythin\\', Ronan? Anythin\\'\\nunusual?\"\\n\"Mars is bright tonight,\" Ronan repeated, while Hagrid watched him\\nimpatiently. \"Unusually bright.\"\\n\"Yeah, but I was meanin\\' anythin\\' unusual a bit nearer home, said\\nHagrid. \"So yeh haven\\'t noticed anythin\\' strange?\"\\nYet again, Ronan took a while to answer. At last, he said, \"The forest\\nhides many secrets.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 202}), Document(page_content='203A movement in the trees behind Ronan made Hagrid raise his bow again,\\nbut it was only a second centaur, black-haired and -bodied andwilder-looking than Ronan.\\n\"Hullo, Bane,\" said Hagrid. \"All right?\"\\n\"Good evening, Hagrid, I hope you are well?\"\\n\"Well enough. Look, I\\'ve jus\\' bin askin\\' Ronan, you seen anythin\\' odd in\\nhere lately? There\\'s a unicorn bin injured -- would yeh know anythin\\'about it?\"\\nBane walked over to stand next to Ronan. He looked skyward. \"Mars is\\nbright tonight,\" he said simply.\\n\"We\\'ve heard,\" said Hagrid grumpily. \"Well, if either of you do see\\nanythin\\', let me know, won\\'t yeh? We\\'ll be off, then.\"\\nHarry and Hermione followed him out of the clearing, staring over their\\nshoulders at Ronan and Bane until the trees blocked their view.\\n\"Never,\" said Hagrid irritably, \"try an\\' get a straight answer out of a\\ncentaur. Ruddy stargazers. Not interested in anythin\\' closer\\'n themoon.\"\\n\"Are there many of them in here?\" asked Hermione.\\n\"Oh, a fair few... Keep themselves to themselves mostly, but they\\'re\\ngood enough about turnin\\' up if ever I want a word. They\\'re deep, mind,centaurs... they know things... jus\\' don\\' let on much.\"\\n\"D\\'you think that was a centaur we heard earlier?\" said Harry.\\n\"Did that sound like hooves to you? Nah, if yeh ask me, that was what\\'s\\nbin killin\\' the unicorns -- never heard anythin\\' like it before.\"\\nThey walked on through the dense, dark trees. Harry kept looking\\nnervously over his shoulder. He had the nasty feeling they were beingwatched. He was very glad they had Hagrid and his crossbow with them.\\nThey had just passed a bend in the path when Hermione grabbed Hagrid\\'s\\narm.\\n\"Hagrid! Look! Red sparks, the others are in trouble!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 203}), Document(page_content='204\"You two wait here!\" Hagrid shouted. \"Stay on the path, I\\'ll come back\\nfor yeh!\"\\nThey heard him crashing away through the undergrowth and stood looking\\nat each other, very scared, until they couldn\\'t hear anything but the\\nrustling of leaves around them.\\n\"You don\\'t think they\\'ve been hurt, do you?\" whispered Hermione.\"I don\\'t care if Malfoy has, but if something\\'s got Neville... it\\'s our\\nfault he\\'s here in the first place.\"\\nThe minutes dragged by. Their ears seemed sharper than usual. Harry\\'s\\nseemed to be picking up every sigh of the wind, every cracking twig.What was going on? Where were the others?\\nAt last, a great crunching noise announced Hagrid\\'s return. Malfoy,\\nNeville, and Fang were with him. Hagrid was fuming. Malfoy, it seemed,\\nhad sneaked up behind Neville and grabbed him as a joke. Neville had\\npanicked and sent up the sparks.\\n\"We\\'ll be lucky ter catch anythin\\' now, with the racket you two were\\nmakin\\'. Right, we\\'re changin\\' groups -- Neville, you stay with me an\\'Hermione, Harry, you go with Fang an\\' this idiot. I\\'m sorry,\" Hagridadded in a whisper to Harry, \"but he\\'ll have a harder time frightenin\\'\\nyou, an\\' we\\'ve gotta get this done.\"\\nSo Harry set off into the heart of the forest with Malfoy and Fang. They\\nwalked for nearly half an hour, deeper and deeper into the forest, untilthe path became almost impossible to follow because the trees were sothick. Harry thought the blood seemed to be getting thicker. There were\\nsplashes on the roots of a tree, as though the poor creature had been\\nthrashing around in pain close by. Harry could see a clearing ahead,through the tangled branches of an ancient oak.\\n\"Look --\" he murmured, holding out his arm to stop Malfoy.Something bright white was gleaming on the ground. They inched closer.\\nIt was the unicorn all right, and it was dead. Harry had never seen\\nanything so beautiful and sad. Its long, slender legs were stuck out atodd angles where it had fallen and its mane was spread pearly-white on', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 204}), Document(page_content='205the dark leaves.\\nHarry had taken one step toward it when a slithering sound made him\\nfreeze where he stood. A bush on the edge of the clearing quivered....Then, out of the shadows, a hooded figure came crawling across theground like some stalking beast. Harry, Malfoy, and Fang stood\\ntransfixed. The cloaked figure reached the unicorn, lowered its head\\nover the wound in the animal\\'s side, and began to drink its blood.\\n\"AAAAAAAAAARGH!\"Malfoy let out a terrible scream and bolted -- so did Fang. The hooded\\nfigure raised its head and looked right at Harry -- unicorn blood was\\ndribbling down its front. It got to its feet and came swiftly toward\\nHarry -- he couldn\\'t move for fear.\\nThen a pain like he\\'d never felt before pierced his head; it was as\\nthough his scar were on fire. Half blinded, he staggered backward. Heheard hooves behind him, galloping, and something jumped clean over\\nHarry, charging at the figure.\\nThe pain in Harry\\'s head was so bad he fell to his knees. It took a\\nminute or two to pass. When he looked up, the figure had gone. A centaurwas standing over him, not Ronan or Bane; this one looked younger; hehad white-blond hair and a palomino body.\\n\"Are you all right?\" said the centaur, pulling Harry to his feet.\\n\"Yes -- thank you -- what was that?\"The centaur didn\\'t answer. He had astonishingly blue eyes, like pale\\nsapphires. He looked carefully at Harry, his eyes lingering on the scar\\nthat stood out, livid, on Harry\\'s forehead.\\n\"You are the Potter boy,\" he said. \"You had better get back to Hagrid.\\nThe forest is not safe at this time -- especially for you. Can you ride?It will be quicker this way.\\n\"My name is Firenze,\" he added, as he lowered himself on to his front\\nlegs so that Harry could clamber onto his back.\\nThere was suddenly a sound of more galloping from the other side of the\\nclearing. Ronan and Bane came bursting through the trees, their flanks', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 205}), Document(page_content='206heaving and sweaty.\\n\"Firenze!\" Bane thundered. \"What are you doing? You have a human on your\\nback! Have you no shame? Are you a common mule?\"\\n\"Do you realize who this is?\" said Firenze. \"This is the Potter boy. The\\nquicker he leaves this forest, the better.\"\\n\"What have you been telling him?\" growled Bane. \"Remember, Firenze, we\\nare sworn not to set ourselves against the heavens. Have we not readwhat is to come in the movements of the planets?\"\\nRonan pawed the ground nervously. \"I\\'m sure Firenze thought he was\\nacting for the best, \" he said in his gloomy voice.\\nBane kicked his back legs in anger.\"For the best! What is that to do with us? Centaurs are concerned with\\nwhat has been foretold! It is not our business to run around like\\ndonkeys after stray humans in our forest!\"\\nFirenze suddenly reared on to his hind legs in anger, so that Harry had\\nto grab his shoulders to stay on.\\n\"Do you not see that unicorn?\" Firenze bellowed at Bane. \"Do you not\\nunderstand why it was killed? Or have the planets not let you in on that\\nsecret? I set myself against what is lurking in this forest, Bane, yes,\\nwith humans alongside me if I must.\"\\nAnd Firenze whisked around; with Harry clutching on as best he could,\\nthey plunged off into the trees, leaving Ronan and Bane behind them.\\nHarry didn\\'t have a clue what was going on.\\n\"Why\\'s Bane so angry?\" he asked. \"What was that thing you saved me from,\\nanyway?\"\\nFirenze slowed to a walk, warned Harry to keep his head bowed in case of\\nlow-hanging branches, but did not answer Harry\\'s question. They made\\ntheir way through the trees in silence for so long that Harry thought\\nFirenze didn\\'t want to talk to him anymore. They were passing through aparticularly dense patch of trees, however, when Firenze suddenlystopped.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 206}), Document(page_content='207\"Harry Potter, do you know what unicorn blood is used -for?\"\\n\"No,\" said Harry, startled by the odd question. \"We\\'ve only used the\\nhorn and tail hair in Potions.\"\\n\"That is because it is a monstrous thing, to slay a unicorn,\" said\\nFirenze. \"Only one who has nothing to lose, and everything to gain,would commit such a crime. The blood of a unicorn will keep you alive,even if you are an inch from death, but at a terrible price. You haveslain something pure and defenseless to save yourself, and you will havebut a half-life, a cursed life, from the moment the blood touches yourlips.\"\\nHarry stared at the back of Firenze\\'s head, which was dappled silver in\\nthe moonlight.\\n\"But who\\'d be that desperate?\" he wondered aloud. \"If you\\'re going to be\\ncursed forever, deaths better, isn\\'t it?\"\\n\"It is,\" Firenze agreed, \"unless all you need is to stay alive long\\nenough to drink something else -- something that will bring you back tofull strength and power -- something that will mean you can never die.Mr. Potter, do you know what is hidden in the school at this verymoment?\"\\n\"The Sorcerer\\'s Stone! Of course -- the Elixir of Life! But I don\\'t\\nunderstand who --\"\\n\"Can you think of nobody who has waited many years to return to power,\\nwho has clung to life, awaiting their chance?\"\\nIt was as though an iron fist had clenched suddenly around Harry\\'s\\nheart. Over the rustling of the trees, he seemed to hear once more whatHagrid had told him on the night they had met: \"Some say he died.Codswallop, in my opinion. Dunno if he had enough human left in him todie.\"\\n\"Do you mean,\" Harry croaked, \"that was Vol-\"\\n\"Harry! Harry, are you all right?\"\\nHermione was running toward them down the path, Hagrid puffing along', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 207}), Document(page_content='208behind her.\\n\"I\\'m fine,\" said Harry, hardly knowing what he was saying. \"The\\nunicorn\\'s dead, Hagrid, it\\'s in that clearing back there.\"\\n\"This is where I leave you,\" Firenze murmured as Hagrid hurried off to\\nexamine the unicorn. \"You are safe now.\"\\nHarry slid off his back.\"Good luck, Harry Potter,\" said Firenze. \"The planets have been read\\nwrongly before now, even by centaurs. I hope this is one of thosetimes.\"\\nHe turned and cantered back into the depths of the forest, leaving Harry\\nshivering behind him.\\nRon had fallen asleep in the dark common room, waiting for them to\\nreturn. He shouted something about Quidditch fouls when Harry roughly\\nshook him awake. In a matter of seconds, though, he was wide-eyed as\\nHarry began to tell him and Hermione what had happened in the forest.\\nHarry couldn\\'t sit down. He paced up and down in front of the fire. He\\nwas still shaking.\\n\"Snape wants the stone for Voldemort... and Voldemort\\'s waiting in the\\nforest... and all this time we thought Snape just wanted to get\\nrich....\"\\n\"Stop saying the name!\" said Ron in a terrified whisper, as if he\\nthought Voldemort could hear them.\\nHarry wasn\\'t listening.\\n\"Firenze saved me, but he shouldn\\'t have done so.... Bane was furious...\\nhe was talking about interfering with what the planets say is going tohappen.... They must show that Voldemort\\'s coming back.... Bane thinksFirenze should have let Voldemort kill me.... I suppose that\\'s writtenin the stars as well.\"\\n\"Will you stop saying the name!\" Ron hissed.\\n\"So all I\\'ve got to wait for now is Snape to steal the Stone,\" Harry', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 208}), Document(page_content='209went on feverishly, \"then Voldemort will be able to come and finish me\\noff... Well, I suppose Bane\\'ll be happy.\"\\nHermione looked very frightened, but she had a word of comfort.\"Harry, everyone says Dumbledore\\'s the only one You-Know-Who was ever\\nafraid of With Dumbledore around, You-Know-Who won\\'t touch you. Anyway,\\nwho says the centaurs are right? It sounds like fortune-telling to me,and Professor McGonagall says that\\'s a very imprecise branch of magic.\"\\nThe sky had turned light before they stopped talking. They went to bed\\nexhausted, their throats sore. But the night\\'s surprises weren\\'t over.\\nWhen Harry pulled back his sheets, he found his invisibility cloak\\nfolded neatly underneath them. There was a note pinned to it:\\nJust in case.\\nCHAPTER SIXTEEN\\nTHROUGH THE TRAPDOORIn years to come, Harry would never quite remember how he had managed to\\nget through his exams when he half expected Voldemort to come burstingthrough the door at any moment. Yet the days crept by, and there could\\nbe no doubt that Fluffy was still alive and well behind the locked door.\\nIt was sweltering hot, especially in the large classroom where they did\\ntheir written papers. They had been given special, new quills for theexams, which had been bewitched with an AntiCheating spell.\\nThey had practical exams as well. Professor Flitwick called them one by\\none into his class to see if they could make a pineapple tapdance acrossa desk. Professor McGonagall watched them turn a mouse into a snuffbox-- points were given for how pretty the snuffbox was, but taken away ifit had whiskers. Snape made them all nervous, breathing down their neckswhile they tried to remember how to make a Forgetfulness potion.\\nHarry did the best he could, trying to ignore the stabbing pains in his\\nforehead, which had been bothering him ever since his trip into theforest. Neville thought Harry had a bad case of exam nerves becauseHarry couldn\\'t sleep, but the truth was that Harry kept being woken by', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 209}), Document(page_content='210his old nightmare, except that it was now worse than ever because there\\nwas a hooded figure dripping blood in it.\\nMaybe it was because they hadn\\'t seen what Harry had seen in the forest,\\nor because they didn\\'t have scars burning on their foreheads, but Ronand Hermione didn\\'t seem as worried about the Stone as Harry. The idea\\nof Voldemort certainly scared them, but he didn\\'t keep visiting them in\\ndreams, and they were so busy with their studying they didn\\'t have muchtime to fret about what Snape or anyone else might be up to.\\nTheir very last exam was History of Magic. One hour of answering\\nquestions about batty old wizards who\\'d invented selfstirring cauldronsand they\\'d be free, free for a whole wonderful week until their exam\\nresults came out. When the ghost of Professor Binns told them to put\\ndown their quills and roll up their parchment, Harry couldn\\'t helpcheering with the rest.\\n\"That was far easier than I thought it would be,\" said Hermione as they\\njoined the crowds flocking out onto the sunny grounds. \"I needn\\'t have\\nlearned about the 1637 Werewolf Code of Conduct or the uprising of\\nElfric the Eager.\"\\nHermione always liked to go through their exam papers afterward, but Ron\\nsaid this made him feel ill, so they wandered down to the lake andflopped under a tree. The Weasley twins and Lee Jordan were tickling thetentacles of a giant squid, which was basking in the warm shallows. \"No\\nmore studying,\" Ron sighed happily, stretching out on the grass. \"You\\ncould look more cheerful, Harry, we\\'ve got a week before we find out howbadly we\\'ve done, there\\'s no need to worry yet.\"\\nHarry was rubbing his forehead.\\n\"I wish I knew what this means!\" he burst out angrily. \"My scar keeps\\nhurting -- it\\'s happened before, but never as often as this.\"\\n\"Go to Madam Pomfrey,\" Hermione suggested.\"I\\'m not ill,\" said Harry. \"I think it\\'s a warning... it means danger\\'s\\ncoming....\"\\nRon couldn\\'t get worked up, it was too hot.\\n\"Harry, relax, Hermione\\'s right, the Stone\\'s safe as long as', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 210}), Document(page_content='211Dumbledore\\'s around. Anyway, we\\'ve never had any proof Snape found out\\nhow to get past Fluffy. He nearly had his leg ripped off once, he\\'s notgoing to try it again in a hurry. And Neville will play Quidditch forEngland before Hagrid lets Dumbledore down.\"\\nHarry nodded, but he couldn\\'t shake off a lurking feeling that there was\\nsomething he\\'d forgotten to do, something important. When he tried to\\nexplain this, Hermione said, \"That\\'s just the exams. I woke up lastnight and was halfway through my Transfiguration notes before Iremembered we\\'d done that one.\"\\nHarry was quite sure the unsettled feeling didn\\'t have anything to do\\nwith work, though. He watched an owl flutter toward the school across\\nthe bright blue sky, a note clamped in its mouth. Hagrid was the only\\none who ever sent him letters. Hagrid would never betray Dumbledore.Hagrid would never tell anyone how to get past Fluffy... never... but --\\nHarry suddenly jumped to his feet.\\n\"Where\\'re you going?\" said Ron sleepily.\\n\"I\\'ve just thought of something,\" said Harry. He had turned white.\\n\"We\\'ve got to go and see Hagrid, now.\"\\n\"Why?\" panted Hermione, hurrying to keep up.\\n\"Don\\'t you think it\\'s a bit odd,\" said Harry, scrambling up the grassy\\nslope, \"that what Hagrid wants more than anything else is a dragon, anda stranger turns up who just happens to have an egg in his pocket? Howmany people wander around with dragon eggs if it\\'s against wizard law?Lucky they found Hagrid, don\\'t you think? Why didn\\'t I see it before?\"\\n\"What are you talking about?\" said Ron, but Harry, sprinting across the\\ngrounds toward the forest, didn\\'t answer.\\nHagrid was sitting in an armchair outside his house; his trousers and\\nsleeves were rolled up, and he was shelling peas into a large bowl.\\n\"Hullo,\" he said, smiling. \"Finished yer exams? Got time fer a drink?\"\\n\"Yes, please,\" said Ron, but Harry cut him off.\\n\"No, we\\'re in a hurry. Hagrid, I\\'ve got to ask you something. You know', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 211}), Document(page_content='212that night you won Norbert? What did the stranger you were playing cards\\nwith look like?\"\\n\"Dunno,\" said Hagrid casually, \"he wouldn\\' take his cloak off.\"He saw the three of them look stunned and raised his eyebrows.\\n\"It\\'s not that unusual, yeh get a lot o\\' funny folk in the Hog\\'s Head --\\nthat\\'s the pub down in the village. Mighta bin a dragon dealer, mightn\\'he? I never saw his face, he kept his hood up.\"\\nHarry sank down next to the bowl of peas. \"What did you talk to him\\nabout, Hagrid? Did you mention Hogwarts at all?\"\\n\"Mighta come up,\" said Hagrid, frowning as he tried to remember.\\n\"Yeah... he asked what I did, an\\' I told him I was gamekeeper here....He asked a bit about the sorta creatures I took after... so I toldhim... an\\' I said what I\\'d always really wanted was a dragon... an\\'then... I can\\' remember too well, \\'cause he kept buyin\\' me drinks....\\nLet\\'s see... yeah, then he said he had the dragon egg an\\' we could play\\ncards fer it if I wanted... but he had ter be sure I could handle it, hedidn\\' want it ter go ter any old home.... So I told him, after Fluffy, adragon would be easy...\"\\n\"And did he -- did he seem interested in Fluffy?\" Harry asked, try ing\\nto keep his voice calm.\\n\"Well -- yeah -- how many three-headed dogs d\\'yeh meet, even around\\nHogwarts? So I told him, Fluffy\\'s a piece o\\' cake if yeh know how tocalm him down, jus\\' play him a bit o\\' music an\\' he\\'ll go straight offter sleep --\"\\nHagrid suddenly looked horrified.\\n\"I shouldn\\'ta told yeh that!\" he blurted out. \"Forget I said it! Hey --\\nwhere\\'re yeh goin\\'?\"\\nHarry, Ron, and Hermione didn\\'t speak to each other at all until they\\ncame to a halt in the entrance hall, which seemed very cold and gloomy\\nafter the grounds.\\n\"We\\'ve got to go to Dumbledore,\" said Harry. \"Hagrid told that stranger\\nhow to get past Fluffy, and it was either Snape or Voldemort under that', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 212}), Document(page_content='213cloak -- it must\\'ve been easy, once he\\'d got Hagrid drunk. I just hope\\nDumbledore believes us. Firenze might back us up if Bane doesn\\'t stophim. Where\\'s Dumbledore\\'s office?\"\\nThey looked around, as if hoping to see a sign pointing them in the\\nright direction. They had never been told where Dumbledore lived, nor\\ndid they know anyone who had been sent to see him.\\n\"We\\'ll just have to --\" Harry began, but a voice suddenly rang across\\nthe hall.\\n\"What are you three doing inside?\"\\nIt was Professor McGonagall, carrying a large pile of books.\\n\"We want to see Professor Dumbledore,\" said Hermione, rather bravely,\\nHarry and Ron thought.\\n\"See Professor Dumbledore?\" Professor McGonagall repeated, as though\\nthis was a very fishy thing to want to do. \"Why?\"\\nHarry swallowed -- now what?\"It\\'s sort of secret,\" he said, but he wished at once he hadn\\'t, because\\nProfessor McGonagall\\'s nostrils flared.\\n\"Professor Dumbledore left ten minutes ago,\" she said coldly. \"He\\nreceived an urgent owl from the Ministry of Magic and flew off forLondon at once.\"\\n\"He\\'s gone?\" said Harry frantically. \"Now?\"\\n\"Professor Dumbledore is a very great wizard, Potter, he has many\\ndemands on his time --\\n\"But this is important.\"\"Something you have to say is more important than the Ministry of Magic,\\nPotter.\\n\"Look,\" said Harry, throwing caution to the winds, \"Professor -- it\\'s\\nabout the Sorcerer\\'s tone --\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 213}), Document(page_content='214Whatever Professor McGonagall had expected, it wasn\\'t that. The books\\nshe was carrying tumbled out of her arms, but she didn\\'t pick them up.\"How do you know --?\" she spluttered.\\n\"Professor, I think -- I know -- that Sn- that someone\\'s going to try\\nand steal the Stone. I\\'ve got to talk to Professor Dumbledore.\"\\nShe eyed him with a mixture of shock and suspicion.\\n\"Professor Dumbledore will be back tomorrow,\" she said finally. I don\\'t\\nknow how you found out about the Stone, but rest assured, no one canpossibly steal it, it\\'s too well protected.\"\\n\"But Professor --\"\\n\"Potter, I know what I\\'m talking about,\" she said shortly. She bent down\\nand gathered up the fallen books. I suggest you all go back outside andenjoy the sunshine.\"\\nBut they didn\\'t.\\n\"It\\'s tonight,\" said Harry, once he was sure Professor McGonagall was\\nout of earshot. \"Snape\\'s going through the trapdoor tonight. He\\'s foundout everything he needs, and now he\\'s got Dumbledore out of the way. Hesent that note, I bet the Ministry of Magic will get a real shock whenDumbledore turns up.\"\\n\"But what can we --\"\\nHermione gasped. Harry and Ron wheeled round.Snape was standing there.\\n\"Good afternoon,\" he said smoothly.\\nThey stared at him.\"You shouldn\\'t be inside on a day like this,\" he said, with an odd,\\ntwisted smile.\\n\"We were --\" Harry began, without any idea what he was going to say.\\n\"You want to be more careful,\" said Snape. \"Hanging around', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 214}), Document(page_content='215like this, people will think you\\'re up to something. And Gryffindor\\nreally can\\'t afford to lose any more points, can it?\"\\nHarry flushed. They turned to go outside, but Snape called them back.\\n\"Be warned, Potter -- any more nighttime wanderings and I will\\npersonally make sure you are expelled. Good day to you.\"\\nHe strode off in the direction of the staffroom.Out on the stone steps, Harry turned to the others.\\n\"Right, here\\'s what we\\'ve got to do,\" he whispered urgently. \"One of us\\nhas got to keep an eye on Snape -- wait outside the staff room andfollow him if he leaves it. Hermione, you\\'d better do that.\"\\n\"Why me?\"\\n\"It\\'s obvious,\" said Ron. \"You can pretend to be waiting for Professor\\nFlitwick, you know.\" He put on a high voice, \"\\'Oh Professor Flitwick,I\\'m so worried, I think I got question fourteen b wrong....\\'\"\\n\"Oh, shut up,\" said Hermione, but she agreed to go and watch out for\\nSnape.\\n\"And we\\'d better stay outside the third-floor corridor,\" Harry told Ron.\\n\"Come on.\"\\nBut that part of the plan didn\\'t work. No sooner had they reached the\\ndoor separating Fluffy from the rest of the school than ProfessorMcGonagall turned up again and this time, she lost her temper.\\n\"I suppose you think you\\'re harder to get past than a pack of\\nenchantments!\" she stormed. \"Enough of this nonsense! If I hear you \\'vecome anywhere near here again, I\\'ll take another fifty points fromGryffindor! Yes, Weasley, from my own house!\" Harry and Ron went back tothe common room, Harry had just said, \"At least Hermione\\'s on Snape\\'stail,\" when the portrait of the Fat Lady swung open and Hermione came\\nin.\\n\"I\\'m sorry, Harry!\" she wailed. \"Snape came out and asked me what I was\\ndoing, so I said I was waiting for Flitwick, and Snape went to get him,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 215}), Document(page_content='216and I\\'ve only just got away, I don\\'t know where Snape went.\"\\n\"Well, that\\'s it then, isn\\'t it?\" Harry said.The other two stared at him. He was pale and his eyes were glittering.\\n\"I\\'m going out of here tonight and I\\'m going to try and get to the Stone\\nfirst.\"\\n\"You\\'re mad!\" said Ron.\"You can\\'t!\" said Hermione. \"After what McGonagall and Snape have said?\\nYou\\'ll be expelled!\"\\n\"SO WHAP\" Harry shouted. \"Don\\'t you understand? If Snape gets hold of\\nthe Stone, Voldemort\\'s coming back! Haven\\'t you heard what it was likewhen he was trying to take over? There won\\'t be any Hogwarts to getexpelled from! He\\'ll flatten it, or turn it into a school for the DarkArts! Losing points doesn\\'t matter anymore, can\\'t you see? D\\'you think\\nhe\\'ll leave you and your families alone if Gryffindor wins the house\\ncup? If I get caught before I can get to the Stone, well, I\\'ll have togo back to the Dursleys and wait for Voldemort to find me there, it\\'sonly dying a bit later than I would have, because I\\'m never going overto the Dark Side! I\\'m going through that trapdoor tonight and nothingyou two say is going to stop me! Voldemort killed my parents, remember?\"\\nHe glared at them.\\n\"You\\'re right Harry,\" said Hermione in a small voice.\"I\\'ll use the invisibility cloak,\" said Harry. \"It\\'s just lucky I got it\\nback.\"\\n\"But will it cover all three of us?\" said Ron.\\n\"All -- all three of us?\"\"Oh, come off it, you don\\'t think we\\'d let you go alone?\"\\n\"Of course not,\" said Hermione briskly. \"How do you think you\\'d get to\\nthe Stone without us? I\\'d better go and took through my books, theremight be something useful...\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 216}), Document(page_content='217\"But if we get caught, you two will be expelled, too.\"\\n\"Not if I can help it,\" said Hermione grimly. \"Flitwick told me in\\nsecret that I got a hundred and twelve percent on his exam. They\\'re notthrowing me out after that.\"\\nAfter dinner the three of them sat nervously apart in the common room.\\nNobody bothered them; none of the Gryffindors had anything to say toHarry any more, after all. This was the first night he hadn\\'t been upsetby it. Hermione was skimming through all her notes, hoping to comeacross one of the enchantments they were about to try to break. Harryand Ron didn\\'t talk much. Both of them were thinking about what theywere about to do.\\nSlowly, the room emptied as people drifted off to bed.\\n\"Better get the cloak,\" Ron muttered, as Lee Jordan finally left,\\nstretching and yawning. Harry ran upstairs to their dark dormitory. Heputted out the cloak and then his eyes fell on the flute Hagrid had\\ngiven him for Christmas. He pocketed it to use on Fluffy -- he didn\\'t\\nfeel much like singing.\\nHe ran back down to the common room.\"We\\'d better put the cloak on here, and make sure it covers all three of\\nus -- if Filch spots one of our feet wandering along on its own --\"\\n\"What are you doing?\" said a voice from the corner of the room. Neville\\nappeared from behind an armchair, clutching Trevor the toad, who lookedas though he\\'d been making another bid for freedom.\\n\"Nothing, Neville, nothing,\" said Harry, hurriedly putting the cloak\\nbehind his back.\\nNeville stared at their guilty faces.\"You\\'re going out again,\" he said.\"No, no, no,\" said Hermione. \"No, we\\'re not. Why don\\'t you go to bed,\\nNeville?\"\\nHarry looked at the grandfather clock by the door. They couldn\\'t afford\\nto waste any more time, Snape might even now be playing Fluffy to sleep.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 217}), Document(page_content='218\"You can\\'t go out,\" said Neville, \"you\\'ll be caught again. Gryffindor\\nwill be in even more trouble.\"\\n\"You don\\'t understand,\" said Harry, \"this is important.\"\\nBut Neville was clearly steeling himself to do something desperate.\\nI won\\'t let you do it,\" he said, hurrying to stand in front of the\\nportrait hole. \"I\\'ll -- I\\'ll fight you!\"\\n\"Neville, \"Ron exploded, \"get away from that hole and don\\'t be an idiot\\n--\"\\n\"Don\\'t you call me an idiot!\" said Neville. I don\\'t think you should be\\nbreaking any more rules! And you were the one who told me to stand up topeople!\"\\n\"Yes, but not to us,\" said Ron in exasperation. \"Neville, you don\\'t know\\nwhat you\\'re doing.\"\\nHe took a step forward and Neville dropped Trevor the toad, who leapt\\nout of sight.\\n\"Go on then, try and hit me!\" said Neville, raising his fists. \"I\\'m\\nready!\"\\nHarry turned to Hermione.\\n\"Do something,\" he said desperately.Hermione stepped forward.\\n\"Neville,\" she said, \"I\\'m really, really sorry about this.\"\\nShe raised her wand.\"Petrificus Totalus!\" she cried, pointing it at Neville.\\nNeville\\'s arms snapped to his sides. His legs sprang together. His whole\\nbody rigid, he swayed where he stood and then fell flat on his face,stiff as a board.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 218}), Document(page_content='219Hermione ran to turn him over. Neville\\'s jaws were jammed together so he\\ncouldn\\'t speak. Only his eyes were moving, looking at them in horror.\\n\"What\\'ve you done to him?\" Harry whispered.\"It\\'s the full Body-Bind,\" said Hermione miserably. \"Oh, Neville, I\\'m so\\nsorry.\"\\n\"We had to, Neville, no time to explain,\" said Harry.\"You\\'ll understand later, Neville,\" said Ron as they stepped over him\\nand pulled on the invisibility cloak.\\nBut leaving Neville lying motionless on the floor didn\\'t feel like a\\nvery good omen. In their nervous state, every statue\\'s shadow lookedlike Filch, every distant breath of wind sounded like Peeves swoopingdown on them. At the foot of the first set of stairs, they spotted Mrs.Norris skulking near the top.\\n\"Oh, let\\'s kick her, just this once,\" Ron whispered in Harry\\'s ear, but\\nHarry shook his head. As they climbed carefully around her, Mrs. Norristurned her lamplike eyes on them, but didn\\'t do anything.\\nThey didn\\'t meet anyone else until they reached the staircase up to the\\nthird floor. Peeves was bobbing halfway up, loosening the carpet so thatpeople would trip.\\n\"Who\\'s there?\" he said suddenly as they climbed toward him. He narrowed\\nhis wicked black eyes. \"Know you\\'re there, even if I can\\'t see you. Areyou ghoulie or ghostie or wee student beastie?\"\\nHe rose up in the air and floated there, squinting at them.\\n\"Should call Filch, I should, if something\\'s a-creeping around unseen.\"\\nHarry had a sudden idea.\"Peeves,\" he said, in a hoarse whisper, \"the Bloody Baron has his own\\nreasons for being invisible.\"\\nPeeves almost fell out of the air in shock. He caught himself in time\\nand hovered about a foot off the stairs.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 219}), Document(page_content='220\"So sorry, your bloodiness, Mr. Baron, Sir,\" he said greasily. \"My\\nmistake, my mistake -- I didn\\'t see you -- of course I didn\\'t, you\\'reinvisible -- forgive old Peevsie his little joke, sir.\"\\n\"I have business here, Peeves,\" croaked Harry. \"Stay away from this\\nplace tonight.\"\\n\"I will, sir, I most certainly will,\" said Peeves, rising up in the air\\nagain. \"Hope your business goes well, Baron, I\\'ll not bother you.\"\\nAnd he scooted off\"Brilliant, Harry!\" whispered Ron.\\nA few seconds later, they were there, outside the third-floor corridor\\n-- and the door was already ajar.\\n\"Well, there you are,\" Harry said quietly, \"Snape\\'s already got past\\nFluffy.\"\\nSeeing the open door somehow seemed to impress upon all three of them\\nwhat was facing them. Underneath the cloak, Harry turned to the othertwo.\\n\"If you want to go back, I won\\'t blame you,\" he said. \"You can take the\\ncloak, I won\\'t need it now.\"\\n\"Don\\'t be stupid,\" said Ron.\\n\"We\\'re coming,\" said Hermione.Harry pushed the door open.\\nAs the door creaked, low, rumbling growls met their ears. All three of\\nthe dog\\'s noses sniffed madly in their direction, even though itcouldn\\'t see them.\\n\"What\\'s that at its feet?\" Hermione whispered.\\n\"Looks like a harp,\" said Ron. \"Snape must have left it there.\"\\n\"It must wake up the moment you stop playing,\" said Harry. \"Well, here\\ngoes...\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 220}), Document(page_content='221He put Hagrid\\'s flute to his lips and blew. It wasn\\'t really a tune, but\\nfrom the first note the beast\\'s eyes began to droop. Harry hardly drewbreath. Slowly, the dog\\'s growls ceased -- it tottered on its paws andfell to its knees, then it slumped to the ground, fast asleep.\\n\"Keep playing,\" Ron warned Harry as they slipped out of the cloak and\\ncrept toward the trapdoor. They could feel the dog\\'s hot, smelly breathas they approached the giant heads. \"I think we\\'ll be able to pull thedoor open,\" said Ron, peering over the dog\\'s back. \"Want to go first,Hermione?\"\\n\"No, I don\\'t!\"\\n\"All right.\" Ron gritted his teeth and stepped carefully over the dog\\'s\\nlegs. He bent and pulled the ring of the trapdoor, which swung up andopen.\\n\"What can you see?\" Hermione said anxiously.\\n\"Nothing -- just black -- there\\'s no way of climbing down, we\\'ll just\\nhave to drop.\"\\nHarry, who was still playing the flute, waved at Ron to get his\\nattention and pointed at himself.\\n\"You want to go first? Are you sure?\" said Ron. \"I don\\'t know how deep\\nthis thing goes. Give the flute to Hermione so she can keep him asleep.\"\\nHarry handed the flute over. In the few seconds\\' silence, the dog\\ngrowled and twitched, but the moment Hermione began to play, it fellback into its deep sleep.\\nHarry climbed over it and looked down through the trapdoor. There was no\\nsign of the bottom.\\nHe lowered himself through the hole until he was hanging on by his\\nfingertips. Then he looked up at Ron and said, \"If anything happens tome, don\\'t follow. Go straight to the owlery and send Hedwig to\\nDumbledore, right?\"\\n\"Right,\" said Ron.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 221}), Document(page_content='222\"See you in a minute, I hope...\\nAnd Harry let go. Cold, damp air rushed past him as he fell down, down,\\ndown and -- FLUMP. With a funny, muffled sort of thump he landed onsomething soft. He sat up and felt around, his eyes not used to thegloom. It felt as though he was sitting on some sort of plant.\\n\"It\\'s okay!\" he called up to the light the size of a postage stamp,\\nwhich was the open trapdoor, \"it\\'s a soft landing, you can jump!\"\\nRon followed right away. He landed, sprawled next to Harry.\"What\\'s this stuff?\" were his first words.\\n\"Dunno, some sort of plant thing. I suppose it\\'s here to break the fall.\\nCome on, Hermione!\"\\nThe distant music stopped. There was a loud bark from the dog, but\\nHermione had already jumped. She landed on Harry\\'s other side.\\n\"We must be miles under the school , she said.\\n\"Lucky this plant thing\\'s here, really,\" said Ron.\"Lucky!\" shrieked Hermione. \"Look at you both!\"\\nShe leapt up and struggled toward a damp wall. She had to struggle\\nbecause the moment she had landed, the plant had started to twistsnakelike tendrils around her ankles. As for Harry and Ron, their legshad already been bound tightly in long creepers without their noticing.\\nHermione had managed to free herself before the plant got a firm grip on\\nher. Now she watched in horror as the two boys fought to pull the plant\\noff them, but the more they strained against it, the tighter and fasterthe plant wound around them.\\n\"Stop moving!\" Hermione ordered them. \"I know what this is -- it\\'s\\nDevil\\'s Snare!\"\\n\"Oh, I\\'m so glad we know what it\\'s called, that\\'s a great help,\" snarled\\nRon, leaning back, trying to stop the plant from curling around hisneck. \"Shut up, I\\'m trying to remember how to kill it!\" said Hermione.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 222}), Document(page_content='223\"Well, hurry up, I can\\'t breathe!\" Harry gasped, wrestling with it as it\\ncurled around his chest.\\n\"Devil\\'s Snare, Devil\\'s Snare... what did Professor Sprout say? -- it\\nlikes the dark and the damp\\n\"So light a fire!\" Harry choked.\\n\"Yes -- of course -- but there\\'s no wood!\" Hermione cried, wringing her\\nhands.\\n\"HAVE YOU GONE MAD?\" Ron bellowed. \"ARE YOU A WITCH OR NOT?\"\\n\"Oh, right!\" said Hermione, and she whipped out her wand, waved it,\\nmuttered something, and sent a jet of the same bluebell flames she hadused on Snape at the plant. In a matter of seconds, the two boys felt itloosening its grip as it cringed away from the light and warmth.Wriggling and flailing, it unraveled itself from their bodies, and theywere able to pull free.\\n\"Lucky you pay attention in Herbology, Hermione,\" said Harry as he\\njoined her by the wall, wiping sweat off his face.\\n\"Yeah,\" said Ron, \"and lucky Harry doesn\\'t lose his head in a crisis --\\n\\'there\\'s no wood,\\' honestly.\"\\n\"This way,\" said Harry, pointing down a stone passageway, which was the\\nonly way forward.\\nAll they could hear apart from their footsteps was the gentle drip of\\nwater trickling down the walls. The passageway sloped downward, andHarry was reminded of Gringotts. With an unpleasant jolt of the heart,\\nhe remembered the dragons said to be guarding vaults in the wizards\\'\\nbank. If they met a dragon, a fully-grown dragon -- Norbert had been badenough...\\n\"Can you hear something?\" Ron whispered.Harry listened. A soft rustling and clinking seemed to be coming from up\\nahead.\\n\"Do you think it\\'s a ghost?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 223}), Document(page_content='224\"I don\\'t know... sounds like wings to me.\"\\n\"There\\'s light ahead -- I can see something moving.\"They reached the end of the passageway and saw before them a brilliantly\\nlit chamber, its ceiling arching high above them. It was full of small,\\njewel-bright birds, fluttering and tumbling all around the room. On the\\nopposite side of the chamber was a heavy wooden door.\\n\"Do you think they\\'ll attack us if we cross the room?\" said Ron.\"Probably,\" said Harry. \"They don\\'t look very vicious, but I suppose if\\nthey all swooped down at once... well, there\\'s no other choice... I\\'ll\\nrun.\"\\nHe took a deep breath, covered his face with his arms, and sprinted\\nacross the room. He expected to feel sharp beaks and claws tearing athim any second, but nothing happened. He reached the door untouched. Hepulled the handle, but it was locked.\\nThe other two followed him. They tugged and heaved at the door, but it\\nwouldn\\'t budge, not even when Hermione tried her Alohomora charm.\\n\"Now what?\" said Ron.\"These birds... they can\\'t be here just for decoration,\" said Hermione.\\nThey watched the birds soaring overhead, glittering -- glittering?\\n\"They\\'re not birds!\" Harry said suddenly. \"They\\'re keys! Winged keys --\\nlook carefully. So that must mean...\" he looked around the chamber whilethe other two squinted up at the flock of keys. \"... yes -- look!\\nBroomsticks! We\\'ve got to catch the key to the door!\"\\n\"But there are hundreds of them!\"Ron examined the lock on the door.\"We\\'re looking for a big, old-fashioned one -- probably silver, like the\\nhandle.\"\\nThey each seized a broomstick and kicked off into the air, soaring into\\nthe midst of the cloud of keys. They grabbed and snatched, but the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 224}), Document(page_content='225bewitched keys darted and dived so quickly it was almost impossible to\\ncatch one.\\nNot for nothing, though, was Harry the youngest Seeker in a century. He\\nhad a knack for spotting things other people didn\\'t. After a minute\\'sweaving about through the whirl of rainbow feathers, he noticed a large\\nsilver key that had a bent wing, as if it had already been caught and\\nstuffed roughly into the keyhole.\\n\"That one!\" he called to the others. \"That big one -- there -- no, there\\n-- with bright blue wings -- the feathers are all crumpled on one side.\"\\nRon went speeding in the direction that Harry was pointing, crashed into\\nthe ceiling, and nearly fell off his broom.\\n\"We\\'ve got to close in on it!\" Harry called, not taking his eyes off the\\nkey with the damaged wing. \"Ron, you come at it from above -- Hermione,stay below and stop it from going down and I\\'ll try and catch it. Right,NOW!\"\\nRon dived, Hermione rocketed upward, the key dodged them both, and Harry\\nstreaked after it; it sped toward the wall, Harry leaned forward andwith a nasty, crunching noise, pinned it against the stone with onehand. Ron and Hermione\\'s cheers echoed around the high chamber.\\nThey landed quickly, and Harry ran to the door, the key struggling in\\nhis hand. He rammed it into the lock and turned -- it worked. The moment\\nthe lock had clicked open, the key took flight again, looking verybattered now that it had been caught twice.\\n\"Ready?\" Harry asked the other two, his hand on the door handle. They\\nnodded. He pulled the door open.\\nThe next chamber was so dark they couldn\\'t see anything at all. But as\\nthey stepped into it, light suddenly flooded the room to reveal anastonishing sight.\\nThey were standing on the edge of a huge chessboard, behind the black\\nchessmen, which were all taller than they were and carved from what\\nlooked like black stone. Facing them, way across the chamber, were the\\nwhite pieces. Harry, Ron and Hermione shivered slightly -- the toweringwhite chessmen had no faces.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 225}), Document(page_content='226\"Now what do we do?\" Harry whispered.\\n\"It\\'s obvious, isn\\'t it?\" said Ron. \"We\\'ve got to play our way across\\nthe room.\"\\nBehind the white pieces they could see another door.\\n\"How?\" said Hermione nervously.\\n\"I think,\" said Ron, \"we\\'re going to have to be chessmen.\"He walked up to a black knight and put his hand out to touch the\\nknight\\'s horse. At once, the stone sprang to life. The horse pawed the\\nground and the knight turned his helmeted head to look down at Ron.\\n\"Do we -- er -- have to join you to get across?\" The black knight\\nnodded. Ron turned to the other two.\\n\"This needs thinking about he said. I suppose we\\'ve got to take the\\nplace of three of the black pieces....\"\\nHarry and Hermione stayed quiet, watching Ron think. Finally he said,\\n\"Now, don\\'t be offended or anything, but neither of you are that good atchess --\"\\n\"We\\'re not offended,\" said Harry quickly. \"Just tell us what to do.\"\\n\"Well, Harry, you take the place of that bishop, and Hermione, YOU 90\\nnext to him instead of that castle.\"\\n\"What about you?\"\\n\"I\\'m going to be a knight,\" said Ron.\\nThe chessmen seemed to have been listening, because at these words a\\nknight, a bishop, and a castle turned their backs on the white piecesand walked off the board, leaving three empty squares that Harry, Ron,and Hermione took.\\n\"White always plays first in chess,\" said Ron, peering across the board.\\n\"Yes... look...\"\\nA white pawn had moved forward two squares.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 226}), Document(page_content='227Ron started to direct the black pieces. They moved silently wherever he\\nsent them. Harry\\'s knees were trembling. What if they lost?\\n\"Harry -- move diagonally four squares to the right.\"\\nTheir first real shock came when their other knight was taken. The white\\nqueen smashed him to the floor and dragged him off the board, where helay quite still, facedown.\\n\"Had to let that happen,\" said Ron, looking shaken. \"Leaves you free to\\ntake that bishop, Hermione, go on.\"\\nEvery time one of their men was lost, the white pieces showed no mercy.\\nSoon there was a huddle of limp black players slumped along the wall.Twice, Ron only just noticed in time that Harry and Hermione were indanger. He himself darted around the board, taking almost as many whitepieces as they had lost black ones.\\n\"We\\'re nearly there,\" he muttered suddenly. \"Let me think let me\\nthink...\"\\nThe white queen turned her blank face toward him.\"Yes...\" said Ron softly, \"It\\'s the only way... I\\'ve got to be taken.\"\\n\"NOF Harry and Hermione shouted.\\n\"That\\'s chess!\" snapped Ron. \"You\\'ve got to make some sacrifices! I take\\none step forward and she\\'ll take me -- that leaves you free to checkmatethe king, Harry!\"\\n\"But --\"\\n\"Do you want to stop Snape or not?\"\"Ron --\"\"Look, if you don\\'t hurry up, he\\'ll already have the Stone!\"\\nThere was no alternative.\\n\"Ready?\" Ron called, his face pale but determined. \"Here I go - now,', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 227}), Document(page_content='228don\\'t hang around once you\\'ve won.\"\\nHe stepped forward, and the white queen pounced. She struck Ron hard\\nacross the head with her stone arm, and he crashed to the floor -Hermione screamed but stayed on her square - the white queen dragged Ronto one side. He looked as if he\\'d been knocked out.\\nShaking, Harry moved three spaces to the left.\\nThe white king took off his crown and threw it at Harry\\'s feet. They had\\nwon. The chessmen parted and bowed, leaving the door ahead clear. Withone last desperate look back at Ron, Harry and Hermione charged throughthe door and up the next passageway.\\n\"What if he\\'s --?\"\\n\"He\\'ll be all right,\" said Harry, trying to convince himself. \"What do\\nyou reckon\\'s next?\"\\n\"We\\'ve had Sprout\\'s, that was the Devil\\'s Snare; Flitwick must\\'ve put\\ncharms on the keys; McGonagall transfigured the chessmen to make themalive; that leaves Quirrell\\'s spell, and Snape\\'s.\"\\nThey had reached another door.\"All right?\" Harry whispered.\\n\"Go on.\"\\nHarry pushed it open.A disgusting smell filled their nostrils, making both of them pull their\\nrobes up over their noses. Eyes watering, they saw, flat on the floor in\\nfront of them, a troll even larger than the one they had tackled, outcold with a bloody lump on its head.\\n\"I\\'m glad we didn\\'t have to fight that one,\" Harry whispered as they\\nstepped carefully over one of its massive legs. \"Come on, I can\\'tbreathe.\"\\nHe pulled open the next door, both of them hardly daring to look at what\\ncame next - but there was nothing very frightening in here, just a tablewith seven differently shaped bottles standing on it in a line.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 228}), Document(page_content='229\"Snape\\'s,\" said Harry. \"What do we have to do?\"\\nThey stepped over the threshold, and immediately a fire sprang up behind\\nthem in the doorway. It wasn\\'t ordinary fire either; it was purple. Atthe same instant, black flames shot up in the doorway leading onward.\\nThey were trapped.\\n\"Look!\" Hermione seized a roll of paper lying next to the bottles. Harry\\nlooked over her shoulder to read it:\\nDanger lies before you, while safety lies behind,\\nTwo of us will help you, which ever you would find,\\nOne among us seven will let you move ahead,Another will transport the drinker back instead,\\nTwo among our number hold only nettle wine,\\nThree of us are killers, waiting bidden in line.Choose, unless you wish to stay here forevermore,To help you in your choice, we give you these clues four:\\nFirst, however slyly the poison tries to hide\\nYou will always find some on nettle wine\\'s left side;Second, different are those who stand at either end,\\nBut if you would move onward, neither is your friend;\\nThird, as you see clearly, all are different size,Neither dwarf nor giant holds death in their insides;\\nFourth, the second left and the second on the right\\nAre twins once you taste them, though different at first sight.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 229}), Document(page_content='230Hermione let out a great sigh and Harry, amazed, saw that she was\\nsmiling, the very last thing he felt like doing.\\n\"Brilliant,\" said Hermione. \"This isn\\'t magic -- it\\'s logic -- a puzzle.\\nA lot of the greatest wizards haven\\'t got an ounce of logic, they\\'d bestuck in here forever.\"\\n\"But so will we, won\\'t we?\" \"Of course not,\" said Hermione. \"Everything\\nwe need is here on this paper. Seven bottles: three are poison; two arewine; one will get us safely through the black fire, and one will get usback through the purple.\"\\n\"But how do we know which to drink?\"\\n\"Give me a minute.\"\\nHermione read the paper several times. Then she walked up and down the\\nline of bottles, muttering to herself and pointing at them. At last, sheclapped her hands.\\n\"Got it,\" she said. \"The smallest bottle will get us through the black\\nfire -- toward the Stone.\"\\nHarry looked at the tiny bottle.\"There\\'s only enough there for one of us,\" he said. \"That\\'s hardly one\\nswallow.\"\\nThey looked at each other.\"Which one will get you back through the purple flames?\"\\nHermione pointed at a rounded bottle at the right end of the line.\\n\"You drink that,\" said Harry. \"No, listen, get back and get Ron. Grab\\nbrooms from the flying- key room, they\\'ll get you out of the trapdoorand past Fluffy -- go straight to the owlery and send Hedwig toDumbledore, we need him. I might be able to hold Snape off for a while,but I\\'m no match for him, really.\"\\n\"But Harry -- what if You-Know-Who\\'s with him?\"\\n\"Well -- I was lucky once, wasn\\'t I?\" said Harry, pointing at his scar.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 230}), Document(page_content='231\"I might get lucky again.\"\\nHermione\\'s lip trembled, and she suddenly dashed at Harry and threw her\\narms around him.\\n\"Hermione!\"\\n\"Harry -- you\\'re a great wizard, you know.\"\\n\"I\\'m not as good as you,\" said Harry, very embarrassed, as she let go of\\nhim.\\n\"Me!\" said Hermione. \"Books! And cleverness! There are more important\\nthings -- friendship and bravery and -- oh Harry -- be careful!\"\\n\"You drink first,\" said Harry. \"You are sure which is which, aren\\'t\\nyou?\"\\n\"Positive,\" said Hermione. She took a long drink from the round bottle\\nat the end, and shuddered.\\n\"It\\'s not poison?\" said Harry anxiously.\"No -- but it\\'s like ice.\"\"Quick, go, before it wears off.\"\\n\"Good luck -- take care.\"\\n\"GO!\"Hermione turned and walked straight through the purple fire.\\nHarry took a deep breath and picked up the smallest bottle. He turned to\\nface the black flames.\\n\"Here I come,\" he said, and he drained the little bottle in one gulp.It was indeed as though ice was flooding his body. He put the bottle\\ndown and walked forward; he braced himself, saw the black flames licking\\nhis body, but couldn\\'t feel them -- for a moment he could see nothingbut dark fire -- then he was on the other side, in the last chamber.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 231}), Document(page_content='232There was already someone there -- but it wasn\\'t Snape. It wasn\\'t even\\nVoldemort.\\nCHAPTER SEVENTEEN\\nTHE MAN WITH TWO FACES\\nIt was Quirrell.\"You!\" gasped Harry.Quirrell smiled. His face wasn\\'t twitching at all.\\n\"Me,\" he said calmly. \"I wondered whether I\\'d be meeting you here,\\nPotter.\"\\n\"But I thought -- Snape --\"\\n\"Severus?\" Quirrell laughed, and it wasn\\'t his usual quivering treble,\\neither, but cold and sharp. \"Yes, Severus does seem the type, doesn\\'the? So useful to have him swooping around like an overgrown bat. Next tohim, who would suspect p-p-poor, st-stuttering P-Professor Quirrell?\"\\nHarry couldn\\'t take it in. This couldn\\'t be true, it couldn\\'t.\\n\"But Snape tried to kill me!\"\\n\"No, no, no. I tried to kill you. Your friend Miss Granger accidentally\\nknocked me over as she rushed to set fire to Snape at that Quidditchmatch. She broke my eye contact with you. Another few seconds and I\\'dhave got you off that broom. I\\'d have managed it before then if Snape\\nhadn\\'t been muttering a countercurse, trying to save you.\"\\n\"Snape was trying to save me?\"\"Of course,\" said Quirrell coolly. \"\\\\Why do you think he wanted to\\nreferee your next match? He was trying to make sure I didn\\'t do itagain. Funny, really... he needn\\'t have bothered. I couldn\\'t do anything\\nwith Dumbledore watching. All the other teachers thought Snape was\\ntrying to stop Gryffindor from winning, he did make himself unpopular...and what a waste of time, when after all that, I\\'m going to kill youtonight.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 232}), Document(page_content='233Quirrell snapped his fingers. Ropes sprang out of thin air and wrapped\\nthemselves tightly around Harry.\\n\"You\\'re too nosy to live, Potter. Scurrying around the school on\\nHalloween like that, for all I knew you\\'d seen me coming to look at what\\nwas guarding the Stone.\"\\n\"You let the troll in?\"\"Certainly. I have a special gift with trolls -- you must have seen what\\nI did to the one in the chamber back there? Unfortunately, whileeveryone else was running around looking for it, Snape, who already\\nsuspected me, went straight to the third floor to head me off -- and not\\nonly did my troll fail to beat you to death, that three-headed dogdidn\\'t even manage to bite Snape\\'s leg off properly.\\n\"Now, wait quietly, Potter. I need to examine this interesting mirror.\\nIt was only then that Harry realized what was standing behind Quirrell.\\nIt was the Mirror of Erised.\\n\"This mirror is the key to finding the Stone,\" Quirrell murmured,\\ntapping his way around the frame. \"Trust Dumbledore to come up withsomething like this... but he\\'s in London... I\\'ll be far away by thetime he gets back....\"\\nAll Harry could think of doing was to keep Quirrell talking and stop him\\nfrom concentrating on the mirror.\\n\"I saw you and Snape in the forest --\" he blurted out.\\n\"Yes,\" said Quirrell idly, walking around the mirror to look at the\\nback. \"He was on to me by that time, trying to find out how far I\\'d got.He suspected me all along. Tried to frighten me - as though he could,when I had Lord Voldemort on my side....\"\\nQuirrell came back out from behind the mirror and stared hungrily into\\nit.\\n\"I see the Stone... I\\'m presenting it to my master... but where is it?\"\\nHarry struggled against the ropes binding him, but they didn\\'t give. He', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 233}), Document(page_content='234had to keep Quirrell from giving his whole attention to the mirror.\\n\"But Snape always seemed to hate me so much.\"\"Oh, he does,\" said Quirrell casually, \"heavens, yes. He was at Hogwarts\\nwith your father, didn\\'t you know? They loathed each other. But he never\\nwanted you dead.\"\\n\"But I heard you a few days ago, sobbing -- I thought Snape was\\nthreatening you....\"\\nFor the first time, a spasm of fear flitted across Quirrell\\'s face.\\n\"Sometimes,\" he said, \"I find it hard to follow my master\\'s instructions\\n-- he is a great wizard and I am weak --\"\\n\"You mean he was there in the classroom with you?\" Harry gasped.\"He is with me wherever I go,\" said Quirrell quietly. \"I met him when I\\ntraveled around the world. A foolish young man I was then, full of\\nridiculous ideas about good and evil. Lord Voldemort showed me how wrongI was. There is no good and evil, there is only power, and those tooweak to seek it.... Since then, I have served him faithfully, although Ihave let him down many times. He has had to be very hard on me.\"Quirrell shivered suddenly. \"He does not forgive mistakes easily. When Ifailed to steal the stone from Gringotts, he was most displeased. He\\npunished me... decided he would have to keep a closer watch on me....\"\\nQuirrell\\'s voice trailed away. Harry was remembering his trip to Diagon\\nAlley -how could he have been so stupid? He\\'d seen Quirrell there thatvery day, shaken hands with him in the Leaky Cauldron.\\nQuirrell cursed under his breath.\\n\"I don\\'t understand... is the Stone inside the mirror? Should I break\\nit?\"\\nHarry\\'s mind was racing.\\nWhat I want more than anything else in the world at the moment, he\\nthought, is to find the Stone before Quirrell does. So if I look in themirror, I should see myseff finding it -- which means I\\'ll see whereit\\'s hidden! But how can I look without Quirrell realizing what I\\'m up', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 234}), Document(page_content='235to?\\nHe tried to edge to the left, to get in front of the glass without\\nQuirrell noticing, but the ropes around his ankles were too tight: hetripped and fell over. Quirrell ignored him. He was still talking tohimself. \"What does this mirror do? How does it work? Help me, Master!\"\\nAnd to Harry\\'s horror, a voice answered, and the voice seemed to come\\nfrom Quirrell himself\\n\"Use the boy... Use the boy...\"Quirrell rounded on Harry.\\n\"Yes -- Potter -- come here.\"\\nHe clapped his hands once, and the ropes binding Harry fell off. Harry\\ngot slowly to his feet.\\n\"Come here,\" Quirrell repeated. \"Look in the mirror and tell me what you\\nsee.\"\\nHarry walked toward him.I must lie, he thought desperately. I must look and lie about what I\\nsee, that\\'s all.\\nQuirrell moved close behind him. Harry breathed in the funny smell that\\nseemed to come from Quirrell\\'s turban. He closed his eyes, stepped infront of the mirror, and opened them again.\\nHe saw his reflection, pale and scared-looking at first. But a moment\\nlater, the reflection smiled at him. It put its hand into its pocket and\\npulled out a blood-red stone. It winked and put the Stone back in itspocket -- and as it did so, Harry felt something heavy drop into hisreal pocket. Somehow -- incredibly -- he\\'d gotten the Stone.\\n\"Well?\" said Quirrell impatiently. \"What do you see?\"\\nHarry screwed up his courage.\\n\"I see myself shaking hands with Dumbledore,\" he invented. \"I -- I\\'ve\\nwon the house cup for Gryffindor.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 235}), Document(page_content='236Quirrell cursed again.\\n\"Get out of the way,\" he said. As Harry moved aside, he felt the\\nSorcerer\\'s Stone against his leg. Dare he make a break for it?\\nBut he hadn\\'t walked five paces before a high voice spoke, though\\nQuirrell wasn\\'t moving his lips.\\n\"He lies... He lies...\"\"Potter, come back here!\" Quirrell shouted. \"Tell me the truth! What did\\nyou just see?\"\\nThe high voice spoke again.\\n\"Let me speak to him... face-to-face...\"\"Master, you are not strong enough!\"\\n\"I have strength enough... for this....\"\\nHarry felt as if Devil\\'s Snare was rooting him to the spot. He couldn\\'t\\nmove a muscle. Petrified, he watched as Quirrell reached up and began tounwrap his turban. What was going on? The turban fell away. Quirrell\\'shead looked strangely small without it. Then he turned slowly on the\\nspot.\\nHarry would have screamed, but he couldn\\'t make a sound. Where there\\nshould have been a back to Quirrell\\'s head, there was a face, the mostterrible face Harry had ever seen. It was chalk white with glaring redeyes and slits for nostrils, like a snake.\\n\"Harry Potter...\" it whispered.\\nHarry tried to take a step backward but his legs wouldn\\'t move.\"See what I have become?\" the face said. \"Mere shadow and vapor ... I\\nhave form only when I can share another\\'s body... but there have always\\nbeen those willing to let me into their hearts and minds.... Unicorn\\nblood has strengthened me, these past weeks... you saw faithful Quirrelldrinking it for me in the forest... and once I have the Elixir of Life,I will be able to create a body of my own.... Now... why don\\'t you give', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 236}), Document(page_content='237me that Stone in your pocket?\"\\nSo he knew. The feeling suddenly surged back into Harry\\'s legs. He\\nstumbled backward.\\n\"Don\\'t be a fool,\" snarled the face. \"Better save your own life and join\\nme... or you\\'ll meet the same end as your parents.... They died begging\\nme for mercy...\"\\n\"LIAR!\" Harry shouted suddenly.Quirrell was walking backward at him, so that Voldemort could still see\\nhim. The evil face was now smiling.\\n\"How touching...\" it hissed. \"I always value bravery... Yes, boy, your\\nparents were brave.... I killed your father first; and he put up acourageous fight... but your mother needn\\'t have died... she was tryingto protect you.... Now give me the Stone, unless you want her to havedied in vain.\"\\n\"NEVER!\"\\nHarry sprang toward the flame door, but Voldemort screamed \"SEIZE HIM!\"\\nand the next second, Harry felt Quirrell\\'s hand close on his wrist. Atonce, a needle-sharp pain seared across Harry\\'s scar; his head felt asthough it was about to split in two; he yelled, struggling with all his\\nmight, and to his surprise, Quirrell let go of him. The pain in his head\\nlessened -- he looked around wildly to see where Quirrell had gone, andsaw him hunched in pain, looking at his fingers -- they were blisteringbefore his eyes.\\n\"Seize him! SEIZE HIM!\" shrieked Voldemort again, and Quirrell lunged,\\nknocking Harry clean off his feet\\' landing on top of him, both hands\\naround Harry\\'s neck -- Harry\\'s scar was almost blinding him with pain,yet he could see Quirrell howling in agony.\\n\"Master, I cannot hold him -- my hands -- my hands!\"And Quirrell, though pinning Harry to the ground with his knees, let go\\nof his neck and stared, bewildered, at his own palms -- Harry could see\\nthey looked burned, raw, red, and shiny.\\n\"Then kill him, fool, and be done!\" screeched Voldemort.', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 237}), Document(page_content='238Quirrell raised his hand to perform a deadly curse, but Harry, by\\ninstinct, reached up and grabbed Quirrell\\'s face --\\n\"AAAARGH!\"\\nQuirrell rolled off him, his face blistering, too, and then Harry knew:\\nQuirrell couldn\\'t touch his bare skin, not without suffering terriblepain -- his only chance was to keep hold of Quirrell, keep him in enoughpain to stop him from doing a curse.\\nHarry jumped to his feet, caught Quirrell by the arm, and hung on as\\ntight as he could. Quirrell screamed and tried to throw Harry off -- the\\npain in Harry\\'s head was building -- he couldn\\'t see -- he could only\\nhear Quirrell\\'s terrible shrieks and Voldemort\\'s yells of, \"KILL HIM!KILL HIM!\" and other voices, maybe in Harry\\'s own head, crying, \"Harry!Harry!\"\\nHe felt Quirrell\\'s arm wrenched from his grasp, knew all was lost, and\\nfell into blackness, down ... down... down...\\nSomething gold was glinting just above him. The Snitch! He tried to\\ncatch it, but his arms were too heavy.\\nHe blinked. It wasn\\'t the Snitch at all. It was a pair of glasses. How\\nstrange.\\nHe blinked again. The smiling face of Albus Dumbledore swam into view\\nabove him.\\n\"Good afternoon, Harry,\" said Dumbledore. Harry stared at him. Then he\\nremembered: \"Sir! The Stone! It was Quirrell! He\\'s got the Stone! Sir,\\nquick --\"\\n\"Calm yourself, dear boy, you are a little behind the times,\" said\\nDumbledore. \"Quirrell does not have the Stone.\"\\n\"Then who does? Sir, I --\"\\n\"Harry, please relax, or Madam Pomfrey will have me thrown out.\\nHarry swallowed and looked around him. He realized he must be in the\\nhospital wing. He was lying in a bed with white linen sheets, and next', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 238}), Document(page_content='239to him was a table piled high with what looked like half the candy shop.\\n\"Tokens from your friends and admirers,\" said Dumbledore, beaming. \"What\\nhappened down in the dungeons between you and Professor Quirrell is acomplete secret, so, naturally, the whole school knows. I believe yourfriends Misters Fred and George Weasley were responsible for trying to\\nsend you a toilet seat. No doubt they thought it would amuse you. Madam\\nPomfrey, however, felt it might not be very hygienic, and confiscatedit.\"\\n\"How long have I been in here?\"\"Three days. Mr. Ronald Weasley and Miss Granger will be most relieved\\nyou have come round, they have been extremely worried.\"\\n\"But sit, the StoneI see you are not to be distracted. Very well, the Stone. Professor\\nQuirrell did not manage to take it from you. I arrived in time to\\nprevent that, although you were doing very well on your own, I must say.\\n\"You got there? You got Hermione\\'s owl?\"\"We must have crossed in midair. No sooner had I reached London than it\\nbecame clear to me that the place I should be was the one I had justleft. I arrived just in time to pull Quirrell off you.\"\\n\"It was you.\"\\n\"I feared I might be too late.\"\"You nearly were, I couldn\\'t have kept him off the Stone much longer --\"\\n\"Not the Stone, boy, you -- the effort involved nearly killed you. For\\none terrible moment there, I was afraid it had. As for the Stone, it hasbeen destroyed.\"\\n\"Destroyed?\" said Harry blankly. \"But your friend -- Nicolas Flamel --\"\\n\"Oh, you know about Nicolas?\" said Dumbledore, sounding quite delighted.\\n\"You did do the thing properly, didn\\'t you? Well, Nicolas and I have hada little chat, and agreed it\\'s all for the best.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 239}), Document(page_content='240\"But that means he and his wife will die, won\\'t they?\"\\n\"They have enough Elixir stored to set their affairs in order and then,\\nyes, they will die.\"\\nDumbledore smiled at the look of amazement on Harry\\'s face.\\n\"To one as young as you, I\\'m sure it seems incredible, but to Nicolas\\nand Perenelle, it really is like going to bed after a very, very longday. After all, to the well-organized mind, death is but the next greatadventure. You know, the Stone was really not such a wonderful thing. Asmuch money and life as you could want! The two things most human beingswould choose above all -- the trouble is, humans do have a knack of\\nchoosing precisely those things that are worst for them.\" Harry lay\\nthere, lost for words. Dumbledore hummed a little and smiled at theceiling.\\n\"Sir?\" said Harry. \"I\\'ve been thinking... sir -- even if the Stone\\'s\\ngone, Vol-, I mean, You-Know- Who --\"\\n\"Call him Voldemort, Harry. Always use the proper name for things. Fear\\nof a name increases fear of the thing itself.\"\\n\"Yes, sir. Well, Voldemort\\'s going to try other ways of coming back,\\nisn\\'t he? I mean, he hasn\\'t gone, has he?\"\\n\"No, Harry, he has not. He is still out there somewhere, perhaps looking\\nfor another body to share... not being truly alive, he cannot be killed.He left Quirrell to die; he shows just as little mercy to his followersas his enemies. Nevertheless, Harry, while you may only have delayed hisreturn to power, it will merely take someone else who is prepared tofight what seems a losing battle next time -- and if he is delayed\\nagain, and again, why, he may never return to power.\"\\nHarry nodded, but stopped quickly, because it made his head hurt. Then\\nhe said, \"Sir, there are some other things I\\'d like to know, if you cantell me... things I want to know the truth about....\"\\n\"The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing,\\nand should therefore be treated with great caution. However, I shall\\nanswer your questions unless I have a very good reason not to, in whichcase I beg you\\'ll forgive me. I shall not, of course, lie.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 240}), Document(page_content='241\"Well... Voldemort said that he only killed my mother because she tried\\nto stop him from killing me. But why would he want to kill me in thefirst place?\"\\nDumbledore sighed very deeply this time.\\n\"Alas, the first thing you ask me, I cannot tell you. Not today. Not\\nnow. You will know, one day... put it from your mind for now, Harry.When you are older... I know you hate to hear this... when you areready, you will know.\"\\nAnd Harry knew it would be no good to argue.\\n\"But why couldn\\'t Quirrell touch me?\"\\n\"Your mother died to save you. If there is one thing Voldemort cannot\\nunderstand, it is love. He didn\\'t realize that love as powerful as yourmother\\'s for you leaves its own mark. Not a scar, no visible sign... tohave been loved so deeply, even though the person who loved us is gone,\\nwill give us some protection forever. It is in your very skin. Quirrell,\\nfull of hatred, greed, and ambition, sharing his soul with Voldemort,could not touch you for this reason. It was agony to touch a personmarked by something so good.\"\\nDumbledore now became very interested in a bird out on the windowsill,\\nwhich gave Harry time to dry his eyes on the sheet. When he had found\\nhis voice again, Harry said, \"And the invisibility cloak - do you know\\nwho sent it to me?\"\\n\"Ah - your father happened to leave it in my possession, and I thought\\nyou might like it.\" Dumbledore\\'s eyes twinkled. \"Useful things... yourfather used it mainly for sneaking off to the kitchens to steal food\\nwhen he was here.\"\\n\"And there\\'s something else...\"\"Fire away.\"\"Quirrell said Snape --\"\\n\"Professor Snape, Harry.\" \"Yes, him -- Quirrell said he hates me because\\nhe hated my father. Is that true?\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 241}), Document(page_content='242\"Well, they did rather detest each other. Not unlike yourself and Mr.\\nMalfoy. And then, your father did something Snape could never forgive.\"\\n\"What?\"\"He saved his life.\"\\n\"What?\"\\n\"Yes...\" said Dumbledore dreamily. \"Funny, the way people\\'s minds work,\\nisn\\'t it? Professor Snape couldn\\'t bear being in your father\\'s debt....I do believe he worked so hard to protect you this year because he feltthat would make him and your father even. Then he could go back to\\nhating your father\\'s memory in peace....\"\\nHarry tried to understand this but it made his head pound, so he\\nstopped.\\n\"And sir, there\\'s one more thing...\"\\n\"Just the one?\"\\n\"How did I get the Stone out of the mirror?\"\"Ah, now, I\\'m glad you asked me that. It was one of my more brilliant\\nideas, and between you and me, that\\'s saying something. You see, only\\none who wanted to find the Stone -- find it, but not use it -- would be\\nable to get it, otherwise they\\'d just see themselves making gold ordrinking Elixir of Life. My brain surprises even me sometimes.... Now,enough questions. I suggest you make a start on these sweets. Ah! BettieBott\\'s Every Flavor Beans! I was unfortunate enough in my youth to comeacross a vomitflavored one, and since then I\\'m afraid I\\'ve rather lost\\nmy liking for them -- but I think I\\'ll be safe with a nice toffee, don\\'t\\nyou?\"\\nHe smiled and popped the golden-brown bean into his mouth. Then he\\nchoked and said, \"Alas! Ear wax!\"\\nMadam Pomfrey, the nurse, was a nice woman, but very strict.\\n\"Just five minutes,\" Harry pleaded.\\n\"Absolutely not.\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 242}), Document(page_content='243\"You let Professor Dumbledore in...\"\\n\"Well, of course, that was the headmaster, quite different. You need\\nrest.\"\\n\"I am resting, look, lying down and everything. Oh, go on, Madam\\nPomfrey...\"\\n\"Oh, very well,\" she said. \"But five minutes only.\"And she let Ron and Hermione in.\\n\"Harry!\"\\nHermione looked ready to fling her arms around him again, but Harry was\\nglad she held herself in as his head was still very sore.\\n\"Oh, Harry, we were sure you were going to -- Dumbledore was so worried\\n--\"\\n\"The whole school\\'s talking about it,\" said Ron. \"What really happened?\"It was one of those rare occasions when the true story is even more\\nstrange and exciting than the wild rumors. Harry told them everything:Quirrell; the mirror; the Stone; and Voldemort. Ron and Hermione were a\\nvery good audience; they gasped in all the right places, and when Harry\\ntold them what was under Quirrell\\'s turban, Hermione screamed out loud.\\n\"So the Stone\\'s gone?\" said Ron finally. \"Flamel\\'s just going to die?\"\"That\\'s what I said, but Dumbledore thinks that -- what was it? -- \\'to\\nthe well-organized mind, death is but the next great adventure.\\n\"I always said he was off his rocker,\" said Ron, looking quite impressed\\nat how crazy his hero was.\\n\"So what happened to you two?\" said Harry.\\n\"Well, I got back all right,\" said Hermione. \"I brought Ron round --\\nthat took a while -- and we were dashing up to the owlery to contactDumbledore when we met him in the entrance hall -- he already knew -- hejust said, \\'Harry\\'s gone after him, hasn\\'t he?\\' and hurtled off to the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 243}), Document(page_content='244third floor.\"\\n\"D\\'you think he meant you to do it?\" said Ron. \"Sending you your\\nfather\\'s cloak and everything?\"\\n\"Well, \" Hermione exploded, \"if he did -- I mean to say that\\'s terrible\\n-- you could have been killed.\"\\n\"No, it isn\\'t,\" said Harry thoughtfully. \"He\\'s a funny man, Dumbledore.\\nI think he sort of wanted to give me a chance. I think he knows more orless everything that goes on here, you know. I reckon he had a prettygood idea we were going to try, and instead of stopping us, he justtaught us enough to help. I don\\'t think it was an accident he let me\\nfind out how the mirror worked. It\\'s almost like he thought I had the\\nright to face Voldemort if I could....\"\\n\"Yeah, Dumbledore\\'s off his rocker, all right,\" said Ron proudly.\\n\"Listen, you\\'ve got to be up for the end-of-year feast tomorrow. Thepoints are all in and Slytherin won, of course -- you missed the last\\nQuidditch match, we were steamrollered by Ravenclaw without you -- but\\nthe food\\'ll be good.\"\\nAt that moment, Madam Pomfrey bustled over.\"You\\'ve had nearly fifteen minutes, now OUT\" she said firmly.\\nAfter a good night\\'s sleep, Harry felt nearly back to normal.\\nI want to go to the feast,\" he told Madam Pomfrey as she straightened\\nhis many candy boxes. I can, can\\'t I?\"\\n\"Professor Dumbledore says you are to be allowed to go,\" she said\\nstiffily, as though in her opinion Professor Dumbledore didn\\'t realize\\nhow risky feasts could be. \"And you have another visitor.\"\\n\"Oh, good,\" said Harry. \"Who is it?\"Hagrid sidled through the door as he spoke. As usual when he was\\nindoors, Hagrid looked too big to be allowed. He sat down next to Harry,\\ntook one look at him, and burst into tears.\\n\"It\\'s -- all -- my -- ruddy -- fault!\" he sobbed, his face in his hands.\\nI told the evil git how ter get past Fluffy! I told him! It was the only', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 244}), Document(page_content='245thing he didn\\'t know, an\\' I told him! Yeh could\\'ve died! All fer a\\ndragon egg! I\\'ll never drink again! I should be chucked out an\\' made terlive as a Muggle!\"\\n\"Hagrid!\" said Harry, shocked to see Hagrid shaking with grief and\\nremorse, great tears leaking down into his beard. \"Hagrid, he\\'d have\\nfound out somehow, this is Voldemort we\\'re talking about, he\\'d have\\nfound out even if you hadn\\'t told him.\"\\n\"Yeh could\\'ve died!\" sobbed Hagrid. \"An\\' don\\' say the name!\"\"VOLDEMORT!\" Harry bellowed, and Hagrid was so shocked, he stopped\\ncrying. \"I\\'ve met him and I\\'m calling him by his name. Please cheer up,\\nHagrid, we saved the Stone, it\\'s gone, he can\\'t use it. Have a Chocolate\\nFrog, I\\'ve got loads....\"\\nHagrid wiped his nose on the back of his hand and said, \"That reminds\\nme. I\\'ve got yeh a present.\"\\n\"It\\'s not a stoat sandwich, is it?\" said Harry anxiously, and at last\\nHagrid gave a weak chuckle. \"Nah. Dumbledore gave me the day offyesterday ter fix it. \\'Course, he shoulda sacked me instead -- anyway,got yeh this...\"\\nIt seemed to be a handsome, leather-covered book. Harry opened it\\ncuriously. It was full of wizard photographs. Smiling and waving at him\\nfrom every page were his mother and father.\\n\"Sent owls off ter all yer parents\\' old school friends, askin\\' fer\\nphotos... knew yeh didn\\' have any... d\\'yeh like it?\"\\nHarry couldn\\'t speak, but Hagrid understood.\\nHarry made his way down to the end-of-year feast alone that night. He\\nhad been held up by Madam Pomfrey\\'s fussing about, insisting on givinghim one last checkup, so the Great Hall was already full. It was deckedout in the Slytherin colors of green and silver to celebrate Slytherin\\'swinning the house cup for the seventh year in a row. A huge bannershowing the Slytherin serpent covered the wall behind the High Table.\\nWhen Harry walked in there was a sudden hush, and then everybody started\\ntalking loudly at once. He slipped into a seat between Ron and Hermioneat the Gryffindor table and tried to ignore the fact that people were', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 245}), Document(page_content='246standing up to look at him.\\nFortunately, Dumbledore arrived moments later. The babble died away.\"Another year gone!\" Dumbledore said cheerfully. \"And I must trouble you\\nwith an old man\\'s wheezing waffle before we sink our teeth into our\\ndelicious feast. What a year it has been! Hopefully your heads are all a\\nlittle fuller than they were... you have the whole summer ahead to getthem nice and empty before next year starts....\\n\"Now, as I understand it, the house cup here needs awarding, and the\\npoints stand thus: In fourth place, Gryffindor, with three hundred andtwelve points; in third, Hufflepuff, with three hundred and fifty-two;\\nRavenclaw has four hundred and twenty-six and Slytherin, four hundred\\nand seventy- two.\"\\nA storm of cheering and stamping broke out from the Slytherin table.\\nHarry could see Draco Malfoy banging his goblet on the table. It was asickening sight.\\n\"Yes, Yes, well done, Slytherin,\" said Dumbledore. \"However, recent\\nevents must be taken into account.\"\\nThe room went very still. The Slytherins\\' smiles faded a little.\"Ahem,\" said Dumbledore. \"I have a few last-minute points to dish out.\\nLet me see. Yes...\\n\"First -- to Mr. Ronald Weasley...\"Ron went purple in the face; he looked like a radish with a bad sunburn.\\n\"...for the best-played game of chess Hogwarts has seen in many years, I\\naward Gryffindor house fifty points.\"\\nGryffindor cheers nearly raised the bewitched ceiling; the stars\\noverhead seemed to quiver. Percy could be heard telling the otherprefects, \"My brother, you know! My youngest brother! Got pastMcGonagall\\'s giant chess set!\"\\nAt last there was silence again.\\n\"Second -- to Miss Hermione Granger... for the use of cool logic in the', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 246}), Document(page_content='247face of fire, I award Gryffindor house fifty points.\"\\nHermione buried her face in her arms; Harry strongly suspected she had\\nburst into tears. Gryffindors up and down the table were besidethemselves -- they were a hundred points up. \"Third -- to Mr. HarryPotter...\" said Dumbledore. The room went deadly quiet for pure nerve\\nand outstanding courage, I award Gryffindor house sixty points.\"\\nThe din was deafening. Those who could add up while yelling themselves\\nhoarse knew that Gryffindor now had four hundred and seventy-two points-- exactly the same as Slytherin. They had tied for the house cup -- ifonly Dumbledore had given Harry just one more point.\\nDumbledore raised his hand. The room gradually fell silent.\\n\"There are all kinds of courage,\" said Dumbledore, smiling. \"It takes a\\ngreat deal of bravery to stand up to our enemies, but just as much tostand up to our friends. I therefore award ten points to Mr. NevilleLongbottom.\"\\nSomeone standing outside the Great Hall might well have thought some\\nsort of explosion had taken place, so loud was the noise that eruptedfrom the Gryffindor table. Harry, Ron, and Hermione stood up to yell andcheer as Neville, white with shock, disappeared under a pile of peoplehugging him. He had never won so much as a point for Gryffindor before.Harry, still cheering, nudged Ron in the ribs and pointed at Malfoy, who\\ncouldn\\'t have looked more stunned and horrified if he\\'d just had the\\nBody-Bind Curse put on him.\\n\"Which means, Dumbledore called over the storm of applause, for even\\nRavenclaw and Hufflepuff were celebrating the downfall of Slytherin, \"weneed a little change of decoration.\"\\nHe clapped his hands. In an instant, the green hangings became scarlet\\nand the silver became gold; the huge Slytherin serpent vanished and atowering Gryffindor lion took its place. Snape was shaking ProfessorMcGonagall\\'s hand, with a horrible, forced smile. He caught Harry\\'s eyeand Harry knew at once that Snape\\'s feelings toward him hadn\\'t changedone jot. This didn\\'t worry Harry. It seemed as though life would be back\\nto normal next year, or as normal as it ever was at Hogwarts.\\nIt was the best evening of Harry\\'s life, better than winning at\\nQuidditch, or Christmas, or knocking out mountain trolls... he would', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 247}), Document(page_content='248never, ever forget tonight.\\nHarry had almost forgotten that the exam results were still to come, but\\ncome they did. To their great surprise, both he and Ron passed with goodmarks; Hermione, of course, had the best grades of the first years. EvenNeville scraped through, his good Herbology mark making up for his\\nabysmal Potions one. They had hoped that Goyle, who was almost as stupid\\nas he was mean, might be thrown out, but he had passed, too. It was ashame, but as Ron said, you couldn\\'t have everything in life.\\nAnd suddenly, their wardrobes were empty, their trunks were packed,\\nNeville\\'s toad was found lurking in a corner of the toilets; notes werehanded out to all students, warning them not to use magic over the\\nholidays (\"I always hope they\\'ll forget to give us these,\" said Fred\\nWeasley sadly); Hagrid was there to take them down to the fleet of boatsthat sailed across the lake; they were boarding the Hogwarts Express;talking and laughing as the countryside became greener and tidier;eating Bettie Bott\\'s Every Flavor Beans as they sped past Muggle towns;pulling off their wizard robes and putting on jackets and coats; pulling\\ninto platform nine and three-quarters at King\\'s Cross Station.\\nIt took quite a while for them all to get off the platform. A wizened\\nold guard was up by the ticket barrier, letting them go through the gatein twos and threes so they didn\\'t attract attention by all bursting outof a solid wall at once and alarming the Muggles.\\n\"You must come and stay this summer,\" said Ron, \"both of you -- I\\'ll\\nsend you an owl.\"\\n\"Thanks,\" said Harry, \"I\\'ll need something to look forward to.\" People\\njostled them as they moved forward toward the gateway back to the Muggleworld. Some of them called:\\n\"Bye, Harry!\"\\n\"See you, Potter!\"\"Still famous,\" said Ron, grinning at him.\\n\"Not where I\\'m going, I promise you,\" said Harry.\\nHe, Ron, and Hermione passed through the gateway together. \"There he is,\\nMom, there he is, look!\"', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 248}), Document(page_content='249It was Ginny Weasley, Ron\\'s younger sister, but she wasn\\'t pointing at\\nRon.\\n\"Harry Potter!\" she squealed. \"Look, Mom! I can see\\n\"Be quiet, Ginny, and it\\'s rude to point.\"\\nMrs. Weasley smiled down at them.\"Busy year?\" she said.\"Very,\" said Harry. \"Thanks for the fudge and the sweater, Mrs.\\nWeasley.\"\\n\"Oh, it was nothing, dear.\"\"Ready, are you?\"\\nIt was Uncle Vernon, still purple-faced, still mustached, still looking\\nfurious at the nerve of Harry, carrying an owl in a cage in a stationfull of ordinary people. Behind him stood Aunt Petunia and Dudley,looking terrified at the very sight of Harry.\\n\"You must be Harry\\'s family!\" said Mrs. Weasley.\\n\"In a manner of speaking,\" said Uncle Vernon. \"Hurry up, boy, we haven\\'t\\ngot all day.\" He walked away.\\nHarry hung back for a last word with Ron and Hermione.\"See you over the summer, then.\"\\n\"Hope you have -- er -- a good holiday,\" said Hermione, looking\\nuncertainly after Uncle Vernon, shocked that anyone could be sounpleasant.\\n\"Oh, I will,\" said Harry, and they were surprised at the grin that was\\nspreading over his face. \"They don\\'t know we\\'re not allowed to use magic\\nat home. I\\'m going to have a lot of fun with Dudley this summer....\"\\nTHE END', metadata={'source': '/content/drive/MyDrive/Harry_Potter.pdf', 'page': 249})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_chroma langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xPedkz7WGDA",
        "outputId": "28dbe7a4-f387-42f4-80d9-ad6d139062bc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.5.0)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.111.0)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (0.2.6)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_chroma) (1.25.2)\n",
            "Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.7.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.7.3)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.30.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.66.4)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (30.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.3.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.10.5)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain_chroma) (2.1.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (0.1.77)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (24.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (2.6.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain_chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.12.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.63.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.23.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.19.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.16.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
            "Installing collected packages: tiktoken, openai, langchain_openai, langchain_chroma\n",
            "Successfully installed langchain_chroma-0.1.1 langchain_openai-0.1.8 openai-1.34.0 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs1)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "AlX9tjGxTZEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# If there is no environment variable set for the API key, you can pass the API\n",
        "# key to the parameter `google_api_key` of the `ChatGoogleGenerativeAI` function:\n",
        "# `google_api_key=\"key\"`.\n",
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\",\n",
        "                 temperature=0.2, top_p=0.85)"
      ],
      "metadata": {
        "id": "vM27qJdTXp7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "\n",
        "results = rag_chain.invoke({\"input\": \"describe the journey of harry potter?\"})\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOCugTP_XBJ3",
        "outputId": "bcabd534-5f2a-4129-e1f2-c008956b6125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'describe the journey of harry potter?',\n",
              " 'context': [Document(page_content='111 The universal workflow of machine learning\\n4.5 The universal workfl ow of machine learning\\nIn this section, we’ll present a universal bl ueprint that you can use to attack and solve\\nany machine-learning problem. The bluepr int ties together the concepts you’ve\\nlearned about in this chapter: problem de finition, evaluation, feature engineering,\\nand fighting overfitting.\\n4.5.1 Defining the problem and assembling a dataset\\nFirst, you must define  the problem at hand:\\n\\uf0a1What will your input data be? What are yo u trying to predict? You can only learn\\nto predict something if you have availa ble training data: for example, you can\\nonly learn to classify the sentiment of  movie reviews if you have both movie\\nreviews and sentiment annotations available.  As such, data availability is usually\\nthe limiting factor at this stage (unless you have the means to pay people to col-\\nlect data for you).\\n\\uf0a1What type of problem are you facing? Is it  binary classification? Multiclass classi-', metadata={'page': 133, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='111 The universal workflow of machine learning\\n4.5 The universal workfl ow of machine learning\\nIn this section, we’ll present a universal bl ueprint that you can use to attack and solve\\nany machine-learning problem. The bluepr int ties together the concepts you’ve\\nlearned about in this chapter: problem de finition, evaluation, feature engineering,\\nand fighting overfitting.\\n4.5.1 Defining the problem and assembling a dataset\\nFirst, you must define  the problem at hand:\\n\\uf0a1What will your input data be? What are yo u trying to predict? You can only learn\\nto predict something if you have availa ble training data: for example, you can\\nonly learn to classify the sentiment of  movie reviews if you have both movie\\nreviews and sentiment annotations available.  As such, data availability is usually\\nthe limiting factor at this stage (unless you have the means to pay people to col-\\nlect data for you).\\n\\uf0a1What type of problem are you facing? Is it  binary classification? Multiclass classi-', metadata={'page': 133, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='111 The universal workflow of machine learning\\n4.5 The universal workfl ow of machine learning\\nIn this section, we’ll present a universal bl ueprint that you can use to attack and solve\\nany machine-learning problem. The bluepr int ties together the concepts you’ve\\nlearned about in this chapter: problem de finition, evaluation, feature engineering,\\nand fighting overfitting.\\n4.5.1 Defining the problem and assembling a dataset\\nFirst, you must define  the problem at hand:\\n\\uf0a1What will your input data be? What are yo u trying to predict? You can only learn\\nto predict something if you have availa ble training data: for example, you can\\nonly learn to classify the sentiment of  movie reviews if you have both movie\\nreviews and sentiment annotations available.  As such, data availability is usually\\nthe limiting factor at this stage (unless you have the means to pay people to col-\\nlect data for you).\\n\\uf0a1What type of problem are you facing? Is it  binary classification? Multiclass classi-', metadata={'page': 133, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='318 CHAPTER  9Conclusions\\nIn the future, deep learning will not only be  used by specialists— researchers, graduate\\nstudents, and engineers with an  academic profile—but will also be a tool in the tool-\\nbox of every developer, much like web te chnology today. Ever yone needs to build\\nintelligent apps: just as every business toda y needs a website, every product will need\\nto intelligently make sense of user-generat ed data. Bringing a bout this future will\\nrequire us to build tools that make deep le arning radically easy to use and accessible\\nto anyone with basic coding abilities. Keras is the first major step in that direction. \\n9.1.5 The universal machine-learning workflow\\nHaving access to an extremely powerful tool  for creating models that map any input\\nspace to any target space is great, but the difficult part of the machine-learning work-\\nflow is often everything that comes before  designing and training such models (and,', metadata={'page': 340, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'})],\n",
              " 'answer': 'Harry Potter\\'s journey is a coming-of-age story filled with magic, friendship, and self-discovery. He starts as an orphaned boy living with his neglectful aunt and uncle, unaware of his magical heritage. He learns about his parents\\' tragic death and his own destiny as \"The Boy Who Lived,\" destined to defeat the dark wizard Voldemort. Throughout the series, Harry faces numerous challenges, battling Voldemort\\'s forces, learning about love and loss, and ultimately confronting his own fears and insecurities. His journey culminates in a final showdown with Voldemort, where he embraces his courage and defeats the evil that has haunted him since childhood. \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z6aMlDj7NFd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiple pdfs:"
      ],
      "metadata": {
        "id": "UXPCUeOSNFgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "# load PDF files from a directory\n",
        "loader = PyPDFDirectoryLoader(\"/content/drive/MyDrive/RAG_DATA\")\n",
        "data = loader.load()\n",
        "# print the loaded data, which is a list of tuples (file name, text extracted from the PDF)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LszbeQk1NIVL",
        "outputId": "639cb3b4-3b59-4b03-c08f-7dca2bff56f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='MANNINGFrançois Chollet', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 0}), Document(page_content='Deep Learning with Python\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 1}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 2}), Document(page_content='Deep Learning\\nwith Python\\nFRANÇOIS CHOLLET\\nMANNING\\nSHELTER  ISLAND\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 3}), Document(page_content='For online information and ordering of this and other Manning books, please visit\\nwww.manning.com. The publisher offers discounts on this book when ordered in quantity. \\nFor more information, please contact\\nSpecial Sales Department\\nManning Publications Co.\\n20 Baldwin Road\\nPO Box 761Shelter Island, NY 11964\\nEmail: orders@manning.com\\n©2018 by Manning Publications Co. All rights reserved.\\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted, in \\nany form or by means electronic, mechanical, photocopying, or otherwise, without prior written \\npermission of the publisher.\\nMany of the designations used by manufacturers and sellers to distinguish their products are \\nclaimed as trademarks. Where those designations appear in the book, and Manning \\nPublications was aware of a trademark claim, the designations have been printed in initial caps or all caps.\\nRecognizing the importance of preserving what has been written, it is Manning’s policy to have \\nthe books we publish printed on acid-free paper, and we exert our best efforts to that end. \\nRecognizing also our responsibility to conserve the resources of our planet, Manning books\\nare printed on paper that is at least 15 percent recycled and processed without the use of elemental chlorine.\\nManning Publications Co. Development editor: Toni Arritola\\n20 Baldwin Road Technical development editor: Jerry Gaines\\nPO Box 761 Review editor: Aleksandar Dragosavljevic ´\\nShelter Island, NY 11964 Project editor: Tiffany Taylor\\n Copyeditor: Tiffany Taylor\\nProofreader: Katie Tennant\\nTechnical proofreaders: Alex Ott and Richard Tobias\\nTypesetter: Dottie Marsico\\nCover designer: Marija Tudor\\nISBN 9781617294433\\nPrinted in the United States of America\\n1234567891 0–E B M–2 22 12 01 91 81 7\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 4}), Document(page_content='vbrief contents\\nPART 1F UNDAMENTALS  OF DEEP  LEARNING .................................. 1\\n1 ■What is deep learning? 3\\n2 ■Before we begin: the mathematical building blocks of neural \\nnetworks 25\\n3 ■Getting started with neural networks 56\\n4 ■Fundamentals of machine learning 93\\nPART 2D EEP LEARNING  IN PRACTICE ........................................ 117\\n5 ■Deep learning for computer vision 119\\n6 ■Deep learning for text and sequences 178\\n7 ■Advanced deep-learning best practices 233\\n8 ■Generative deep learning 269\\n9 ■Conclusions 314\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 5}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 6}), Document(page_content='viicontents\\npreface xiii\\nacknowledgments xv\\nabout this book xvi\\nabout the author xxabout the cover xxi\\nPART 1F UNDAMENTALS  OF DEEP  LEARNING ...................1\\n1 What is deep learning? 3\\n1.1 Artificial intelligence, machine learning, \\nand deep learning 4\\nArtificial intelligence 4■Machine learning 4■Learning \\nrepresentations from data 6■The “deep” in deep learning 8\\nUnderstanding how deep learning works, in three figures 9What deep learning has achieved so far 11\\n■Don’t believe \\nthe short-term hype 12■The promise of AI 13\\n1.2 Before deep learning: a brief history of machine \\nlearning 14\\nProbabilistic modeling 14■Early neural networks 14\\nKernel methods 15■Decision trees, random forests, \\nand gradient boosting machines 16■Back to neural \\nnetworks 17■What makes deep learning different 17\\nThe modern machine-learning landscape 18\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 7}), Document(page_content='CONTENTS viii\\n1.3 Why deep learning? Why now? 20\\nHardware 20■Data 21■Algorithms 21■A new \\nwave of investment 22■The democratization of deep \\nlearning 23■Will it last? 23\\n2 Before we begin: the mathem atical building blocks of \\nneural networks 25\\n2.1 A first look at a neural network 27\\n2.2 Data representations for neural networks 31\\nScalars (0D tensors) 31■Vectors (1D tensors) 31\\nMatrices (2D tensors) 31■3D tensors and higher-\\ndimensional tensors 32■Key attributes 32\\nManipulating tensors in Numpy 34■The notion \\nof data batches 34■Real-world examples of data \\ntensors 35■Vector data 35■Timeseries data or \\nsequence data 35■Image data 36■Video data 37\\n2.3 The gears of neural ne tworks: tensor operations 38\\nElement-wise operations 38■Broadcasting 39■Tensor \\ndot 40■Tensor reshaping 42■Geometric interpretation \\nof tensor operations 43■A geometric interpretation of deep \\nlearning 44\\n2.4 The engine of neural networks: gradient-based \\noptimization 46\\nWhat’s a derivative? 47■Derivative of a te nsor operation: \\nthe gradient 48■Stochastic gradient descent 48\\nChaining derivatives: the Backpropagation algorithm 51\\n2.5 Looking back at our first example 53\\n2.6 Chapter summary 55\\n3 Getting started with neural networks 56\\n3.1 Anatomy of a neural network 58\\nLayers: the building bloc ks of deep learning 58■Models: \\nnetworks of layers 59■Loss functions and optimizers: keys \\nto configuring the learning process 60\\n3.2 Introduction to Keras 61\\nKeras, TensorFlow, Theano, and CNTK 62■Developing \\nwith Keras: a quick overview 62\\n3.3 Setting up a deep-learning workstation 65\\nJupyter notebooks: the preferre d way to run deep-learning \\nexperiments 65■Getting Keras running: two options 66\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 8}), Document(page_content='CONTENTS ix\\nRunning deep-learning jobs in  the cloud: pros and cons 66\\nWhat is the best GPU for deep learning? 66\\n3.4 Classifying movie reviews:  a binary classification \\nexample 68\\nThe IMDB dataset 68■Preparing the data 69\\nBuilding your network 70■Validating your approach 73\\nUsing a trained network to ge nerate predictions on new \\ndata 76■Further experiments 77■Wrapping up 77\\n3.5 Classifying newswires: a multiclass classification \\nexample 78\\nThe Reuters dataset 78■Preparing the data 79\\nBuilding your network 79■Validating your approach 80\\nGenerating predictions on new data 83■A different way to \\nhandle the labels and the loss 83■The importance of \\nhaving sufficiently large intermediate layers 83■Further \\nexperiments 84■Wrapping up 84\\n3.6 Predicting house prices : a regression example 85\\nThe Boston Housing Price dataset 85■Preparing the \\ndata 86■Building your network 86■Validating \\nyour approach using K-fold validation 87■Wrapping up 91\\n3.7 Chapter summary 92\\n4 Fundamentals of machine learning 93\\n4.1 Four branches of machine learning 94\\nSupervised learning 94■Unsupervised learning 94\\nSelf-supervised learning 94■Reinforcement learning 95\\n4.2 Evaluating machine-learning models 97\\nTraining, validation, and test sets 97■Things to \\nkeep in mind 100\\n4.3 Data preprocessing, feature engineering, \\nand feature learning 101\\nData preprocessing fo r neural networks 101■Feature \\nengineering 102\\n4.4 Overfitting and underfitting 104\\nReducing the network’s size 104■Adding weight \\nregularization 107■Adding dropout 109\\n4.5 The universal workflow of machine learning 111\\nDefining the problem and assembling a dataset 111Choosing a measure of success 112\\n■Deciding on an \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 9}), Document(page_content='CONTENTS x\\nevaluation protocol 112■Preparing your data 112\\nDeveloping a model that does better than a baseline 113\\nScaling up: developing a model that overfits 114Regularizing your model and t uning your hyperparameters 114\\n4.6 Chapter summary 116\\nPART 2D EEP LEARNING  IN PRACTICE ................ .........117\\n5 Deep learning for computer vision 119\\n5.1 Introduction to convnets 120\\nThe convolution operation 122■The max-pooling \\noperation 127\\n5.2 Training a convnet from scratch on a small dataset 130\\nThe relevance of deep learni ng for small-data problems 130\\nDownloading the data 131■Building your network 133\\nData preprocessing 135■Using data augmentation 138\\n5.3 Using a pretrained convnet 143\\nFeature extraction 143■Fine-tuning 152■Wrapping \\nup 159\\n5.4 Visualizing what convnets learn 160\\nVisualizing intermediate activations 160■Visualizing \\nconvnet filters 167■Visualizing heatmaps of class \\nactivation 172\\n5.5 Chapter summary 177\\n6 Deep learning for te xt and sequences 178\\n6.1 Working with text data 180\\nOne-hot encoding of words and characters 181■Using \\nword embeddings 184■Putting it all together: from raw \\ntext to word embeddings 188■Wrapping up 195\\n6.2 Understanding recurrent neural networks 196\\nA recurrent layer in Keras 198■Understanding the \\nLSTM and GRU layers 202■A concrete LSTM example \\nin Keras 204■Wrapping up 206\\n6.3 Advanced use of recurrent neural networks 207\\nA temperature-forecasting problem 207■Preparing the \\ndata 210■A common-sense, non-machine-learning \\nbaseline 212■A basic machine-lear ning approach 213\\nA first recurrent baseline 215■Using recurrent dropout \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 10}), Document(page_content='CONTENTS xi\\nto fight overfitting 216■Stacking recurrent layers 217\\nUsing bidirectional RNNs 219■Going even further 222\\nWrapping up 223\\n6.4 Sequence processing with convnets 225\\nUnderstanding 1D convolution for sequence data 2251D pooling for sequence data 226\\n■Implementing a 1D \\nconvnet 226■Combining CNNs and RNNs to process long \\nsequences 228■Wrapping up 231\\n6.5 Chapter summary 232\\n7 Advanced deep-learnin g best practices 233\\n7.1 Going beyond the Sequ ential model: the Keras\\n functional API 234\\nIntroduction to the functional API 236■Multi-input \\nmodels 238■Multi-output models 240■Directed acyclic \\ngraphs of layers 242■Layer weight sharing 246■Models \\nas layers 247■Wrapping up 248\\n7.2 Inspecting and monitoring deep-learning models using \\nKeras callbacks and TensorBoard 249\\nUsing callbacks to act on a model during training 249\\nIntroduction to TensorBoard: the TensorFlow visualization \\nframework 252■Wrapping up 259\\n7.3 Getting the most out of your models 260\\nAdvanced architecture patterns 260■Hyperparameter \\noptimization 263■Model ensembling 264■Wrapping \\nup 266\\n7.4 Chapter summary 268\\n8 Generative deep learning 269\\n8.1 Text generation with LSTM 271\\nA brief history of  generative recurrent networks 271■How \\ndo you generate sequence data? 272■The importance of \\nthe sampling strategy 272■Implementing character-level \\nLSTM text generation 274■Wrapping up 279\\n8.2 DeepDream 280\\nImplementing DeepDream in Keras 281■Wrapping up 286\\n8.3 Neural style transfer 287\\nThe content loss 288■The style loss 288■Neural style \\ntransfer in Keras 289■Wrapping up 295\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 11}), Document(page_content='CONTENTS xii\\n8.4 Generating images with variational autoencoders 296\\nSampling from latent spaces of images 296■Concept vectors \\nfor image editing 297■Variational autoencoders 298\\nWrapping up 304\\n8.5 Introduction to generati ve adversarial networks 305\\nA schematic GAN implementation 307■A bag of tricks 307\\nThe generator 308■The discriminator 309■The adversarial \\nnetwork 310■How to train your DCGAN 310■Wrapping \\nup 312\\n8.6 Chapter summary 313\\n9 Conclusions 314\\n9.1 Key concepts in review 315\\nVarious approaches to AI 315■What makes deep learning \\nspecial within the field of machine learning 315■How to \\nthink about deep learning 316■Key enabling technologies 317\\nThe universal machine-learning workflow 318■Key network \\narchitectures 319■The space of possibilities 322\\n9.2 The limitations of deep learning 325\\nThe risk of anthropomorphizing  machine-learning models 325\\nLocal generalization vs. extreme generalization 327Wrapping up 329\\n9.3 The future of deep learning 330\\nModels as programs 330■Beyond backpropagation and \\ndifferentiable layers 332■Automated machine learning 332\\nLifelong learning and modular subroutine reuse 333The long-term vision 335\\n9.4 Staying up to date in a fast-moving field 337\\nPractice on real-world  problems using Kaggle 337\\nRead about the latest developments on arXiv 337Explore the Keras ecosystem 338\\n9.5 Final words 339\\nappendix A Installing Keras and its dependencies on Ubuntu 340\\nappendix B Running Jupyter note books on an EC2 GPU instance 345\\nindex 353\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 12}), Document(page_content='xiiipreface\\nIf you’ve picked up this book, you’re pr obably aware of the extraordinary progress\\nthat deep learning has represented for the fi eld of artificial intelligence in the recent\\npast. In a mere five years,  we’ve gone from near-unusable image recognition and\\nspeech transcription, to superhuman performance on these tasks.\\n The consequences of this sudden progre ss extend to almost every industry. But in\\norder to begin deploying deep-learning technology to every problem that it could\\nsolve, we need to make it accessible to as many people as possible, including non-\\nexperts—people who aren’t re searchers or graduate stud ents. For deep learning to\\nreach its full potential, we need to radically democratize it.\\n When I released the first version of th e Keras deep-learning framework in March\\n2015, the democratization of AI wasn’t what I had in mind . I had been doing research\\nin machine learning for several years, and had built Keras to help me with my own\\nexperiments. But throughout 2015 and 2016, tens of thousands of new people\\nentered the field of deep learning; many of  them picked up Keras because it was—and\\nstill is—the easiest framework to get starte d with. As I watched scores of newcomers\\nuse Keras in unexpected, powerful ways, I ca me to care deeply about the accessibility\\nand democratization of AI. I realized that the further we spread these technologies,\\nthe more useful and valuable they become . Accessibility quickly became an explicit\\ngoal in the development of Keras, and over a few short years, the Keras developer\\ncommunity has made fantastic achievements on this front. We’ve put deep learning\\ninto the hands of tens of thousands of people , who in turn are using it to solve import-\\nant problems we didn’t even know existed until recently.\\n The book you’re holding is another step on  the way to making deep learning avail-\\nable to as many people as  possible. Keras had always needed a companion course to\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 13}), Document(page_content='PREFACE xiv\\nsimultaneously cover fundamen tals of deep learning, Keras usage patterns, and deep-\\nlearning best practices. This book is my be st effort to produce su ch a course. I wrote it\\nwith a focus on making the concepts behi nd deep learning, and their implementa-\\nt i o n ,  a s  a p p r o a c h a b l e  a s  p o s s i b l e .  D o i n g  s o  d i d n ’ t  r e q u i r e  m e  t o  d u m b  d o w n  a n y -thing—I strongly believe that there are no  difficult ideas in deep learning. I hope\\nyou’ll find this book valuable and that it w ill enable you to begin building intelligent\\napplications and solve the problems that matter to you. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 14}), Document(page_content='xvacknowledgments\\nI’d like to thank the Keras community for making this book possible. Keras has grown\\nto have hundreds of open so urce contributors and more than 200,000 users. Your con-\\ntributions and feedback have turn ed Keras into what it is today.\\n I’d also like to thank Google for backing the Keras project. It has been fantastic to\\nsee Keras adopted as TensorFlow’s high-level API. A smooth integration between Keras\\nand TensorFlow greatly benefits both TensorFlow users and Keras users and makesdeep learning accessible to most.\\n I want to thank the people at Manning who made this book possible: publisher\\nMarjan Bace and everyone on the editorial and production teams,  including Christina\\nTaylor, Janet Vail, Tiffany Taylor, Katie Te nnant, Dottie Marsico, and many others who\\nworked behind the scenes. \\n Many thanks go to the technical peer reviewers led by Alek sandar Dragosavljevic\\n´—\\nDiego Acuña Rozas, Geoff Barto, David Bl umenthal-Barby, Abel Brown, Clark Dor-\\nman, Clark Gaylord, Thomas Heiman, Wilson  Mar, Sumit Pal, Vl adimir Pasman, Gus-\\ntavo Patino, Peter Rabinovitch, Alvin Raj, Claudio Rodriguez, Sr djan Santic, Richard\\nTobias, Martin Verzilli, William E. Wheele r, and Daniel Williams—and the forum con-\\ntributors. Their contributions included catc hing technical mistakes, errors in termi-\\nnology, and typos, and making topic su ggestions. Each pass through the review\\nprocess and each piece of feedback implemented through the forum topics shaped\\nand molded the manuscript. \\n On the technical side, special thanks go  to Jerry Gaines, who served as the book’s\\ntechnical editor; and Alex Ott and Richard T obias, who served as the book’s technical\\nproofreaders. They’re the best techni cal editors I could have hoped for. \\n Finally, I’d like to express my gratit ude to my wife Maria for being extremely\\nsupportive throughout the development of Keras and the writing of this book.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 15}), Document(page_content='xviabout this book\\nThis book was written for anyone who wishes to explore deep learning from scratch or\\nbroaden their understanding of deep learning . Whether you’re a practicing machine-learn-\\ning engineer, a software developer, or a colle ge student, you’ll find value in these pages.\\n This book offers a practical, hands-on expl oration of deep learning. It avoids math-\\nematical notation, preferring instead to ex plain quantitative concepts via code snip-\\npets and to build practical intuition about the core ideas of machine learning and\\ndeep learning. \\n You’ll learn from more than 30 code examples that include detailed commentary,\\npractical recommendations, and simple high -level explanations of everything you\\nneed to know to start using deep learning to solve concrete problems.\\n The code examples use the Python deep-learning framework Keras, with Tensor-\\nFlow as a backend engine. Keras, one of the most popular and fastest-growing deep-\\nlearning frameworks, is widely recommended as the best tool to get started with deep\\nlearning. \\n After reading this book, you’ll have a soli d understand of what deep learning is,\\nwhen it’s applicable, and what its limitations  are. You’ll be familiar with the standard\\nworkflow for approaching and solving machine-learning problems, and you’ll know\\nhow to address commonly enco untered issues. You’ll be ab le to use Keras to tackle\\nreal-world problems ranging fr om computer vision to na tural-language processing:\\nimage classification, ti meseries forecasting, sentiment analysis, image and text genera-\\ntion, and more.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 16}), Document(page_content='ABOUT  THIS BOOK xvii\\nWho should read this book\\nThis book is written for peop le with Python programming experience who want to get\\nstarted with machine learning and deep lear ning. But this book can also be valuable\\nto many different types of readers:\\n\\uf0a1If you’re a data scientist familiar with machine learning, this book will provide\\nyou with a solid, practical introduction to deep learning, the fastest-growing\\nand most significant subfield of machine learning.\\n\\uf0a1If you’re a deep-learning expert looking to get started with the Keras frame-work, you’ll find this book to be th e best Keras crash course available.\\n\\uf0a1If you’re a graduate studen t studying deep learning in  a formal setting, you’ll\\nfind this book to be a practical comp lement to your education, helping you\\nbuild intuition around the behavior of deep neural networks and familiarizing\\nyou with key best practices.\\nEven technically minded people who don’t code  regularly will find this book useful as\\nan introduction to both basic an d advanced deep-learning concepts.\\n In order to use Keras, you’ll need reason able Python proficiency. Additionally, famil-\\niarity with the Numpy library will be helpful, although it isn’t required. You don’t need\\nprevious experience with machine learning  or deep learning: this book covers from\\nscratch all the necessary basics. You don’t need an advanced mathematics background,\\neither—high school–level mathematics shou ld suffice in order to follow along.\\nRoadmap\\nThis book is structured in two parts. If you have no prior experience with machine\\nlearning, I strongly recommend that you co mplete part 1 before approaching part 2.\\nWe’ll start with simple examples, and as th e book goes on, we’ll get increasingly close\\nto state-of-the-art techniques.\\n Part 1 is a high-level introduction to deep learning, providing context and defini-\\ntions, and explaining all the notions requ ired to get started with machine learning\\nand neural networks:\\n\\uf0a1Chapter 1 presents essential contex t and background knowledge around AI,\\nmachine learning, and deep learning.\\n\\uf0a1Chapter 2 introduces fundamental conc epts necessary in order to approach\\ndeep learning: tensors, te nsor operations, gradient descent, and backpropaga-\\ntion. This chapter also features the bo ok’s first example of a working neural\\nnetwork.\\n\\uf0a1Chapter 3 includes everything you need to get started with neural networks: an\\nintroduction to Keras, our deep-learning framework of choice; a guide for set-\\nting up your workstation; and three foundational code examples with detailed\\nexplanations. By the end of this chapter,  you’ll be able to  train simple neural\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 17}), Document(page_content='ABOUT  THIS BOOK xviii\\nnetworks to handle classification and re gression tasks, and you’ll have a solid\\nidea of what’s happening in th e background as you train them.\\n\\uf0a1Chapter 4 explores the canonical machine- learning workflow. You’ll also learn\\nabout common pitfalls and their solutions.\\nPart 2 takes an in-depth dive into practica l applications of deep learning in computer\\nvision and natural-language processing. Many  of the examples introduced in this part\\ncan be used as templates to solve problems you’ll encounter in the real-world practice\\nof deep learning:\\n\\uf0a1Chapter 5 examines a range of practical computer-vision examples, with a focus\\non image classification.\\n\\uf0a1Chapter 6 gives you practice with techni ques for processing sequence data, such\\nas text and timeseries.\\n\\uf0a1Chapter 7 introduces advanc ed techniques for building state-of-the-art deep-\\nlearning models.\\n\\uf0a1Chapter 8 explains generative models: deep-learning models capable of creat-\\ning images and text, with sometime s surprisingly artistic results.\\n\\uf0a1Chapter 9 is dedicated to consolidating what you’ve learned throughout the\\nbook, as well as opening perspectives on  the limitations of deep learning and\\nexploring its pr obable future.\\nSoftware/hardware requirements\\nAll of this book’s code examples use the Keras deep-learning framework ( https:/ /\\nkeras.io ), which is open source and free to  download. You’ll need access to a UNIX\\nmachine; it’s possible to us e Windows, too, but I don’t recommend it. Appendix A\\nwalks you through the complete setup. \\n I also recommend that you have a recent NVIDIA  GPU on your machine, such as a\\nTITAN  X. This isn’t required, but it will make your experience better by allowing you\\nto run the code examples several times faster. See section 3.3 for more informationabout setting up a deep -learning workstation.\\n If you don’t have access to a local workstation with a recent \\nNVIDIA  GPU, you can\\nuse a cloud environment, instead. In particular, you can use Google Cloud instances\\n(such as an n1-standar d-8 instance with an NVIDIA  Tesla K80 add-on) or Amazon Web\\nServices ( AWS) GPU instances (such as a p2.xlarge in stance). Appendix B presents in\\ndetail one possible cloud workflow that runs an AWS instance via Jupyter notebooks,\\naccessible in your browser.\\nSource code\\nAll code examples in this book are availa ble for download as Jupyter notebooks from\\nthe book’s website, www.manning.com/books/deep-learning-with-python , and on\\nGitHub at https:/ /github.com/fchollet/deep -learning-with-python-notebooks .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 18}), Document(page_content='ABOUT  THIS BOOK xix\\nBook forum\\nPurchase of Deep Learning with Python includes free access to a private web forum run by\\nManning Publications where you can make  comments about the book, ask technical\\nquestions, and receive help from the author and from other users. To access the forum,\\ngo to https:/ /forums.manning.com/for ums/deep-learning-with-python . You can also\\nlearn more about Manning’s forums  and the rules of conduct at https:/ /forums\\n.manning.com/forums/about .\\n Manning’s commitment to our readers is  to provide a venue where a meaningful\\ndialogue between individual readers and between readers and the author can take\\nplace. It isn’t a commitment to any specific amount of participation on the part of the\\nauthor, whose contribution to the forum re mains voluntary (and unpaid). We suggest\\nyou try asking him some chal lenging questions lest his in terest stray! The forum and\\nthe archives of previous discussions will be accessible from the publisher’s website as\\nlong as the book is in print.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 19}), Document(page_content='xxabout the author\\nFrançois Chollet works on deep learning at Google in Moun-\\ntain View, CA. He is the creator of the Keras deep-learning\\nlibrary, as well as a contribu tor to the TensorFlow machine-\\nlearning framework. He also does deep-learning research,\\nwith a focus on computer vi sion and the application of\\nmachine learning to formal re asoning. His papers have been\\npublished at major conferences in the field, including the\\nConference on Computer Vision and Pattern Recognition\\n(CVPR ), the Conference and Workshop on Neural Informa-\\ntion Processing Systems ( NIPS ), the International Conferen ce on Learning Represen-\\ntations ( ICLR ), and others.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 20}), Document(page_content='xxiabout the cover\\nThe figure on the cover of Deep Learning with Python is captioned “Habit of a Persian\\nLady in 1568.” The illustration is taken from Thomas Jefferys’ A Collection of the Dresses\\nof Different Nations, Ancient and Modern  (four volumes), Lond on, published between\\n1757 and 1772. The title page states that these are hand-colored copperplate engrav-\\nings, heightened with gum arabic. \\n Thomas Jefferys (1719–1771) was called “Geographer to King George III.” He was\\nan English cartographer who was the leadin g map supplier of his day. He engraved\\nand printed maps for government and other official bodies and produced a widerange of commercial maps and atlases, especi ally of North America. His work as a map\\nmaker sparked an interest in local dre ss customs of the lands he surveyed and\\nmapped, which are brilliantly displayed in this collection. Fascination with faraway\\nlands and travel for pleasure were relati vely new phenomena in the late eighteenth\\ncentury, and collections such as this one we re popular, introducing both the tourist as\\nwell as the armchair traveler to the inhabitants of other countries.\\n The diversity of the drawings in Jefferys ’ volumes speaks vividly of the uniqueness\\nand individuality of the world’s nations some  200 years ago. Dress codes have changed\\nsince then, and the diversity by region and country, so rich at the time, has faded away.\\nIt’s now often hard to tell the inhabitants of  one continent from another. Perhaps, try-\\ning to view it optimistically, we’ve traded a cultural and visual di versity for a more var-\\nied personal life—or a more varied and in teresting intellectual and technical life.\\n At a time when it’s difficult to tell on e computer book from another, Manning cel-\\nebrates the inventiveness and initiative of the computer busi ness with book covers\\nbased on the rich diversity of regional life of two centuries ago, brought back to life by\\nJefferys’ pictures.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 21}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 22}), Document(page_content='Part 1\\nFundamentals\\nof deep learning\\nC hapters 1–4 of this book will give you a foundational understanding of\\nwhat deep learning is, what it can achieve,  and how it works. It will also make you\\nfamiliar with the canonical workflow for solving data problems using deep learn-ing. If you aren’t already highly know ledgeable about deep learning, you should\\ndefinitely begin by reading part 1 in full  before moving on to the practical appli-\\ncations in part 2.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 23}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 24}), Document(page_content='3What is deep learning?\\nIn the past few years, ar tificial intelligence ( AI) has been a subject of intense media\\nhype. Machine learning, deep learning, and AI come up in countless articles, often\\noutside of technology-minded publications. We’re promised a futu re of intelligent\\nchatbots, self-driving cars, and virtual a ssistants—a future sometimes painted in a\\ngrim light and other times as utopian, wh ere human jobs will be scarce and most\\neconomic activity will be handled by robots or AI agents. For a future or current\\npractitioner of machine learning, it’s impo rtant to be able to recognize the signal\\nin the noise so that you can tell world-changing developments from overhyped\\npress releases. Our future is at stake, and it’s a future in which you have an active\\nrole to play: after reading this book, you’ll be one of those who develop the AI\\nagents. So let’s tackle these questions: What has deep learning achieved so far?\\nHow significant is it? Where are we head ed next? Should you believe the hype?\\n This chapter provides essential context around artificial in telligence, machine\\nlearning, and deep learning.This chapter covers\\n\\uf0a1High-level definitions of fundamental concepts\\n\\uf0a1Timeline of the development of machine learning\\n\\uf0a1Key factors behind deep learning’s rising \\npopularity and future potential\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 25}), Document(page_content='4 CHAPTER  1What is deep learning?\\n1.1 Artificial intelligen ce, machine learning, \\nand deep learning\\nFirst, we need to define clearly what  we’re talking about when we mention AI. What\\nare artificial intelligence, machine learning, and deep learning (see figure 1.1)? How\\ndo they relate to each other?\\n1.1.1 Artificial intelligence\\nArtificial intelligence was born in the 195 0s, when a handful of pioneers from the\\nnascent field of computer science started asking whether computers could be made to\\n“think”—a question whose ramifications we’r e still exploring today. A concise defini-\\ntion of the field would be as follows: the effort to automate inte llectual tasks normally per-\\nformed by humans . As such, AI is a general field that encompasses machine learning and\\ndeep learning, but that also includes many  more approaches that don’t involve any\\nlearning. Early chess programs,  for instance, only involved hardcoded rules crafted by\\nprogrammers, and didn’t qualify as machin e learning. For a fairly long time, many\\nexperts believed that human-le vel artificial intelligence could be achieved by having\\nprogrammers handcraft a suffi ciently large set of explicit rules for manipulating\\nknowledge. This approach is known as symbolic AI, and it was the dominant paradigm\\nin AI from the 1950s to the late 1980s. It reached its peak popularity during the expert\\nsystems  boom of the 1980s.\\n Although symbolic AI proved suitable to solve well-d efined, logical problems, such as\\nplaying chess, it turned out to be intractabl e to figure out explicit rules for solving more\\ncomplex, fuzzy problems, such as image cla ssification, speech recognition, and lan-\\nguage translation. A new approa ch arose to take symbolic AI’s place: machine learning .\\n1.1.2 Machine learning\\nIn Victorian England, Lady Ada Lovelace was a friend and coll aborator of Charles\\nBabbage, the inventor of the Analytical Engine : the first-known general-purpose,\\nmechanical computer. Although visionary and far ahead of its time, the AnalyticalArtificial\\nintelligence\\nMachine\\nlearning\\nDeep\\nlearning\\nFigure 1.1 Artificial intelligence, \\nmachine learning, and deep learning\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 26}), Document(page_content='5 Artificial intelligence, machine learning, and deep learning\\nEngine wasn’t meant as a general-purpose computer when it was designed in the\\n1830s and 1840s, because the concept of general-purpose computation was yet to be\\ninvented. It was merely meant as a way to use mechanical operatio ns to automate cer-\\ntain computations from the field of math ematical analysis—hence, the name Analyti-\\ncal Engine. In 1843, Ada Lovelace remarked on the invention, “The Analytical Engine\\nhas no pretensions whatever to originate an ything. It can do whatever we know how to\\norder it to perform.… Its prov ince is to assist us in making available what we’re\\nalready acquainted with.”\\n This remark was later quoted by AI pioneer Alan Turing as “Lady Lovelace’s objec-\\ntion” in his landmark 1950 paper “Computing Machinery and Intelligence,”1 which\\nintroduced the Turing test  as well as key concepts that would come to shape AI. Turing\\nwas quoting Ada Lovelace while pondering whether general-purpose computers could\\nbe capable of learning and originality, and he came to the conclusion that they could.\\n Machine learning arises from this ques tion: could a computer go beyond “what we\\nknow how to order it to perform” and learn on its own how to perf orm a specified task?\\nCould a computer surprise us? Rather th an programmers crafting data-processing\\nrules by hand, could a computer automatica lly learn these rules by looking at data?\\n This question opens the door to a ne w programming paradigm. In classical pro-\\ngramming, the paradigm of symbolic AI, hu mans input rules (a program) and data to\\nbe processed according to th ese rules, and out come answ ers (see figure 1.2). With\\nmachine learning, humans input data as well  as the answers expected from the data,\\nand out come the rules. These rules can then  be applied to new data to produce orig-\\ninal answers.\\nA machine-learning system is trained  rather than explicitly programmed. It’s presented\\nwith many examples relevant to a task, and it finds statistical structure in these exam-\\nples that eventually allows the system to come up with rules for automating the task.\\nFor instance, if you wished to automate the task of tagging your vacation pictures, you\\ncould present a machine-learning system wi th many examples of pictures already\\ntagged by humans, and the system would lear n statistical rules fo r associating specific\\npictures to specific tags.\\n1A. M. Turing, “Computing Machinery and Intelligence,” Mind  59, no. 236 (1950): 433-460.AnswersRules\\nDataClassical\\nprogramming\\nRulesData\\nAnswersMachine\\nlearningFigure 1.2 Machine learning: \\na new programming paradigm\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 27}), Document(page_content='6 CHAPTER  1What is deep learning?\\n Although machine learning only started to  flourish in the 1990s, it has quickly\\nbecome the most popular and mo st successful subfield of AI, a trend driven by the\\navailability of faster hardware and larger datasets. Machine learning is tightly related\\nto mathematical statistics, but it differs from statistics in several important ways.\\nUnlike statistics, machine learning tends to deal with large, complex datasets (such as\\na dataset of millions of images, each consis ting of tens of thousands of pixels) for\\nwhich classical statistical analys is such as Bayesian analysis  would be impractical. As a\\nresult, machine learning, and especially de ep learning, exhibits  comparatively little\\nmathematical theory—maybe too little—and is engineering oriented. It’s a hands-on\\ndiscipline in which ideas are proven empirically more often than theoretically.\\n1.1.3 Learning representations from data\\nTo define deep learning  and understand the difference between deep learning\\nand other machine-learning ap proaches, first we need some idea of what machine-\\nlearning algorithms do. I just stated that machine lear ning discovers rules to execute\\na data-processing task, given examples of what’s expected. So, to do machine learn-\\ning, we need three things:\\n\\uf0a1Input data points —For instance, if the task is speech recognition, these data\\npoints could be sound files of people speaking. If the task  is image tagging,\\nthey could be pictures.\\n\\uf0a1Examples of the expected output —In a speech-recognition task, these could be\\nhuman-generated transcripts of sound files. In an im age task, expected outputs\\ncould be tags such as “dog,” “cat,” and so on.\\n\\uf0a1A way to measure whether the algorithm is doing a good job —This is necessary in\\norder to determine the distance between the algorithm’s current output andits expected output. The measurement is used as a feedback signal to adjust\\nthe way the algorithm works. This adjustment step is what we call learning .\\nA machine-learning model tran sforms its input data into meaningful outputs, a pro-\\ncess that is “learned” from exposure to kn own examples of inputs and outputs. There-\\nfore, the central problem in machine learning and deep learning is to meaningfully\\ntransform data : in other words, to learn useful representations  of the input data at\\nhand—representations that get us closer to  the expected output. Before we go any\\nfurther: what’s a representation? At its core, it’s a different way to look at data—to rep-\\nresent  or encode  data. For instance, a color image can be encoded in the \\nRGB format\\n(red-green-blue) or in the HSV format (hue-saturation-value): these are two different\\nrepresentations of the same data. Some task s that may be difficult with one represen-\\ntation can become easy with another. For exam ple, the task “select all red pixels in the\\nimage” is simpler in the RG format, whereas “make the image less saturated” is simpler\\nin the HSV format. Machine-learning models ar e all about finding appropriate repre-\\nsentations for their input data—transformatio ns of the data that make it more amena-\\nble to the task at hand, such as a classification task.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 28}), Document(page_content='7 Artificial intelligence, machine learning, and deep learning\\n Let’s make this concrete. Cons ider an x-axis, a y-axis, and\\nsome points represented by their coordinates in the (x, y) sys-\\ntem, as shown in figure 1.3.\\n As you can see, we have a few white points and a few black\\npoints. Let’s say we want to develop an algorithm that can take\\nthe coordinates (x, y) of a point and output whether that\\npoint is likely to be black or to be white. In this case,\\n\\uf0a1The inputs are the coordinates of our points.\\n\\uf0a1The expected outputs are the colors of our points.\\n\\uf0a1A way to measure whether our algorithm is doing agood job could be, for instance, the percentage of\\npoints that are being correctly classified.\\nWhat we need here is a new representation of our data that cleanly separates the white\\npoints from the black points. One transfor mation we could use, among many other\\npossibilities, would be a coordinate change, illustrated in figure 1.4.\\nIn this new coordinate system, the coordinate s of our points can be said to be a new\\nrepresentation of our data. And it’s a go od one! With this representation, the\\nblack/white classification problem can be expressed as a simple rule: “Black points\\nare such that x > 0,” or “White points are such that x < 0.” This new representation\\nbasically solves the classification problem.\\n In this case, we defined the coordinate change by hand. But if instead we tried sys-\\ntematically searching for different possible coordinate changes, and used as feedback\\nthe percentage of points being correctly cl assified, then we would be doing machine\\nlearning. Learning , in the context of machine learni ng, describes an automatic search\\nprocess for better representations.\\n All machine-learning algorithms consist of  automatically finding such transforma-\\ntions that turn data into more-useful re presentations for a given task. These opera-\\ntions can be coordinate changes, as you ju st saw, or linear pr ojections (which may\\ndestroy information), translations, nonlinea r operations (such as “select all points\\nsuch that x > 0”), and so on. Machine-lear ning algorithms aren’t usually creative iny2: Coordinate change\\nxy1: Raw data\\nxy3: Better representation\\nx\\nFigure 1.4 Coordinate changey\\nx\\nFigure 1.3\\nSome sample data\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 29}), Document(page_content='8 CHAPTER  1What is deep learning?\\nfinding these transformations; they’re mere ly searching through a predefined set of\\noperations, called a hypothesis space .\\n So that’s what machine learning is, te chnically: searching for useful representa-\\ntions of some input data, within a predef ined space of possibi lities, using guidance\\nfrom a feedback signal. This simple idea allows for solv ing a remarkably broad range\\nof intellectual tasks, from speech re cognition to autonomous car driving.\\n Now that you understand what we mean by learning , let’s take a look at what makes\\ndeep learning  special. \\n1.1.4 The “deep” in deep learning\\nDeep learning is a specific subfield of ma chine learning: a new take on learning repre-\\nsentations from data that puts an  emphasis on learning successive layers  of increasingly\\nmeaningful representations. The deep in deep learning  isn’t a reference to any kind of\\ndeeper understanding achieved by the approach ; rather, it stands for this idea of suc-\\ncessive layers of representations. How many layers contribute to a model of the data is\\ncalled the depth  of the model. Other appropriate names for the field could have been\\nlayered representations learning  and hierarchical representations learning . Modern deep\\nlearning often involves tens or even hundre ds of successive layers of representations—\\nand they’re all learned automatically from  exposure to training data. Meanwhile,\\nother approaches to machine learning tend to focus on learning only one or two lay-\\ners of representations of the data ; hence, they’re sometimes called shallow learning .\\n In deep learning, these layered representations are (almost always) learned via\\nmodels called neural networks , structured in literal layers stacked on top of each other.\\nThe term neural network  is a reference to neurobiology , but although some of the cen-\\ntral concepts in deep learni ng were developed in part by drawing inspiration from our\\nunderstanding of the brain, deep-learning models are not m o d e l s  o f  t h e  b r a i n .\\nThere’s no evidence that the brain implem ents anything like the learning mecha-\\nnisms used in modern deep-learning mode ls. You may come across pop-science arti-\\ncles proclaiming that deep learning work s like the brain or was modeled after the\\nbrain, but that isn’t the case. It would be confusing and counterproductive for new-\\ncomers to the field to think of deep learni ng as being in any way related to neurobiol-\\nogy; you don’t need that shroud of “just li ke our minds” mystique and mystery, and\\nyou may as well forget anyt hing you may have read abou t hypothetical links between\\ndeep learning and biology. For our purposes , deep learning is a mathematical frame-\\nwork for learning representations from data.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 30}), Document(page_content='9 Artificial intelligence, machine learning, and deep learning\\n What do the representations learned by a deep-learning algorithm look like? Let’s\\nexamine how a network several layers deep (see figure 1.5) transforms an image of a\\ndigit in order to recognize what digit it is.\\nAs you can see in figure 1.6, the network transforms the digit image into representa-\\ntions that are increasingly different from the original image and increasingly informa-tive about the final result. You can th ink of a deep network as a multistage\\ninformation-distillation operation, where in formation goes through successive filters\\nand comes out increasingly purified  (that is, useful with regard to some task).\\nSo that’s what deep learning  is, technically: a multistage way to learn data representa-\\ntions. It’s a simple idea—but, as it turn s out, very simple me chanisms, sufficiently\\nscaled, can end up looking like magic. \\n1.1.5 Understanding how deep lear ning works, in three figures\\nAt this point, you know that machine learning is about mapping inputs (such as\\nimages) to targets (such as th e label “cat”), which is done by observing many examples\\nof input and targets. You also know that de ep neural networks do this input-to-target\\nLayer 1\\nOriginal\\ninput\\nFinal\\noutputLayer 2 Layer 3 Layer 4\\n0\\n123456789\\nFigure 1.5 A deep neural \\nnetwork for digit classification\\nLayer 1\\nrepresentations\\nOriginal\\ninputLayer 2\\nrepresentationsLayer 3\\nrepresentations\\nLayer 4\\nrepresentations\\n(final output)\\nLayer 1 Layer 2 Layer 3 Layer 40\\n123456789\\nFigure 1.6 Deep representations learned by a digit-classification model\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 31}), Document(page_content=\"10 CHAPTER  1What is deep learning?\\nmapping via a deep sequence of simple data  transformations (layers) and that these\\ndata transformations are lear ned by exposure to examples. Now let’s look at how this\\nlearning happens, concretely.\\n The specification of what a layer does to  its input data is stored in the layer’s\\nweights , which in essence are a bunc h of numbers. In technical terms, we’d say that the\\ntransformation implemented by a layer is parameterized  by its weights (see figure 1.7).\\n(Weights are also sometimes called the parameters  of a layer.) In this context, learning\\nmeans finding a set of values for the weights of all layers in a network, such that the\\nnetwork will correctly map example inputs to  their associated targets. But here’s the\\nthing: a deep neural networ k can contain tens of millions of parameters. Finding the\\ncorrect value for all of them may seem like a daunting task, especially given that mod-\\nifying the value of one pa rameter will affect the behavior of all the others!\\nTo control something, first you need to be able to observe it. To control the output of\\na neural network, you need to be able to measure how far this output is from what you\\nexpected. This is the job of the loss function  of the network, also called the objective\\nfunction . The loss function takes the prediction s of the network and the true target\\n(what you wanted the network to output) and computes a distance score, capturinghow well the network has done on this  specific example (see figure 1.8).Goal: finding the\\nright values for\\nthese weightsLayer\\n(data transformation)Input X\\nWeights\\nLayer\\n(data transformation)\\nPredictions\\nY'Weights\\nFigure 1.7 A neural network is \\nparameterized by its weights.\\nLayer\\n(data transformation)Input X\\nWeights\\nLayer\\n(data transformation)\\nPredictions\\nY'True targets\\nYWeights\\nLoss function\\nLoss scoreFigure 1.8 A loss function measures \\nthe quality of the network’s output.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 32}), Document(page_content=\"11 Artificial intelligence, machine learning, and deep learning\\nThe fundamental trick in deep learning is to use this score as a feedback signal to\\nadjust the value of the weight s a little, in a direction that will lower the loss score for\\nthe current example (see figure 1.9). This adjustment is the job of the optimizer , which\\nimplements what’s called the Backpropagation  algorithm: the central algorithm in deep\\nlearning. The next chapter explains in more detail how backpropagation works.\\nInitially, the weights of the network are assigned random values, so the network\\nmerely implements a series of random tran sformations. Naturally, its output is far\\nfrom what it should ideally be, and the lo ss score is accordingly very high. But with\\nevery example the network processes, the weig hts are adjusted a little in the correct\\ndirection, and the loss scor e decreases. This is the training loop , which, repeated a suffi-\\ncient number of times (typically tens of it erations over thousands of examples), yields\\nweight values that minimize the loss functi on. A network with a minimal loss is one for\\nwhich the outputs are as close as they can be to the targets: a trained network. Once\\nagain, it’s a simple mechanism that, on ce scaled, ends up looking like magic. \\n1.1.6 What deep learning has achieved so far\\nAlthough deep learning is a fairly old subfield of machine learning, it only rose to\\nprominence in the early 2010s. In the few ye ars since, it has achieved nothing short of\\na revolution in the field, with remarkable results on perceptual problems such as see-\\ning and hearing—problems involving skills th at seem natural and intuitive to humans\\nbut have long been elusive for machines.\\n In particular, deep learning has achieved the following breakthroughs, all in his-\\ntorically difficult areas of machine learning:\\n\\uf0a1Near-human-level image classification\\n\\uf0a1Near-human-level speech recognition\\n\\uf0a1Near-human-level handwriting transcription\\n\\uf0a1Improved machine translationLayer\\n(data transformation)Input X\\nWeights\\nLayer\\n(data transformation)\\nPredictions\\nY'Weight\\nupdateTrue targets\\nYWeights\\nLoss function Optimizer\\nLoss scoreFigure 1.9 The loss score is used as a \\nfeedback signal to adjust the weights.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 33}), Document(page_content='12 CHAPTER  1What is deep learning?\\n\\uf0a1Improved text-to-speech conversion\\n\\uf0a1Digital assistants such as Google Now and Amazon Alexa\\n\\uf0a1Near-human-level autonomous driving\\n\\uf0a1Improved ad targeting, as used  by Google, Baidu, and Bing\\n\\uf0a1Improved search re sults on the web\\n\\uf0a1Ability to answer natural-language questions\\n\\uf0a1Superhuman Go playing\\nWe’re still exploring the full extent of what  deep learning can do. We’ve started apply-\\ning it to a wide variety of problems outsid e of machine perception and natural-language\\nunderstanding, such as formal reasoning. If successful, this may herald an age where\\ndeep learning assists huma ns in science, software development, and more. \\n1.1.7 Don’t believe the short-term hype\\nAlthough deep learning has led to remarkab le achievements in recent years, expecta-\\ntions for what the field will be able to ac hieve in the next decade tend to run much\\nhigher than what will likely be possible. Although some world- changing applications\\nlike autonomous cars are already within reac h, many more are likely to remain elusive\\nfor a long time, such as beli evable dialogue systems, hu man-level machine translation\\nacross arbitrary langua ges, and human-level natural-la nguage understanding. In par-\\nticular, talk of human-level general intelligence  shouldn’t be taken too seriously. The risk\\nwith high expectations for the short term is that, as technology fails to deliver,research investment will dry up, slowing progress for a long time.\\n This has happened before. Twice in the pa st, AI went through a cycle of intense\\noptimism followed by disappointment and skepticism, wi th a dearth of funding as a\\nresult. It started with symbolic \\nAI in the 1960s. In those early days, projections about AI\\nwere flying high. One of the best-known pi oneers and proponents of the symbolic AI\\napproach was Marvin Minsky, who claimed in  1967, “Within a generation … the prob-\\nlem of creating ‘artificial intelligence’ will substantially be solved.” Three years later, in\\n1970, he made a more precisely quantified prediction: “In from three to eight years wewill have a machine with the general intelli gence of an average human being.” In 2016,\\nsuch an achievement still appears to be far in the future—so far that we have no way to\\npredict how long it will take—but in the 1 960s and early 1970s, se veral experts believed\\nit to be right around the corner (as do many  people today). A few years later, as these\\nhigh expectations failed to materialize,  researchers and gove rnment funds turned\\naway from the field, marking the start of the first \\nAI winter  (a reference to a nuclear win-\\nter, because this was shortly after the height of the Cold War).\\n It wouldn’t be the last one. In the 1980s, a new take on symbolic AI, expert systems ,\\nstarted gathering steam among large companie s. A few initial succ ess stories triggered\\na wave of investment, with corporations around the worl d starting their own in-house\\nAI departments to develop ex pert systems. Around 1985,  companies were spending\\nover $1 billion each year on the technolo gy; but by the early 1990s, these systems had\\nproven expensive to maintain, difficult to scale, and limited in scope, and interest\\ndied down. Thus began the second AI winter.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 34}), Document(page_content='13 Artificial intelligence, machine learning, and deep learning\\n We may be currently witnessing the third cycle of AI hype and disappointment—\\nand we’re still in the phase of intense optimi sm. It’s best to mode rate our expectations\\nfor the short term and make sure people le ss familiar with the technical side of the\\nfield have a clear idea of what de ep learning can and can’t deliver. \\n1.1.8 The promise of AI\\nAlthough we may have unrealistic short-term expectations for AI, the long-term pic-\\nture is looking bright. We’re only getting started in applying deep learning to many\\nimportant problems for which it could prov e transformative, from medical diagnoses\\nto digital assistants. AI research has been moving forward amazingly quickly in the past\\nfive years, in large part due to a level of funding never before seen in the short history\\nof AI, but so far relatively little of this prog ress has made its way into the products and\\nprocesses that form our world. Most of the research findings of deep learning aren’tyet applied, or at least not applied to th e full range of problems they can solve across\\nall industries. Your doctor doesn’t yet use \\nAI, and neither does your accountant. You\\nprobably don’t use AI technologies in your day-to-day  life. Of course, you can ask your\\nsmartphone simple questions and get reason able answers, you can get fairly useful\\nproduct recommendations on Amazon.com, and you can search for “birthday” on\\nGoogle Photos and instantly find those pict ures of your daughter’s birthday party\\nfrom last month. That’s a far cry from wh ere such technologies used to stand. But\\nsuch tools are still only acce ssories to our daily lives. AI has yet to transition to being\\ncentral to the way we work, think, and live.\\n Right now, it may seem hard to believe that AI could have a large impact on our\\nworld, because it isn’t yet widely deployed—much as, back in 1995, it would have been\\ndifficult to believe in the future impact of  the internet. Back then, most people didn’t\\nsee how the internet was relevant to them and how it was going to change their lives. The\\nsame is true for deep learning and AI today. But make no mistake: AI is coming. In a not-\\nso-distant future, AI will be your assistant, even your friend; it will answer your questions,\\nhelp educate your kids, and watc h over your health. It will deliver your gr oceries to your\\ndoor and drive you from point A to point B. It  will be your interface to an increasingly\\ncomplex and information-intensive world. And, even more important, AI will help\\nhumanity as a whole move forward, by assi sting human scientists  in new breakthrough\\ndiscoveries across all scientific fiel ds, from genomics to mathematics.\\n On the way, we may face a few setbacks and maybe a new AI winter—in much the\\nsame way the internet industry was overhyped in 1998–1999 and suffered from a crashthat dried up investment throughout the ea rly 2000s. But we’ll get there eventually. \\nAI\\nwill end up being applied to nearly every process that makes up our society and our\\ndaily lives, much like the internet is today.\\n Don’t believe the short-term hype, but do  believe in the long-term vision. It may\\ntake a while for AI to be deployed to its true pote ntial—a potential the full extent of\\nwhich no one has yet dared to dream—but AI is coming, and it will transform our\\nworld in a fantastic way. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 35}), Document(page_content='14 CHAPTER  1What is deep learning?\\n1.2 Before deep learning: \\na brief history of machine learning\\nDeep learning has reached a level of pub lic attention and industry investment never\\nbefore seen in the history of AI, but it isn’t the first succe ssful form of machine learn-\\ning. It’s safe to say that most of the mach ine-learning algorithms used in the industry\\ntoday aren’t deep-learning algorithms. Deep le arning isn’t always the right tool for the\\njob—sometimes there isn’t enough data for de ep learning to be applicable, and some-\\ntimes the problem is better solved by a diff erent algorithm. If d eep learning is your\\nfirst contact with machine learning, then you may find yourself in a situation where all\\nyou have is the deep-learning hammer, and every machine-learning problem starts to\\nlook like a nail. The only way not to fall into this trap is to be familiar with other\\napproaches and practice them when appropriate.\\n A detailed discussion of classical machin e-learning approaches is outside of the\\nscope of this book, but we’ll briefly go over  them and describe the historical context\\nin which they were developed. This will allo w us to place deep learning in the broader\\ncontext of machine learning and better un derstand where deep learning comes from\\nand why it matters.\\n1.2.1 Probabilistic modeling\\nProbabilistic modeling  is the application of the principles  of statistics to data analysis. It\\nwas one of the earliest forms of machine learni ng, and it’s still widely used to this day.\\nOne of the best-known algorithms in this category is the Naive Bayes algorithm.\\n Naive Bayes is a type of machine-learning classifier based on applying Bayes’ theo-\\nrem while assuming that the fe atures in the input data are all independent (a strong,\\nor “naive” assumption, which is where the na me comes from). This form of data analy-\\nsis predates computers and was applied by hand decade s before its first computer\\nimplementation (most likely dating back to the 1950s). Bayes’ theorem and the foun-\\ndations of statistics date back to the eighteenth century, and these are all you need tostart using Naive Bayes classifiers.\\n A closely related model is the logistic regression  (logreg for short) , which is some-\\ntimes considered to be the “hello world” of modern machine learning. Don’t be mis-\\nled by its name—logreg is a classification algorithm rather than a regression\\nalgorithm. Much like Naive Bayes, logreg pr edates computing by a long time, yet it’s\\nstill useful to this day, thanks  to its simple and versatile nature. It’s often the first thing\\na data scientist will try on a dataset to get a feel for the classifi cation task at hand. \\n1.2.2 Early neural networks\\nEarly iterations of neural networks have  been completely supplanted by the modern\\nvariants covered in these pages, but it’s help ful to be aware of how deep learning origi-\\nnated. Although the core ideas of neural netw orks were investigated in toy forms as early\\nas the 1950s, the approach took decades to ge t started. For a long time, the missing piece\\nwas an efficient way to trai n large neural networks. This changed in the mid-1980s,\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 36}), Document(page_content='15 Before deep learning: a brief history of machine learning\\nwhen  multiple people independently redi scovered the Backpr opagation algorithm—\\na way to train chains of parametric oper ations using gradient-descent optimization\\n(later in the book, we’ll precisely define these concepts)—and st arted applying it to\\nneural networks.\\n The  fi rs t  s uc ce s s fu l p ract ic al app li cat io n of  ne ura l ne ts  c ame  in 1 989  fr om  B el l\\nLabs, when Yann LeCun combined the earlie r ideas of convolutional neural networks\\nand backpropagation, and a pplied them to the problem of classifying handwritten\\ndigits. The resultin g network, dubbed LeNet , was used by the United States Postal Ser-\\nvice in the 1990s to automate the reading of ZIP codes on mail envelopes. \\n1.2.3 Kernel methods\\nAs neural networks started to gain some  respect among researchers in the 1990s,\\nthanks to this first success, a new approa ch to machine learning rose to fame and\\nquickly sent neural nets back to oblivion: kernel methods. Kernel methods  are a group of\\nclassification algorithms, the best known of which is the support vector machine  (SVM).\\nThe modern formulation of an SVM was developed by Vladimir\\nVapnik and Corinna Cortes in the early 1990s at Bell Labs and\\npublished in 1995,2 although an older li near formulation was\\npublished by Vapnik and Alexey Chervonenkis as early as 1963.3\\n SVMs aim at solving classificati on problems by finding good\\ndecision boundaries  (see figure 1.10) between two sets of points\\nbelonging to two different cate gories. A decision boundary can\\nbe thought of as a line or surf ace separating your training data\\ninto two spaces corresponding to two categories. To classify new\\ndata points, you just need to check which side of the decisionboundary they fall on.\\n \\nSVMs proceed to find these boundaries in two steps:\\n1The data is mapped to a new high-dimensional representation where the\\ndecision boundary can be expressed as a hyperplane (if the data was two-\\ndimensional, as in figure 1.10, a hy perplane would be a straight line).\\n2A good decision boundary (a separation hyperplane) is com puted by trying to\\nmaximize the distance between the hyperplane and the closest data points from\\neach class, a step called maximizing the margin . This allows the boundary to gen-\\neralize well to new samples outs ide of the training dataset.\\nThe technique of mapping data to a high-dim ensional representation where a classifi-\\ncation problem becomes simpler may look good on paper, but in practice it’s\\noften computationally intrac table. That’s where the kernel trick  comes in (the key idea\\nthat kernel methods are named after). Here’s  t h e  g i s t  o f  i t :  t o  f i n d  g o o d  d e c i s i o n\\n2Vladimir Vapnik and Corinna Co rtes, “Support-Vector Networks,” Machine Learning  20, no. 3 (1995): 273–297.\\n3Vladimir Vapnik and Alexey Chervonenkis, “A Note on One Class of Perceptrons,” Automation and Remote Con-\\ntrol 25 (1964).Figure 1.10\\nA decision boundary\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 37}), Document(page_content='16 CHAPTER  1What is deep learning?\\nhyperplanes in the ne w representation space, you don’ t have to explicitly compute\\nthe coordinates of your points in the new space; you just need to compute the dis-\\ntance between pairs of points in that spac e, which can be done efficiently using a ker-\\nnel function . A kernel function is a computationa lly tractable operat ion that maps any\\ntwo points in your initial space to the di stance between these points in your target\\nrepresentation space, completely bypassing  the explicit computation of the new rep-\\nresentation. Kernel functions are typically crafted by hand rather than learned from\\ndata—in the case of an SVM, only the separation hyperplane is learned.\\n At the time they were developed, SVMs exhibited state-of-the-art performance on\\nsimple classification problems and were one of the few machine-learning methods\\nbacked by extensive theory and amenable to serious mathematical analysis, making\\nthem well understood and easily interpreta ble. Because of these useful properties,\\nSVMs became extremely popular in the field for a long time.\\n But SVMs proved hard to scale to large datase ts and didn’t provide good results for\\nperceptual problems such as im age classification. Because an SVM is a shallow\\nmethod, applying an SVM to perceptual problems requires first extracting useful rep-\\nresentations manually (a step called feature engineering ), which is difficult and brittle. \\n1.2.4 Decision trees, random forests, and gradient boosting machines\\nDecision trees  are flowchart-like structur es that let you classify input data points or pre-\\ndict output values given inputs (see figure 1.11). They’re easy to visualize and inter-\\npret. Decisions trees learned from data began to receive significant research interest\\nin the 2000s, and by 2010 they were often preferred to kernel methods.\\nIn particular, the Random Forest  algorithm introduced a robust, practical take on\\ndecision-tree learning that involves buildi ng a large number of specialized decision\\ntrees and then ensembling their outputs. Random forests are a pplicable to a wide\\nrange of problems—you could say that they’r e almost always the second-best algorithm\\nfor any shallow machine-learning task. When the popular machine-learning competi-tion website Kaggle ( http:/ /kaggle.com ) got started in 2010, random forests quickly\\nbecame a favorite on the platform—until 2014, when gradient boosting machines  took\\nover. A gradient boosting machine, much li ke a random forest, is a machine-learning\\ntechnique based on ensembling weak predic tion models, generally decision trees. ItQuestion\\nCategory CategoryQuestionInput data\\nQuestion\\nCategory CategoryFigure 1.11 A decision tree: the parameters \\nthat are learned are the questions about the \\ndata. A question could be, for instance, “Is \\ncoefficient 2 in the data greater than 3.5?”\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 38}), Document(page_content='17 Before deep learning: a brief history of machine learning\\nuses gradient boosting , a way to improve any machine-lear ning model by iteratively train-\\ning new models that specialize  in addressing the weak points of the previous models.\\nApplied to decision trees, the use of the gradient boosting techni que results in models\\nthat strictly outperform random forests most  of the time, while having similar proper-\\nties. It may be one of the best, if not the best, algorithm for dealing with nonperceptual\\ndata today. Alongside deep learning, it’s one of the most commonly used techniques in\\nKaggle competitions. \\n1.2.5 Back to neural networks\\nAround 2010, although neural networks we re almost completely shunned by the sci-\\ne n t i f i c  c o m m u n i t y  a t  l a r g e ,  a  n u m b e r  o f  p e o p l e  s t i l l  w o r k i n g  o n  n e u r a l  n e t w o r k s\\nstarted to make important breakthroughs: th e groups of Geoffrey Hinton at the Uni-\\nversity of Toronto, Yoshua Bengio at the University of Montreal, Yann LeCun at New\\nYork University, and IDSIA  in Switzerland.\\n In 2011, Dan Ciresan from IDSIA  began to win academic image-classification com-\\npetitions with GPU-trained deep neural networks—the first practical success of mod-\\nern deep learning. But the watershed mo ment came in 2012, with the entry of\\nHinton’s group in the yearly large-scale im age-classification ch allenge ImageNet. The\\nImageNet challenge was notoriousl y difficult at the time, consisting of classifying high-\\nresolution color images into 1,000 different categories after training on 1.4 million\\nimages. In 2011, the top-five accuracy of  the winning model, based on classical\\napproaches to computer vision, was only 74.3%. Then, in 2012, a team led by Alex\\nKrizhevsky and advised by Geo ffrey Hinton was able to ac hieve a top-five accuracy of\\n83.6%—a significant breakthrough. The co mpetition has been dominated by deep\\nconvolutional neural networks  every year since. By 2015, the winner reached an accu-\\nracy of 96.4%, and the classification task  on ImageNet was cons idered to be a com-\\npletely solved problem.\\n Since 2012, deep convolut ional neural networks ( convnets ) have become the go-to\\nalgorithm for all computer vision tasks; mo re generally, they work on all perceptual\\ntasks. At major computer vi sion conferences in 2015 and 2016, it was nearly impossi-\\nble to find presentations that didn’t involv e convnets in some form. At the same time,\\ndeep learning has also found applications in many other types of problems, such as\\nnatural-language processing. It has completely replaced SVMs and decision trees in a\\nwide range of applications. For instance, for several year s, the European Organization\\nfor Nuclear Research, CERN , used decision tree–based me thods for analysis of particle\\ndata from the ATLAS  detector at the Large Hadron Collider ( LHC); but CERN  eventu-\\nally switched to Keras-base d deep neural networks due to their higher performance\\nand ease of training on large datasets. \\n1.2.6 What makes deep learning different\\nThe primary reason deep learning took off so  quickly is that it offered better perfor-\\nmance on many problems. But that’s not th e only reason. Deep learning also makes\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 39}), Document(page_content='18 CHAPTER  1What is deep learning?\\nproblem-solving much easier, because it completely automates what used to be the\\nmost crucial step in a machine-learning workfl ow: feature engineering.\\n Previous machine-learning  techniques—shallow lear ning—only involved trans-\\nforming the input data into one or two succ essive representation spaces, usually via\\nsimple transformations such as high -dimensional non-linear projections ( SVMs) or\\ndecision trees. But the refined representa tions required by co mplex problems gener-\\nally can’t be attained by such techniques. As such, humans had to go to great lengths\\nto make the initial input data more amenab le to processing by these methods: they\\nhad to manually engineer good layers of representations for their data. This is called\\nfeature engineering . Deep learning, on the other hand , completely automates this step:\\nwith deep learning, you learn all features in one pass rather than having to engineer\\nthem yourself. This has greatly simplified machine-learning workflows, often replac-\\ning sophisticated multistage pipelines with a single, simple, end-to-end deep-learningmodel.\\n You may ask, if the crux of the issue is to have multiple successive layers of repre-\\nsentations, could shallow methods be appl ied repeatedly to emulate the effects of\\ndeep learning? In practice, there are fast-diminishing re turns to successive applica-\\ntions of shallow-learning methods, because the optimal first representation layer in a three-\\nlayer model isn’t the optimal first lay er in a one-layer or two-layer model . What is transforma-\\ntive about deep learning is th at it allows a model to learn all layers of representation\\njointly , at the same time, rather than in succession ( greedily , as it’s called). With joint\\nfeature learning, whenever the model adjusts one of its internal features, all other fea-\\ntures that depend on it automatically ad apt to the change, without requiring human\\nintervention. Everything is supervised by a single feedback signal: every change in the\\nmodel serves the end goal. This is much more  powerful than greed ily stacking shallow\\nmodels, because it allows for complex, ab stract representations to be learned by\\nb re aki ng t hem  do wn i nto  lo ng s e rie s  o f intermediate spaces (layers); each space is\\nonly a simple transformation away from the previous one.\\n These are the two essential characteristics of how deep learning learns from data:\\nthe incremental, layer-by-layer way in which incr easingly complex representations are developed ,\\nand the fact that these intermediate incremental representations are learned jointly , each layer\\nbeing updated to follow both the representational needs of the layer above and theneeds of the layer below. Together, these two properties have made deep learning\\nvastly more successful than previous  approaches to machine learning. \\n1.2.7 The modern machine-learning landscape\\nA great way to get a sense of the current landscape of machine-learning algorithms\\nand tools is to look at machine-learning competitions on Kaggle. Due to its highly\\ncompetitive environment (some contests ha ve thousands of entrants and million-\\ndollar prizes) and to the wide variety of  machine-learning problems covered, Kaggle\\noffers a realistic way to assess what works an d what doesn’t. So, what kind of algorithm\\nis reliably winning competitions? What tools do top entrants use?\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 40}), Document(page_content='19 Before deep learning: a brief history of machine learning\\n In 2016 and 2017, Kaggle was dominate d by two approaches: gradient boosting\\nmachines and deep learning . Specifically, gradient boosting is used for problems\\nwhere structured data is available, whereas deep learning is used  for perceptual prob-\\nlems such as image classifica tion. Practitioners of the fo rmer almost always use the\\nexcellent XGBoost library, wh ich offers support for the two most popular languages of\\ndata science: Python and R. Meanwhile, most  of the Kaggle entrants using deep learn-\\ning use the Keras library, due to its ease of  use, flexibility, and support of Python.\\n These are the two techniques you should be  the most familiar with in order to be\\nsuccessful in applied machine learning toda y: gradient boosting machines, for shallow-\\nlearning problems; and deep learning, for perceptual pr oblems. In technical terms,\\nthis means you’ll need to be familiar with XGBoost and Keras—the two libraries that\\ncurrently dominate Kaggle competitions. With  this book in hand, you’re already one\\nbig step closer. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 41}), Document(page_content='20 CHAPTER  1What is deep learning?\\n1.3 Why deep learning? Why now?\\nThe two key ideas of deep learning for co mputer vision—convolutional neural net-\\nworks and backpropagation—we re already well understood in 1989. The Long Short-\\nTerm Memory ( LSTM ) algorithm, which is fundamental to deep learning for\\ntimeseries, was developed in 1997 and ha s barely changed since. So why did deep\\nlearning only take off after 2012? What changed in these two decades?\\n In general, three technical forces are driving advances in machine learning:\\n\\uf0a1Hardware\\n\\uf0a1Datasets and benchmarks\\n\\uf0a1Algorithmic advances\\nBecause the field is guided by experimental findings rather than by theory, algorith-\\nmic advances only become possible when ap propriate data and hardware are available\\nto try new ideas (or scale up old ideas, as is often the case). Machine learning isn’t\\nmathematics or physics, wher e major advances can be done with a pen and a piece of\\npaper. It’s an engineering science.\\n The real bottlenecks throughout the 1990s and 2000s were data and hardware. But\\nhere’s what happened during  that time: the internet to ok off, and high-performance\\ngraphics chips were developed for the needs of the gaming market.\\n1.3.1 Hardware\\nBetween 1990 and 2010, off-the-shelf CPUs became faster by a factor of approximately\\n5,000. As a result, nowadays it’s possible to run small deep-learning models on your\\nlaptop, whereas this would have been intractable 25 years ago.\\n But typical deep-learning models used in  computer vision or speech recognition\\nrequire orders of magnitude more computational power th an what your laptop can\\ndeliver. Throughout the 2000s, companies like NVIDIA  and AMD  have been investing\\nbillions of dollars in developing fast, massively parallel chips (graphical processingunits [\\nGPUs]) to power the graphics of incr easingly photorealistic video games—\\ncheap, single-purpose supercomputers designed to render complex 3D scenes on your\\nscreen in real time. This investment came  to benefit the scientific community when,\\nin 2007, NVIDIA  launched CUDA  (https:/ /developer.nvidia.com/about-cuda ), a pro-\\ngramming interface for its line of GPUs. A small number of GPUs started replacing\\nmassive clusters of CPUs in various highly parallelizable applications, beginning with\\nphysics modeling. Deep neural  networks, consisting mostly  of many small matrix mul-\\ntiplications, are also highly parallelizable;  and around 2011, so me researchers began\\nto write CUDA  implementations of neural nets—Dan Ciresan4 and Alex Krizhevsky5\\nwere among the first.\\n4See “Flexible, High Performance Convolutional Neural Networks for Image Classification,” Proceedings of the\\n22nd International Joint Conference on Artificial Intelligence  (2011), www.ijcai.org/Proceedings/11/Papers/\\n210.pdf .\\n5See “ImageNet Classification with Deep Convolutional Neural Networks,” Advances in Neural Information Pro-\\ncessing Systems  25 (2012), http://mng.bz/2286 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 42}), Document(page_content='21 Why deep learning? Why now?\\n What happened is that the gaming mark et subsidized supercomputing for the next\\ngeneration of artificial intelligence ap plications. Sometimes, big things begin as\\ngames. Today, the NVIDIA  TITAN  X, a gaming GPU that cost $1,000 at the end of 2015,\\ncan deliver a peak of 6.6 TFLOPS  in single precision: 6.6 trillion float32  operations\\nper second. That’s about 350 times more th an what you can get out of a modern lap-\\ntop. On a TITAN  X, it takes only a couple of days to train an ImageNet model of the\\nsort that would have won the ILSVRC  competition a few years ago. Meanwhile, large\\ncompanies train deep-learning models on clusters of hundreds of GPUs of a type\\ndeveloped specifically for the need s of deep learning, such as the NVIDIA Tesla K80 .\\nThe sheer computational power of such clus ters is something that would never have\\nbeen possible wi thout modern GPUs.\\n What’s more, the deep-learning industry is starting to go beyond GPUs and is\\ninvesting in increasingly specialized, effici ent chips for deep learning. In 2016, at its\\nannual I/O convention, Google revealed its tensor processing unit ( TPU) project: a\\nnew chip design developed from the ground up to run deep neural networks, which is\\nreportedly 10 times faster and far more energy efficient than top-of-the-line GPUs. \\n1.3.2 Data\\nAI is sometimes heralded as th e new industrial revolution. If  deep learning is the steam\\nengine of this revolution, then data is its coal: the raw material that powers our intelli-\\ngent machines, without which nothing would be possible. When it comes to data, in\\naddition to the exponential progress in stor age hardware over the past 20 years (fol-\\nlowing Moore’s law), the game changer has been  the rise of the internet, making it fea-\\nsible to collect and distribute  very large datasets for machine learning. Today, large\\ncompanies work with image datasets, video da tasets, and natural-language datasets that\\ncouldn’t have been collected without th e internet. User-generated image tags on\\nFlickr, for instance, have been a treasure tr ove of data for computer vision. So are You-\\nTube videos. And Wikipedia is a key da taset for natural-language processing.\\n If there’s one dataset that has been a cataly st for the rise of deep learning, it’s the\\nImageNet dataset, consisting of 1.4 millio n images that have been hand annotated\\nwith 1,000 image categories (1 category per image). But what makes ImageNet special\\nisn’t just its large size, but also the yearly competition associated with it.6\\n As Kaggle has been demonstrating sinc e 2010, public competitions are an excel-\\nlent way to motivate researchers and engi neers to push the envelope. Having common\\nbenchmarks that researchers compete to be at has greatly helped the recent rise of\\ndeep learning. \\n1.3.3 Algorithms\\nIn addition to hardware and data, until the late 2000s, we were missing a reliable way to\\ntrain very deep neural networks. As a result , neural networks were still fairly shallow,\\n6The ImageNet Large Scale Visual Recognition Challenge (ILSVRC), www.image-net.org/challenges/LSVRC .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 43}), Document(page_content='22 CHAPTER  1What is deep learning?\\nusing only one or two layers of representation s; thus, they weren’t able to shine against\\nmore-refined shallow methods such as SVMs and random forests. The key issue was that\\nof gradient propagation  through deep stacks of layers. Th e feedback signal used to train\\nneural networks would fa de away as the number of layers increased.\\n This changed around 2009–2010 with the advent of several simple but important\\nalgorithmic improvements that allo wed for better grad ient propagation:\\n\\uf0a1Better activation functions  for neural layers\\n\\uf0a1Better weight-initialization schemes , starting with layer-wise pretraining, which was\\nquickly abandoned\\n\\uf0a1Better optimization schemes , such as RMSP rop and Adam\\nOnly when these improvements began to al low for training models with 10 or more\\nlayers did deep learning start to shine.\\n Finally, in 2014, 2015, and 2016, even more advanced ways to help gradient propa-\\ngation were discovered, such as batch norm alization, residual connections, and depth-\\nwise separable convolutions . Today we can train from scratch models that are\\nthousands of layers deep. \\n1.3.4 A new wave of investment\\nAs deep learning became the new state of  the art for computer vision in 2012–2013,\\nand eventually for all perceptual tasks, in dustry leaders took note. What followed was\\na gradual wave of industry investment far be yond anything previously seen in the his-\\ntory of AI.\\n In 2011, right before deep learning took  the spotlight, the total venture capital\\ninvestment in AI was around $19 million, which went almost entirely to practical appli-\\ncations of shallow machine-le arning approaches. By 2014, it had risen to a staggering\\n$394 million. Dozens of startups launched in these three years, trying to capitalize onthe deep-learning hype. Mean while, large tech companies such as Google, Facebook,\\nBaidu, and Microsoft have invested in inte rnal research depart ments in amounts that\\nwould most likely dwarf the flow of vent ure-capital money. Only a few numbers have\\nsurfaced: In 2013, Google acquired th e deep-learning startup DeepMind for a\\nreported $500 million—the largest acquisition of an AI company in history. In 2014,\\nBaidu started a deep-learning research center  in Silicon Valley, investing $300 million\\nin the project. The deep-learning hardware  startup Nervana Syst ems was acquired by\\nIntel in 2016 for over $400 million.\\n Machine learning—in partic ular, deep learning—has be come central to the prod-\\nuct strategy of these tech gi ants. In late 2015, Google \\nCEO Sundar Pichai stated,\\n“Machine learning is a core, transformative  way by which we’re rethinking how we’re\\ndoing everything. We’re thoughtfully applying it across all our products, be it search,\\nads, YouTube, or Play. And we’re in early days, but you’ll see us—in a systematic way—\\napply machine learning in all these areas.”7\\n7Sundar Pichai, Alphabet earnings call, Oct. 22, 2015.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 44}), Document(page_content='23 Why deep learning? Why now?\\n A s  a  r e s u l t  o f  t h i s  w a v e  o f  i n v e s t m e n t ,  t h e  n u m b e r  o f  p e o p l e  w o r k i n g  o n  d e e p\\nlearning went in just five years from a fe w hundred to tens of thousands, and research\\nprogress has reached a frenetic pace. There ar e currently no signs that this trend will\\nslow any time soon. \\n1.3.5 The democratization of deep learning\\nOne of the key factors driving this inflow of  new faces in deep learning has been the\\ndemocratization of the toolsets  used in the field. In the early days, doing deep learning\\nrequired significant C++ and CUDA  expertise, which few peop le possessed. Nowadays,\\nbasic Python scripting skills suffice to do ad vanced deep-learning research. This has been\\ndriven most notably by the development of  Theano and then TensorFlow—two symbolic\\ntensor-manipulation frameworks for Python th at support autodifferentiation, greatly sim-\\nplifying the implementation of new models—a nd by the rise of user-friendly libraries\\nsuch as Keras, which makes deep learning as easy as manipulating LEGO  bricks. After its\\nrelease in early 2015, Keras quickly became the go-to deep-learning solution for large\\nnumbers of new startups, graduate students, and researchers pivoting into the field. \\n1.3.6 Will it last?\\nIs there anything special abou t deep neural networks that makes them the “right”\\napproach for companies to be investing in and for researchers to flock to? Or is deep\\nlearning just a fad that may not last? Will we still be using deep neural networks in\\n20 years?\\n Deep learning has several pr operties that justif y its status as an AI revolution, and\\nit’s here to stay. We may not be using neur al networks two decades from now, but what-\\never we use will directly inherit from mo dern deep learning and its core concepts.\\nThese important properties can be br oadly sorted into three categories:\\n\\uf0a1Simplicity —Deep learning removes the need fo r feature engineering, replacing\\ncomplex, brittle, engineering-heavy pipe lines with simple, en d-to-end trainable\\nmodels that are typically built using only five or six different tensor operations.\\n\\uf0a1Scalability —Deep learning is highly amenable to parallelization on GPUs or\\nTPUs, so it can take full advantage of Moore’s law. In addition, deep-learning\\nmodels are trained by iterating over small  batches of data, allowing them to be\\ntrained on datasets of arbitrary size. (The only bottleneck is the amount of\\nparallel computational power available, which, thanks to  Moore’s law, is a fast-\\nmoving barrier.)\\n\\uf0a1Versatility and reusability —Unlike many prior machine-learning approaches,\\ndeep-learning models can be trained on additional data without restarting from\\nscratch, making them viable for cont inuous online learning—an important\\nproperty for very large production mode ls. Furthermore, trained deep-learning\\nmodels are repurposable and thus reusable : for instance, it’s possible to take a\\ndeep-learning model trained for image cla ssification and drop it into a video-\\nprocessing pipeline. This allows us to reinvest previous work into increasingly\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 45}), Document(page_content='24 CHAPTER  1What is deep learning?\\ncomplex and powerful mode ls. This also makes deep learning applicable to\\nfairly small datasets.\\nDeep learning has only been in the spotlight  for a few years, and we haven’t yet estab-\\nlished the full scope of what it can do. Wi th every passing month, we learn about new\\nuse cases and engineering improvements that lift previous limitations. Following a sci-\\nentific revolution, progress generally follows a sigmoid curve: it starts with a period of\\nfast progress, which graduall y stabilizes as researchers hi t hard limitations, and then\\nfurther improvements become incremental. De ep learning in 2017 seems to be in the\\nfirst half of that sigmoid, with much more  progress to come in the next few years. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 46}), Document(page_content='25Before we begin: the\\nmathematical building\\nblocks of neural networks\\nUnderstanding deep learning requires familiarity with many simple mathematical\\nconcepts: tensors, tensor operations, differ entiation, gradient descent, and so on.\\nOur goal in this chapter will be to buil d your intuition about these notions without\\ngetting overly technical. In particular, we ’ll steer away from mathematical notation,\\nwhich can be off-putting for those without any mathematics background and isn’t\\nstrictly necessary to explain things well.\\n To add some context for tensors and gr adient descent, we’ll begin the chapter\\nwith a practical example of a neural networ k. Then we’ll go over every new conceptThis chapter covers\\n\\uf0a1A first example of a neural network\\n\\uf0a1Tensors and tensor operations\\n\\uf0a1How neural networks learn via backpropagation \\nand gradient descent\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 47}), Document(page_content='26 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nthat’s been introduced, point by point. Keep in mind that these concepts will be essen-\\ntial for you to understand the practical ex amples that will come in the following\\nchapters!\\n After reading this chapter, you’ll have  an intuitive understanding of how neural\\nnetworks work, and you’ll be able to move  on to practical ap plications—which will\\nstart with chapter 3.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 48}), Document(page_content='27 A first look at a neural network\\n2.1 A first look at a neural network\\nLet’s look at a concrete exam ple of a neural network that uses the Python library Keras\\nto learn to classify handwritten digits. Un less you already have ex perience with Keras\\nor similar libraries, you won’t understand everything about this first example right\\naway. You probably haven’t even installed Ke ras yet; that’s fine. In the next chapter,\\nwe’ll review each element in the example an d explain them in detail. So don’t worry if\\nsome steps seem arbitrary or  look like magic to you! We’ve got to start somewhere.\\n The problem we’re trying to solve here is to classify grayscale images of handwrit-\\nten digits (28 × 28 pixels) into their 10 categories (0 through 9). We’ll use the MNIST\\ndataset, a classic in the machine-learning  community, which has been around almost\\nas long as the field itself and has been inte nsively studied. It’s a set of 60,000 training\\nimages, plus 10,000 test images, assembled by  the National Institute of Standards and\\nTechnology (the NIST  in MNIST ) in the 1980s. You can think of “solving” MNIST  as the\\n“Hello World” of deep learning—it’s what you do to verify that your algorithms are\\nworking as expected. As you become a ma chine-learning practitioner, you’ll see\\nMNIST  come up over and over again, in scientific papers, blog posts, and so on. You\\ncan see some MNIST  samples in figure 2.1.\\nYou don’t need to try to reproduce this example on your machine just now. If you wish\\nto, you’ll first need to set up Kera s, which is covered in section 3.3.\\n The MNIST  dataset comes preloaded in Keras, in  the form of a set of four Numpy\\narrays.\\nfrom keras.datasets import mnist\\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\\ntrain_images  and train_labels  form the training set , the data that the model will\\nlearn from. The model will then be tested on the test set , test_images  and test_labels .Listing 2.1 Loading the MNIST dataset in KerasNote on classes and labels\\nIn machine learning, a category  in a classification problem is called a class. Data\\npoints are called samples . The class associated with a specific sample is called a\\nlabel.\\nFigure 2.1 MNIST sample digits\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 49}), Document(page_content=\"28 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nThe images are encoded as Numpy arrays, and the labels are an array of digits, ranging\\nfrom 0 to 9. The images and labels have a one-to-one correspondence.\\n Let’s look at the training data:\\n>>> train_images.shape\\n(60000, 28, 28)\\n>>> len(train_labels)60000\\n>>> train_labels\\narray([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\\nAnd here’s the test data:\\n>>> test_images.shape(10000, 28, 28)>>> len(test_labels)\\n10000\\n>>> test_labelsarray([7, 2, 1, ..., 4, 5, 6], dtype=uint8)\\nThe workflow will be as follow s: First, we’ll feed the neur al network the training data,\\ntrain_images  and train_labels . The network will then lear n to associate images and\\nlabels. Finally, we’ll ask the network to produce predictions for test_images , and we’ll\\nverify whether these predictions match the labels from test_labels .\\n Let’s build the network—agai n, remember that you aren’t expected to understand\\neverything about this example yet.\\nfrom keras import models\\nfrom keras import layers\\nnetwork = models.Sequential()\\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))network.add(layers.Dense(10, activation='softmax'))\\nThe core building block of neural networks is the layer, a data-processing module that\\nyou can think of as a filter for data. Some data goes in, and it comes out in a more use-\\nful form. Specifically, layers extract representations  out of the data fed into them—hope-\\nfully, representations that are more mean ingful for the problem at hand. Most of\\ndeep learning consists of chaining together  simple layers that will implement a form\\nof progressive data distillation . A deep-learning model is like a sieve for data process-\\ning, made of a succession of increasi ngly refined data filters—the layers.\\n Here, our network consists of a sequence of two Dense  layers, which are densely\\nconnected (also called fully connected ) neural layers. The second (and last) layer is a\\n10-way softmax  layer, which means it will return an array of 10 probability scores (sum-\\nming to 1). Each score will be the probabi lity that the current digit image belongs to\\none of our 10 digit classes.Listing 2.2 The network architecture\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 50}), Document(page_content=\"29 A first look at a neural network\\n To make the network ready for training, we  need to pick three more things, as part\\nof the compilation  step:\\n\\uf0a1A loss function —How the network will be able to measure its performance on\\nthe training data, and thus how it will be  able to steer itself in the right direc-\\ntion.\\n\\uf0a1An optimizer —The mechanism through which the network will update itself\\nbased on the data it se es and its loss function.\\n\\uf0a1Metrics to monitor during training and testing —Here, we’ll only care about accu-\\nracy (the fraction of the images that were correctly classified).\\nThe exact purpose of the loss function and the optimizer will be made clear through-\\nout the next two chapters.\\nnetwork.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nBefore training, we’ll preprocess the data by  reshaping it into the shape the network\\nexpects and scaling it so th at all values are in the [0, 1] interval. Previously, our train-\\ning images, for instance, were stored in an array of shape (60000,  28, 28) of type\\nuint8  with values in the [0, 255]  interval. We transform it into a float32  array of\\nshape (60000, 28 * 28)  with values between 0 and 1.\\ntrain_images = train_images.reshape((60000, 28 * 28))\\ntrain_images = train_images.astype('float32') / 255\\ntest_images = test_images.reshape((10000, 28 * 28))\\ntest_images = test_images.astype('float32') / 255\\nWe also need to categorically encode the la bels, a step that’s explained in chapter 3.\\nfrom keras.utils import to_categorical\\ntrain_labels = to_categorical(train_labels)\\ntest_labels = to_categorical(test_labels)\\nWe’re now ready to train the network, which in Keras is done via a call to the net-\\nwork’s fit method—we fit the model to its training data:\\n>>> network.fit(train_images, train_labels, epochs=5, batch_size=128)\\nEpoch 1/5\\n60000/60000 [==============================] - 9s - loss: 0.2524 - acc: 0.9273Epoch 2/5\\n51328/60000 [========================>.....] - ETA: 1s - loss: 0.1035 - acc: 0.9692Listing 2.3 The compilation step\\nListing 2.4 Preparing the image data\\nListing 2.5 Preparing the labels\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 51}), Document(page_content=\"30 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nTwo quantities are displayed during training: the loss of the network over the training\\ndata, and the accuracy of the network over the training data.\\n We quickly reach an accuracy of 0.989 (98.9%) on the training data. Now let’s\\ncheck that the model performs well on the test set, too:\\n>>> test_loss, test_acc = network.evaluate(test_images, test_labels)\\n>>> print('test_acc:', test_acc)test_acc: 0.9785\\nThe test-set accuracy turns out to be 97.8% —that’s quite a bit lower than the training\\nset accuracy. This gap between  training accuracy and test accuracy is an example of\\noverfitting : the fact that machine-learning mode ls tend to perform worse on new data\\nthan on their training data. Overfitting is a central topic in chapter 3.\\n This concludes our first example—you ju st saw how you can build and train a neu-\\nral network to classify handwritten digits in  less than 20 lines of Python code. In the\\nnext chapter, I’ll go into detail about ever y moving piece we just previewed and clarify\\nwhat’s going on behind the scenes. You’ll le arn about tensors, the data-storing objects\\ngoing into the network; tensor operations , which layers are made of; and gradient\\ndescent, which allows your network to  learn from its tr aining examples. \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 52}), Document(page_content='31 Data representations for neural networks\\n2.2 Data representations for neural networks\\nIn the previous example, we started from  data stored in multidimensional Numpy\\narrays, also called tensors . In general, all current machin e-learning systems use tensors\\nas their basic data structur e. Tensors are fundamental to  the field—so fundamental\\nthat Google’s TensorFlow was name d after them. So what’s a tensor?\\n At its core, a tensor is a container for data—almost always numerical data. So, it’s a\\ncontainer for numbers. You may be already familiar with matrices, which are 2D ten-\\nsors: tensors are a generalization of matric es to an arbitrary number of dimensions\\n(note that in the context of tensors, a dimension  is often called an axis).\\n2.2.1 Scalars (0D tensors)\\nA tensor that contains only one number is called a scalar  (or scalar tensor, or 0-dimensional\\ntensor, or 0D tensor). In Numpy, a float32  or float64  number is a scalar  tensor (or scalar\\narray). You can display the number of  axes of a Numpy tensor via the ndim  attribute; a sca-\\nlar tensor has 0 axes ( ndim == 0 ). The number of axes of a tensor is also called its rank.\\nHere’s a Numpy scalar:\\n>>> import numpy as np\\n>>> x = np.array(12)>>> xarray(12)>>> x.ndim\\n0\\n2.2.2 Vectors (1D tensors)\\nAn array of numbers is called a vector , or 1D tensor. A 1D tensor is said to have exactly\\none axis. Following is a Numpy vector:\\n>>> x = np.array([12, 3, 6, 14])\\n>>> x\\narray([12, 3, 6, 14])>>> x.ndim1\\nThis vector has five entr ies and so is called a 5-dimensional vector . Don’t confuse a 5D\\nvector with a 5D tensor! A 5D vector has only one axis and has five dimensions along its\\naxis, whereas a 5D tensor has five axes (and ma y have any number of dimensions\\nalong each axis). Dimensionality  can denote either the number of entries along a spe-\\ncific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a\\n5D tensor), which can be confusing at time s. In the latter case, it’s technically more\\ncorrect to talk about a tensor of rank 5  (the rank of a tensor being the number of axes),\\nbut the ambiguous notation 5D tensor  is common regardless. \\n2.2.3 Matrices (2D tensors)\\nAn array of vectors is a matrix , or 2D tensor. A matrix has two axes (often referred to\\nrows and columns ). You can visually interpret a matrix  as a rectangular grid of numbers.\\nThis is a Numpy matrix:\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 53}), Document(page_content='32 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\n>>> x = np.array([[5, 78, 2, 34, 0],\\n[6, 79, 3, 35, 1],\\n[7, 80, 4, 36, 2]])\\n>>> x.ndim\\n2\\nThe entries from the firs t axis are called the rows, and the entries from the second axis\\nare called the columns . In the previous example, [5, 78, 2, 34, 0] is the first row of x,\\nand [5, 6, 7] is the first column. \\n2.2.4 3D tensors and higher-dimensional tensors\\nIf you pack such matrices in a new array, you obtain a 3D tensor, which you can visually\\ninterpret as a cube of numb ers. Following is a Numpy 3D tensor:\\n>>> x = np.array([[[5, 78, 2, 34, 0],\\n[6, 79, 3, 35, 1],\\n[7, 80, 4, 36, 2]],\\n[[5, 78, 2, 34, 0],\\n[6, 79, 3, 35, 1],\\n[7, 80, 4, 36, 2]],\\n[[5, 78, 2, 34, 0],\\n[6, 79, 3, 35, 1],\\n[7, 80, 4, 36, 2]]])\\n>>> x.ndim3\\nBy packing 3D tensors in an array, you can create a 4D tensor, and so on. In deep learn-\\ning, you’ll generally manipulate tensors that are 0D to 4D, although you may go up to\\n5D if you process video data. \\n2.2.5 Key attributes\\nA tensor is defined by three key attributes:\\n\\uf0a1Number of axes (rank) —For instance, a 3D tensor has three axes, and a matrix has\\ntwo axes. This is also called the tensor’s ndim  in Python libraries such as Numpy.\\n\\uf0a1Shape —This is a tuple of integers that de scribes how many dimensions the ten-\\nsor has along each axis. For instance, the previous matrix example has shape\\n(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\\nwith a single element, such as (5,) , whereas a scalar has an empty shape, ().\\n\\uf0a1Data type  (usually called dtype  in Python libraries)—This is the type of the data\\ncontained in the tensor; for inst ance, a tensor’s type could be float32 , uint8 ,\\nfloat64 , and so on. On rare o ccasions, you may see a char  tensor. Note that\\nstring tensors don’t exist in Numpy (or in  most other libraries), because tensors\\nlive in preallocated, contiguous memory  segments: and strings, being variable\\nlength, would preclude the use of this implementation.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 54}), Document(page_content='33 Data representations for neural networks\\nTo make this more concrete, let’s look back at the data we processed in the MNIST\\nexample. First, we load the MNIST  dataset:\\nfrom keras.datasets import mnist\\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\\nNext, we display the number of axes of the tensor train_images , the ndim  attribute:\\n>>> print(train_images.ndim)\\n3\\nHere’s its shape:\\n>>> print(train_images.shape)\\n(60000, 28, 28)\\nAnd this is its data type, the dtype  attribute:\\n>>> print(train_images.dtype)\\nuint8\\nSo what we have here is a 3D tensor of 8-bit integers. More precisely, it’s an array of\\n60,000 matrices of 28 × 8 integers. Each such  matrix is a grayscale image, with coeffi-\\ncients between 0 and 255.\\n Let’s display the fourth digit in this 3D tensor, using the libra ry Matplotlib (part of\\nthe standard scientific Pyth on suite); see figure 2.2. \\ndigit = train_images[4]\\nimport matplotlib.pyplot as plt\\nplt.imshow(digit, cmap=plt.cm.binary)\\nplt.show()Listing 2.6 Displaying the fourth digit\\nFigure 2.2 The fourth sample in our dataset\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 55}), Document(page_content='34 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\n2.2.6 Manipulating tensors in Numpy\\nIn the previous example, we selected  a specific digit alongside the first axis using the\\nsyntax train_images[i] . Selecting specific elements in a tensor is called tensor slicing .\\nLet’s look at the tensor-slicing oper ations you can do on Numpy arrays.\\n The following example selects digits #10 to #100 (#100 isn’t included) and puts\\nthem in an array of shape (90, 28, 28) :\\n>>> my_slice = train_images[10:100]\\n>>> print(my_slice.shape)(90, 28, 28)\\nIt’s equivalent to this more detailed nota tion, which specifies a start index and stop\\nindex for the slice along each tensor axis. Note that : is equivalent to selecting the\\nentire axis:\\n>>> my_slice = train_images[10:100, :, :]\\n>>> my_slice.shape(90, 28, 28)>>> my_slice = train_images[10:100, 0:28, 0:28]>>> my_slice.shape(90, 28, 28)\\nIn general, you may select between any two indices along each tensor axis. For\\ninstance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you\\ndo this:\\nmy_slice = train_images[:, 14:, 14:]\\nIt’s also possible to use negative indices. Much like negative indices in Python lists,\\nthey indicate a position relative to the end of the current axis. In order to crop the\\nimages to patches of 14 × 14 pixels centered in the middle, you do this:\\nmy_slice = train_images[:, 7:-7, 7:-7]\\n2.2.7 The notion of data batches\\nIn general, the first axis (axis 0, because inde xing starts at 0) in all data tensors you’ll\\ncome across in deep learning will be the samples axis  (sometimes called the samples\\ndimension ). In the MNIST  example, samples are images of digits.\\n In addition, deep-learning models don’t pr ocess an entire dataset at once; rather,\\nthey break the data into small batches.  Concretely, here’s one batch of our MNIST  dig-\\nits, with batch size of 128:\\nbatch = train_images[:128]\\nAnd here’s the next batch:\\nbatch = train_images[128:256]\\nAnd the nth batch:\\nbatch = train_images[128 * n:128 * (n + 1)]Equivalent to the \\nprevious example\\nAlso equivalent to the \\nprevious example\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 56}), Document(page_content='35 Data representations for neural networks\\nWhen considering such a batch tensor, the first axis (axis 0) is called the batch axis  or\\nbatch dimension . This is a term you’ll frequently encounter when using Keras and other\\ndeep-learning libraries. \\n2.2.8 Real-world examples of data tensors\\nLet’s make data tensors more concrete wi th a few examples similar to what you’ll\\nencounter later. The data you’ll manipulate wi ll almost always fall into one of the fol-\\nlowing categories:\\n\\uf0a1Vector data —2D tensors of shape (samples,  features)\\n\\uf0a1Timeseries data or sequence data —3D tensors of shape (samples,  timesteps,\\nfeatures)\\n\\uf0a1Images —4D tensors of shape (samples,  height,  width,  channels)  or (samples,\\nchannels,  height,  width)\\n\\uf0a1Video —5D tensors of shape (samples, frames, height, width, channels)  or\\n(samples, frames, channels, height, width)\\n2.2.9 Vector data\\nThis is the most common case. In such a data set, each single data point can be encoded\\nas a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\\nvectors), where the first axis is the samples axis  and the second axis is the features axis .\\n Let’s take a look at two examples:\\n\\uf0a1An actuarial dataset of people, wher e we consider each person’s age, ZIP code,\\nand income. Each person can be characterized as a vector of 3 values, and thusan entire dataset of 100,000 people can be stored in a \\n2D tensor of shape\\n(100000, 3) .\\n\\uf0a1A dataset of text documents, where we represent each document by the counts\\nof how many times each word appears in it (out of a dictionary of 20,000 com-\\nmon words). Each document can be encode d as a vector of 20,000 values (one\\ncount per word in the dictionary), and th us an entire dataset of 500 documents\\ncan be stored in a tensor of shape (500,  20000) . \\n2.2.10 Timeseries data or sequence data\\nWhenever time matters in your data (or the notion of sequence order), it makes sense\\nto store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a\\nsequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D\\ntensor (see figure 2.3).\\nFeatures\\nTimestepsSamples\\nFigure 2.3 A 3D timeseries data tensor\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 57}), Document(page_content='36 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nThe time axis is always the second axis (axi s of index 1), by convention. Let’s look at a\\nfew examples:\\n\\uf0a1A dataset of stock prices. Every minute, we store the current price of the stock,\\nthe highest price in the past minute, an d the lowest price in the past minute.\\nThus every minute is encoded as a 3D vector, an entire day of trading is\\nencoded as a 2D tensor of shape (390,  3) (there are 390 minutes in a trading\\nday), and 250 days’ worth of data can be stored in a 3D tensor of shape (250,\\n390,  3). Here, each sample would be  one day’s worth of data.\\n\\uf0a1A dataset of tweets, where we encode each tweet as a sequence of 280 characters\\nout of an alphabet of 128 unique characters. In this setting, each character can\\nbe encoded as a binary vector of size 128  (an all-zeros vector except for a 1 entry\\nat the index corresponding to the character). Then each tweet can be encoded\\nas a 2D tensor of shape (280, 128) , and a dataset of 1 million tweets can be\\nstored in a tensor of shape (1000000, 280, 128) . \\n2.2.11 Image data\\nImages typically have three dimensions: he ight, width, and color depth. Although\\ngrayscale images (like our MNIST  digits) have only a single color channel and could\\nthus be stored in 2D tensors, by convention image tensors are always 3D, with a one-\\ndimensional color channel for grayscale im ages. A batch of 128 grayscale images of\\nsize 256 × 256 could thus be stored in a tensor of shape (128,  256,  256,  1), and a\\nbatch of 128 color images could be stored in a tensor of shape (128,  256,  256,  3)\\n(see figure 2.4).\\nThere are two conventions for shapes of images tensors: the channels-last  convention\\n(used by TensorFlow) and the channels-first  convention (used by Theano). The Tensor-\\nFlow machine-learning framework, from G oogle, places the color-depth axis at the\\nend: (samples, height, width, color_depth) . Meanwhile, Theano places the color\\ndepth axis right after the batch axis: (samples,  color_depth, height,  width) . WithColor channels\\nHeight\\nWidthSamples\\nFigure 2.4 A 4D image data \\ntensor (channels-first convention)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 58}), Document(page_content='37 Data representations for neural networks\\nthe Theano convention, the previous examples would become (128,  1, 256,  256)\\nand (128,  3, 256,  256) . The Keras framework provides support for both formats. \\n2.2.12 Video data\\nVideo data is one of the few types of real-world data for which you’ll need 5D tensors.\\nA video can be understood as a sequence of frames, each frame being a color image.\\nBecause each frame can be stored in a 3D tensor (height,  width,  color_depth) , a\\nsequence of frames can be stored in a 4D tensor (frames,  height,  width,  color_\\ndepth) , and thus a batch of differen t videos can be stored in a 5D tensor of shape\\n(samples,  frames,  height,  width,  color_depth) .\\n For instance, a 60-second, 144 × 256 YouTube video clip sampled at 4 frames per\\nsecond would have 240 frames. A batch of fo ur such video clips would be stored in a\\ntensor of shape (4, 240,  144,  256,  3). That’s a total of 106,168,320 values! If the\\ndtype  of the tensor was float32 , then each value would be stored in 32 bits, so the\\ntensor would represent 405 MB. Heavy! Vi deos you encounter in real life are much\\nlighter, because they aren’t stored in float32 , and they’re typically compressed by a\\nlarge factor (such as in the MPEG  format). \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 59}), Document(page_content=\"38 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\n2.3 The gears of neural ne tworks: tensor operations\\nMuch as any computer program can be ulti mately reduced to a small set of binary\\noperations on binary inputs ( AND, OR, NOR , and so on), all transformations learned\\nby deep neural networks can be reduced to a handful of tensor operations  applied to\\ntensors of numeric data. For instance, it’s possible to add tensor s, multiply tensors,\\nand so on.\\n In our initial example, we were building our network by stacking Dense  layers on\\ntop of each other. A Keras layer instance looks like this:\\nkeras.layers.Dense(512, activation='relu')\\nThis layer can be interpreted as a function, which takes as input a 2D tensor and\\nreturns another 2D tensor—a new representation for the input tensor. Specifically, the\\nfunction is as follows (where W is a 2D tensor and b is a vector, both attributes of the\\nlayer):\\noutput = relu(dot(W, input) + b)\\nLet’s unpack this. We have three tens or operations here: a dot product ( dot) between\\nthe input tensor and a tensor named W; an addition ( +) between the resulting 2D ten-\\nsor and a vector b; and, finally, a relu  operation. relu(x)  is max(x, 0) .\\nNOTE Although this section deals entirely with linear algebra expressions,\\nyou won’t find any mathematical notation here. I’ve found that mathematicalconcepts can be more readily mastered  by programmers with no mathemati-\\ncal background if they’re expressed as short Python snippets  instead of math-\\nematical equations. So we’ll use Numpy code throughout.\\n2.3.1 Element-wise operations\\nThe relu  operation and addition are element-wise  operations: operations that are\\napplied independently to each entry in the tensors being considered. This means\\nthese operations are highly amenable to massively parallel implementations ( vectorized\\nimplementations, a term that comes from the vector processor  supercomputer archi-\\ntecture from the 1970–1990 period). If you want to write a naive Python imple-\\nmentation of an element-wise operation, you use a for loop, as in this naive\\nimplementation of an element-wise relu  operation:\\ndef naive_relu(x):\\nassert len(x.shape) == 2\\nx = x.copy()\\nfor i in range(x.shape[0]):\\nfor j in range(x.shape[1]):\\nx[i, j] = max(x[i, j], 0)\\nreturn xx is a 2D Numpy tensor.\\nAvoid overwriting the input tensor.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 60}), Document(page_content='39 The gears of neural networks: tensor operations\\nYou do the same for addition:\\ndef naive_add(x, y):\\nassert len(x.shape) == 2assert x.shape == y.shape\\nx = x.copy()\\nfor i in range(x.shape[0]):\\nfor j in range(x.shape[1]):\\nx[i, j] += y[i, j]\\nreturn x\\nOn the same principle, you can do element-wi se multiplication, subtraction, and so on.\\n In practice, when dealing with Numpy arra ys, these operations are available as well-\\noptimized built-in Numpy func tions, which themselves delegate the heavy lifting to a\\nBasic Linear Algebra Subprograms ( BLAS ) implementation if you have one installed\\n(which you should). BLAS  are low-level, highly parallel, efficient tensor-manipulation\\nroutines that are typically implemented in Fortran or C.\\n So, in Numpy, you can do the following el ement-wise operation, and it will be blaz-\\ning fast:\\nimport numpy as np\\nz=x+yz = np.maximum(z, 0.)\\n2.3.2 Broadcasting\\nOur earlier naive implementation of naive_add  only supports the addition of 2D ten-\\nsors with identical shapes. But in the Dense  layer introduced earlier, we added a 2D\\ntensor with a vector. What happens with ad dition when the shapes of the two tensors\\nbeing added differ?\\n When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted  to\\nmatch the shape of the larger tensor. Broadcasting consists of two steps:\\n1Axes (called broadcast axes ) are added to the smaller tensor to match the ndim  of\\nthe larger tensor.\\n2The smaller tensor is repeated alongsid e these new axes to match the full shape\\nof the larger tensor.\\nLet’s look at a concre te example. Consider X with shape (32,  10) and y with shape\\n(10,) . First, we add an empty first axis to y, whose shape becomes (1, 10). Then, we\\nrepeat y 32 times alongside this new axis, so  that we end up with a tensor Y with shape\\n(32, 10) , where Y[i,  :] == y for i in range(0,  32). At this point, we can proceed to\\nadd X and Y, because they have the same shape.\\n In terms of implementation, no new 2D tensor is created, because that would be\\nterribly inefficient. The repetition operation is  entirely virtual: it happens at the algo-\\nrithmic level rather than at the memory level. But thinking of the vector beingx and y are 2D \\nNumpy tensors.\\nAvoid overwriting \\nthe input tensor.\\nElement-wise addition\\nElement-wise relu \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 61}), Document(page_content='40 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nrepeated 10 times alongside a new axis is a helpful mental model. Here’s what a naive\\nimplementation would look like:\\ndef naive_add_matrix_and_vector(x, y):\\nassert len(x.shape) == 2\\nassert len(y.shape) == 1\\nassert x.shape[1] == y.shape[0]\\nx = x.copy()\\nfor i in range(x.shape[0]):\\nfor j in range(x.shape[1]):\\nx[i, j] += y[j]\\nreturn x\\nWith broadcasting, you can generally apply tw o-tensor element-wise operations if one\\ntensor has shape (a, b, … n,  n + 1, … m)  and the other has shape (n, n + 1, … m) . The\\nbroadcasting will then automatically happen for axes a through n - 1.\\n The following example ap plies the element-wise maximum  operation to two tensors\\nof different shapes via broadcasting:\\nimport numpy as np\\nx = np.random.random((64, 3, 32, 10))\\ny = np.random.random((32, 10))\\nz = np.maximum(x, y)\\n2.3.3 Tensor dot\\nThe dot operation,  also called a tensor product  (not to be confused with an element-\\nwise product) is the most common, most  useful tensor operation. Contrary to\\nelement-wise operations, it combin es entries in the input tensors.\\n An element-wise product is done with the * operator in Numpy, Keras, Theano,\\nand TensorFlow. dot uses a different syntax in Te nsorFlow, but in both Numpy and\\nKeras it’s done using the standard dot operator:\\nimport numpy as np\\nz = np.dot(x, y)\\nIn mathematical notation, you’d note the operation with a dot ( .):\\nz=x.y\\nMathematically, what does the dot operatio n do? Let’s start with the dot product of\\ntwo vectors x and y. It’s computed as follows:\\ndef naive_vector_dot(x, y):\\nassert len(x.shape) == 1assert len(y.shape) == 1\\nassert x.shape[0] == y.shape[0]x is a 2D Numpy tensor.\\ny is a Numpy vector.\\nAvoid overwriting \\nthe input tensor.\\nx is a random tensor with \\nshape (64, 3, 32, 10).\\ny is a random tensor \\nwith shape (32, 10).\\nThe output z has shape \\n(64, 3, 32, 10) like x.\\nx and y are Numpy vectors.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 62}), Document(page_content='41 The gears of neural networks: tensor operations\\nz=0 .\\nfor i in range(x.shape[0]):\\nz += x[i] * y[i]\\nreturn z\\nYou’ll have noticed that the dot product betw een two vectors is a scalar and that only\\nvectors with the same number of elem ents are compatible  for a dot product.\\n You can also take the dot product between a matrix x and a vector y, which returns\\na vector where the coefficients are the dot products between y and the rows of x. You\\nimplement it as follows:\\nimport numpy as np\\ndef naive_matrix_vector_dot(x, y):\\nassert len(x.shape) == 2assert len(y.shape) == 1\\nassert x.shape[1] == y.shape[0]\\nz = np.zeros(x.shape[0])\\nfor i in range(x.shape[0]):\\nfor j in range(x.shape[1]):\\nz[i] += x[i, j] * y[j]\\nreturn z\\nYou could also reuse the code we wrote pr eviously, which highlights the relationship\\nbetween a matrix-vector product and a vector product:\\ndef naive_matrix_vector_dot(x, y):\\nz = np.zeros(x.shape[0])for i in range(x.shape[0]):\\nz[i] = naive_vector_dot(x[i, :], y)\\nreturn z\\nNote that as soon as one of the two tensors has an ndim  greater than 1, dot is no lon-\\nger symmetric, which is to say that dot(x, y)  isn’t the same as dot(y, x) .\\n Of course, a dot product generalizes to te nsors with an arbitrary number of axes.\\nThe most common applications may be th e dot product between two matrices. You\\ncan take the dot product of two matrices x and y (dot(x,  y)) if and only if\\nx.shape[1]  == y.shape[0] . The result is a matrix with shape (x.shape[0],\\ny.shape[1]) , where the coefficients are the vector products between the rows of x\\nand the columns of y. Here’s the naive implementation:\\ndef naive_matrix_dot(x, y):\\nassert len(x.shape) == 2\\nassert len(y.shape) == 2\\nassert x.shape[1] == y.shape[0]\\nz = np.zeros((x.shape[0], y.shape[1]))\\nfor i in range(x.shape[0]):\\nfor j in range(y.shape[1]):\\nrow_x = x[i, :]column_y = y[:, j]\\nz[i, j] = naive_vector_dot(row_x, column_y)\\nreturn zx is a Numpy matrix.\\ny is a Numpy vector.\\nThe first dimension of x must be the \\nsame as the 0th dimension of y!\\nThis operation returns a vector of \\n0s with the same shape as y.\\nx and y\\nare\\nNumpy\\nmatrices.The first dimension of x must be the \\nsame as the 0th dimension of y!\\nThis operation returns a matrix \\nof 0s with a specific shape.\\nIterates over the rows of x …\\n… and over the columns of y.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 63}), Document(page_content='42 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nTo understand dot-product shape compatibility , it helps to visualize the input and out-\\nput tensors by aligning them as shown in figure 2.5.\\nx, y, and z are pictured as rectangl es (literal boxes of coefficients). Because the rows\\nand x and the columns of y must have the same size, it follows that the width of x must\\nmatch the height of y. If you go on to develop ne w machine-learning algorithms,\\nyou’ll likely be drawing such diagrams often.\\n More generally, you can take the dot pr oduct between higher-dimensional tensors,\\nfollowing the same rules for shape compatibi lity as outlined earlier for the 2D case:\\n(a, b, c, d) . (d,) -> (a, b, c)\\n(a, b, c, d) . (d, e) -> (a, b, c, e)\\nAnd so on. \\n2.3.4 Tensor reshaping\\nA third type of tensor operation that’s essential to understand is tensor reshaping .\\nAlthough it wasn’t used in the Dense  layers in our first neural network example, we\\nused it when we preprocessed the digits data before feeding it into our network:\\ntrain_images = train_images.reshape((60000, 28 * 28))\\nReshaping a tensor means rearranging its ro ws and columns to match a target shape.\\nNaturally, the reshaped tensor  has the same total number of coefficients as the initial\\ntensor. Reshaping is best unde rstood via simple examples:\\n>>> x = np.array([[0., 1.],\\n[2., 3.],\\n[4., 5.]])\\n>>> print(x.shape)(3, 2)abx . y = z\\nb\\nx.shape:\\n(a, b)y.shape:\\n(b, c)\\nz.shape:\\n(a, c)\\nRow of xColumn of y\\nz [ i,  j ]c\\nFigure 2.5 Matrix dot-product box diagram\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 64}), Document(page_content='43 The gears of neural networks: tensor operations\\n>>> x = x.reshape((6, 1))\\n>>> x\\narray([[ 0.],\\n[ 1.],\\n[ 2.],\\n[ 3.],[ 4.],\\n[ 5.]])\\n>>> x = x.reshape((2, 3))\\n>>> x\\narray([[ 0., 1., 2.],\\n[ 3., 4., 5.]])\\nA special case of reshaping th at’s commonly encountered is transposition . Transposing  a\\nmatrix means exchanging its ro ws and its columns, so that x[i,  :] becomes x[:,  i]:\\n>>> x = np.zeros((300, 20))\\n>>> x = np.transpose(x)\\n>>> print(x.shape)\\n(20, 300)\\n2.3.5 Geometric interpretation of tensor operations\\nBecause the contents of the tensors manipu lated by tensor operations can be inter-\\npreted as coordinates of points in some ge ometric space, all tens or operations have a\\ngeometric interpretation. For instance, let’s consider addition. We’ll start with the fol-\\nlowing vector:\\nA = [0.5, 1]\\nIt’s a point in a 2D space (see figure 2.6). It’s commo n to picture a vector as an arrow\\nlinking the origin to the point, as shown in figure 2.7.Creates an all-zeros matrix \\nof shape (300, 20) \\n1\\n1A [0.5, 1]\\nFigure 2.6 A point in a 2D space1\\n1A [0.5, 1]\\nFigure 2.7 A point in a 2D space \\npictured as an arrow\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 65}), Document(page_content='44 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nLet’s consider a new point, B = [1, 0.25] , which we’ll add to the previous one. This is\\ndone geometrically by chaining together th e vector arrows, with the resulting location\\nbeing the vector representing the sum of th e previous two vectors (see figure 2.8).\\nIn general, elementary geometric operations such as affine transformations, rotations,\\nscaling, and so on can be ex pressed as tensor operations. For instance, a rotation of a\\n2D vector by an angle theta can be achiev ed via a dot product with a 2 × 2 matrix\\nR=[ u ,  v], where u and v are both vectors of the plane: u = [cos(theta),\\nsin(theta)]  and v = [-sin(theta),  cos(theta)] . \\n2.3.6 A geometric interpre tation of deep learning\\nYou just learned that neural networks consist entirely of chains of tensor operations and\\nthat all of these tensor operations are just  geometric transformations of the input data.\\nIt follows that you can interp ret a neural network as a very  complex geometric transfor-\\nmation in a high-dimensional space, implem ented via a long series of simple steps.\\n In 3D, the following mental image may prove useful. Imagine two sheets of colored\\npaper: one red and one blue. Put one on  top of the other. Now crumple them\\ntogether into a small ball. That crumpled pa per ball is your input data, and each sheet\\nof paper is a class of data in a classifica tion problem. What a neural network (or any\\nother machine-learning model) is meant to do is figure out a transformation of the\\npaper ball that would uncrumple it, so as to make the two classes cleanly separable\\nagain. With deep learning, this would be im plemented as a series of simple transfor-\\nmations of the 3D space, such as those you could apply on the paper ball with your fin-\\ngers, one movement at a time.1\\n1A\\nBA + B\\nFigure 2.8 Geometric interpretation of \\nthe sum of two vectors\\nFigure 2.9 Uncrumpling a \\ncomplicated manifold of data\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 66}), Document(page_content='45 The gears of neural networks: tensor operations\\nUncrumpling paper balls is what machine lear ning is about: find ing neat representa-\\ntions for complex, highly folded data mani f o l d s .  A t  t h i s  p o i n t ,  y o u  s h o u l d  h a v e  a\\npretty good intuition as to why deep learni ng excels at this: it takes the approach of\\nincrementally decomposing a complicated geometric transformation into a longchain of elementary ones, which is pretty much the strategy a human would follow to\\nuncrumple a paper ball. Each layer in a d eep network applies a transformation that\\ndisentangles the data a little —and a deep stack of layers makes tractable an extremely\\ncomplicated disentan glement process. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 67}), Document(page_content='46 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\n2.4 The engine of neural networks: \\ngradient-based optimization\\nAs you saw in the previous section, each neural layer from our first network example\\ntransforms its input data as follows:\\noutput = relu(dot(W, input) + b)\\nIn this expression, W and b are tensors that are attributes  of the layer. They’re called\\nthe weights  or trainable parameters  of the layer (the kernel  and bias  attributes, respec-\\ntively). These weights contain the informat ion learned by the network from exposure\\nto training data.\\n Initially, these weight matrices are filled with small random values (a step called ran-\\ndom initialization ). Of course, there’s no reason to expect that relu(dot(W,  input)  + b),\\nwhen W and b are random, will yield any useful re presentations. The resulting represen-\\ntations are meaningless—but they’re a starting  point. What comes ne xt is to gradually\\nadjust these weights, based on a feedback signal. This gradual ad justment, also called\\ntraining , is basically the learning that  machine learning is all about.\\n This happens within what’s called a training loop , which works as follows. Repeat\\nthese steps in a loop, as long as necessary:\\n1Draw a batch of training samples x and corresponding targets y.\\n2Run the network on x (a step called the forward pass ) to obtain predictions y_pred .\\n3Compute the loss of the network on the batch, a measure of the mismatch\\nbetween y_pred  and y.\\n4Update all weights of the network in a wa y that slightly reduces the loss on this\\nbatch.\\nYou’ll eventually end up with a network that has a very low loss on its training data: a\\nlow mismatch between predictions y_pred  and expected targets y. The network has\\n“learned” to map its inputs to correct target s. From afar, it may look like magic, but\\nwhen you reduce it to elementary steps, it turns out to be simple.\\n Step 1 sounds easy enough—just I/O code. Steps 2 and 3 are merely the applica-\\ntion of a handful of tensor operations, so you could implement these steps purely\\nfrom what you learned in the previous section. The difficult part is step 4: updating\\nthe network’s weights. Given an individual weight coefficient in the network, how can\\nyou compute whether the coefficient should be increased or decreased, and by how\\nmuch?\\n One naive solution would be to freeze al l weights in the network except the one\\nscalar coefficient being consid ered, and try different values for this coefficient. Let’s\\nsay the initial value of the coefficient is 0. 3. After the forward pass on a batch of data,\\nthe loss of the network on the batch is 0.5. If you change the coefficient’s value to 0.35\\nand rerun the forward pass, the loss increases to 0.6. But if you lower the coefficient to\\n0.25, the loss falls to 0.4. In this case, it seems that updating the coefficient by -0.05\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 68}), Document(page_content=\"47 The engine of neural networks: gradient-based optimization\\nwould contribute to minimizing  the loss. This would have to be repeated for all coeffi-\\ncients in the network.\\n But such an approach would be horribly  inefficient, because you’d need to com-\\npute two forward passes (which are expensiv e) for every individual coefficient (of\\nwhich there are many, usually thousands an d sometimes up to millions). A much bet-\\nter approach is to take advantage of the fa ct that all operations used in the network\\nare differentiable , and compute the gradient  of the loss with regard to the network’s\\ncoefficients. You can then move the coeffici ents in the opposite direction from the\\ngradient, thus de creasing the loss.\\n If you already know what differentiable  means and what a gradient  is, you can skip to\\nsection 2.4.3. Otherwise, the following two sections will help you understand these\\nconcepts.\\n2.4.1 What’s a derivative?\\nConsider a continuous, smooth function f(x) = y , mapping a real number x to a new\\nreal number y. Because the function is continuous , a small change in x can only result\\nin a small change in y—that’s the intuition behind cont inuity. Let’s say you increase x\\nby a small factor epsilon_x : this results in a small epsilon_y  change to y:\\nf(x + epsilon_x) = y + epsilon_y\\nIn addition, because the function is smooth  (its curve doesn’t ha ve any abrupt angles),\\nwhen epsilon_x  is small enough, around a certain point p, it’s possible to approxi-\\nmate f as a linear function of slope a, so that epsilon_y  becomes a * epsilon_x :\\nf(x + epsilon_x) = y + a * epsilon_x\\nObviously, this linear approximation is valid only when x is close enough to p.\\n The slope a is called the derivative  of f in p. If a is negative, it means a small change\\nof x around p will result in a decrease of f(x)  (as shown in figure 2.10); and if a is pos-\\nitive, a small change in x will result in an increase of f(x) . Further, the absolute value\\nof a (the magnitude  of the derivative) tells you how quickly this increase or decrease\\nwill happen.\\nFor every differentiable function f(x)  (differentiable  means “can be de rived”: for exam-\\nple, smooth, continuous functions can be de rived), there exists a derivative function\\nf'(x)  that maps values of x to the slope of the local linear approximation of f in thoseLocal linear\\napproximation of f,\\nwith slope a\\nfFigure 2.10 Derivative of f in p\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 69}), Document(page_content=\"48 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\npoints. For instance, the derivative of cos(x)  is -sin(x) , the derivative of f(x)  = a * x\\nis f'(x)  = a, and so on.\\n If you’re trying to update x by a factor epsilon_x  in order to minimize f(x) , and\\nyou know the derivative of f, then your job is done: the derivative completely\\ndescribes how f(x)  evolves as you change x. If you want to reduce the value of f(x) ,\\nyou just need to move x a little in the opposite direction from the derivative. \\n2.4.2 Derivative of a tensor  operation: the gradient\\nA gradient  is the derivative of a tensor operatio n. It’s the generalization of the concept\\nof derivatives to functions of multidimension al inputs: that is, to functions that take\\ntensors as inputs.\\n Consider an input vector x, a matrix W, a target y, and a loss function loss . You can\\nuse W to compute a target candidate y_pred , and compute the loss, or mismatch,\\nbetween the target candidate y_pred  and the target y:\\ny_pred = dot(W, x)\\nloss_value = loss(y_pred, y)\\nIf the data inputs x and y are frozen, then this can be interpreted as a function map-\\nping values of W to loss values:\\nloss_value = f(W)\\nLet’s say the current value of W is W0. Then the derivative of f in the point W0 is a tensor\\ngradient(f)(W0)  with the same shape as W, where each coefficient gradient(f)\\n(W0)[i,  j] indicates the direction and magnitude of the change in loss_value  you\\nobserve when modifying W0[i,  j]. That tensor gradient(f)(W0)  is the gradient of\\nthe function f(W)  = loss_value  in W0.\\n You saw earlier that the derivative of a function f(x)  of a single coefficient can be\\ninterpreted as the slope of the curve of f. Likewise, gradient(f)(W0)  can be inter-\\npreted as the tensor describing the curvature  of f(W)  around W0.\\n For this reason, in much the same way that, for a function f(x) , you can reduce\\nthe value of f(x)  by moving x a little in the opposite direction from the derivative,\\nwith a function f(W)  of a tensor, you can reduce f(W)  by moving W in the opposite\\ndirection from the gradient: for example, W1 = W0 - step  * gradient(f)(W0)  (where\\nstep  is a small scaling factor). That means going against the curvature, which intui-\\ntively should put you lower on the cu rve. Note that the scaling factor step  is needed\\nbecause gradient(f)(W0)  only approximates the curv ature when you’re close to W0,\\nso you don’t want to get too far from W0. \\n2.4.3 Stochastic gradient descent\\nGiven a differentiable function, it’s theoreti cally possible to find its minimum analyti-\\ncally: it’s known that a function’s minimum is  a point where the derivative is 0, so all\\nyou have to do is find all the points where the derivative goes to 0 and check for which\\nof these points the function has the lowest value.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 70}), Document(page_content='49 The engine of neural networks: gradient-based optimization\\n Applied to a neural network, that mean s finding analytically the combination of\\nweight values that yields the smallest possibl e loss function. This can be done by solv-\\ning the equation gradient(f)(W)  = 0 for W. This is a polynomial equation of N vari-\\nables, where N is the number of coefficients in the network. Although it would be\\npossible to solve such  an equation for N = 2 or N = 3, doing so is intractable for real\\nneural networks, where the number of para meters is never less than a few thousand\\nand can often be several tens of millions.\\n Instead, you can use the four-step algorith m outlined at the beginning of this sec-\\ntion: modify the parameters little by littl e based on the current loss value on a ran-\\ndom batch of data. Because you’re dealing with a differentiable function, you can\\ncompute its gradient, which gives you an efficient way to implement step 4. If you\\nupdate the weights in the opposite direction from the gradient, the loss will be a little\\nless every time:\\n1Draw a batch of training samples x and corresponding targets y.\\n2Run the network on x to obtain predictions y_pred .\\n3Compute the loss of the network on the batch, a measure of the mismatchbetween \\ny_pred  and y.\\n4Compute the gradient of the loss with regard to the network’s parameters (abackward pass ).\\n5Move the parameters a little in the o pposite direction from the gradient—for\\nexample W -= step * gradient —thus reducing the loss on the batch a bit.\\nEasy enough! What I just described is called mini-batch stochastic gradient descent  (mini-\\nbatch SGD). The term stochastic  refers to the fact that each batch of data is drawn at\\nrandom ( stochastic  is a scientific synonym of random ). Figure 2.11 illustrates what hap-\\npens in 1D, when the network has only one parameter and you have only one training\\nsample.\\nLoss\\nvalueStartingpoint (t=0)Step, also called learning rate\\nt=1\\nt=2\\nt=3\\nParameter\\nvalueFigure 2.11 SGD down a 1D loss \\ncurve (one learnable parameter)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 71}), Document(page_content='50 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\nAs you can see, intuitively it’s important to pick a reasonable value for the step  factor.\\nIf it’s too small, the descent down the curv e will take many iterations, and it could get\\nstuck in a local minimum. If step  is too large, your updates may end up taking you to\\ncompletely random locations on the curve.\\n Note that a variant of the mini-batch SGD algorithm would be to  draw a single sam-\\nple and target at each iteration, rather than drawing a batch of data. This would be\\ntrue SGD (as opposed to mini-batch  SGD). Alternatively, going to the opposite extreme,\\nyou could run every step on all data available, which is called batch SGD. Each update\\nwould then be more accurate, but far mo re expensive. The efficient compromise\\nbetween these two extremes is to us e mini-batches of reasonable size.\\n Although figure 2.11 illustr ates gradient descent in a 1D parameter space, in prac-\\ntice you’ll use gradient descent in highly dimensional spaces: every weight coefficient\\nin a neural network is a free dimension in the space, and there may be tens of thou-\\nsands or even millions of them. To help you build intuition about loss surfaces, you\\ncan also visualize gradient descent along a 2D loss surface, as shown in figure 2.12. But\\nyou can’t possibly visualize what the actual process of training a neural network looks\\nlike—you can’t represent a 1,000,000-dimensional space in a way that makes sense to\\nhumans. As such, it’s good to keep in mi nd that the intuitions you develop through\\nthese low-dimensional representations may no t always be accurate in practice. This\\nhas historically been a source of issues  in the world of deep-learning research.\\nAdditionally, there exist multiple variants of SGD that differ by taking into account\\nprevious weight updates when computing the next weight update, rather than just\\nlooking at the current value of the gradients. There is, for instance, SGD with momen-\\ntum, as well as Adagrad, RMSP rop, and several others. Such variants are known as opti-\\nmization methods  or optimizers . In particular, the concept of momentum , which is used in\\nmany of these variants, deserves your atte ntion. Momentum addr esses two issues with\\nSGD: convergence speed and local minima. Co nsider figure 2.13, which shows the\\ncurve of a loss as a functi on of a network parameter.\\nStarting point\\nFinal point45\\n40\\n35\\n30\\n25\\n20\\n15\\n10\\n5\\nFigure 2.12 Gradient descent \\ndown a 2D loss surface (two learnable parameters)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 72}), Document(page_content=\"51 The engine of neural networks: gradient-based optimization\\nAs you can see, around a certai n parameter value, there is a local minimum : around\\nthat point, moving left would result in th e loss increasing, but so  would moving right.\\nIf the parameter under consideration were being optimized via SGD with a small\\nlearning rate, then the optimization proc ess would get stuck at the local minimum\\ninstead of making its wa y to the global minimum.\\n You can avoid such issues by using mome ntum, which draws inspiration from phys-\\nics. A useful mental image he re is to think of the optimization process as a small ball\\nrolling down the loss curve. If it has enou gh momentum, the ball won’t get stuck in a\\nravine and will end up at the global mini mum. Momentum is implemented by moving\\nthe ball at each step based not only on th e current slope value (current acceleration)\\nbut also on the current velocity (resulting from past acceleration). In practice, this\\nmeans updating the parameter w based not only on the current gradient value but also\\non the previous parameter update, such as in this naive implementation:\\npast_velocity = 0.\\nmomentum = 0.1\\nwhile loss > 0.01:\\nw, loss, gradient = get_current_parameters()velocity = past_velocity * momentum + learning_rate * gradient\\nw=w+ momentum * velocity - learning_rate * gradient\\npast_velocity = velocityupdate_parameter(w)\\n2.4.4 Chaining derivatives: the Backpropagation algorithm\\nIn the previous algorithm, we casually assu med that because a function is differentia-\\nble, we can explicitly compute its derivative. In practice, a neural network function\\nconsists of many tensor operations chai ned together, each of which has a simple,\\nknown derivative. For instance, this is a network f composed of three tensor opera-\\ntions, a, b, and c, with weight matrices W1, W2, and W3:\\nf(W1, W2, W3) = a(W1, b(W2, c(W3)))\\nCalculus tells us that such a chain of functions can be derived using the following iden-\\ntity, called the chain rule : f(g(x)) = f'(g(x)) * g'(x) . Applying the chain rule to the\\ncomputation of the gradient values of a ne ural network gives rise to an algorithmLoss\\nvalue\\nParameter\\nvalueLocal\\nminimum\\nGlobal\\nminimum\\nFigure 2.13 A local minimum \\nand a global minimum\\nConstant momentum factor\\nOptimization loop \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 73}), Document(page_content='52 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\ncalled Backpropagation  (also sometimes called reverse-mode differentiation ). Backpropaga-\\ntion starts with the final loss value and work s backward from the top layers to the bot-\\ntom layers, applying the chain rule to com pute the contribution that each parameter\\nhad in the loss value.\\n Nowadays, and for years to come, peop le will implement networks in modern\\nframeworks that are capable of symbolic differentiation , such as TensorFlow. This means\\nthat, given a chain of operat ions with a known derivative , they can compute a gradient\\nfunction  for the chain (by applying the chain ru le) that maps network parameter values\\nto gradient values. When you have access to such a function, the backward pass is\\nreduced to a call to this gradient function . Thanks to symbolic differentiation, you’ll\\nnever have to implement the Backpropagatio n algorithm by hand. For this reason, we\\nwon’t waste your time and your focus on de riving the exact formulation of the Back-\\npropagation algorithm in these pages. All you need is a good understanding of how\\ngradient-based opti mization works. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 74}), Document(page_content=\"53 Looking back at our first example\\n2.5 Looking back at our first example\\nYou’ve reached the end of this chapter, and you should now have a general under-\\nstanding of what’s going on behind the scenes in a neural network. Let’s go back tothe first example and review each  piece of it in the light of what you’ve learned in the\\nprevious three sections.\\n This was the input data:\\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\\ntrain_images = train_images.reshape((60000, 28 * 28))\\ntrain_images = train_images.astype('float32') / 255\\ntest_images = test_images.reshape((10000, 28 * 28))\\ntest_images = test_images.astype('float32') / 255\\nNow you understand that the input images are stored in Numpy tensors, which are\\nhere formatted as float32  tensors of shape (60000,  784)  (training data) and (10000,\\n784)  (test data), respectively.\\n This was our network:\\nnetwork = models.Sequential()\\nnetwork.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\\nnetwork.add(layers.Dense(10, activation='softmax'))\\nNow you understand that this network consists of a chain of two Dense  layers, that\\neach layer applies a few simp le tensor operations to the input data, and that these\\noperations involve weight tensors. Weight te nsors, which are attributes of the layers,\\nare where the knowledge  of the network persists.\\n This was the network-compilation step:\\nnetwork.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nNow you understand that categorical_crossentropy  is the loss function that’s used\\nas a feedback signal for learning the weight  tensors, and which the training phase will\\nattempt to minimize. You also know that th is reduction of the loss happens via mini-\\nbatch stochastic gradient desc ent. The exact rules governin g a specific use of gradient\\ndescent are defined by the rmsprop  optimizer passed as the first argument.\\n Finally, this was the training loop:\\nnetwork.fit(train_images, train_labels, epochs=5, batch_size=128)\\nNow you understand what happens when you call fit: the network will start to iterate\\non the training data in mini-batches of 128  samples, 5 times over (each iteration over\\nall the training data is called an epoch ). At each iteration, the network will compute the\\ngradients of the weights with regard to th e loss on the batch, and update the weights\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 75}), Document(page_content='54 CHAPTER  2Before we begin: the mathematical building blocks of neural networks\\naccordingly. After these 5 epochs, the network will have performed 2,345 gradient\\nupdates (469 per epoch), and the loss of the network will be sufficiently low that the\\nnetwork will be capable of classifying handwritten digits with high accuracy.\\n At this point, you already know most of what there is to know about neural networks.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 76}), Document(page_content='55 Looking back at our first example\\nChapter summary\\n\\uf0a1Learning  means finding a combination of model parameters that mini-\\nmizes a loss function for a given set of  training data samples and their cor-\\nresponding targets.\\n\\uf0a1Learning happens by drawing random batches of data samples and theirtargets, and computing the gradient  of the network parameters with\\nrespect to the loss on the batch. The network parameters are then moved\\na bit (the magnitude of the move is defined by the learning rate) in the\\nopposite direction from the gradient.\\n\\uf0a1The entire learning process is made possible by the fact that neural net-\\nworks are chains of differentiable tens or operations, and thus it’s possible\\nto apply the chain rule of derivation  to find the gradient function map-\\nping the current parameters and curren t batch of data to a gradient value.\\n\\uf0a1Two key concepts you’ll see frequently in future chapters are loss and opti-\\nmizers . These are the two things you need to define before you begin feed-\\ning data into a network.\\n\\uf0a1The loss is the quantity you’ll attempt to minimize during training, so it\\nshould represent a measure of success for the task you’re trying to solve.\\n\\uf0a1The optimizer  specifies the exact way in which the gradient of the loss will\\nbe used to update parameters: for instance, it could be the RMSP rop opti-\\nmizer, SGD with momentum, and so on.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 77}), Document(page_content='56Getting started\\nwith neural networks\\nThis chapter is designed to get you starte d with using neural networks to solve real\\nproblems. You’ll consolidate the knowledg e you gained from our first practical\\nexample in chapter 2, and you’ll apply wh at you’ve learned to three new problems\\ncovering the three most common use cases of neural networks: binary classifica-\\ntion, multiclass classificati on, and scalar regression.\\n In this chapter, we’ll take a closer look  at the core components of neural networks\\nthat we introduced in chapter 2: layers, networks, objective functions, and optimiz-\\ners. We’ll give you a quick introduction to Keras, the Python deep-learning library\\nthat we’ll use throughout the book. You’ll  set up a deep-learning workstation, withThis chapter covers\\n\\uf0a1Core components of neural networks\\n\\uf0a1An introduction to Keras\\n\\uf0a1Setting up a deep-learning workstation\\n\\uf0a1Using neural networks to solve basic \\nclassification and regression problems\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 78}), Document(page_content='57\\nTensorFlow, Keras, and GPU support. We’ll dive into th ree introductory examples of\\nhow to use neural networks to address real problems: \\n\\uf0a1Classifying movie reviews as positive or negative  (binary classification) \\n\\uf0a1Classifying news wires by topic (multiclass classification) \\n\\uf0a1Estimating the price of a house, given real-estate data (regression)\\nBy the end of this chapter, you’ll be ab le to use neural networks to solve simple\\nmachine problems such as classification and regression over vector data. You’ll then\\nbe ready to start building a more principled, theory-driven understanding of machine\\nlearning in chapter 4.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 79}), Document(page_content=\"58 CHAPTER  3Getting started with neural networks\\n3.1 Anatomy of a neural network\\nAs you saw in the previous chapters, training  a neural network revolves around the fol-\\nlowing objects:\\n\\uf0a1Layers , which are combined into a network  (or model )\\n\\uf0a1The input data  and corresponding targets\\n\\uf0a1The loss function , which defines the feedback  signal used  for learning\\n\\uf0a1The optimizer , which determines how learning proceeds\\nYou can visualize their interaction as illust rated in figure 3.1: the network, composed\\nof layers that are chained to gether, maps the input data to predictions. The loss func-\\ntion then compares these predictions to th e targets, producing a loss value: a measure\\nof how well the network’s pr edictions match what was ex pected. The optimizer uses\\nthis loss value to update the network’s weights.\\nLet’s take a closer look at layers, ne tworks, loss functions, and optimizers.\\n3.1.1 Layers: the building blocks of deep learning\\nThe fundamental data structure in neural networks is the layer, to which you were\\nintroduced in chapter 2. A layer is a data-p rocessing module that takes as input one or\\nmore tensors and that output s one or more tensors. Some  layers are stateless, but\\nmore frequently layers have a state: the layer’s weights , one or several tensors learned\\nwith stochastic gradient  descent, which together  contain the network’s knowledge .\\n Different layers are appropriate for different  tensor formats and different types of data\\nprocessing. For instance, simple vector data, stored in 2D tensors of shape (samples,\\nfeatures) , is often processed by densely connected  layers, also called fully connected  or dense\\nlayers (the Dense  class in Keras). Sequence data, stored in 3D tensors of shape (samples,\\ntimesteps,  features) , is typically processed by recurrent  l a y e r s  s u c h  a s  a n  LSTM  layer.\\nImage data, stored in 4D tensors, is usually processed by 2D convolution layers ( Conv2D ).Layer\\n(data transformation)Input X\\nWeights\\nLayer\\n(data transformation)\\nPredictions\\nY'Weight\\nupdateTrue targets\\nYWeights\\nLoss function Optimizer\\nLoss scoreFigure 3.1 Relationship between the \\nnetwork, layers, loss function, and optimizer\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 80}), Document(page_content='59 Anatomy of a neural network\\n You can think of layers as the LEGO  bricks of deep learning, a metaphor that is\\nmade explicit by frameworks like Keras. Building deep-learning models in Keras is\\ndone by clipping together compatible layers  to form useful data-transformation pipe-\\nlines. The notion of layer compatibility  here refers specifically to  the fact that every layer\\nwill only accept input tensors of a certain sh ape and will return ou tput tensors of a cer-\\ntain shape. Consider the following example:\\nfrom keras import layers\\nlayer = layers.Dense(32, input_shape=(784,))\\nWe’re creating a layer that will only accept as input 2D tensors where the first dimen-\\nsion is 784 (axis 0, the batch dimension, is unspecified, and thus any value would beaccepted). This layer will return a tensor  where the first dimension has been trans-\\nformed to be 32.\\n Thus this layer can only be connected to a downstream layer that expects 32-\\ndimensional vectors as its input. When us ing Keras, you don’t have to worry about\\ncompatibility, because the layers you add to your models are dynamically built to\\nmatch the shape of the incoming layer. Fo r instance, suppose you write the following:\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, input_shape=(784,)))\\nmodel.add(layers.Dense(32))\\nThe second layer didn’t receive an input shape argument—instead , it automatically\\ninferred its input shape as being the outp ut shape of the layer that came before. \\n3.1.2 Models: networks of layers\\nA deep-learning model is a directed, ac yclic graph of layers. The most common\\ninstance is a linear stack of layers, ma pping a single input to a single output.\\n But as you move forward, you’ll be exposed to a much  broader variety of network\\ntopologies. Some common ones include the following:\\n\\uf0a1Two-branch networks\\n\\uf0a1Multihead networks\\n\\uf0a1Inception blocks\\nThe topology of a network defines a hypothesis space . You may remember that in chap-\\nter 1, we defined machine learning as “sea rching for useful representations of some\\ninput data, within a predefined space of po ssibilities, using guid ance from a feedback\\nsignal.” By choosing a networ k topology, you constrain your space of possibilities\\n(hypothesis space) to a specif ic series of tensor operatio ns, mapping input data to out-\\nput data. What you’ll then be searching for is  a good set of values for the weight ten-\\nsors involved in these tensor operations.A dense layer with 32 \\noutput units\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 81}), Document(page_content='60 CHAPTER  3Getting started with neural networks\\n Picking the right network ar chitecture is more an art than a science; and although\\nthere are some best practices and principles you can rely on, only practice can help\\nyou become a proper neural-network architec t. The next few chapters will both teach\\nyou explicit principles for building neural networks and help yo u develop intuition as\\nto what works or doesn’t wo rk for specific problems. \\n3.1.3 Loss functions and optimizers: \\nkeys to config uring the learning process\\nOnce the network architecture is defined, you still have to choose two more things:\\n\\uf0a1Loss function (objective function) —The quantity that will be minimized during\\ntraining. It represents a measure of success for the task at hand.\\n\\uf0a1Optimizer —Determines how the network will be  updated based on the loss func-\\ntion. It implements a specific varian t of stochastic gradient descent ( SGD).\\nA neural network that has mu ltiple outputs may have multiple loss functions (one per\\noutput). But the gradient-descent  process must be based on a single  scalar loss value;\\nso, for multiloss networks, all losses are combin ed (via averaging) into a single scalar\\nquantity.\\n Choosing the right objective function fo r the right problem is extremely import-\\nant: your network will take any shortcut it ca n, to minimize the loss; so if the objective\\ndoesn’t fully correlate with success for the task at hand, your network will end up\\ndoing things you may not have want ed. Imagine a stupid, omnipotent AI trained via\\nSGD, with this poorly chosen objective fu nction: “maximizing the average well-being\\nof all humans alive.” To make its job easier, this AI might choose to kill all humans\\nexcept a few and focus on the well-being  of the remaining ones—because average\\nwell-being isn’t affected by how many humans are left. That might not be what you\\nintended! Just remember that all neural networks you build will be just as ruthless in\\nlowering their loss function—so choose the objective wisely, or you’ll have to face\\nunintended side effects.\\n Fortunately, when it come s to common problems such as classification, regression,\\nand sequence prediction, ther e are simple guidelines you can follow to choose the\\ncorrect loss. For instance, you’ll use binary  crossentropy for a tw o-class classification\\nproblem, categorical crossentropy for a many-class classification problem, mean-\\nsquared error for a regressi on problem, connectionist temporal classification ( CTC)\\nfor a sequence-learning problem, and so on. Only when you’re working on truly new\\nresearch problems will you have to develop your ow n objective functions. In the next\\nfew chapters, we’ll detail explicitly which loss functions to choose for a wide range of\\ncommon tasks. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 82}), Document(page_content='61 Introduction to Keras\\n3.2 Introduction to Keras\\nThroughout this book, the code examples use Keras ( https:/ /keras.io ). Keras is a\\ndeep-learning framework for Python that provides a convenient way to define andtrain almost any kind of deep-learning model. Keras was initially developed for\\nresearchers, with the aim of enabling fast experimentation.\\n Keras has the following key features:\\n\\uf0a1It allows the same code to run seamlessly on CPU or GPU.\\n\\uf0a1It has a user-friendly API that makes it easy to qu ickly prototype deep-learning\\nmodels.\\n\\uf0a1It has built-in support for convolutional networks (for comput er vision), recur-\\nrent networks (for sequence proce ssing), and any combination of both.\\n\\uf0a1It supports arbitrary networ k architectures: multi-input  or multi-output models,\\nlayer sharing, mo del sharing, and so on. This means Keras is appropriate for\\nbuilding essentially any deep-learning mo del, from a generative adversarial net-\\nwork to a neural Turing machine.\\nKeras is distributed under the permissive MIT license, which means it can be freely\\nused in commercial projects. It’s compatible with any version of Python from 2.7 to 3.6\\n(as of mid-2017).\\n Keras has well over 200,000 users, rang ing from academic researchers and engi-\\nneers at both startups and large companies to graduate students and hobbyists. Keras\\nis used at Google, Netflix, Uber, CERN , Yelp, Square, and hundreds of startups work-\\ning on a wide range of problems. Keras is  also a popular framework on Kaggle, the\\nmachine-learning competition website, wher e almost every recent deep-learning com-\\npetition has been won using Keras models.\\nFigure 3.2 Google web search interest for di fferent deep-learning frameworks over time\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 83}), Document(page_content='62 CHAPTER  3Getting started with neural networks\\n3.2.1 Keras, TensorFlow, Theano, and CNTK\\nKeras is a model-level library, providing high-level building blocks for developing\\ndeep-learning models. It doesn’t handle low- level operations such as tensor manipula-\\ntion and differentiation. Instead, it relie s on a specialized, well-optimized tensor\\nlibrary to do so, serving as the backend engine  of Keras. Rather than choosing a single\\ntensor library and tying the implementation of  Keras to that library, Keras handles the\\nproblem in a modular way (see figure 3.3); thus several different backend engines can\\nbe plugged seamlessly into Keras. Currentl y, the three existing backend implementa-\\ntions are the TensorFlow backend, the Thea no backend, and the Microsoft Cognitive\\nToolkit ( CNTK ) backend. In the future, it’s likely that Keras will be extended to work\\nwith even more deep-lea rning execution engines.\\nTensorFlow, CNTK , and Theano are some of the pr imary platforms for deep learning\\ntoday. Theano ( http:/ /deeplearning. net/software/theano ) is developed by the MILA\\nlab at Université de Montréal , TensorFlow ( www.tensorflow.org ) is developed by Google,\\nand CNTK  (https:/ /github.com/Microsoft/ CNTK ) is developed by Microsoft. Any\\npiece of code that you write with Keras can be run with any of these backends without\\nhaving to change anything in the code: you can seamlessly switch between the two\\nduring development, which often proves usef ul—for instance, if one of these backends\\nproves to be faster for a sp ecific task. We recommend us ing the TensorFlow backend as\\nthe default for most of your deep-learning ne eds, because it’s the most widely adopted,\\nscalable, and production ready.\\n Via TensorFlow (or Theano, or CNTK ), Keras is able to run seamlessly on both\\nCPUs and GPUs. When running on CPU, TensorFlow is itself wrapping a low-level\\nlibrary for tensor operations called Eigen ( http:/ /eigen.tuxfamily.org ). On GPU,\\nTensorFlow wraps a library of  well-optimized deep-learn ing operations called the\\nNVIDIA  CUDA  Deep Neural Network library (cu DNN ). \\n3.2.2 Developing with Keras: a quick overview\\nYou’ve already seen one example of a Keras model: the MNIST  example. The typical\\nKeras workflow looks just like that example:\\n1Define your training data: input tensors and target tensors.\\n2Define a network of layers (or model ) that maps your inputs to your targets.\\nFigure 3.3 The deep-learning \\nsoftware and hardware stack\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 84}), Document(page_content=\"63 Introduction to Keras\\n3Configure the learning process by choos ing a loss function, an optimizer, and\\nsome metrics to monitor.\\n4Iterate on your training data by calling the fit()  method of your model.\\nThere are two ways to define a model: using the Sequential  class (only for linear\\nstacks of layers, which is the most comm on network architectu re by far) or the func-\\ntional API (for directed acyclic grap hs of layers, which lets you build completely arbi-\\ntrary architectures).\\n As a refresher, here’s a two-layer model defined using the Sequential  class (note\\nthat we’re passing the expected shape of  the input data to the first layer):\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, activation='relu', input_shape=(784,)))\\nmodel.add(layers.Dense(10, activation='softmax'))\\nAnd here’s the same model defined using the functional API:\\ninput_tensor = layers.Input(shape=(784,))\\nx = layers.Dense(32, activation='relu')(input_tensor)\\noutput_tensor = layers.Dense(10, activation='softmax')(x)\\nmodel = models.Model(inputs=input_tensor, outputs=output_tensor)\\nWith the functional API, you’re manipulating the data tensors that the model pro-\\ncesses and applying layers to this tensor as if they were functions.\\nNOTE A detailed guide to what you can do with the functional API can be\\nfound in chapter 7. Until chapte r 7, we’ll only be using the Sequential  class\\nin our code examples.\\nOnce your model architecture is define d, it doesn’t matter whether you used a\\nSequential  model or the functional API. All of the following  steps are the same.\\n The learning process is configured in the compilation step, where you specify the\\noptimizer and loss function(s) that the model should use, as well as the metrics you\\nwant to monitor during training. Here’s an  example with a single loss function, which\\nis by far the most common case:\\nfrom keras import optimizers\\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\\nloss='mse',metrics=['accuracy'])\\nFinally, the learning process consists of pa ssing Numpy arrays of input data (and the\\ncorresponding target data) to the model via the fit()  method, similar to what you\\nwould do in Scikit-Learn and severa l other machine-learning libraries:\\nmodel.fit(input_tensor, target_tensor, batch_size=128, epochs=10)\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 85}), Document(page_content='64 CHAPTER  3Getting started with neural networks\\nOver the next few chapters, you’ll build a solid intuition about what type of network\\narchitectures work for different kinds of pr oblems, how to pick the right learning con-\\nfiguration, and how to tweak a model until it  gives the results you want to see. We’ll\\nlook at three basic examples in sections 3.4, 3.5, and 3.6: a two-class classificationexample, a many-class classification example, and a regr ession example. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 86}), Document(page_content='65 Setting up a deep-learning workstation\\n3.3 Setting up a deep-learning workstation\\nBefore you can get started developing deep-learning applications, you need to set up\\nyour workstation. It’s highly  recommended, although not strictly necessary, that you\\nrun deep-learning code on a modern NVIDIA  GPU. Some applicatio ns—in particular,\\nimage processing with convolutional networ ks and sequence processing with recur-\\nrent neural networks—will be  excruciatingly slow on CPU, even a fast multicore CPU.\\nAnd even for applications that can realistically be run on CPU, you’ll generally see\\nspeed increase by a factor or 5 or 10 by using a modern GPU. If you don’t want to\\ninstall a GPU on your machine, you can alternat ively consider running your experi-\\nments on an AWS EC2 GPU instance or on Google Cloud Platform. But note that cloud\\nGPU instances can become expensive over time.\\n Whether you’re running locally or in the cl oud, it’s better to be using a Unix work-\\nstation. Although it’s technically possible to use Keras on Windows (all three Keras\\nbackends support Windows), We don’t recomme nd it. In the installation instructions\\nin appendix A, we’ll consider an Ubuntu machine. If you’re a Windows user, the sim-\\nplest solution to get everything running is to set up an Ubuntu dual boot on your\\nmachine. It may seem like a hassle, but us ing Ubuntu will save you a lot of time and\\ntrouble in the long run.\\n Note that in order to use Keras, you need to install TensorFlow or CNTK  or Theano\\n(or all of them, if you want to be able to  switch back and forth among the three back-\\nends). In this book, we’ll focus on TensorFl ow, with some light in structions relative to\\nTheano. We won’t cover CNTK .\\n3.3.1 Jupyter notebooks: the preferred way \\nto run deep-learning experiments\\nJupyter notebooks are a great way to run deep-learning experiments—in particular,\\nthe many code examples in this book. They ’re widely used in the data-science and\\nmachine-learning communities. A notebook  is a file generated by the Jupyter Notebook\\napp ( https:/ /jupyter.org ), which you can edit in your browser. It mixes the ability to\\nexecute Python code with rich text-editing  capabilities for annotating what you’re\\ndoing. A notebook also allows you to br eak up long experiments into smaller pieces\\nthat can be executed independently, whic h makes development interactive and means\\nyou don’t have to rerun all of your previous  code if something goes wrong late in an\\nexperiment.\\n We recommend using Jupyter notebooks to get started with Keras, although that\\nisn’t a requirement: you can also run standalo ne Python scripts or run code from within\\nan IDE such as PyCharm. All the code examples in this book are available as open source\\nnotebooks; you can download them from the book’s website at www.manning\\n.com/books/deep-learning-with-python . \\n \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 87}), Document(page_content='66 CHAPTER  3Getting started with neural networks\\n3.3.2 Getting Keras running: two options\\nTo get started in practice, we recomme nd one of the following two options:\\n\\uf0a1Use the official EC2 Deep Learning AMI (https:/ /aws.amazon.com/amazon-\\nai/amis ), and run Keras experiment s as Jupyter notebooks on EC2. Do this if\\nyou don’t already have a GPU on your local machine. Appendix B provides a\\nstep-by-step guide.\\n\\uf0a1Install everything from scratch on a lo cal Unix workstation. You can then run\\neither local Jupyter notebooks or a regu lar Python codebase. Do this if you\\nalready have a high-end NVIDIA  GPU. Appendix A provides an Ubuntu-specific,\\nstep-by-step guide.\\nLet’s take a closer look at some of the compromises involved in picking one option\\nover the other. \\n3.3.3 Running deep-learning jobs  in the cloud: pros and cons\\nIf you don’t already have a GPU that you can use for deep learning (a recent, high-end\\nNVIDIA  GPU), then running deep-learning experi ments in the cloud is a simple, low-\\ncost way for you to get started without having to buy any additional hardware. If you’reusing Jupyter notebooks, the experience of running in the cloud is no different from\\nrunning locally. As of mid-2017, the cloud o ffering that makes it easiest to get started\\nwith deep learning is definitely \\nAWS EC2. Appendix B provides a step-by-step guide to\\nrunning Jupyter notebooks on a EC2 GPU instance.\\n But if you’re a heavy user of deep learni ng, this setup isn’t sustainable in the long\\nterm—or even for more than a few weeks. EC2 instances are expensive: the instance\\ntype recommended in appendix B (the p2.xlarge  instance, which won’t provide you\\nwith much power) costs $0.90 per hour as of mid-2017. Meanwhil e, a solid consumer-\\nclass GPU will cost you somewher e between $1,000 and $1, 500—a price that has been\\nfairly stable over time, even as the specs of these GPUs keep improving. If you’re serious\\nabout deep learning, you should set up a local workstation with one or more GPUs.\\n In short, EC2 is a great way to get started. Yo u could follow the code examples in\\nthis book entirely on an EC2 GPU instance. But if you’re going to be a power user of\\ndeep learning, get your own GPUs. \\n3.3.4 What is the best GPU for deep learning?\\nIf you’re going to buy a GPU, which one should you choose? The first thing to note is\\nthat it must be an NVIDIA  GPU. NVIDIA  is the only graphics  computing company that\\nhas invested heavily in deep learning so  far, and modern deep-learning frameworks\\ncan only run on NVIDIA  cards.\\n As of mid-2017, we recommend the NVIDIA  TITAN  Xp as the best card on the mar-\\nket for deep learning. For lower budg ets, you may want to consider the GTX 1060. If\\nyou’re reading these pages in 2018 or later,  take the time to look online for fresher\\nrecommendations, because new mo dels come out every year.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 88}), Document(page_content='67 Setting up a deep-learning workstation\\n From this section onward , we’ll assume that you ha ve access to a machine with\\nKeras and its dependencies installed—preferably with GPU support. Make sure you\\nfinish this step before you proceed. Go th rough the step-by-step guides in the appen-\\ndixes, and look online if you need further help. There is no shortage of tutorials on\\nhow to install Keras and common deep-learning dependencies.\\n We can now dive into practical Keras examples. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 89}), Document(page_content='68 CHAPTER  3Getting started with neural networks\\n3.4 Classifying movie reviews: \\na binary classification example\\nTwo-class classification, or binary classifi cation, may be the most  widely applied kind\\nof machine-learning problem. In this exampl e, you’ll learn to classify movie reviews as\\npositive or negative, based on the text content of the reviews.\\n3.4.1 The IMDB dataset\\nYou’ll work with the IMDB  dataset: a set of 50,000 highly polarized reviews from the\\nInternet Movie Database. They’re split into  25,000 reviews for training and 25,000\\nreviews for testing, each se t consisting of 50% negative  and 50% positive reviews.\\n Why use separate training and test sets ? Because you should never test a machine-\\nlearning model on the same data that you used to train it! Just because a model per-\\nforms well on its training data doesn’t mean it will perform well on data it has neverseen; and what you care about is your mode l’s performance on new data (because you\\nalready know the labels of your training data—obviously you don’t need your model\\nto predict those). For instance, it’s possible that your model could end up merely mem-\\norizing  a mapping between your training samp les and their targets, which would be\\nuseless for the task of pred icting targets for data the model has never seen before.\\nWe’ll go over this point in much more detail in the next chapter.\\n Just like the \\nMNIST  dataset, the IMDB  dataset comes packaged with Keras. It has\\nalready been preprocessed: the reviews (seq uences of words) have been turned into\\nsequences of integers, where each integer st ands for a specific word in a dictionary.\\n The following code will load the datase t (when you run it the first time, about\\n80MB of data will be downloaded to your machine).\\nfrom keras.datasets import imdb\\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\\nnum_words=10000)\\nThe argument num_words=10000  means you’ll only keep the top 10,000 most fre-\\nquently occurring words in the training data. Rare words will be discarded. This allows\\nyou to work with vector data of manageable size.\\n The variables train_data  and test_data  are lists of reviews; each review is a list of\\nword indices (encoding a sequence of words). train_labels  and test_labels  are\\nlists of 0s and 1s, where 0 stands for negative  and 1 stands for positive :\\n>>> train_data[0]\\n[1, 14, 22, 16, ... 178, 32]\\n>>> train_labels[0]\\n1Listing 3.1 Loading the IMDB dataset\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 90}), Document(page_content=\"69 Classifying movie reviews: a binary classification example\\nBecause you’re restricting yourself to th e top 10,000 most freq uent words, no word\\nindex will exceed 10,000:\\n>>> max([max(sequence) for sequence in train_data])\\n9999\\nFor kicks, here’s how you can quickly deco de one of these reviews back to English\\nwords:\\nword_index = imdb.get_word_index()\\nreverse_word_index = dict(\\n[(value, key) for (key, value) in word_index.items()])\\ndecoded_review = ' '.join(\\n[reverse_word_index.get(i - 3, '?') for i in train_data[0]])\\n3.4.2 Preparing the data\\nYou can’t feed lists of integers into a neural network. You have to turn your lists into\\ntensors. There are two ways to do that:\\n\\uf0a1Pad your lists so that they all have the same length, turn them into an integertensor of shape \\n(samples,  word_indices) , and then use as the first layer in\\nyour network a layer capable of ha ndling such integer tensors (the Embedding\\nlayer, which we’ll cover in detail later in the book).\\n\\uf0a1One-hot encode your lists to turn them into vectors of 0s and 1s. This would\\nmean, for instance, turning the sequence [3, 5]  into a 10,000-dimensional vec-\\ntor that would be all 0s except for indi ces 3 and 5, which would be 1s. Then you\\ncould use as the first layer in your network a Dense  layer, capable of handling\\nfloating-point vector data.\\nLet’s go with the latter solution to vector ize the data, which you’ll do manually for\\nmaximum clarity.\\nimport numpy as np\\ndef vectorize_sequences(sequences, dimension=10000):\\nresults = np.zeros((len(sequences), dimension))for i, sequence in enumerate(sequences):\\nresults[i, sequence] = 1.\\nreturn results\\nx_train = vectorize_sequences(train_data)\\nx_test = vectorize_sequences(test_data)\\n Listing 3.2 Encoding the integer sequences into a binary matrixword_index is a dictionary mapping \\nwords to an integer index.\\nReverses it, mapping \\ninteger indices to wordsDecodes the review. Note that the indices\\nare offset by 3 because 0, 1, and 2 are\\nreserved indices for “padding,” “start of\\nsequence,” and “unknown.”\\nCreates an all-zero matrix \\nof shape (len(sequences), \\ndimension)\\nSets specific indices \\nof results[i] to 1s\\nVectorized tr aining data\\nVectorized test data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 91}), Document(page_content=\"70 CHAPTER  3Getting started with neural networks\\nHere’s what the samp les look like now:\\n>>> x_train[0]\\narray([ 0., 1., 1., ..., 0., 0., 0.])\\nYou should also vectorize your labels, which is straightforward:\\ny_train = np.asarray(train_labels).astype('float32')\\ny_test = np.asarray(test_labels).astype('float32')\\nNow the data is ready to be fed into a neural network.\\n3.4.3 Building your network\\nThe input data is vectors, and the labels are scalars (1s and 0s): this is the easiest setup\\nyou’ll ever encounter. A type of networ k that performs well on such a problem is\\na simple stack of fully connected ( Dense ) layers with relu  activations: Dense(16,\\nactivation='relu') .\\n The argument being passed to each Dense  l a y e r  ( 1 6 )  i s  t h e  n u m b e r  o f  h i d d e n\\nunits of the layer. A hidden unit  is a dimension in the representation space of the layer.\\nYou may remember from ch apter 2 that each such Dense  layer with a relu  activation\\nimplements the following ch ain of tensor operations:\\noutput = relu(dot(W, input) + b)\\nHaving 16 hidden units means the weig ht matrix W will have shape (input_dimension,\\n16): the dot product with W will project the input data onto a 16-dimensional represen-\\ntation space (and then you’ll add the bias vector b and apply the relu  operation). You\\ncan intuitively understand the dimensionali ty of your representation space as “how\\nmuch freedom you’re allowing the network to  have when learning internal represen-\\ntations.” Having more hidden units (a higher-dimensional representation space)\\nallows your network to lear n more-complex representations, but it makes the network\\nmore computationally expensive and may lead  to learning unwanted patterns (pat-\\nterns that will improve performance on the training data but not on the test data).\\n There are two key architecture decision s to be made about such a stack of Dense  layers:\\n\\uf0a1How many layers to use\\n\\uf0a1How many hidden units to choose for each layer\\nIn chapter 4, you’ll learn formal principles to guide you in making these choices. For\\nthe time being, you’ll have to trust me  with the following architecture choice: \\n\\uf0a1Two intermediate layers with 16 hidden units each \\n\\uf0a1A third layer that will output the scalar  prediction regarding the sentiment of\\nthe current review\\nThe intermediate layers will use relu  as their activation function, and the final layer\\nwill use a sigmoid activation so as to ou tput a probability (a score between 0 and 1,\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 92}), Document(page_content='71 Classifying movie reviews: a binary classification example\\nindicating how likely the sample is to have th e target “1”: how likely the review is to be\\npositive). A relu  (rectified linear unit) is a functi on meant to zero out negative values\\n(see figure 3.4), whereas a sigmoid “s quashes” arbitrary values into the [0, 1]  interval\\n(see figure 3.5), outputting something th at can be interpreted as a probability.\\n \\nFigure 3.4 The rectified linear unit function\\nFigure 3.5 The sigmoid function\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 93}), Document(page_content=\"72 CHAPTER  3Getting started with neural networks\\nFigure 3.6 shows what the network looks li ke. And here’s the Keras implementation,\\nsimilar to the MNIST  example you saw previously.\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(16, activation='relu'))model.add(layers.Dense(1, activation='sigmoid'))\\nFinally, you need to choose a loss function and an optimizer. Because you’re facing a\\nbinary classification problem and the output of your network is a probability (you end\\nyour network with a single-unit layer with a sigmoid activation), it’s best to use theListing 3.3 The model definitionDense (units=1)Output\\n(probability)\\nInput\\n(vectorized text)SequentialDense (units=16)\\nDense (units=16)\\nFigure 3.6 The three-layer network\\nWhat are activation functions, and why are they necessary?\\nWithout an activation function like relu (also called a non-linearity ), the Dense  layer\\nwould consist of two linear operati ons—a dot product and an addition:\\noutput = dot(W, input) + b\\nSo the layer could only learn linear transformations  (affine transformations) of the\\ninput data: the hypothesis space  of the layer would be the set of all possible linear\\ntransformations of the input data into a 16-dimensional space. Such a hypothesis\\nspace is too restricted and wouldn’t benefit from multiple layers of representations,\\nbecause a deep stack of linear layers would still impl ement a linear op eration: adding\\nmore layers wouldn’t extend the hypothesis space.\\nIn order to get access to a much richer hypothesis space that would benefit from\\ndeep representations, you need a non-lin earity, or activation function. relu is the\\nmost popular activation function in deep learning, but there are many other candi-\\ndates, which all come with  similarly strange names: prelu , elu, and so on.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 94}), Document(page_content=\"73 Classifying movie reviews: a binary classification example\\nbinary_crossentropy  loss. It isn’t the only viable ch oice: you could use, for instance,\\nmean_squared_error . But crossentropy is usually the best choice when you’re dealing\\nwith models that output probabilities. Crossentropy  is a quantity from the field of Infor-\\nmation Theory that measures the distance between probability distributions or, in this\\ncase, between the ground-truth di stribution and your predictions.\\n Here’s the step where you configure the model with the rmsprop  optimizer and\\nthe binary_crossentropy  loss function. Note that yo u’ll also monitor accuracy\\nduring training.\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['accuracy'])\\nYou’re passing your optimizer,  loss function, and metrics as  strings, which is possible\\nbecause rmsprop , binary_crossentropy , and accuracy  are packaged as part of Keras.\\nSometimes you may want to configure the para meters of your optimizer or pass a cus-\\ntom loss function or metric fu nction. The former can be done by passing an optimizer\\nclass instance as the optimizer  argument, as shown in listing 3.5; the latter can be\\ndone by passing function objects as the loss  and/or metrics  arguments, as shown in\\nlisting 3.6.\\nfrom keras import optimizers\\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\\nloss='binary_crossentropy',metrics=['accuracy'])\\nfrom keras import losses\\nfrom keras import metrics\\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\\nloss=losses.binary_crossentropy,metrics=[metrics.binary_accuracy])\\n3.4.4 Validating your approach\\nIn order to monitor during training the ac curacy of the model on data it has never\\nseen before, you’ll create a validation set by setting apart 10,0 00 samples from the\\noriginal training data.\\nx_val = x_train[:10000]\\npartial_x_train = x_train[10000:]Listing 3.4 Compiling the model\\nListing 3.5 Configuring the optimizer\\nListing 3.6 Using custom losses and metrics\\nListing 3.7 Setting aside a validation set\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 95}), Document(page_content=\"74 CHAPTER  3Getting started with neural networks\\ny_val = y_train[:10000]\\npartial_y_train = y_train[10000:]\\nYou’ll now train the model for 20 epochs (20 iterations over all samples in the\\nx_train  and y_train  tensors), in mini-batches of 512 samples. At the same time,\\nyou’ll monitor loss and accuracy on the 10,000  samples that you set apart. You do so by\\npassing the validation data as the validation_data  argument.\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])\\nhistory = model.fit(partial_x_train,\\npartial_y_train,epochs=20,batch_size=512,validation_data=(x_val, y_val))\\nOn CPU, this will take less than 2 seconds per epoch—training is over in 20 seconds.\\nAt the end of every epoch, there is a slight pause as the model computes its loss andaccuracy on the 10,000 samples of the validation data.\\n Note that the call to \\nmodel.fit()  returns a History  object. This object has a mem-\\nber history , which is a dictionary containing data about everything that happened\\nduring training. Let’s look at it:\\n>>> history_dict = history.history\\n>>> history_dict.keys()[u'acc', u'loss', u'val_acc', u'val_loss']\\nThe dictionary contains four entries: one per metric that was being monitored during\\ntraining and during validation . In the following two listing, let’s use Matplotlib to plot\\nthe training and validation loss si de by side (see figure 3.7), as well as the training and\\nvalidation accuracy (see figure  3.8). Note that your own re sults may vary slightly due to\\na different random initialization of your network.\\nimport matplotlib.pyplot as plt\\nhistory_dict = history.history\\nloss_values = history_dict['loss']val_loss_values = history_dict['val_loss']\\nepochs = range(1, len(acc) + 1)\\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')plt.title('Training and validation loss')plt.xlabel('Epochs')plt.ylabel('Loss')plt.legend()\\nplt.show()Listing 3.8 Training your model\\nListing 3.9 Plotting the training and validation loss\\n“bo” is for \\n“blue dot.”\\n“b” is for “solid\\nblue line.”\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 96}), Document(page_content=\"75 Classifying movie reviews: a binary classification example\\nplt.clf()\\nacc_values = history_dict['acc']\\nval_acc_values = history_dict['val_acc']\\nplt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')\\nplt.xlabel('Epochs')plt.ylabel('Loss')\\nplt.legend()\\nplt.show()Listing 3.10 Plotting the training and validation accuracy\\nFigure 3.7 Training and validation loss\\nClears the figure\\nFigure 3.8 Training and validation accuracy\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 97}), Document(page_content=\"76 CHAPTER  3Getting started with neural networks\\nAs you can see, the training loss decreases with every epoch, and the training accuracy\\nincreases with every epoch. That’s what you would expect when running gradient-\\ndescent optimization—the quantity you’re trying to minimize should be less with\\nevery iteration. But that isn’t the case for the validation loss and accuracy: they seem to\\npeak at the fourth epoch. This is an exam ple of what we warned against earlier: a\\nmodel that performs better on the training data isn’t necessarily a model that will do\\nbetter on data it has never seen before. In precise terms, what you’re seeing is overfit-\\nting: after the second epoch, you’re overopti mizing on the training data, and you end\\nup learning representations th at are specific to the traini ng data and don’t generalize\\nto data outside of the training set.\\n In this case, to prevent overfitting, yo u could stop training after three epochs. In\\ngeneral, you can use a range of techniques to  mitigate overfitting, which we’ll cover in\\nchapter 4.\\n Let’s train a new network from scratch for four epochs and then evaluate it on the\\ntest data.\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))model.add(layers.Dense(16, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',\\nmetrics=['accuracy'])\\nmodel.fit(x_train, y_train, epochs=4, batch_size=512)\\nresults = model.evaluate(x_test, y_test)\\nThe final results are as follows:\\n>>> results[0.2929924130630493, 0.88327999999999995]\\nThis fairly naive approach achieves an  accuracy of 88%. With state-of-the-art\\napproaches, you should be able to get close to 95%.\\n3.4.5 Using a trained network to generate predictions on new data\\nAfter having trained a network, you’ll want to use it in a practical setting. You can gen-\\nerate the likelihood of reviews being positive by using the predict  method:\\n>>> model.predict(x_test)\\narray([[ 0.98006207]\\n[ 0.99758697]\\n[ 0.99975556]\\n...,[ 0.82167041]\\n[ 0.02885115]\\n[ 0.65371346]], dtype=float32)Listing 3.11 Retraining a model from scratch\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 98}), Document(page_content='77 Classifying movie reviews: a binary classification example\\nAs you can see, the network is confident for some samples (0.99 or more, or 0.01 or\\nless) but less confident for others (0.6, 0.4).\\n3.4.6 Further experiments\\nThe following experiments will  help convince you that the architecture choices you’ve\\nmade are all fairly reasonable, althou gh there’s still room for improvement:\\n\\uf0a1You used two hidden layers. Try using one or three hidden layers, and see how\\ndoing so affects validati on and test accuracy.\\n\\uf0a1Try using layers with more hidden units or  fewer hidden units: 32 units, 64 units,\\nand so on.\\n\\uf0a1Try using the mse loss function instead of binary_crossentropy .\\n\\uf0a1Try using the tanh  activation (an activation that was popular in the early days of\\nneural networks) instead of relu .\\n3.4.7 Wrapping up\\nHere’s what you should take away from this example:\\n\\uf0a1You usually need to do quite a bit of preprocessing on your raw data in order tobe able to feed it—as tensors—into a neural network. Sequences of words can\\nbe encoded as binary vectors, but th ere are other encoding options, too.\\n\\uf0a1Stacks of Dense  layers with relu  activations can solve a wide range of problems\\n(including sentiment classification), an d you’ll likely use them frequently.\\n\\uf0a1In a binary classification  problem (two output cla sses), your network should\\nend with a Dense  layer with one unit and a sigmoid  activation: the output of\\nyour network should be a scalar betw een 0 and 1, encoding a probability.\\n\\uf0a1With such a scalar sigmoid output on a binary classi fication problem, the loss\\nfunction you should use is binary_crossentropy .\\n\\uf0a1The rmsprop  optimizer is generally a good enough choice, whatever your prob-\\nlem. That’s one less thing for you to worry about.\\n\\uf0a1As they get better on their training data, neural networks eventually start over-\\nfitting and end up obtaining increasingly  worse results on data they’ve never\\nseen before. Be sure to always monitor performance on data that is outside ofthe training set. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 99}), Document(page_content=\"78 CHAPTER  3Getting started with neural networks\\n3.5 Classifying newswires: \\na multiclass classification example\\nIn the previous section, you saw how to classify vector inputs into two mutually exclu-\\nsive classes using a densely connected neural ne twork. But what happens when you\\nhave more than two classes?\\n In this section, you’ll bu ild a network to classify Reut ers newswires into 46 mutually\\nexclusive topics. Because you have many cl asses, this problem is an instance of multi-\\nclass classification ; and because each data point should be classified into only one cate-\\ngory, the problem is  more specifically an instance of single-label, multiclass classification .\\nIf each data point could belong to multiple  categories (in this case, topics), you’d be\\nfacing a multilabel, multiclass classification  problem.\\n3.5.1 The Reuters dataset\\nYou’ll work with the Reuters dataset , a set of short newswires and their topics, published\\nby Reuters in 1986. It’s a simple, widely us ed toy dataset for text classification. There\\nare 46 different topics; some topics are mo re represented than others, but each topic\\nhas at least 10 examples in the training set.\\n Like IMDB  and MNIST , the Reuters dataset comes packag ed as part of Keras. Let’s\\ntake a look.\\nfrom keras.datasets import reuters\\n(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\\nnum_words=10000)\\nAs with the IMDB  dataset, the argument num_words=10000  restricts the data to the\\n10,000 most frequently occurring words found in the data.\\n You have 8,982 training examples and 2,246 test examples:\\n>>> len(train_data)\\n8982>>> len(test_data)2246\\nAs with the IMDB  reviews, each example is a li st of integers (word indices):\\n>>> train_data[10]\\n[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\\nHere’s how you can decode it back to words, in case you’re curious.\\nword_index = reuters.get_word_index()\\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])decoded_newswir e='' . join([reverse_word_index.get(i - 3, '?') for i in\\ntrain_data[0]])Listing 3.12 Loading the Reuters dataset\\nListing 3.13 Decoding newswires back to text\\nNote that the indices are offset by 3 because 0, 1, and 2 are reserved \\nindices for “padding,” “start of sequence,” and “unknown.”\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 100}), Document(page_content='79 Classifying newswires: a multiclass classification example\\nThe label associated with an example is an integer between 0 and 45—a topic index:\\n>>> train_labels[10]\\n3\\n3.5.2 Preparing the data\\nYou can vectorize the data wi th the exact same code as in the previous example.\\nimport numpy as np\\ndef vectorize_sequences(sequences, dimension=10000):\\nresults = np.zeros((len(sequences), dimension))\\nfor i, sequence in enumerate(sequences):\\nresults[i, sequence] = 1.\\nreturn results\\nx_train = vectorize_sequences(train_data)\\nx_test = vectorize_sequences(test_data)\\nTo vectorize the labels, there are two possibilitie s: you can cast the label list as an inte-\\nger tensor, or you can use one-hot encoding . One-hot encoding is a widely used for-\\nmat for categorical data, also called categorical encoding . For a more detailed\\nexplanation of one-hot encoding, see sectio n 6.1. In this case, one-hot encoding of\\nthe labels consists of embedding each label as an all-zero vector with a 1 in the place of\\nthe label index. Here’s an example:\\ndef to_one_hot(labels, dimension=46):\\nresults = np.zeros((len(labels), dimension))\\nfor i, label in enumerate(labels):\\nresults[i, label] = 1.\\nreturn results\\none_hot_train_labels = to_one_hot(train_labels)\\none_hot_test_labels = to_one_hot(test_labels)\\nNote that there is a built-in way to do this in Keras, which you’ve already seen in action\\nin the MNIST  example:\\nfrom keras.utils.np_utils import to_categorical\\none_hot_train_labels = to_categorical(train_labels)\\none_hot_test_labels = to_categorical(test_labels)\\n3.5.3 Building your network\\nThis topic-classification prob lem looks similar to the previous movie-review classifica-\\ntion problem: in both cases, you’re trying to  classify short snippets of text. But there is\\na new constraint here: the number of outp ut classes has gone from 2 to 46. The\\ndimensionality of the output  space is much larger.\\n In a stack of Dense  layers like that you’ve been usin g, each layer can only access infor-\\nmation present in the output of the previous  layer. If one layer drops some informationListing 3.14 Encoding the data\\nVectorized tr aining data\\nVectorized test data\\nVectorized tr aining labels\\nVectorized test labels\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 101}), Document(page_content=\"80 CHAPTER  3Getting started with neural networks\\nrelevant to the classification  problem, this information ca n never be recovered by later\\nlayers: each layer can potentially become an information bottleneck. In the previous\\nexample, you used 16-dimensional intermed iate layers, but a 16-dimensional space may\\nbe too limited to learn to separate 46 differen t classes: such small layers may act as infor-\\nmation bottlenecks, permanently dropping relevant information.\\n For this reason you’ll use larger layers. Let’s go with 64 units.\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))model.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(46, activation='softmax'))\\nThere are two other things you shou ld note about this architecture:\\n\\uf0a1You end the network with a Dense  layer of size 46. This means for each input\\nsample, the network will output a 46-dimen sional vector. Each entry in this vec-\\ntor (each dimension) will enco de a different output class.\\n\\uf0a1The last layer uses a softmax  activation. You saw this pattern in the MNIST\\nexample. It means the network will output a probability distribution  over the 46\\ndifferent output classes—for every input sample, the network will produce a 46-\\ndimensional output  vector, where output[i]  is the probability that the sample\\nbelongs to class i. The 46 scores will sum to 1.\\nThe best loss function to use in this case is categorical_crossentropy . It measures\\nthe distance between two probability distri butions: here, between the probability dis-\\ntribution output by the network and the true  distribution of the labels. By minimizing\\nthe distance between these two distribution s, you train the network to output some-\\nthing as close as possible to the true labels.\\nmodel.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\n3.5.4 Validating your approach\\nLet’s set apart 1,000 samples in the trai ning data to use as a validation set.\\nx_val = x_train[:1000]\\npartial_x_train = x_train[1000:]\\ny_val = one_hot_train_labels[:1000]\\npartial_y_train = one_hot_train_labels[1000:]Listing 3.15 Model definition\\nListing 3.16 Compiling the model\\nListing 3.17 Setting aside a validation set\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 102}), Document(page_content=\"81 Classifying newswires: a multiclass classification example\\nNow, let’s train the network for 20 epochs.\\nhistory = model.fit(partial_x_train,\\npartial_y_train,\\nepochs=20,batch_size=512,\\nvalidation_data=(x_val, y_val))\\nAnd finally, let’s display its loss and accu racy curves (see figures 3.9 and 3.10).\\nimport matplotlib.pyplot as plt\\nloss = history.history['loss']\\nval_loss = history.history['val_loss']\\nepochs = range(1, len(loss) + 1)plt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')\\nplt.xlabel('Epochs')plt.ylabel('Loss')\\nplt.legend()\\nplt.show()\\nplt.clf()\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']\\nplt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')plt.title('Training and validation accuracy')\\nplt.xlabel('Epochs')\\nplt.ylabel('Loss')plt.legend()\\nplt.show()Listing 3.18 Training the model\\nListing 3.19 Plotting the training and validation loss\\nListing 3.20 Plotting the training and validation accuracy\\nClears the figure\\nFigure 3.9 Training and validation loss\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 103}), Document(page_content=\"82 CHAPTER  3Getting started with neural networks\\nThe network begins to overfit after nine  epochs. Let’s train a new network from\\nscratch for nine epochs and then  evaluate it on the test set.\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(46, activation='softmax'))\\nmodel.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nmodel.fit(partial_x_train,\\npartial_y_train,\\nepochs=9,batch_size=512,\\nvalidation_data=(x_val, y_val))\\nresults = model.evaluate(x_test, one_hot_test_labels)\\nHere are the final results:\\n>>> results[0.9565213431445807, 0.79697239536954589]\\nThis approach reaches an accuracy of ~80 %. With a balanced binary classification\\nproblem, the accuracy reached by a purely random classifier would be 50%. But in\\nthis case it’s closer to 19%, so the result s seem pretty good, at least when compared to\\na random baseline:\\n>>> import copy\\n>>> test_labels_copy = copy.copy(test_labels)>>> np.random.shuffle(test_labels_copy)\\n>>> hits_array = np.array(test_labels) == np.array(test_labels_copy)\\n>>> float(np.sum(hits_array)) / len(test_labels)0.18655387355298308Listing 3.21 Retraining a model from scratch\\nFigure 3.10 Training and validation accuracy\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 104}), Document(page_content=\"83 Classifying newswires: a multiclass classification example\\n3.5.5 Generating predictions on new data\\nYou can verify that the predict  method of the model instance returns a probability\\ndistribution over all 46 topics. Let’s generate  topic predictions for all of the test data.\\npredictions = model.predict(x_test)\\nEach entry in predictions  is a vector of length 46:\\n>>> predictions[0].shape\\n(46,)\\nThe coefficients in this vector sum to 1:\\n>>> np.sum(predictions[0])1.0\\nThe largest entry is the predicted class— the class with the highest probability:\\n>>> np.argmax(predictions[0])\\n4\\n3.5.6 A different way to handle the labels and the loss\\nWe mentioned earlier that another way to en code the labels would be to cast them as\\nan integer tensor, like this:\\ny_train = np.array(train_labels)\\ny_test = np.array(test_labels)\\nThe only thing this approach would change is the choice of the loss function. The loss\\nfunction used in listing 3.21, categorical_crossentropy , expects the labels to follow\\na categorical encoding. With integer labels, you should use sparse_categorical_\\ncrossentropy :\\nmodel.compile(optimizer='rmsprop',\\nloss='sparse_categorical_crossentropy',metrics=['acc'])\\nThis new loss function is still mathematically the same as categorical_crossentropy ;\\nit just has a different interface.\\n3.5.7 The importance of having su fficiently large intermediate layers\\nWe mentioned earlier that because the final outputs are 46-dimensional, you should\\navoid intermediate layers with many fewer than 46 hidden units. Now let’s see what\\nhappens when you introduce an information bottleneck by having intermediate layers\\nthat are significantly le ss than 46-dimensional: fo r example, 4-dimensional.Listing 3.22 Generating predictions for new data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 105}), Document(page_content=\"84 CHAPTER  3Getting started with neural networks\\n \\nmodel = models.Sequential()\\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(4, activation='relu'))model.add(layers.Dense(46, activation='softmax'))\\nmodel.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',metrics=['accuracy'])\\nmodel.fit(partial_x_train,\\npartial_y_train,epochs=20,\\nbatch_size=128,\\nvalidation_data=(x_val, y_val))\\nThe network now peaks at ~71% validation accuracy, an 8% abso lute drop. This drop\\nis mostly due to the fact that you’re trying to compress a lot of information (enough\\ninformation to recover the separation hyperplanes of 46 classes) into an intermediate\\nspace that is too low-dimensional.  The network is able to cram most of the necessary\\ninformation into these eight-dimensional representations, but not all of it.\\n3.5.8 Further experiments\\n\\uf0a1Try using larger or smaller layers: 32 units, 128 units, and so on.\\n\\uf0a1You used two hidden layers. Now try using a single hidden layer, or three hid-\\nden layers.\\n3.5.9 Wrapping up\\nHere’s what you should take away from this example:\\n\\uf0a1If you’re trying to classify data points among N classes, your network should end\\nwith a Dense  layer of size N.\\n\\uf0a1In a single-label, multiclass classifica tion problem, your network should end\\nwith a softmax  activation so that it will output a probability distribution over the\\nN output classes.\\n\\uf0a1Categorical crossentropy is  almost always the loss fu nction you should use for\\nsuch problems. It minimizes the distance  between the probability distributions\\noutput by the network and the tr ue distribution of the targets.\\n\\uf0a1There are two ways to handle labels in multiclass classification:\\n– Encoding the labels via categorical encoding (also known as one-hot encod-\\ning) and using categorical_crossentropy  as a loss function\\n– Encoding the labels as integers and using the sparse_categorical_crossentropy\\nloss function\\n\\uf0a1If you need to classify data into a larg e number of categories, you should avoid\\ncreating information bottlenecks in your network due to intermediate layers\\nthat are too small. Listing 3.23 A model with an information bottleneck\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 106}), Document(page_content='85 Predicting house prices: a regression example\\n3.6 Predicting house prices: a regression example\\nThe two previous examples we re considered classificati on problems, where the goal\\nwas to predict a single discrete label of an  input data point. Another common type of\\nmachine-learning problem is regression , which consists of predicting a continuous\\nvalue instead of a discrete label: for inst ance, predicting the temperature tomorrow,\\ngiven meteorological data; or predicting the time that a software project will take to\\ncomplete, given it s specifications.\\nNOTE Don’t confuse regression  and the algorithm logistic regression . Con-\\nfusingly, logistic regression isn’t a re gression algo rithm—it’s a classification\\nalgorithm.\\n3.6.1 The Boston Housing Price dataset\\nYou’ll attempt to predict the median price of  homes in a given Boston suburb in the\\nmid-1970s, given data points about the suburb  at the time, such as the crime rate, the\\nlocal property tax rate, and so on. The data set you’ll use has an interesting difference\\nfrom the two previous examples. It has relatively few data points: only 506, splitbetween 404 training samples an d 102 test samples. And each feature  in the input data\\n(for example, the crime rate) has a different  scale. For instance, some values are pro-\\nportions, which take values between 0 and 1;  others take values between 1 and 12, oth-\\ners between 0 and 100, and so on.\\nfrom keras.datasets import boston_housing\\n(train_data, train_targets), (test_data, test_targets) =\\n➥boston_housing.load_data()\\nLet’s look at the data:\\n>>> train_data.shape\\n(404, 13)>>> test_data.shape\\n(102, 13)\\nAs you can see, you have 404 training sa mples and 102 test samples, each with 13\\nnumerical features, such as per capita crim e rate, average number of rooms per dwell-\\ning, accessibility to highways, and so on.\\n The targets are the median values of owner-occupied homes, in thousands of\\ndollars:\\n>>> train_targets\\n[ 15.2, 42.3, 50. ... 19.4, 19.4, 29.1]\\nThe prices are typically between $10,000 an d $50,000. If that sounds cheap, remem-\\nber that this was the mid-1970s, and thes e prices aren’t adju sted for inflation.Listing 3.24 Loading the Boston housing dataset\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 107}), Document(page_content=\"86 CHAPTER  3Getting started with neural networks\\n3.6.2 Preparing the data\\nIt would be problematic to feed into a neural  network values that all take wildly differ-\\nent ranges. The network might be able to automatically adapt to such heterogeneous\\ndata, but it would definitely make learning more difficult. A widespread best practice\\nto deal with such data is to do feature-wise  normalization: for each feature in the input\\ndata (a column in the input data matrix),  you subtract the mean of the feature and\\ndivide by the standard deviation, so that the feature is centered around 0 and has a\\nunit standard deviation. This is easily done in Numpy.\\nmean = train_data.mean(axis=0)\\ntrain_data -= mean\\nstd = train_data.std(axis=0)\\ntrain_data /= std\\ntest_data -= mean\\ntest_data /= std\\nNote that the quantities us ed for normalizing the test data are computed using the\\ntraining data. You should never use in your  workflow any quantity computed on the\\ntest data, even for something as  simple as data normalization.\\n3.6.3 Building your network\\nBecause so few samples are available, you’ll  use a very small network with two hidden\\nlayers, each with 64 units. In general, the less training data you have, the worse overfit-\\nting will be, and using a small networ k is one way to mitigate overfitting.\\nfrom keras import models\\nfrom keras import layers\\ndef build_model():\\nmodel = models.Sequential()model.add(layers.Dense(64, activation='relu',\\ninput_shape=(train_data.shape[1],)))\\nmodel.add(layers.Dense(64, activation='relu'))model.add(layers.Dense(1))\\nmodel.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\\nreturn model\\nThe network ends with a single unit and no ac tivation (it will be a linear layer). This is\\na typical setup for scalar regre ssion (a regression where you’ re trying to predict a single\\ncontinuous value). Applying an activation function would constrain the range the out-\\nput can take; for instance, if you applied a sigmoid  activation function to the last layer,\\nthe network could only learn to predict values between 0 and 1. Here, because the last\\nlayer is purely linear, the network is free to learn to predict values in any range.Listing 3.25 Normalizing the data\\nListing 3.26 Model definition\\nBecause you’ll need to instantiate \\nthe same model multiple times, you \\nuse a function to construct it.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 108}), Document(page_content='87 Predicting house prices: a regression example\\n Note that you compile the network with the mse loss function— mean squared error ,\\nthe square of the difference between the predictions and the targets. This is a widely\\nused loss function fo r regression problems.\\n You’re also monitoring a new metric during training: mean absolute error  (MAE). It’s\\nthe absolute value of the difference betw een the predictions and the targets. For\\ninstance, an MAE  of 0.5 on this problem would mean your predictions are off by $500\\non average.\\n3.6.4 Validating your approach using K-fold validation\\nTo evaluate your network while you keep ad justing its parameters (such as the number\\nof epochs used for training), you could spli t the data into a training set and a valida-\\ntion set, as you did in the previous examples. But because you have so few data points,\\nthe validation set would end up being very small (for instance, about 100 examples).\\nAs a consequence, the validation scores mi ght change a lot depending on which data\\npoints you chose to use for validation and which you chose for training: the validation\\nscores might have a high variance  with regard to the validation split. This would pre-\\nvent you from reliably evaluating your model.\\n The best practice in such situations is to use K-fold cross-validation (see figure 3.11).\\nIt consists of splitting the available data into K partitions (typically K = 4 or 5), instanti-\\nating K identical models, and training each one on K – 1 partitions while evaluating on\\nthe remaining partition. The validation scor e for the model used is then the average of\\nthe K validation scores obtained. In ter ms of code, this is straightforward.\\nimport numpy as np\\nk=4\\nnum_val_samples = len(train_data) // k\\nnum_epochs = 100\\nall_scores = []Listing 3.27 K-fold validationData split into 3 partitions\\nValidation Training TrainingValidation\\nscore #1Fold 1\\nValidation Validation TrainingValidation\\nscore #2Final score:\\naverageFold 2\\nValidation Training ValidationValidation\\nscore #3Fold 3\\nFigure 3.11 3-fold cross-validation\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 109}), Document(page_content=\"88 CHAPTER  3Getting started with neural networks\\nfor i in range(k):\\nprint('processing fold #', i)val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\\nval_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\\npartial_train_data = np.concatenate(\\n[train_data[:i * num_val_samples],\\ntrain_data[(i + 1) * num_val_samples:]],\\naxis=0)\\npartial_train_targets = np.concatenate(\\n[train_targets[:i * num_val_samples],\\ntrain_targets[(i + 1) * num_val_samples:]],\\naxis=0)\\nmodel = build_model()\\nmodel.fit(partial_train_data, partial_train_targets,\\nepochs=num_epochs, batch_size=1, verbose=0)\\nval_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\\nall_scores.append(val_mae)\\nRunning this with num_epochs = 100  yields the following results:\\n>>> all_scores[2.588258957792037, 3.1289568449719116, 3.1856116051248984, 3.0763342615401386]>>> np.mean(all_scores)\\n2.9947904173572462\\nThe different runs do indeed show rather different validation scores, from 2.6 to 3.2.\\nThe average (3.0) is a much more reliable metric than any sing le score—that’s the\\nentire point of K-fold cross-validation. In this case, you’re off by $3,000 on average,\\nwhich is significant considering that the prices range from $10,000 to $50,000.\\n Let’s try training the network a bit long er: 500 epochs. To keep a record of how\\nwell the model does at each epoch, you’ll modify the training loop to save the per-\\nepoch validation score log.\\nnum_epochs = 500\\nall_mae_histories = []\\nfor i in range(k):\\nprint('processing fold #', i)val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\\nval_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\\npartial_train_data = np.concatenate(\\n[train_data[:i * num_val_samples],\\ntrain_data[(i + 1) * num_val_samples:]],\\naxis=0)Listing 3.28 Saving the validation logs at each foldPrepares the va lidation data: \\ndata from partition #kPrepares the tr aining data:\\ndata from all other partitions\\nBuilds the Keras model (already compiled)\\nTrains the model (in silent mode, \\nverbose = 0)\\nEvaluates the model\\non the validation data\\nPrepares the validation data:\\ndata from partition #k\\nPrepares the training data: data from all \\nother partitions\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 110}), Document(page_content=\"89 Predicting house prices: a regression example\\npartial_train_targets = np.concatenate(\\n[train_targets[:i * num_val_samples],\\ntrain_targets[(i + 1) * num_val_samples:]],\\naxis=0)\\nmodel = build_model()\\nhistory = model.fit(partial_train_data, partial_train_targets,\\nvalidation_data=(val_data, val_targets),\\nepochs=num_epochs, batch_size=1, verbose=0)\\nmae_history = history.history['val_mean_absolute_error']all_mae_histories.append(mae_history)\\nYou can then compute the average of the per-epoch MAE  scores for all folds.\\naverage_mae_history = [\\nnp.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\\nLet’s plot this; see figure 3.12.\\nimport matplotlib.pyplot as plt\\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\\nplt.xlabel('Epochs')\\nplt.ylabel('Validation MAE')\\nplt.show()\\nIt may be a little difficult to see the plot, due  to scaling issues and relatively high vari-\\nance. Let’s do the following:\\n\\uf0a1Omit the first 10 data points, which are on a different scale than the rest of the curve.\\n\\uf0a1Replace each point with an exponential moving average of the previous points,\\nto obtain a smooth curve.Listing 3.29 Building the history of successive mean K-fold validation scores\\nListing 3.30 Plotting validation scoresBuilds the Keras model \\n(already compiled)\\nTrains the model\\n(in silent mode, verbose=0)\\nFigure 3.12 Validation \\nMAE by epoch\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 111}), Document(page_content=\"90 CHAPTER  3Getting started with neural networks\\nThe result is shown in figure 3.13.\\ndef smooth_curve(points, factor=0.9):\\nsmoothed_points = []\\nfor point in points:\\nif smoothed_points:\\nprevious = smoothed_points[-1]\\nsmoothed_points.append(previous * factor + point * (1 - factor))\\nelse:\\nsmoothed_points.append(point)\\nreturn smoothed_points\\nsmooth_mae_history = smooth_curve(average_mae_history[10:])\\nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\\nplt.xlabel('Epochs')plt.ylabel('Validation MAE')\\nplt.show()\\nAccording to this plot, validation MAE  stops improving signific antly after 80 epochs.\\nPast that point, you start overfitting.\\n Once you’re finished tuning other para meters of the model (in addition to the\\nnumber of epochs, you could also adjust the size of the hidden layers), you can train a\\nfinal production model on all of the traini ng data, with the best parameters, and then\\nlook at its performance on the test data.\\nmodel = build_model()\\nmodel.fit(train_data, train_targets,\\nepochs=80, batch_size=16, verbose=0)\\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)Listing 3.31 Plotting validation scores, excluding the first 10 data points\\nListing 3.32 Training the final model\\nFigure 3.13 Validation MAE by epoch, excluding the first \\n10 data points\\nGets a fresh, compiled model\\nTrains it on the en tirety of the data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 112}), Document(page_content='91 Predicting house prices: a regression example\\nHere’s the final result:\\n>>> test_mae_score\\n2.5532484335057877\\nYou’re still off by about $2,550.\\n3.6.5 Wrapping up\\nHere’s what you should take away from this example:\\n\\uf0a1Regression is done using different loss fu nctions than what we used for classifi-\\ncation. Mean squared error ( MSE) is a loss function co mmonly used for regres-\\nsion.\\n\\uf0a1Similarly, evaluation metrics to be used for regression differ from those used for\\nclassification; naturally, the concept of accuracy doesn’t apply for regression. A\\ncommon regression metric is mean absolute error ( MAE).\\n\\uf0a1When features in the input data have va lues in different ranges, each feature\\nshould be scaled independen tly as a preprocessing step.\\n\\uf0a1When there is little data available, using K-fold validation is a great way to reli-\\nably evaluate a model.\\n\\uf0a1When little training data is available, it’s preferable to use a small network withfew hidden layers (typically only one or two), in order to avoid severe overfitting. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 113}), Document(page_content='92 CHAPTER  3Getting started with neural networks\\nChapter summary\\n\\uf0a1You’re now able to handle the mo st common kinds of machine-learning\\ntasks on vector data: binary classifica tion, multiclass classification, and sca-\\nlar regression. The “Wrapping up” sections earlier in the chapter summa-rize the important points you’ve learned regarding these types of tasks.\\n\\uf0a1You’ll usually need to preprocess raw data before feeding it into a neuralnetwork.\\n\\uf0a1W h e n  y o u r  d a t a  h a s  f e a t u r e s  w i t h  different ranges, scale each feature\\nindependently as part of preprocessing.\\n\\uf0a1As training progresses, neural networ ks eventually begin to overfit and\\nobtain worse results on never-before-seen data.\\n\\uf0a1If you don’t have much training data , use a small network with only one or\\ntwo hidden layers, to avoid severe overfitting.\\n\\uf0a1If your data is divided into many categories, you may cause informationbottlenecks if you make the intermediate layers too small.\\n\\uf0a1Regression uses different loss functi ons and different evaluation metrics\\nthan classification.\\n\\uf0a1When you’re working with little data, K-fold validation can help reliably\\nevaluate your model.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 114}), Document(page_content='93Fundamentals of\\nmachine learning\\nAfter the three practical exampl es in chapter 3, you should be starting to feel famil-\\niar with how to approach classification and regression proble ms using neural net-\\nworks, and you’ve witnesse d the central problem of ma chine learning: overfitting.\\nThis chapter will formalize some of yo ur new intuition into  a solid conceptual\\nframework for attacking and solving deep-l earning problems. We’ll consolidate all\\nof these concepts—model evaluation, data  preprocessing and feature engineering,\\nand tackling overfitting—in to a detailed seven-step workflow for tackling any\\nmachine-learning task.This chapter covers\\n\\uf0a1Forms of machine learning beyond classification \\nand regression\\n\\uf0a1Formal evaluation procedures for machine-learning models\\n\\uf0a1Preparing data for deep learning\\n\\uf0a1Feature engineering\\n\\uf0a1Tackling overfitting\\n\\uf0a1The universal workflow for approaching machine-\\nlearning problems\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 115}), Document(page_content='94 CHAPTER  4Fundamentals of machine learning\\n4.1 Four branches of machine learning\\nIn our previous examples, you’ve become  familiar with three specific types of\\nmachine-learning problems: binary classifi cation, multiclass cla ssification, and scalar\\nregression. All three are instances of supervised learning , where the goal is to learn the\\nrelationship between training inputs and training targets.\\n Supervised learning is just the tip of th e iceberg—machine learning is a vast field\\nwith a complex subfield taxonomy. Machin e-learning algorithms generally fall into\\nfour broad categories, described in the following sections.\\n4.1.1 Supervised learning\\nThis is by far the most common case. It co nsists of learning to map input data to\\nknown targets (also called annotations ), given a set of examples (often annotated by\\nhumans). All four examples you’ve encounte red in this book so far were canonical\\nexamples of supervised learning. Generally,  almost all applications of deep learning\\nthat are in the spotlight these days belong in this category, such as optical character\\nrecognition, speech recognition, image classification, and language translation.\\n Although supervised learning mostly consis ts of classification and regression, there\\nare more exotic variants as well, in cluding the following (with examples):\\n\\uf0a1Sequence generation —Given a picture, predict a ca ption describing it. Sequence\\ngeneration can sometimes be reformulated as a series of classification problems\\n(such as repeatedly pr edicting a word or token in a sequence).\\n\\uf0a1Syntax tree prediction —Given a sentence, predict its decomposition into a syntax\\ntree.\\n\\uf0a1Object detection —Given a picture, draw a boundi ng box around certain objects\\ninside the picture. This can also be ex pressed as a classification problem (given\\nmany candidate bounding boxe s, classify the contents of  each one) or as a joint\\nclassification and regression problem, where the bounding-b ox coordinates are\\npredicted via vector regression.\\n\\uf0a1Image segmentation —Given a picture, draw a pixel-le vel mask on a specific object. \\n4.1.2 Unsupervised learning\\nThis branch of machine learning consists of  finding interesting transformations of the\\ninput data without the help of any targets, for the purposes of data visualization, datacompression, or data denoising, or to be tter understand the correlations present in\\nthe data at hand. Unsupervised learning is the bread and butter of data analytics, and\\nit’s often a necessary step in better understanding a da taset before attempting to solve\\na supervised-learning problem. Dimensionality reduction  and clustering  are well-known\\ncategories of unsupervised learning. \\n4.1.3 Self-supervised learning\\nThis is a specific instance of supervised learning, but it’s different enough that it\\ndeserves its own category. Self-supervised learning is supervised learning without\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 116}), Document(page_content='95 Four branches of machine learning\\nhuman-annotated labels—you can think of it as supervised learning without any\\nhumans in the loop. There are still labels involved (because the learning has to be\\nsupervised by something), but they’re genera ted from the input data, typically using a\\nheuristic algorithm.\\n For instance, autoencoders  are a well-known instance of  self-supervised learning,\\nwhere the generated targets are the input, un modified. In the same way, trying to pre-\\ndict the next frame in a video, given past fr ames, or the next word in a text, given previ-\\nous words, are instances of self-supervised learning ( temporally supervised learning , in this\\ncase: supervision comes from future input data). Note that the distinction between\\nsupervised, self-supervised, an d unsupervised learning can be blurry sometimes—these\\ncategories are more of a continuum without solid borders. Self-supervised learning can\\nbe reinterpreted as either supervised or unsupervised learning, depending on whether\\nyou pay attention to the learning mechani sm or to the context of its application.\\nNOTE In this book, we’ll focus specifically  on supervised learning, because\\nit’s by far the dominant form of deep learning today, with a wide range of\\nindustry applications. We’ll also take a briefer look at self-supervised learning\\nin later chapters. \\n4.1.4 Reinforcement learning\\nLong overlooked, this branch of machine learning recently started to get a lot of\\nattention after Google DeepMind successfully applied it  to learning to play Atari\\ngames (and, later, learning to play Go at the highest level). In reinforcement learning,\\nan agent  receives information about its environm ent and learns to choose actions that\\nwill maximize some reward. For instance, a neur al network that “looks” at a video-\\ngame screen and outputs game actions in or der to maximize its score can be trained\\nvia reinforcement learning.\\n Currently, reinforcement learning is most ly a research area and hasn’t yet had sig-\\nnificant practical succ esses beyond games. In time, ho wever, we expect to see rein-\\nforcement learning take over an increasing ly large range of real -world applications:\\nself-driving cars, robotics, resource management, educatio n, and so on. It’s an idea\\nwhose time has come, or will come soon.  \\nClassification and regression glossary\\nClassification and regression involve many specialized terms. You’ve come across\\nsome of them in earlier examples, and you’ll see more of them in future chapters.\\nThey have precise, machine-learning-specific definitio ns, and you should be familiar\\nwith them:\\n\\uf0a1Sample  or input—One data point that goes into your model.\\n\\uf0a1Prediction  or output —What comes out of your model.\\n\\uf0a1Target —The truth. What your model should ideally have predicted, according\\nto an external source of data.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 117}), Document(page_content='96 CHAPTER  4Fundamentals of machine learning\\n \\n(continued)\\n\\uf0a1Prediction error  or loss value —A measure of the distance between your\\nmodel’s prediction and the target.\\n\\uf0a1Classes —A set of possible labels to choose from in a classification problem.\\nFor example, when classifying cat and dog pictures, “dog” and “cat” are the\\ntwo classes.\\n\\uf0a1Label —A specific instance of a class anno tation in a classification problem.\\nFor instance, if picture #1234 is annota ted as containing the class “dog,”\\nthen “dog” is a label of picture #1234.\\n\\uf0a1Ground-truth  or annotations —All targets for a dataset,  typically collected by\\nhumans.\\n\\uf0a1Binary classification —A classification task where each input sample should\\nbe categorized into two exclusive categories.\\n\\uf0a1Multiclass classification —A classification task where each input sample\\nshould be categorized into more than two categories: for instance, classifying\\nhandwritten digits.\\n\\uf0a1Multilabel classification —A classification task where each input sample can\\nbe assigned multiple labels. For instance, a given image may contain both a\\ncat and a dog and should be annotated both with the “cat” label and the\\n“dog” label. The number of labels per image is usually variable.\\n\\uf0a1Scalar regression —A task where the target is a continuous scalar value. Pre-\\ndicting house prices is a good example: the different target prices form a con-\\ntinuous space.\\n\\uf0a1Vector regression —A task where the target is a set of continuous values: for\\nexample, a continuous vector. If you’re doing regression against multiple val-\\nues (such as the coordinates of a bounding box in an image), then you’re\\ndoing vector regression.\\n\\uf0a1Mini-batch  or batch —A small set of samples (t ypically between 8 and 128)\\nthat are processed simultaneously by the model. The number of samples isoften a power of 2, to facilitate memory alloca tion on GPU. When training, a\\nmini-batch is used to compute a si ngle gradient-descent update applied to\\nthe weights of the model. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 118}), Document(page_content='97 Evaluating machine-learning models\\n4.2 Evaluating machine-learning models\\nIn the three examples presented in chapter 3,  we split the data into a training set, a\\nvalidation set, and a test set. The reason not to evaluate the models on the same datathey were trained on quickly became eviden t: after just a few epochs, all three models\\nbegan to overfit . That is, their performance on neve r-before-seen data started stalling\\n(or worsening) compared to their perfor mance on the training data—which always\\nimproves as training progresses.\\n In machine learning, the goal is to achieve models that generalize —that perform\\nwell on never-before-seen data—and overfi tting is the central obstacle. You can only\\ncontrol that which you can observe, so it’s crucial to be able to reliably measure the\\ngeneralization power of your model. The following sections look at strategies for miti-\\ngating overfitting and maximizing generalizat ion. In this section, we’ll focus on how\\nto measure generalization: how to evaluate machine-learning models.\\n4.2.1 Training, validation, and test sets\\nEvaluating a model always boils down to sp litting the available data into three sets:\\ntraining, validation, and test. You train on the training data and evaluate your model\\non the validation data. Once your model is ready for prime time, you test it one final\\ntime on the test data.\\n You may ask, why not have two sets: a training set and a test set? You’d train on the\\ntraining data and evaluate on  the test data. Much simpler!\\n The reason is that developing a model alwa ys involves tuning its configuration: for\\ne x a m p l e ,  c h o o s i n g  t h e  n u m b e r  o f  l a y e r s  o r  t h e  s i z e  o f  t h e  l a y e r s  ( c a l l e d  t h e  hyper-\\nparameters  of the model, to distinguish them from the parameters , which are the net-\\nwork’s weights). You do this tuning by using as a feedback signal the performance of\\nthe model on the validation data. In essence, this tuning is a form of learning : a search\\nfor a good configuration in some parameter space. As a result, tuning the configura-\\ntion of the model based on its performance on the validation set can quickly result in\\noverfitting to the validation set , even though your model is never directly trained on it.\\n Central to this phenomenon is the notion of information leaks . Every time you tune\\na hyperparameter of your model based on the model’s performance on the validation\\nset, some information about the validation data leaks into the model. If you do this\\nonly once, for one parameter, then very few bits of information will leak, and your val-\\nidation set will remain reliable to evalua te the model. But if you repeat this many\\ntimes—running one experiment, evaluating on  the validation set, and modifying your\\nmodel as a result—then you’ll leak an incr easingly significant am ount of information\\nabout the validation set into the model.\\n At the end of the day, you’ll end up with  a model that performs artificially well on\\nthe validation data, because that’s what you optimized it for. You care about perfor-\\nmance on completely new data, not the vali dation data, so you need to use a com-\\npletely different, never-before-seen dataset to evaluate the model: the test dataset. Your\\nmodel shouldn’t have had access to any information about the test set, even indirectly.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 119}), Document(page_content='98 CHAPTER  4Fundamentals of machine learning\\nIf anything about the model has been tuned based on test set performance, then your\\nmeasure of generalization will be flawed.\\n Splitting your data into training, validati on, and test sets may seem straightforward,\\nbut there are a few advanced ways to do it that can come in handy when little data is\\navailable. Let’s review three classic evaluati on recipes: simple ho ld-out validation, K-\\nfold validation, and iterated K- fold validation with shuffling.\\nSIMPLE  HOLD-OUT VALIDATION\\nSet apart some fraction of your data as your  test set. Train on the remaining data, and\\nevaluate on the test set. As you saw in the previous sections, in order to prevent infor-\\nmation leaks, you shou ldn’t tune your model based on the test set, and therefore you\\nshould also reserve a validation set.\\n Schematically, hold-out valid ation looks like figure 4.1.  The following listing shows\\na simple implementation.\\nnum_validation_samples = 10000\\nnp.random.shuffle(data)\\nvalidation_data = data[:num_validation_samples]\\ndata = data[num_validation_samples:]\\ntraining_data = data[:]\\nmodel = get_model()\\nmodel.train(training_data)\\nvalidation_score = model.evaluate(validation_data)\\n# At this point you can tune your model,\\n# retrain it, evaluate it, tune it again...\\nmodel = get_model()\\nmodel.train(np.concatenate([training_data,\\nvalidation_data]))\\ntest_score = model.evaluate(test_data)Listing 4.1 Hold-out validationTraining setTotal available labeled data\\nTrain on this Evaluate\\non thisHeld-out\\nvalidation\\nsetFigure 4.1 Simple hold-\\nout validation split\\nShuffling the data is \\nusually appropriate.Defines the \\nvalidation set\\nDefines the training set\\nTrains a model on the training \\ndata, and evaluates it on the \\nvalidation data\\nOnce you’ve tuned your \\nhyperparameters, it’s common to \\ntrain your final model from scratch \\non all non-test data available.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 120}), Document(page_content='99 Evaluating machine-learning models\\nThis is the simplest evaluation protocol, an d it suffers from one flaw: if little data is\\navailable, then your validation and test sets  may contain too few samples to be statisti-\\ncally representative of the data at hand. This  is easy to recognize: if different random\\nshuffling rounds of the data before splitti ng end up yielding very different measures\\nof model performance, then you’re having this issue. K-fold validation and iterated\\nK-fold validation are two ways to address this, as discussed next. \\nK-FOLD VALIDATION\\nWith this approach, you split your data into K partitions of equal size. For each parti-\\ntion i, train a model on the remaining K – 1 partitions, and evaluate it on partition i.\\nYour final score is then  the averages of the K scores obtained. This method is helpful\\nwhen the performance of your model shows significant variance based on your train-\\ntest split. Like hold-out validation, this method doesn’t exempt you from using a dis-\\ntinct validation set for model calibration.\\n Schematically, K-fold cross- validation looks like figure 4.2. Listing 4.2 shows a simple\\nimplementation.\\nk=4\\nnum_validation_samples = len(data) // k\\nnp.random.shuffle(data)\\nvalidation_scores = []\\nfor fold in range(k):\\nvalidation_data = data[num_validation_samples * fold:\\nnum_validation_samples * (fold + 1)]\\ntraining_data = data[:num_validation_samples * fold] +\\ndata[num_validation_samples * (fold + 1):]\\nmodel = get_model()\\nmodel.train(training_data)validation_score = model.evaluate(validation_data)\\nvalidation_scores.append(validation_score)Listing 4.2 K-fold cross-validationData split into 3 partitions\\nValidation Training TrainingValidation\\nscore #1Fold 1\\nValidation Validation TrainingValidation\\nscore #2Final score:\\naverageFold 2\\nValidation Training ValidationValidation\\nscore #3Fold 3\\nFigure 4.2 Three-fold validation\\nSelects the validation-\\ndata partition\\nUses the remainder of the data \\nas training data . Note that the \\n+ operator is list concatenation, not summation.\\nCreates a brand-new instance \\nof the model (untrained)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 121}), Document(page_content='100 CHAPTER  4Fundamentals of machine learning\\nvalidation_score = np.average(validation_scores)\\nmodel = get_model()\\nmodel.train(data)\\ntest_score = model.evaluate(test_data)\\nITERATED  K-FOLD VALIDATION  WITH SHUFFLING\\nThis one is for situations in which you have relatively little data available and you need\\nto evaluate your model as precisely as possible. I’ve found it to be extremely helpful in\\nKaggle competitions. It consists of applying K-fold validation multiple times, shuffling\\nthe data every time before splitting it K ways. The final score is the average of the\\nscores obtained at each run of K-fold validation. Note that you end up training and\\nevaluating P × K models (where P is the number of iterations you use), which can very\\nexpensive. \\n4.2.2 Things to keep in mind\\nKeep an eye out for the following when yo u’re choosing an evaluation protocol:\\n\\uf0a1Data representativeness —You want both your training set and test set to be repre-\\nsentative of the data at hand. For instance , if you’re trying to classify images of\\ndigits, and you’re starting from an array of samples where the samples are\\nordered by their class, taking the first 80%  of the array as your training set and\\nthe remaining 20% as your test set will result in your training set containing\\nonly classes 0–7, whereas your test set co ntains only classes 8–9. This seems like\\na ridiculous mistake, but it’s surprising ly common. For this reason, you usually\\nshould randomly shuffle  your data before splitting it into training and test sets.\\n\\uf0a1The arrow of time —If you’re trying to predict the future given the past (for exam-\\nple, tomorrow’s weathe r, stock movements, and so on), you should not ran-\\ndomly shuffle your data before splitting  it, because doing so will create a\\ntemporal leak : your model will effectively be trained on data from the future. In\\nsuch situations, you should always make  sure all data in your test set is posterior\\nto the data in the training set.\\n\\uf0a1Redundancy in your data —If some data points in your data appear twice (fairly\\ncommon with real-world data ), then shuffling the data and splitting it into a\\ntraining set and a validation set will result in redundancy between the training\\nand validation sets. In effect, you’ll be testing on part of your training data,\\nwhich is the worst thing you can do! Make  sure your training set and validation\\nset are disjoint. Validation score: \\naverage of the validation scores \\nof the k foldsTrains the final \\nmodel on all non-\\ntest data available\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 122}), Document(page_content='101 Data preprocessing, feature engineering, and feature learning\\n4.3 Data preprocessing, feature engineering, \\nand feature learning\\nIn addition to model evaluati on, an important question we must tackle before we dive\\ndeeper into model development is the foll owing: how do you prepare the input data\\nand targets before feeding them into a neur al network? Many data-preprocessing and\\nfeature-engineering techniques are domain spec ific (for example, specific to text data\\nor image data); we’ll cover those in the fo llowing chapters as we encounter them in\\npractical examples. For now, we’ll review  the basics that are common to all data\\ndomains.\\n4.3.1 Data preprocessing for neural networks\\nData preprocessing aims at making the raw data at hand more amenable to neural\\nnetworks. This includes vectorization, no rmalization, handling missing values, and\\nfeature extraction.\\nVECTORIZATION\\nAll inputs and targets in a neural network must  be tensors of floating-point data (or, in\\nspecific cases, tensors of integers). Whatever data you need to process—sound,\\nimages, text—you must first turn  into tensors, a step called data vectorization . For\\ninstance, in the two previous text-classifica tion examples, we started from text repre-\\nsented as lists of integers (standing for sequences of words), and we used one-hot\\nencoding to turn them into a tensor of float32  data. In the examples of classifying\\ndigits and predicting house prices, the data  already came in vectorized form, so you\\nwere able to skip this step. \\nVALUE NORMALIZATION\\nIn the digit-classification example, you star ted from image data encoded as integers in\\nthe 0–255 range, encoding grayscale values. Before you fed this data into your net-\\nwork, you had to cast it to float32  and divide by 255 so you’d end up with floating-\\npoint values in the 0–1 rang e. Similarly, when predicti ng house prices, you started\\nfrom features that took a variety of ranges —some features had small floating-point val-\\nues, others had fairly large integer values. Before you fed this data into your network,\\nyou had to normalize each feature independen tly so that it had a standard deviation\\nof 1 and a mean of 0.\\n In general, it isn’t safe to feed into a neur al network data that takes relatively large val-\\nues (for example, multidigit integers, which ar e much larger than the initial values taken\\nby the weights of a network) or data that is heterogeneous (for example, data where onefeature is in the range 0–1 and another is in the range 100–200). Doing so can trigger\\nlarge gradient updates that w ill prevent the network from co nverging. To make learning\\neasier for your network, your data sh ould have the following characteristics:\\n\\uf0a1Take small values —Typically, most values sh ould be in the 0–1 range.\\n\\uf0a1Be homogenous —That is, all features should take values in roughly the same\\nrange.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 123}), Document(page_content='102 CHAPTER  4Fundamentals of machine learning\\nAdditionally, the following stricter normal ization practice is common and can help,\\nalthough it isn’t always necessary (for example,  you didn’t do this in  the digit-classification\\nexample):\\n\\uf0a1Normalize each feature independ ently to have a mean of 0.\\n\\uf0a1Normalize each feature independently to have a standard deviation of 1.\\nThis is easy to do with Numpy arrays:\\nx -= x.mean(axis=0)\\nx /= x.std(axis=0)\\nHANDLING  MISSING  VALUES\\nYou may sometimes have missing values in yo ur data. For instance, in the house-price\\nexample, the first feature (the column of in dex 0 in the data) was the per capita crime\\nrate. What if this feature wasn’t available for all samples? You’d then have missing val-\\nues in the training or test data.\\n In general, with neural networks, it’s safe to input missing values as 0, with the con-\\ndition that 0 isn’t already a meaningful valu e. The network will learn from exposure to\\nthe data that the value 0 means missing data  and will start ignoring the value.\\n Note that if you’re expecting missing values in the test data, but the network was\\ntrained on data without any missing values, the network won’t have learned to ignore\\nmissing values! In this situation, you should  artificially generate  training samples with\\nmissing entries: copy some training samples several ti mes, and drop some of the fea-\\ntures that you expect are likely to be missing in the test data. \\n4.3.2 Feature engineering\\nFeature engineering  is the process of using your own knowledge about the data and about\\nthe machine-learning algorithm at hand (in this case, a neural network) to make the\\nalgorithm work better by applying\\nhardcoded (nonlearned) transfor-mations to the data before it goesinto the model. In many cases, it isn’t\\nreasonable to expect a machine-\\nlearning model to be able to learn\\nfrom completely arbitrary data. The\\ndata needs to be presented to the\\nmodel in a way that will make themodel’s job easier.\\n Let’s look at an intuitive example.\\nSuppose you’re trying to develop amodel that can take as input an\\nimage of a clock and can output the\\ntime of day (see figure 4.3).Assuming x is a 2D data matrix \\nof shape (samples, features) \\nRaw data:\\npixel grid\\nBetter\\nfeatures:\\nclock hands’\\ncoordinates{x1: 0.7,\\ny1: 0.7}\\n{x2: 0.5,\\ny2: 0.0}{x1: 0.0,\\ny2: 1.0}\\n{x2: -0.38,\\n2: 0.32}\\nEven better\\nfeatures:\\nangles of\\nclock handstheta1: 45\\ntheta2: 0theta1: 90\\ntheta2: 140\\nFigure 4.3 Feature engineering for reading the time on \\na clock\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 124}), Document(page_content='103 Data preprocessing, feature engineering, and feature learning\\nIf you choose to use the raw pixels of the image as input data, then you have a difficult\\nmachine-learning problem on your hands. You’ll need a convolutional neural net-\\nwork to solve it, and you’ll have to expend  quite a bit of com putational resources to\\ntrain the network.\\n But if you already understa nd the problem at a high level (you understand how\\nhumans read time on a clock face), then you can come up with much better input fea-\\ntures for a machine-learning algorithm: for instance, it’s easy to write a five-line\\nPython script to follow the black pixels of  the clock hands and ou tput the (x, y) coor-\\ndinates of the tip of each hand. Then a si mple machine-learning  algorithm can learn\\nto associate these coordinates with the appropriate time of day.\\n You can go even further: do a coordina te change, and express the (x, y) coordi-\\nnates as polar coordinates with regard to the center of the image. Your input will\\nbecome the angle theta  of each clock hand. At this point, your features are making\\nthe problem so easy that no machine learni ng is required; a simple rounding opera-\\ntion and dictionary lookup are enough to recover the approximate time of day.\\n That’s the essence of feature engineerin g: making a problem easier by expressing\\nit in a simpler way. It usually requir es understanding the problem in depth.\\n Before deep learning, feature engineering used to be critical, because classical\\nshallow algorithms didn’t have hypothesis sp aces rich enough to learn useful features\\nby themselves. The way you presented the data  to the algorithm was essential to its suc-\\ncess. For instance, before convolutional ne ural networks became successful on the\\nMNIST  digit-classification probl em, solutions were typically  based on hardcoded fea-\\ntures such as the number of loops in a digit image, the height of each digit in an\\nimage, a histogram of pixel values, and so on.\\n Fortunately, modern deep learning remo ves the need for most feature engineer-\\ning, because neural networks are capable of  automatically extrac ting useful features\\nfrom raw data. Does this mean you don’t have to worry about feature engineering as\\nlong as you’re using deep neural networks? No, for two reasons:\\n\\uf0a1Good features still allow you to solve problems more elegantly while using fewer\\nresources. For instance, it would be ridiculous to solve the problem of reading a\\nclock face using a convol utional neural network.\\n\\uf0a1Good features let you solve a problem wi th far less data. The ability of deep-\\nlearning models to learn fe atures on their own relies on having lots of training\\ndata available; if you have only a few samples, then the information value in\\ntheir features becomes critical. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 125}), Document(page_content='104 CHAPTER  4Fundamentals of machine learning\\n4.4 Overfitting and underfitting\\nIn all three examples in the previous chapte r—predicting movie reviews, topic classifi-\\ncation, and house-price regression—the performance of the model on the held-outvalidation data always peaked after a fe w epochs and then began to degrade: the\\nmodel quickly started to overfit  to the training data. Ov erfitting happens in every\\nmachine-learning problem. Learning how to de al with overfitting is essential to mas-\\ntering machine learning.\\n The fundamental issue in machine learni ng is the tension between optimization\\nand generalization. Optimization  refers to the process of adjusting a model to get the\\nbest performance possible on the training data (the learning  in machine learning ),\\nwhereas generalization  refers to how well the trained model performs on data it has\\nnever seen before. The goal of the game is to get good generalization, of course, but\\nyou don’t control generalization; you can on ly adjust the model based on its training\\ndata.\\n At the beginning of training, optimizati on and generalization are correlated: the\\nlower the loss on training data , the lower the loss on test data. While this is happening,\\nyour model is said to be underfit : there is still progress to be made; the network hasn’t\\nyet modeled all relevant patterns in the tr aining data. But after a certain number of\\niterations on the training data, generalizati on stops improving, and validation metrics\\nstall and then begin to degrade: the model is starting to overfit. That is, it’s beginning\\nto learn patterns that are specific to the trai ning data but that are misleading or irrele-\\nvant when it comes to new data.\\n To prevent a model from le arning misleading or irrelevant patterns found in the\\ntraining data, the best solution is to get more training data . A model trained on more data\\nwill naturally generalize better. When that isn’t possible, the next-best solution is to\\nmodulate the quantity of information that yo ur model is allowed to store or to add\\nconstraints on what information it’s allowed to store. If a network can only afford to\\nmemorize a small number of patterns, the opti mization process will force it to focus\\non the most prominent patterns, which have  a better chance of generalizing well.\\n The processing of fighting ov erfitting this way is called regularization . Let’s review\\nsome of the most common regularization techniques and apply them in practice to\\nimprove the movie-classificati on model from section 3.4.\\n4.4.1 Reducing the network’s size\\nThe simplest way to prevent overfitting is to  reduce the size of the model: the number\\nof learnable parameters in the model (which  is determined by the number of layers\\nand the number of units per layer). In deep  learning, the number of learnable param-\\neters in a model is often referred to as the model’s capacity . Intuitively, a model with\\nmore parameters has more memorization capacity  and therefore can easily learn a per-\\nfect dictionary-like mapping between trai ning samples and their targets—a mapping\\nwithout any generalization power. For instan ce, a model with 500,000 binary parame-\\nters could easily be made to lear n the class of every digit in the MNIST  training set:\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 126}), Document(page_content=\"105 Overfitting and underfitting\\nwe’d need only 10 binary parameters for each of the 50,000 digits. But such a model\\nwould be useless for cl assifying new digit sa mples. Always keep this in mind: deep-\\nlearning models tend to be good at fitting to the training data, but the real challenge\\nis generalization, not fitting.\\n On the other hand, if the network has li mited memorization re sources, it won’t be\\nable to learn this mapping as easily; thus, in  order to minimize it s loss, it will have to\\nresort to learning compressed representati ons that have predictive power regarding\\nthe targets—precisely the type of represen tations we’re interested in. At the same\\ntime, keep in mind that you should use models that have enough parameters that they\\ndon’t underfit: your model shouldn’t be st arved for memorization  resources. There is\\na compromise to be found between too much capacity  and not enough capacity .\\n Unfortunately, there is no magical form ula to determine the right number of lay-\\ners or the right size for each layer. You mu st evaluate an array of different architec-\\ntures (on your validation set, not on your test set, of course) in order to find the\\ncorrect model size for your data. The genera l workflow to find an appropriate model\\nsize is to start with relatively few layers an d parameters, and increase the size of the lay-\\ners or add new layers until you see diminish ing returns with regard to validation loss.\\n Let’s try this on the movie-review classi fication network. The original network is\\nshown next.\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))model.add(layers.Dense(16, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nNow let’s try to replace it with this smaller network.\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(4, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nFigure 4.4 shows a comparison of the validat ion losses of the original network and the\\nsmaller network. The dots are the validation  loss values of the smaller network, and\\nthe crosses are the initial ne twork (remember, a lower valid ation loss signals a better\\nmodel).Listing 4.3 Original model\\nListing 4.4 Version of the model with lower capacity\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 127}), Document(page_content=\"106 CHAPTER  4Fundamentals of machine learning\\n \\nAs you can see, the smaller network starts overfitting later than the reference network\\n(after six epochs rather than four), and it s performance degrades more slowly once it\\nstarts overfitting.\\n Now, for kicks, let’s add to this benc hmark a network that has much more capac-\\nity—far more than the problem warrants.\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(512, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nFigure 4.5 shows how the bigger network fa res compared to the reference network.\\nThe dots are the validation loss values of the bigger network, and the crosses are the\\ninitial network.Listing 4.5 Version of the model with higher capacity\\nFigure 4.4 Effect of model \\ncapacity on validation loss: trying \\na smaller model\\nFigure 4.5 Effect of model \\ncapacity on validation loss: trying a bigger model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 128}), Document(page_content='107 Overfitting and underfitting\\nThe bigger network starts over fitting almost immediately, after just one epoch, and it\\noverfits much more se verely. Its validation loss is also noisier.\\n Meanwhile, figure 4.6 shows the training  losses for the two networks. As you can\\nsee, the bigger network gets its training lo ss near zero very quic kly. The more capacity\\nthe network has, the more quickly it can model the training data (resulting in a low\\ntraining loss), but the more su sceptible it is to overfittin g (resulting in a large differ-\\nence between the training and validation loss).  \\n4.4.2 Adding weight regularization\\nYou may be familiar wi th the principle of Occam’s razor : given two explanations for\\nsomething, the explanation most  likely to be correct is the simplest one—the one that\\nmakes fewer assumptions. This idea also ap plies to the models le arned by neural net-\\nworks: given some training data and a netw ork architecture, multiple sets of weight\\nvalues (multiple models ) could explain the data. Simpler models are less likely to over-\\nfit than complex ones.\\n A simple model  in this context is a model where the distribution of parameter values\\nhas less entropy (or a model with fewer para meters, as you saw in the previous sec-\\ntion). Thus a common way to mitigate overfi tting is to put constraints on the complex-\\nity of a network by forcing its weights to take only small values, which makes the\\ndistribution of weight values more regular . This is called weight regularization , and it’s\\ndone by adding to the loss function of the network a cost associated with having large\\nweights. This cost comes in two flavors:\\n\\uf0a1L1 regularization —The cost added is proportional to the absolute value of the\\nweight coefficients  (the L1 norm  of the weights).\\n\\uf0a1L2 regularization —The cost added is proportional to the square of the value of the\\nweight coefficients  (the L2 norm  of the weights). L2 regularization is also called\\nweight decay  in the context of neural networks . Don’t let the different name con-\\nfuse you: weight decay is mathematically the same as L2 regularization.\\nFigure 4.6 Effect of model \\ncapacity on training loss: trying a bigger model\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 129}), Document(page_content=\"108 CHAPTER  4Fundamentals of machine learning\\nIn Keras, weight regulariza tion is added by passing weight regularizer instances  to layers\\nas keyword arguments. Let’s add L2 weight regularization to the movie-review classifi-\\ncation network.\\nfrom keras import regularizers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\\nactivation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\\nactivation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nl2(0.001)  means every coefficient in the weight matrix of the layer will add 0.001 *\\nweight_coefficient_value  to the total loss of the network. Note that because this\\npenalty is only added at training time , the loss for this network will be much higher at\\ntraining than at test time.\\n Figure 4.7 shows the impact of the L2 regularization penalty. As you can see, the\\nmodel with L2 regularization (dots) has become much more resistant to overfitting\\nthan the reference model (crosses), even though both models ha ve the same number\\nof parameters.\\nAs an alternative to L2 regularization, you can use one of the following Keras weight\\nregularizers.\\nfrom keras import regularizers\\nregularizers.l1(0.001)\\nregularizers.l1_l2(l1=0.001, l2=0.001)Listing 4.6 Adding L2 weight regularization to the model\\nListing 4.7 Different weight regularizers available in Keras\\nFigure 4.7 Effect of L2 weight \\nregularization on validation loss\\nL1 regularizationSimultaneous L1 and \\nL2 regularization \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 130}), Document(page_content='109 Overfitting and underfitting\\n4.4.3 Adding dropout\\nDropout  is one of the most effective and mo st commonly used regularization tech-\\nniques for neural networks, developed by Geoff Hinton and his students at the Uni-versity of Toronto. Dropout, applied to a layer, consists of randomly dropping out\\n(setting to zero) a number of output featur es of the layer during training. Let’s say a\\ngiven layer would normally return a vector [0 .2, 0.5, 1.3, 0.8, 1.1] for a given input\\nsample during training. After ap plying dropout, this vector will have a few zero entries\\ndistributed at random: for example, [0, 0.5, 1.3, 0, 1.1]. The dropout rate  is the fraction\\nof the features that are zeroed  out; it’s usually set between 0.2 and 0.5. At test time, no\\nunits are dropped out; instead, the layer’s output values are scaled down by a factor\\nequal to the dropout rate, to balance for th e fact that more units are active than at\\ntraining time.\\n Consider a Numpy matrix contai ning the output of a layer, \\nlayer_output , of\\nshape (batch_size, features) . At training time, we zero out at random a fraction of\\nthe values in the matrix:\\nlayer_output *= np.random.randint(0, high=2, size=layer_output.shape)\\nAt test time, we scale down the output by the dropout rate. Here, we scale by 0.5\\n(because we previously dropped half the units):\\nlayer_output *= 0.5\\nNote that this process can be implemented by doing both operations at training time\\nand leaving the output unchanged at test time, which is often the way it’s imple-\\nmented in practice (see figure 4.8):\\nlayer_output *= np.random.randint(0, high=2, size=layer_output.shape)\\nlayer_output /= 0.5\\nThis technique may seem strange and arbitr ary. Why would this help reduce overfit-\\nting? Hinton says he was inspired by, am ong other things, a fr aud-prevention mecha-\\nnism used by banks. In his own words, “I went to my bank. The tellers kept changing\\nand I asked one of them why. He said he didn’t know but they got moved around a lot.At training time , drops out 50%\\nof the units in the output\\nAt test time\\nAt training timeNote that we’re scaling up rather \\nscaling down in this case.\\n0.3\\n* 20.6\\n0.20.70.2\\n0.11.90.51.50.00.31.00.00.3\\n1.2\\n0.00.0\\n50%\\ndropout 0.6\\n0.00.70.2\\n0.11.90.01.5\\n0.00.30.00.0\\n0.30.00.0\\nFigure 4.8 Dropout applied to an \\nactivation matrix at training time, with rescaling happening during \\ntraining. At test time, the activation \\nmatrix is unchanged.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 131}), Document(page_content=\"110 CHAPTER  4Fundamentals of machine learning\\nI figured it must be becaus e it would require cooperation between employees to suc-\\ncessfully defraud the bank. This made me re alize that randomly removing a different\\nsubset of neurons on each example would prevent conspiracies and thus reduce over-fitting.”\\n1 The core idea is that introducing nois e in the output values of a layer can\\nbreak up happenstance patterns that aren’t  significant (what Hinton refers to as con-\\nspiracies ), which the network will start memorizing if no noise is present.\\n In Keras, you can introduce dropout in a network via the Dropout  layer, which is\\napplied to the output of the layer right before it:\\nmodel.add(layers.Dropout(0.5))\\nLet’s add two Dropout  layers in the IMDB  network to see how well they do at reducing\\noverfitting.\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\\nmodel.add(layers.Dropout(0.5))model.add(layers.Dense(16, activation='relu'))model.add(layers.Dropout(0.5))model.add(layers.Dense(1, activation='sigmoid'))\\nFigure 4.9 shows a plot of the results. Again, this is a clear improvement over the refer-\\nence network.\\nTo recap, these are the most common ways to prevent overfitting in neural networks:\\n\\uf0a1Get more training data.\\n\\uf0a1Reduce the capacity of the network.\\n\\uf0a1Add weight regularization.\\n\\uf0a1Add dropout. \\n1See the Reddit thread “AMA: We are the Google Brain team. We’d love to answer your questions about\\nmachine learning,” http:/ /mng.bz/XrsS .Listing 4.8 Adding dropout to the IMDB network\\nFigure 4.9 Effect of dropout \\non validation loss\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 132}), Document(page_content='111 The universal workflow of machine learning\\n4.5 The universal workfl ow of machine learning\\nIn this section, we’ll present a universal bl ueprint that you can use to attack and solve\\nany machine-learning problem. The bluepr int ties together the concepts you’ve\\nlearned about in this chapter: problem de finition, evaluation, feature engineering,\\nand fighting overfitting.\\n4.5.1 Defining the problem and assembling a dataset\\nFirst, you must define  the problem at hand:\\n\\uf0a1What will your input data be? What are yo u trying to predict? You can only learn\\nto predict something if you have availa ble training data: for example, you can\\nonly learn to classify the sentiment of  movie reviews if you have both movie\\nreviews and sentiment annotations available.  As such, data availability is usually\\nthe limiting factor at this stage (unless you have the means to pay people to col-\\nlect data for you).\\n\\uf0a1What type of problem are you facing? Is it  binary classification? Multiclass classi-\\nfication? Scalar regression? Vector regression? Multicla ss, multilabel classifica-\\ntion? Something else, like clustering, ge neration, or reinforcement learning?\\nIdentifying the problem type will guide yo ur choice of model architecture, loss\\nfunction, and so on.\\nYou can’t move to the next stage until you know what your inputs and outputs are, and\\nwhat data you’ll use. Be aware of th e hypotheses you make at this stage:\\n\\uf0a1You hypothesize that your outputs can be predicted given your inputs.\\n\\uf0a1You hypothesize that your available data is sufficiently informative to learn the\\nrelationship between inputs and outputs.\\nUntil you have a working model, these are merely hypotheses, waiting to be validated\\nor invalidated. Not all problems can be solv ed; just because you’ve assembled exam-\\nples of inputs X and targets Y doesn’t mean X contai ns enough information to predict\\nY. For instance, if you’re trying to predic t the movements of a stock on the stock mar-\\nket given its recent price hi story, you’re unlikely to succeed, because price history\\ndoesn’t contain much pr edictive information.\\n One class of unsolvable problems you should be aware of is nonstationary problems .\\nSuppose you’re trying to build a recommend ation engine for clothing, you’re training\\nit on one month of data (August), and yo u want to start gene rating recommendations\\nin the winter. One big issue is  that the kinds of clothes people buy change from season\\nto season: clothes buying is a nonstation ary phenomenon over the scale of a few\\nmonths. What you’re trying to  model changes over time. In this case, the right move is\\nt o  c o n s t a n t l y  r e t r a i n  y o u r  m o d e l  o n  d a t a  f r o m  t h e  r e c e n t  p a s t ,  o r  g a t h e r  d a t a  a t  a\\ntimescale where the problem is stationary. Fo r a cyclical problem like clothes buying, a\\nfew years’ worth of data will suffice to capture seasonal variation—but remember to\\nmake the time of the year an input of your model!\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 133}), Document(page_content='112 CHAPTER  4Fundamentals of machine learning\\n Keep in mind that machine learning can only be used to memorize patterns that\\nare present in your training data. You can only recognize what you’ve seen before.\\nUsing machine learning trained on past da ta to predict the future is making the\\nassumption that the future will behave like the past. That often isn’t the case. \\n4.5.2 Choosing a measure of success\\nTo control something, you need  to be able to observe it. To achieve success, you must\\ndefine what you mean by success—accuracy ? Precision and recall? Customer-retention\\nrate? Your metric for success will guide the choice of a loss functi on: what your model\\nwill optimize. It should direct ly align with your higher-level  goals, such as the success\\nof your business.\\n For balanced-classification pr oblems, where every class is equally likely, accuracy and\\narea under the receiver operating characteristic curve  (ROC AUC) are common metrics. For\\nclass-imbalanced problems, you can use pr ecision and recall. For ranking problems or\\nmultilabel classification, you can use mean  average precision. And it isn’t uncommon\\nto have to define your own custom metric by which to measure success. To get a sense\\nof the diversity of machine-learning success metrics and how they relate to different\\nproblem domains, it’s helpfu l to browse the data scie nce competitions on Kaggle\\n(https:/ /kaggle.com ); they showcase a wide range of  problems and eval uation metrics. \\n4.5.3 Deciding on an evaluation protocol\\nOnce you know what you’re aiming for, you must establish ho w you’ll measure your\\ncurrent progress. We’ve previously revi ewed three common evaluation protocols:\\n\\uf0a1Maintaining a hold-out validation set —The way to go when you have plenty of\\ndata\\n\\uf0a1Doing K-fold cross-validation —The right choice when you have too few samples\\nfor hold-out validation to be reliable\\n\\uf0a1Doing iterated K-fold validation —For performing highly accurate model evalua-\\ntion when little data is available\\nJust pick one of these. In most case s, the first will work well enough. \\n4.5.4 Preparing your data\\nOnce you know what you’re training on, what  you’re optimizing for, and how to evalu-\\nate your approach, you’re almost ready to begin training models. But first, you should\\nformat your data in a way that can be fed into a machine-learning model—here, we’ll\\nassume a deep neural network:\\n\\uf0a1As you saw previously, your data should be formatted as tensors.\\n\\uf0a1The values taken by these tensors should usually be scaled to small values: for\\nexample, in the [-1, 1] range or [0, 1] range.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 134}), Document(page_content='113 The universal workflow of machine learning\\n\\uf0a1If different features take values in di fferent ranges (heterogeneous data), then\\nthe data should be normalized.\\n\\uf0a1You may want to do some feature engineer ing, especially for small-data problems.\\nOnce your tensors of input data and target da ta are ready, you can begin to train models. \\n4.5.5 Developing a model that does better than a baseline\\nYour goal at this stage is to achieve statistical power : that is, to develop a small model\\nthat is capable of beating a dumb baseline. In the MNIST  digit-classification example,\\nanything that achieves an a ccuracy greater than 0.1 can be said to have statistical\\npower; in the IMDB  example, it’s anything with an accuracy greater than 0.5.\\n Note that it’s not always possible to achiev e statistical power. If  you can’t beat a ran-\\ndom baseline after trying multiple reasonable  architectures, it may be that the answer\\nto the question you’re asking isn’t presen t in the input data. Remember that you make\\ntwo hypotheses:\\n\\uf0a1You hypothesize that your outputs can be predicted given your inputs.\\n\\uf0a1You hypothesize that the available data is sufficiently informative to learn the\\nrelationship between inputs and outputs.\\nIt may well be that these hypotheses are false, in which case you must go back to the\\ndrawing board.\\n Assuming that things go well, you need  to make three key choices to build your\\nfirst working model:\\n\\uf0a1Last-layer activation —This establishes useful cons traints on the network’s out-\\nput. For instance, the IMDB  classification example used sigmoid  in the last\\nlayer; the regression example didn’t us e any last-layer acti vation; and so on.\\n\\uf0a1Loss function —This should match the type of problem you’re trying to solve. For\\ninstance, the IMDB  example used binary_crossentropy , the regression exam-\\nple used mse, and so on.\\n\\uf0a1Optimization configuration —What optimizer will you use? What will its learning\\nrate be? In most cases, it’s safe to go with rmsprop  and its default learning rate.\\nRegarding the choice of a loss function, note  that it isn’t always possible to directly\\noptimize for the metric that measures su ccess on a problem. Sometimes there is no\\neasy way to turn a metric into a loss function ; loss functions, after all, need to be com-\\nputable given only a mini-batch of data (i deally, a loss function should be computable\\nfor as little as a single data point) and must  be differentiable (otherwise, you can’t use\\nbackpropagation to train your  network). For instance, the widely used classification\\nmetric ROC AUC can’t be directly optimi zed. Hence, in classifi cation tasks, it’s com-\\nmon to optimize for a proxy metric of ROC  AUC, such as crossentropy. In general, you\\ncan hope that the lower the crossentropy gets, the higher the ROC AUC will be.\\n Table 4.1 can help you choose a last-layer  activation and a loss function for a few\\ncommon prob lem types.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 135}), Document(page_content='114 CHAPTER  4Fundamentals of machine learning\\n \\n4.5.6 Scaling up: developing a model that overfits\\nOnce you’ve obtained a model that has statistical power, the question becomes, is your\\nmodel sufficiently powerful? Does it have enough layers and parameters to properly\\nmodel the problem at hand? For instance, a network with a single hidden layer with\\ntwo units would have statistical power on MNIST  but wouldn’t be sufficient to solve the\\nproblem well. Remember that the universa l tension in machine learning is between\\noptimization and generalization; the ideal mo del is one that stands right at the border\\nbetween underfitting and over fitting; between undercapacit y and overcapacity. To fig-\\nure out where this border li es, first you must cross it.\\n To figure out how big a model you’ll need , you must develop a model that overfits.\\nThis is fairly easy:\\n1Add layers.\\n2Make the layers bigger.\\n3Train for more epochs.\\nAlways monitor the training loss and validati on loss, as well as the training and valida-\\ntion values for any metrics you care abou t. When you see that the model’s perfor-\\nmance on the validation data begins to  degrade, you’ve achieved overfitting.\\n The next stage is to start regularizing and tuning the mo del, to get as close as pos-\\nsible to the ideal model that neither underfits nor overfits. \\n4.5.7 Regularizing your model and tuning your hyperparameters\\nThis step will take the most time: you’ll re peatedly modify your model, train it, evalu-\\nate on your validation data (not the test da ta, at this point), modify it again, and\\nrepeat, until the model is as good as it ca n get. These are some things you should try:\\n\\uf0a1Add dropout.\\n\\uf0a1Try different architectures:  add or remove layers.\\n\\uf0a1Add L1 and/or L2 regularization.Table 4.1 Choosing the right last-layer activation and loss function for your model\\nProblem type Last-layer activation Loss function\\nBinary classification sigmoid binary_crossentropy\\nMulticlass, single-label classification softmax categorical_crossentropy\\nMulticlass, multilabel classification sigmoid binary_crossentropy\\nRegression to arbitrary values None mse\\nRegression to values between 0 and 1 sigmoid mse  or binary_crossentropy\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 136}), Document(page_content='115 The universal workflow of machine learning\\n\\uf0a1Try different hyperparameter s (such as the number of units per layer or the\\nlearning rate of the optimizer) to find the optimal configuration.\\n\\uf0a1Optionally, iterate on feature engineer ing: add new features, or remove fea-\\ntures that don’t seem to be informative.\\nBe mindful of the following: every time you use feedback from your validation process\\nto tune your model, you leak information about the validation process into the model.\\nRepeated just a few times, th is is innocuous; but done sy stematically over many itera-\\ntions, it will eventually cause your mode l to overfit to the validation process (even\\nthough no model is directly trained on an y of the validation data). This makes the\\nevaluation process less reliable.\\n Once you’ve developed a sa tisfactory model configuration, you can train your final\\nproduction model on all the available data  (training and validation) and evaluate it\\none last time on the test set.  If it turns out that performance on the test set is signifi-\\ncantly worse than the performance measured on the validation data, this may mean\\neither that your validation pr ocedure wasn’t reliable after all, or that you began over-\\nfitting to the validation data while tuning the parameters of the model. In this case,\\nyou may want to switch to a more reliabl e evaluation protocol (such as iterated K-fold\\nvalidation). \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 137}), Document(page_content='116 CHAPTER  4Fundamentals of machine learning\\nChapter summary\\n\\uf0a1Define the problem at hand and the data on which you’ll train. Collect\\nthis data, or annotate it with labels if need be.\\n\\uf0a1Choose how you’ll meas ure success on your probl em. Which metrics will\\nyou monitor on your validation data?\\n\\uf0a1Determine your evaluation protocol: hold-out validation? K-fold valida-\\ntion? Which portion of the data  should you use for validation?\\n\\uf0a1Develop a first model that does better  than a basic baseline: a model with\\nstatistical power.\\n\\uf0a1Develop a model that overfits.\\n\\uf0a1Regularize your model and tune its hyperparameters, based on perfor-\\nmance on the validation data. A lot of  machine-learning research tends to\\nfocus only on this step—but keep the big picture in mind.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 138}), Document(page_content='Part 2\\nDeep learning in practice\\nC hapters 5–9 will help you gain practi cal intuition about how to solve real-\\nworld problems using deep learning, and wi ll familiarize you with essential deep-\\nlearning best practices. Mo st of the code examples in the book are concentrated\\nin this second half.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 139}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 140}), Document(page_content='119Deep learning\\nfor computer vision\\nThis chapter introduces convolutiona l neural networks, also known as convnets , a\\ntype of deep-learning model almost univer sally used in computer vision applica-\\ntions. You’ll learn to apply convnets to image-classification problems—in particular\\nthose involving small training datasets, wh ich are the most common use case if you\\naren’t a large tech company.This chapter covers\\n\\uf0a1Understanding convolutional neural networks \\n(convnets)\\n\\uf0a1Using data augmentation to mitigate overfitting\\n\\uf0a1Using a pretrained convnet to do feature extraction\\n\\uf0a1Fine-tuning a pretrained convnet\\n\\uf0a1Visualizing what convnets learn and how they make classification decisions\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 141}), Document(page_content=\"120 CHAPTER  5Deep learning for computer vision\\n5.1 Introduction to convnets\\nWe’re about to dive into the theory of what convnets are and why they have been so\\nsuccessful at computer vision ta sks. But first, let’s take a pr actical look at a simple conv-\\nnet example. It uses a convnet to classify MNIST  digits, a task we performed in chapter\\n2 using a densely connected ne twork (our test accuracy then was 97.8%). Even though\\nthe convnet will be basic, its accuracy will  blow out of the water that of the densely\\nconnected model from chapter 2.\\n The following lines of code show you what  a basic convnet looks like. It’s a stack of\\nConv2D  and MaxPooling2D  layers. You’ll see in a minute exactly what they do.\\nfrom keras import layers\\nfrom keras import models\\nmodel = models.Sequential()\\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nImportantly, a convnet takes as input tensors of shape (image_height, image_width,\\nimage_channels)  (not including the batch dimension). In this case, we’ll configure\\nthe convnet to process inputs of size (28, 28, 1) , which is the format of MNIST\\nimages. We’ll do this by passing the argument input_shape=(28, 28, 1)  to the first\\nlayer.\\n Let’s display the architecture of the convnet so far:\\n>>> model.summary()\\n________________________________________________________________\\nLayer (type) Output Shape Param #\\n================================================================\\nconv2d_1 (Conv2D) (None, 26, 26, 32) 320________________________________________________________________\\nmaxpooling2d_1 (MaxPooling2D) (None, 13, 13, 32) 0\\n________________________________________________________________conv2d_2 (Conv2D) (None, 11, 11, 64) 18496\\n________________________________________________________________\\nmaxpooling2d_2 (MaxPooling2D) (None, 5, 5, 64) 0________________________________________________________________\\nconv2d_3 (Conv2D) (None, 3, 3, 64) 36928\\n================================================================Total params: 55,744\\nTrainable params: 55,744\\nNon-trainable params: 0\\nYou can see that the output of every Conv2D  and MaxPooling2D  layer is a 3D tensor of\\nshape (height, width, channels) . The width and height dimensions tend to shrinkListing 5.1 Instantiating a small convnet\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 142}), Document(page_content=\"121 Introduction to convnets\\nas you go deeper in the netw ork. The number of channels is controlled by the first\\nargument passed to the Conv2D  layers (32 or 64).\\n The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely\\nconnected classifier network like those yo u’re already familiar with: a stack of Dense\\nlayers. These classifiers pr ocess vectors, which are 1D, whereas the current output is a\\n3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense  lay-\\ners on top.\\nmodel.add(layers.Flatten())\\nmodel.add(layers.Dense(64, activation='relu'))\\nmodel.add(layers.Dense(10, activation='softmax'))\\nWe’ll do 10-way classification, using a final layer with 10 outputs and a softmax activa-\\ntion. Here’s what the network looks like now:\\n>>> model.summary()\\nLayer (type) Output Shape Param #\\n================================================================\\nconv2d_1 (Conv2D) (None, 26, 26, 32) 320\\n________________________________________________________________maxpooling2d_1 (MaxPooling2D) (None, 13, 13, 32) 0\\n________________________________________________________________\\nconv2d_2 (Conv2D) (None, 11, 11, 64) 18496________________________________________________________________\\nmaxpooling2d_2 (MaxPooling2D) (None, 5, 5, 64) 0\\n________________________________________________________________conv2d_3 (Conv2D) (None, 3, 3, 64) 36928\\n________________________________________________________________\\nflatten_1 (Flatten) (None, 576) 0________________________________________________________________\\ndense_1 (Dense) (None, 64) 36928\\n________________________________________________________________dense_2 (Dense) (None, 10) 650\\n================================================================\\nTotal params: 93,322Trainable params: 93,322\\nNon-trainable params: 0\\nAs you can see, the (3, 3, 64) outputs are flattened into vectors of shape (576,)\\nbefore going through two Dense  layers.\\n Now, let’s train the convnet on the MNIST  digits. We’ll reuse a lot of the code from\\nthe MNIST  example in chapter 2.\\nfrom keras.datasets import mnist\\nfrom keras.utils import to_categorical\\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()Listing 5.2 Adding a classifier on top of the convnet\\nListing 5.3 Training the convnet on MNIST images\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 143}), Document(page_content=\"122 CHAPTER  5Deep learning for computer vision\\ntrain_images = train_images.reshape((60000, 28, 28, 1))\\ntrain_images = train_images.astype('float32') / 255\\ntest_images = test_images.reshape((10000, 28, 28, 1))\\ntest_images = test_images.astype('float32') / 255\\ntrain_labels = to_categorical(train_labels)\\ntest_labels = to_categorical(test_labels)\\nmodel.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['accuracy'])\\nmodel.fit(train_images, train_labels, epochs=5, batch_size=64)\\nLet’s evaluate the model on the test data:\\n>>> test_loss, test_acc = model.evaluate(test_images, test_labels)>>> test_acc\\n0.99080000000000001\\nWhereas the densely connected network from chapter 2 had a test accuracy of 97.8%,\\nthe basic convnet has a test accuracy of 99.3%: we decreased the error rate by 68%(relative). Not bad!\\n But why does this simple convnet work so well, compared to a densely connected\\nmodel? To answer this, let’s dive into what the \\nConv2D  and MaxPooling2D  layers do.\\n5.1.1 The convolution operation\\nThe fundamental difference between a dens ely connected layer and a convolution\\nlayer is this: Dense  layers learn global patterns in their input feature space (for exam-\\nple, for a MNIST  digit, patterns involving all pixels), whereas convolution layers learn\\nlocal patterns (see figure 5.1): in the case of images, patterns found in small 2D win-\\ndows of the inputs. In the previous example, these windows were all 3 × 3.\\nFigure 5.1 Images can be broken \\ninto local patterns such as edges, \\ntextures, and so on.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 144}), Document(page_content='123 Introduction to convnets\\nThis key characteristic gives convnets two interesting properties:\\n\\uf0a1The patterns they learn are translation invariant.  After learning a certain pattern in\\nthe lower-right corner of a picture, a convnet can recognize it anywhere: for\\nexample, in the upper-left corner. A densely connected network would have to\\nlearn the pattern anew if it appeared at a new location. This makes convnets\\ndata efficient when processing images (because the visual world is fundamentally\\ntranslation invariant ): they need fewer training sa mples to learn representations\\nthat have generalization power.\\n\\uf0a1They can learn spatial hierarchies of patterns (see figure 5.2) . A first convolution layer\\nwill learn small local patterns such as  edges, a second convolution layer will\\nlearn larger patterns made of the features of the first layers, and so on. Thisallows convnets to efficiently learn incr easingly complex and abstract visual con-\\ncepts (because the visual world is fundamentally spatially hierarchical ).\\nConvolutions operate over \\n3D tensors, called feature maps , with two spatial axes ( height\\nand width ) as well as a depth  axis (also called the channels  axis). For an RGB image, the\\ndimension of the depth axis is 3, becaus e the image has three color channels: red,\\ngreen, and blue. For a black- and-white picture, like the MNIST  digits, the depth is 1\\n(levels of gray). The convolution operatio n extracts patches from its input feature\\nmap and applies the same transformation to all of these patches, producing an output\\nfeature map . This output feature map is still a 3D tensor: it has a width and a height. Its\\ndepth can be arbitrary, because the output depth is a parameter of the layer, and the“cat”\\nFigure 5.2 The visual world forms a spatial hierarchy of visual \\nmodules: hyperlocal edges combine into local objects such as eyes or ears, which combine into high-level concepts such as “cat.”\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 145}), Document(page_content='124 CHAPTER  5Deep learning for computer vision\\ndifferent channels in that depth axis no longer stand for specific colors as in RGB\\ninput; rather, they stand for filters . Filters encode specific aspe cts of the input data: at a\\nhigh level, a single filter could encode th e concept “presence of a face in the input,”\\nfor instance.\\n In the MNIST  example, the first convolution layer takes a feature map of size (28,\\n28, 1)  and outputs a feature map of size (26,  26, 32): it computes 32 filters over its\\ninput. Each of these 32 output channels cont ains a 26 × 26 grid of values, which is a\\nresponse map  of the filter over the input, indicating  the response of that filter pattern at\\ndifferent locations in the input (see figure 5.3). That is what the term feature map\\nmeans: every dimension in the depth axis is a feature (or filter), and the 2D tensor\\noutput[:, :, n]  is the 2D spatial map of the response of this filter over the input.\\nConvolutions are defined by two key parameters:\\n\\uf0a1Size of the patches extracted from the inputs —These are typically 3 × 3 or 5 × 5. In the\\nexample, they were 3 × 3, which is a common choice.\\n\\uf0a1Depth of the output feature map —The number of filters computed by the convolu-\\ntion. The example started with a depth of 32 and ended with a depth of 64.\\nIn Keras Conv2D  layers, these parameters are the first arguments passed to the layer:\\nConv2D(output_depth, (window_height, window_width)) .\\n A convolution works by sliding  these windows of size 3 × 3 or 5 × 5 over the 3D input\\nfeature map, stopping at every po ssible location, and extracting the 3D patch of sur-\\nrounding features (shape (window_height,  window_width,  input_depth) ). Each\\nsuch 3D patch is then transformed (via a tensor product with the same learned weight\\nmatrix, called the convolution kernel ) into a 1D vector of shape (output_depth,) . All of\\nthese vectors are then spatially reassembled into a 3D output map of shape (height,\\nwidth, output_depth) . Every spatial location in the output feature map corresponds\\nto the same location in the input feature map (for example, the lower-right corner of\\nthe output contains information about th e lower-right corner of the input). For\\ninstance, with 3 × 3 windows, the vector output[i,  j, :] comes from the 3D patch\\ninput[i-1:i+1,  j-1:j+1,  :]. The full process is detailed in figure 5.4.Response map,\\nquantifying the presenceof the filter’s pattern at different locations Original input\\nSingle filter\\nFigure 5.3 The concept of a \\nresponse map : a 2D map of the \\npresence of a pattern at different locations in an input\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 146}), Document(page_content='125 Introduction to convnets\\n \\nNote that the output width and height ma y differ from the input width and height.\\nThey may differ for two reasons:\\n\\uf0a1Border effects, which can be countered by padding the input feature map\\n\\uf0a1The use of strides , which I’ll define in a second\\nLet’s take a deeper look at these notions.\\nUNDERSTANDING  BORDER  EFFECTS  AND PADDING\\nConsider a 5 × 5 feature map (25 tiles total) . There are only 9 tiles around which you\\ncan center a 3 × 3 window, forming a 3 × 3 grid (see figure 5.5). Hence, the output fea-\\nture map will be 3 × 3. It shrinks a little: by exactly two tiles alongside each dimension,\\nin this case. You can see this border effect in action in the earlier example: you start\\nwith 28 × 28 inputs, which become 26 × 26 after the first convolution layer.Height\\nInput feature map\\nOutput feature map3 × 3 input patches\\nTransformed patchesWidth\\nInput\\ndepth\\nDot product\\nwith kernel\\nOutput\\ndepth\\nOutput\\ndepth\\nFigure 5.4 How convolution works\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 147}), Document(page_content='126 CHAPTER  5Deep learning for computer vision\\n \\nIf you want to get an output feature map with the same spatial dimensions as the\\ninput, you can use padding . Padding consists of adding an appropriate number of rows\\nand columns on each side of the input featur e map so as to make it possible to fit cen-\\nter convolution window s around every input tile. For a 3 × 3 window, you add one col-\\numn on the right, one column on the left,  one row at the top, and one row at the\\nbottom. For a 5 × 5 window, you add two rows (see figure 5.6).\\nIn Conv2D  layers, padding is configurable via the padding  argument, which takes two\\nvalues: \"valid\" , which means no padding (only valid window locations will be used);\\nand \"same\" , which means “pad in such a way as to  have an output with the same width\\nand height as the input.” The padding  argument defaults to \"valid\" . \\n Figure 5.5 Valid locations of 3 × 3 patches in a 5 × 5 input feature map\\netc.\\nFigure 5.6 Padding a 5 × 5 input in order to be able to extract 25 3 × 3 patches\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 148}), Document(page_content='127 Introduction to convnets\\nUNDERSTANDING  CONVOLUTION  STRIDES\\nThe other factor that can influence output size is the notion of strides . The description\\nof convolution so far has assumed that the center tiles of the co nvolution windows are\\nall contiguous. But the distance between two successive windows is  a parameter of the\\nconvolution, called its stride , which defaults to 1. It’s possible to have strided convolu-\\ntions : convolutions with a stride higher than 1. In figure 5.7, you can see the patches\\nextracted by a 3 × 3 convolution with stride  2 over a 5 × 5 input (without padding).\\nUsing stride 2 means the width and height of the feature map are downsampled by a\\nfactor of 2 (in addition to any changes in duced by border effects). Strided convolu-\\ntions are rarely used in practice, although  they can come in handy for some types of\\nmodels; it’s good to be familiar with the concept.\\n To downsample feature maps, instea d of strides, we tend to use the max-pooling\\noperation, which you saw in action in the first convnet example. Let’s look at it in\\nmore depth. \\n5.1.2 The max-pooling operation\\nIn the convnet example, you may have noticed that the size of the feature maps ishalved after every \\nMaxPooling2D  layer. For instance, before the first MaxPooling2D  lay-\\ners, the feature map is 26 × 26, but the max-pooling operation halves it to 13 × 13.\\nThat’s the role of max pooling: to aggre ssively downsample fe ature maps, much like\\nstrided convolutions.\\n Max pooling consists of extracting wind ows from the input feature maps and out-\\nputting the max value of each channel. It’s conceptually similar to  convolution, except\\nthat instead of transforming local patches vi a a learned linear tran sformation (the con-\\nvolution kernel), they’re transformed via a hardcoded max tensor operation. A big dif-\\nference from convolution is that max poolin g is usually done with 2 × 2 windows and11 2\\n3 42\\n34\\nFigure 5.7 3 × 3 convolution patches with 2 × 2 strides\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 149}), Document(page_content=\"128 CHAPTER  5Deep learning for computer vision\\nstride 2, in order to downsample the feature maps by a factor of 2. On the other hand,\\nconvolution is typically done with 3 × 3 windows and no stride (stride 1).\\n Why downsample feature maps this way?  Why not remove the max-pooling layers\\nand keep fairly large feature maps all the wa y up? Let’s look at this option. The convo-\\nlutional base of the model would then look like this:\\nmodel_no_max_pool = models.Sequential()\\nmodel_no_max_pool.add(layers.Conv2D(32, (3, 3), activation='relu',\\ninput_shape=(28, 28, 1)))\\nmodel_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nHere’s a summary of the model:\\n>>> model_no_max_pool.summary()\\nLayer (type) Output Shape Param #\\n================================================================\\nconv2d_4 (Conv2D) (None, 26, 26, 32) 320________________________________________________________________conv2d_5 (Conv2D) (None, 24, 24, 64) 18496\\n________________________________________________________________\\nconv2d_6 (Conv2D) (None, 22, 22, 64) 36928================================================================\\nTotal params: 55,744\\nTrainable params: 55,744Non-trainable params: 0\\nWhat’s wrong with this setup? Two things:\\n\\uf0a1It isn’t conducive to learning a spatial hierarchy of features . The 3 × 3 windows\\nin the third layer will only contain information coming from 7 × 7 windows in\\nthe initial input. The high-level patterns learned by the convnet will still be very\\nsmall with regard to the initial input, wh ich may not be enough to learn to clas-\\nsify digits (try recognizing a digit by on ly looking at it through windows that are\\n7 × 7 pixels!). We need the features from the last convolution layer to containinformation about the totality of the input.\\n\\uf0a1The final feature map has 22 × 22 × 64 = 30,976 total coefficients per sample.This is huge. If you were to flatten it to stick a \\nDense  layer of size 512 on top,\\nthat layer would have 15.8 million parameters. This is far too large for such a\\nsmall model and would result in intense overfitting.\\nIn short, the reason to use downsampling is to reduce the number of feature-map\\ncoefficients to process, as well as to induce  spatial-filter hierarch ies by making succes-\\nsive convolution layers look at increasingly  large windows (in terms of the fraction of\\nthe original input they cover).\\n Note that max pooling isn’t the only way you can achieve such downsampling. As\\nyou already know, you can also use strides in  the prior convolution layer. And you can\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 150}), Document(page_content='129 Introduction to convnets\\nuse average pooling instead of max pooling, where each local input patch is trans-\\nformed by taking the average value of each  channel over the patch, rather than the\\nmax. But max pooling tends to work better than these alternative solutions. In a nut-\\nshell, the reason is that features tend to  encode the spatial presence of some pattern\\nor concept over the different tiles of the feature map (hence, the term feature map ),\\nand it’s more informative to look at the maximal presence  of different features than at\\ntheir average presence . So the most reasonable subsampling strategy is to first produce\\ndense maps of features (via unstrided co nvolutions) and then look at the maximal\\nactivation of the features over small patches,  rather than looking at sparser windows of\\nthe inputs (via strided convolutions) or av eraging input patches, which could cause\\nyou to miss or dilute feature-presence information.\\n At this point, you should understand the basics of convnets—feature maps, convo-\\nlution, and max pooling—and you know how to build a small convnet to solve a toyproblem such as \\nMNIST  digits classification. Now let’s move on to more useful, practi-\\ncal applications. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 151}), Document(page_content='130 CHAPTER  5Deep learning for computer vision\\n5.2 Training a convnet from scratch on a small dataset\\nHaving to train an image-classification mode l using very little data is a common situ-\\nation, which you’ll likely encounter in prac tice if you ever do computer vision in a\\nprofessional context. A “few” samples can mean anywhere from a few hundred to a\\nfew tens of thousands of images. As a prac tical example, we’ll focus on classifying\\nimages as dogs or cats, in a dataset contai ning 4,000 pictures of cats and dogs (2,000\\ncats, 2,000 dogs). We’ll use 2,000 pictures for training—1,000 for validation, and\\n1,000 for testing.\\n In this section, we’ll review one basic strategy to tackle this problem: training a new\\nmodel from scratch using what little data yo u have. You’ll start by naively training a\\nsmall convnet on the 2,000 trai ning samples, without any re gularization, to set a base-\\nline for what can be achieved. This will ge t you to a classification accuracy of 71%. At\\nthat point, the main issue will be overfitting. Then we’ll introduce data augmentation , a\\npowerful technique for mitigating overfitting in computer vision. By using data aug-\\nmentation, you’ll improve the networ k to reach an accuracy of 82%.\\n In the next section, we’ ll review two more essential techniques for applying deep\\nlearning to small datasets: feature extraction with a pretrained network  (which will get you\\nto an accuracy of 90% to 96%) and fine-tuning a pretrained network  (this will get you to a\\nfinal accuracy of 97%). To gether, these three strategi es—training a small model from\\nscratch, doing feature extraction using a pretrained model, and fine-tuning a pre-\\ntrained model—will constitute your future  toolbox for tackling the problem of per-\\nforming image classification with small datasets.\\n5.2.1 The relevance of deep le arning for small-data problems\\nYou’ll sometimes hear th at deep learning only works when lots of data is available.\\nThis is valid in part: one fundamental characte ristic of deep learning is that it can find\\ninteresting features in the training data on  its own, without any need for manual fea-\\nture engineering, and this can only be achi eved when lots of training examples are\\navailable. This is especially true for pr oblems where the input samples are very high-\\ndimensional, like images.\\n But what constitutes lots of samples is relative—relative to the size and depth of the\\nnetwork you’re trying to train, for starters. It isn’t possible to train a convnet to solve a\\ncomplex problem with just a few tens of samples, bu t a few hundred can potentially\\nsuffice if the model is small and well regularized and the task is simple. Because conv-\\nnets learn local, translation-invariant featur es, they’re highly data efficient on percep-\\ntual problems. Training a convnet from scratc h on a very small image dataset will still\\nyield reasonable results despite a relative lack of data, without the need for any customfeature engineering. You’ll see th is in action in this section.\\n What’s more, deep-learning models are by nature highly repurposable: you can\\ntake, say, an image-classification or speech- to-text model trained on a large-scale dataset\\nand reuse it on a significantly different problem with only minor changes. Specifically,\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 152}), Document(page_content='131 Training a convnet from scratch on a small dataset\\nin the case of computer vision, many pretra ined models (usually trained on the Image-\\nNet dataset) are now publicly available for do wnload and can be used to bootstrap pow-\\nerful vision models out of very little data. That ’s what you’ll do in the next section. Let’s\\nstart by getting your hands on the data. \\n5.2.2 Downloading the data\\nThe Dogs vs. Cats dataset that you’ll use isn’t packaged with Keras. It was made avail-a b l e  b y  K a g g l e  a s  p a r t  o f  a  c o m p u t e r - v ision competition in late 2013, back when\\nconvnets weren’t ma instream. You can download the original dataset from www.kaggle\\n.com/c/dogs-vs-cats/data  (you’ll need to create a Kagg le account if you don’t already\\nhave one—don’t worry, the process is painless).\\n The pictures are medium-resolution color \\nJPEG s. Figure 5.8 shows some examples.\\nUnsurprisingly, the dogs-versus-cats Kaggle  competition in 2013 was won by entrants\\nwho used convnets. The best entries achiev ed up to 95% accuracy. In this example,\\nyou’ll get fairly close to this accuracy (i n the next section), even though you’ll train\\nyour models on less than 10% of the data  that was available to the competitors.\\n This dataset contains 25,000 images of dogs and cats (12,500 from each class) and\\nis 543 MB  (compressed). After downloading and un compressing it, you’ll create a new\\ndataset containing three subsets: a training se t with 1,000 samples of each class, a vali-\\ndation set with 500 samples of each class, an d a test set with 500 samples of each class.\\nFigure 5.8 Samples from the Dogs vs. Cats dat aset. Sizes weren’t modified: the samples are \\nheterogeneous in size, appearance, and so on.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 153}), Document(page_content=\"132 CHAPTER  5Deep learning for computer vision\\n Following is the code to do this.\\nimport os, shutil\\noriginal_dataset_dir = '/Users/fchollet/Downloads/kaggle_original_data'base_dir = '/Users/fchollet/Downloads/cats_and_dogs_small'\\nos.mkdir(base_dir)\\ntrain_dir = os.path.join(base_dir, 'train')\\nos.mkdir(train_dir)\\nvalidation_dir = os.path.join(base_dir, 'validation')\\nos.mkdir(validation_dir)test_dir = os.path.join(base_dir, 'test')\\nos.mkdir(test_dir)\\ntrain_cats_dir = os.path.join(train_dir, 'cats')\\nos.mkdir(train_cats_dir)\\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\\nos.mkdir(train_dogs_dir)\\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\\nos.mkdir(validation_cats_dir)\\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\\nos.mkdir(validation_dogs_dir)\\ntest_cats_dir = os.path.join(test_dir, 'cats')\\nos.mkdir(test_cats_dir)\\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\\nos.mkdir(test_dogs_dir)\\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)dst = os.path.join(train_cats_dir, fname)\\nshutil.copyfile(src, dst)\\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)\\ndst = os.path.join(validation_cats_dir, fname)\\nshutil.copyfile(src, dst)\\nfnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)\\ndst = os.path.join(test_cats_dir, fname)shutil.copyfile(src, dst)Listing 5.4 Copying images to training, validation, and test directories\\nPath to the directory where the \\noriginal dataset was uncompressedDirectory where you’ll store\\nyour smaller dataset\\nDirectories for the training, \\nvalidation, and \\ntest splits\\nDirectory with \\ntraining cat pictures\\nDirectory with \\ntraining dog pictures\\nDirectory with \\nvalidation cat pictures\\nDirectory with \\nvalidation dog pictures\\nDirectory with test cat pictures\\nDirectory with test dog pictures\\nCopies the first \\n1,000 cat images \\nto train_cats_dir\\nCopies the next 500 \\ncat images to validation_cats_dir\\nCopies the next 500 \\ncat images to \\ntest_cats_dir\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 154}), Document(page_content=\"133 Training a convnet from scratch on a small dataset\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)dst = os.path.join(train_dogs_dir, fname)\\nshutil.copyfile(src, dst)\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)\\ndst = os.path.join(validation_dogs_dir, fname)\\nshutil.copyfile(src, dst)\\nfnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\\nfor fname in fnames:\\nsrc = os.path.join(original_dataset_dir, fname)\\ndst = os.path.join(test_dogs_dir, fname)shutil.copyfile(src, dst)\\nAs a sanity check, let’s count how many pict ures are in each training split (train/vali-\\ndation/test):\\n>>> print('total training cat images:', len(os.listdir(train_cats_dir)))\\ntotal training cat images: 1000\\n>>> print('total training dog images:', len(os.listdir(train_dogs_dir)))\\ntotal training dog images: 1000>>> print('total validation cat images:', len(os.listdir(validation_cats_dir)))\\ntotal validation cat images: 500\\n>>> print('total validation dog images:', len(os.listdir(validation_dogs_dir)))total validation dog images: 500\\n>>> print('total test cat images:', len(os.listdir(test_cats_dir)))\\ntotal test cat images: 500>>> print('total test dog images:', len(os.listdir(test_dogs_dir)))\\ntotal test dog images: 500\\nSo you do indeed have 2,000 training imag es, 1,000 validation images, and 1,000 test\\nimages. Each split contains the same number of samples from each class: this is a bal-\\nanced binary-classification problem, which me ans classification accuracy will be an\\nappropriate measure of success. \\n5.2.3 Building your network\\nYou built a small convnet for MNIST  in the previous example, so you should be famil-\\niar with such convnets. You’ll reuse the same  general structure: th e convnet will be a\\nstack of alternated Conv2D  (with relu  activation) and MaxPooling2D  layers.\\n But because you’re dealing with bigger images and a more complex problem, you’ll\\nmake your network larger, accord ingly: it will have one more Conv2D  + MaxPooling2D\\nstage. This serves both to augment the capa city of the network and to further reduce\\nthe size of the feature maps so they aren’t overly large when you reach the Flatten\\nlayer. Here, because you start from inputs of size 150 × 150 (a somewhat arbitrary\\nchoice), you end up with feature maps of size 7 × 7 just before the Flatten  layer.Copies the first \\n1,000 dog images \\nto train_dogs_dir\\nCopies the next 500 \\ndog images to \\nvalidation_dogs_dir\\nCopies the next 500 \\ndog images to test_dogs_dir\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 155}), Document(page_content=\"134 CHAPTER  5Deep learning for computer vision\\nNOTE The depth of the feature maps prog ressively increases in the network\\n(from 32 to 128), whereas the size of the feature maps decreases (from 148 ×\\n148 to 7 × 7). This is a pattern you’ll see in almost all convnets.\\nBecause you’re attacking a binary-classification problem, you’ll end the network with a\\nsingle unit (a Dense  layer of size 1) and a sigmoid  activation. This unit will encode the\\nprobability that the network is l ooking at one class or the other.\\nfrom keras import layers\\nfrom keras import models\\nmodel = models.Sequential()\\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\\ninput_shape=(150, 150, 3)))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(128, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))model.add(layers.Flatten())\\nmodel.add(layers.Dense(512, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nLet’s look at how the dimensions of the feature maps change with every successive\\nlayer:\\n>>> model.summary()\\nLayer (type) Output Shape Param #\\n================================================================\\nconv2d_1 (Conv2D) (None, 148, 148, 32) 896________________________________________________________________\\nmaxpooling2d_1 (MaxPooling2D) (None, 74, 74, 32) 0\\n________________________________________________________________conv2d_2 (Conv2D) (None, 72, 72, 64) 18496\\n________________________________________________________________\\nmaxpooling2d_2 (MaxPooling2D) (None, 36, 36, 64) 0________________________________________________________________\\nconv2d_3 (Conv2D) (None, 34, 34, 128) 73856\\n________________________________________________________________maxpooling2d_3 (MaxPooling2D) (None, 17, 17, 128) 0\\n________________________________________________________________\\nconv2d_4 (Conv2D) (None, 15, 15, 128) 147584________________________________________________________________\\nmaxpooling2d_4 (MaxPooling2D) (None, 7, 7, 128) 0\\n________________________________________________________________flatten_1 (Flatten) (None, 6272) 0\\n________________________________________________________________\\ndense_1 (Dense) (None, 512) 3211776________________________________________________________________Listing 5.5 Instantiating a small convnet for dogs vs. cats classification\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 156}), Document(page_content=\"135 Training a convnet from scratch on a small dataset\\ndense_2 (Dense) (None, 1) 513\\n================================================================\\nTotal params: 3,453,121Trainable params: 3,453,121\\nNon-trainable params: 0\\nFor the compilation step, you’ll go with the RMSprop  optimizer, as usual. Because you\\nended the network with a single sigmoid unit, you’ll use binary crossentropy as theloss (as a reminder, check out table 4.1 for a cheatsheet on what loss function to use in\\nvarious situations).   \\nfrom keras import optimizers\\nmodel.compile(loss='binary_crossentropy',\\noptimizer=optimizers.RMSprop(lr=1e-4),\\nmetrics=['acc'])\\n5.2.4 Data preprocessing\\nAs you know by now, data should be formatted into appropriately preprocessed floating-\\npoint tensors before being fed into the network. Currently, the data sits on a drive as\\nJPEG  files, so the steps for getting it into the network are roughly as follows:\\n1Read the picture files.\\n2Decode the JPEG  content to RGB grids of pixels.\\n3Convert these into floating-point tensors.\\n4Rescale the pixel values (between 0 and 25 5) to the [0, 1] interval (as you know,\\nneural networks prefer to de al with small input values).\\nIt may seem a bit daunting, bu t fortunately Keras has utilities to take care of these\\nsteps automatically. Keras has a module with image-processing helper tools, located at\\nkeras.preprocessing.image . In particular, it contains the class ImageDataGenerator ,\\nwhich lets you quickly set up Python generato rs that can automatically turn image files\\non disk into batches of preprocessed tensors. This is what you’ll use here.\\nfrom keras.preprocessing.image import ImageDataGenerator\\ntrain_datagen = ImageDataGenerator(rescale=1./255)\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\ntrain_generator = train_datagen.flow_from_directory(\\ntrain_dir,\\ntarget_size=(150, 150)\\nbatch_size=20,class_mode='binary')\\nvalidation_generator = test_datagen.flow_from_directory(\\nvalidation_dir,Listing 5.6 Configuring the model for training\\nListing 5.7 Using ImageDataGenerator  to read images from directories\\nRescales all images by 1/255\\nTarget\\ndirectoryResizes all images to 150 × 150\\nBecause you use \\nbinary_crossentropy loss, you need binary \\nlabels.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 157}), Document(page_content=\"136 CHAPTER  5Deep learning for computer vision\\ntarget_size=(150, 150),\\nbatch_size=20,\\nclass_mode='binary')\\nLet’s look at the output of one of these generators: it yields batches of 150 × 150 RGB\\nimages (shape (20,  150,  150,  3)) and binary labels (shape (20,) ). There are 20 sam-\\nples in each batch (the batch size). Note that the generator yields these batches indef-\\ninitely: it loops endlessly over  the images in the target folder. For this reason, you need\\nto break  the iteration loop at some point:\\n>>> for data_batch, labels_batch in train_generator:\\n>>> print('data batch shape:', data_batch.shape)>>> print('labels batch shape:', labels_batch.shape)\\n>>> break\\ndata batch shape: (20, 150, 150, 3)labels batch shape: (20,)\\nLet’s fit the model to the data using the generator. You do so using the fit_generator\\nmethod, the equivalent of fit for data generators like this one. It expects as its first\\nargument a Python generator that will yield batches of inputs and targets indefinitely,\\nlike this one does. Because the data is being generated endlessly, the Keras model\\nneeds to know how many samples to draw  from the generator before declaring an\\nepoch over. This is the role of the steps_per_epoch  argument: after having drawn\\nsteps_per_epoch  batches from the generator—that is, after having run forUnderstanding Python generators\\nA Python generator  is an object that acts as an iterator: it’s an object you can use\\nwith the for … in operator. Generators are built using the yield  operator.\\nHere is an example of a generator that yields integers:\\ndef generator():\\ni=0while True:\\ni+ =1\\nyield i\\nfor item in generator():\\nprint(item)if item > 4:\\nbreak\\nIt prints this:\\n1\\n2\\n3\\n45\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 158}), Document(page_content=\"137 Training a convnet from scratch on a small dataset\\nsteps_per_epoch  gradient descent steps—the fitt ing process will go to the next\\nepoch. In this case, batches are 20 samples,  so it will take 100 batches until you see\\nyour target of 2,000 samples.\\n When using fit_generator , you can pass a validation_data  argument, much as\\nwith the fit method. It’s important to note that this argument is allowed to be a data\\ngenerator, but it could also be a tuple of Numpy arrays. If you pass a generator as\\nvalidation_data , then this generator is expected to yield batches of validation data\\nendlessly; thus you sh ould also specify the validation_steps  argument, which tells\\nthe process how many batches to draw from  the validation generator for evaluation.\\nhistory = model.fit_generator(\\ntrain_generator,\\nsteps_per_epoch=100,\\nepochs=30,validation_data=validation_generator,\\nvalidation_steps=50)\\nIt’s good practice to always save your models after training.\\nmodel.save('cats_and_dogs_small_1.h5')\\nLet’s plot the loss and accuracy of the model over the training and validation data\\nduring training (see figures 5.9 and 5.10).\\nimport matplotlib.pyplot as plt\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']loss = history.history['loss']\\nval_loss = history.history['val_loss']\\nepochs = range(1, len(acc) + 1)plt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')plt.legend()\\nplt.figure()\\nplt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')\\nplt.legend()\\nplt.show()Listing 5.8 Fitting the model using a batch generator\\nListing 5.9 Saving the model\\nListing 5.10 Displaying curves of loss and accuracy during training\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 159}), Document(page_content='138 CHAPTER  5Deep learning for computer vision\\nThese plots are characteristic of overfitting. The training accuracy increases linearly\\nover time, until it reaches nearly 100%, wherea s the validation accuracy stalls at 70–72%.\\nThe validation loss reaches it s minimum after only five epochs and then stalls, whereas\\nthe training loss keeps decreasing li nearly until it reaches nearly 0.\\n Because you have relatively few training  samples (2,000), overfitting will be your\\nnumber-one concern. You alre ady know about a number of  techniques that can help\\nmitigate overfitting, such as dropout and weight decay (L2 regularization). We’re now\\ngoing to work with a new one, specific to computer vision and used almost universally\\nwhen processing images wi th deep-learning models: data augmentation . \\n5.2.5 Using data augmentation\\nOverfitting is caused by having too few samples to learn from, rendering you unable\\nto train a model that can generalize to new data. Given infinite data, your model\\nFigure 5.9 Training and \\nvalidation accuracy\\nFigure 5.10 Training and \\nvalidation loss\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 160}), Document(page_content=\"139 Training a convnet from scratch on a small dataset\\nwould be exposed to every possi ble aspect of the data distribution at hand: you would\\nnever overfit. Data augmentation takes the approach of generating more training data\\nfrom existing training samples, by augmenting  the samples via a number of random\\ntransformations that yield believable-looking im ages. The goal is that at training time,\\nyour model will never see the exact same pi cture twice. This helps expose the model\\nto more aspects of the da ta and generalize better.\\n In Keras, this can be done by configur ing a number of random transformations to\\nbe performed on the images read by the ImageDataGenerator  instance. Let’s get\\nstarted with an example.\\ndatagen = ImageDataGenerator(\\nrotation_range=40,\\nwidth_shift_range=0.2,height_shift_range=0.2,\\nshear_range=0.2,\\nzoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\\nThese are just a few of the options availabl e (for more, see the Keras documentation).\\nLet’s quickly go over this code:\\n\\uf0a1rotation_range  is a value in degrees (0–180),  a range within which to ran-\\ndomly rotate pictures.\\n\\uf0a1width_shift  and height_shift  are ranges (as a fraction of total width or\\nheight) within which to randomly translat e pictures vertically or horizontally.\\n\\uf0a1shear_range  is for randomly applying  shearing transformations.\\n\\uf0a1zoom_range  is for randomly zooming inside pictures.\\n\\uf0a1horizontal_flip  is for randomly flipping half the images horizontally—rele-\\nvant when there are no assumptions of  horizontal asymmetry (for example,\\nreal-world pictures).\\n\\uf0a1fill_mode  is the strategy used for filling in newly created pixels, which can\\nappear after a rotation or a width/height shift.\\nLet’s look at the augmented images (see figure 5.11).\\nfrom keras.preprocessing import image\\nfnames = [os.path.join(train_cats_dir, fname) for\\nfname in os.listdir(train_cats_dir)]\\nimg_path = fnames[3]img = image.load_img(img_path, target_size=(150, 150))Listing 5.11 Setting up a data augmentation configuration via ImageDataGenerator\\nListing 5.12 Displaying some randomly augmented training images\\nModule with image-\\npreprocessing utilities\\nChooses one image to augment\\nReads the image \\nand resizes it\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 161}), Document(page_content='140 CHAPTER  5Deep learning for computer vision\\nx = image.img_to_array(img)\\nx = x.reshape((1,) + x.shape)i=0\\nfor batch in datagen.flow(x, batch_size=1):\\nplt.figure(i)imgplot = plt.imshow(image.array_to_img(batch[0]))\\ni+ =1\\ni fi%4= =0 :\\nbreak\\nplt.show()\\nIf you train a new network using this data -augmentation configur ation, the network\\nwill never see the same input twice. But the inputs it sees  are still heavily intercor-\\nrelated, because they come from a small nu mber of original images—you can’t pro-\\nduce new information, you can only remix ex isting information. As such, this may not\\nbe enough to completely get rid of overfitt ing. To further fight overfitting, you’ll also\\nadd a Dropout  layer to your model, right before  the densely connected classifier.Converts it to a Numpy array with shape ( 150, 150, 3)\\nReshapes it to ( 1, 150, 150, 3)\\nGenerates batches of \\nrandomly transformed \\nimages. Loops indefinitely, so you need to break the \\nloop at some point!\\nFigure 5.11 Generation of cat pictures via random data augmentation\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 162}), Document(page_content=\"141 Training a convnet from scratch on a small dataset\\n \\nmodel = models.Sequential()\\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\\ninput_shape=(150, 150, 3)))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))model.add(layers.Conv2D(128, (3, 3), activation='relu'))\\nmodel.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))model.add(layers.MaxPooling2D((2, 2)))\\nmodel.add(layers.Flatten())\\nmodel.add(layers.Dropout(0.5))model.add(layers.Dense(512, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nmodel.compile(loss='binary_crossentropy',\\noptimizer=optimizers.RMSprop(lr=1e-4),\\nmetrics=['acc'])\\nLet’s train the network using data augmentation and dropout.\\ntrain_datagen = ImageDataGenerator(\\nrescale=1./255,rotation_range=40,\\nwidth_shift_range=0.2,\\nheight_shift_range=0.2,shear_range=0.2,\\nzoom_range=0.2,\\nhorizontal_flip=True,)\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\ntrain_generator = train_datagen.flow_from_directory(\\ntrain_dir,target_size=(150, 150),\\nbatch_size=32,\\nclass_mode='binary')\\nvalidation_generator = test_datagen.flow_from_directory(\\nvalidation_dir,\\ntarget_size=(150, 150),batch_size=32,\\nclass_mode='binary')\\nhistory = model.fit_generator(\\ntrain_generator,\\nsteps_per_epoch=100,\\nepochs=100,validation_data=validation_generator,\\nvalidation_steps=50)Listing 5.13 Defining a new convnet that includes dropout\\nListing 5.14 Training the convnet using data-augmentation generators\\nNote that the \\nvalidation data shouldn’t be \\naugmented!\\nTarget\\ndirectoryResizes all images to 150 × 150\\nBecause you use \\nbinary_crossentropy \\nloss, you need binary \\nlabels.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 163}), Document(page_content=\"142 CHAPTER  5Deep learning for computer vision\\nLet’s save the model—you’ll use it in section 5.4.\\nmodel.save('cats_and_dogs_small_2.h5')\\nAnd let’s plot the results again: see figures 5.12 and 5.13. Thanks to data augmenta-\\ntion and dropout, you’re no longer overfitt ing: the training curv es are closely tracking\\nthe validation curves. You now reach an accuracy of 82%, a 15% relative improvementover the non-regularized model.\\n \\nBy using regularization techniques even fu rther, and by tuning the network’s parame-\\nters (such as the number of filters per convolution layer, or the number of layers in\\nthe network), you may be able to get an even  better accuracy, likely up to 86% or 87%.\\nBut it would prove difficult to go any high er just by training your own convnet from\\nscratch, because you have so little data to  work with. As a next step to improve your\\naccuracy on this problem, you’ll have to us e a pretrained model, which is the focus of\\nthe next two sections. Listing 5.15 Saving the model\\nFigure 5.12 Training and validation \\naccuracy with data augmentation\\nFigure 5.13 Training and validation \\nloss with data augmentation\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 164}), Document(page_content='143 Using a pretrained convnet\\n5.3 Using a pretrained convnet\\nA common and highly effective approach to deep learning on small image datasets is\\nto use a pretrained network. A pretrained network  is a saved network that was previously\\ntrained on a large dataset, typically on a la rge-scale image-classifi cation task. If this\\noriginal dataset is large enough and general enough, then the spatial hierarchy of fea-\\ntures learned by the pretrained network can effectively act as a generic model of the\\nvisual world, and hence its features can prove useful for many different computer-\\nvision problems, even though these new problems may involve completely different\\nclasses than those of the original task. For instance, you might train a network on\\nImageNet (where classes are mostly animal s and everyday objects) and then repur-\\npose this trained network for something as  remote as identifying furniture items in\\nimages. Such portability of learned features across differ ent problems is a key advan-\\ntage of deep learning compared to many older, shallow-learning approaches, and it\\nmakes deep learning very effe ctive for small-data problems.\\n In this case, let’s consider a large convnet trained on the ImageNet dataset\\n(1.4 million labeled images and 1,000 differe nt classes). ImageNet contains many ani-\\nmal classes, including different species of cats and dogs, and you can thus expect to\\nperform well on the dogs-versu s-cats classification problem.\\n You’ll use the VGG16  architecture, developed by Karen Simonyan and Andrew\\nZisserman in 2014; it’s a si mple and widely used convne t architecture for ImageNet.1\\nAlthough it’s an older model, far from the current state of the art and somewhat\\nheavier than many other recent models, I chos e it because its architecture is similar to\\nwhat you’re already familiar with and is easy to understand without introducing any\\nnew concepts. This may be your first encounter with one of these cutesy modelnames—\\nVGG, ResNet, Inception, Ince ption-ResNet, Xception, and so on; you’ll get\\nused to them, because they will come up fr equently if you keep doing deep learning\\nfor computer vision.\\n There are two ways to us e a pretrained network: feature extraction  and fine-tuning .\\nWe’ll cover both of them. Let’s start with feature extraction.\\n5.3.1 Feature extraction\\nFeature extraction consists of using the re presentations learned by a previous network\\nto extract interesting features from new sa mples. These features are then run through\\na new classifier, which is trained from scratch.\\n As you saw previously, convnets used fo r image classification  comprise two parts:\\nthey start with a series of pooling and conv olution layers, and they end with a densely\\nconnected classifier. The fi rst part is called the convolutional base  of the model. In the\\ncase of convnets, feature extraction consists of taking the convolutional base of a\\n1Karen Simonyan and Andrew Zisserman, “Very Deep Co nvolutional Networks for Large-Scale Image Recog-\\nnition,” arXiv (2014), https:/ /arxiv.org/abs/1409.1556 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 165}), Document(page_content='144 CHAPTER  5Deep learning for computer vision\\npreviously trained network, running the new data through it, and training a new clas-\\nsifier on top of the output (see figure 5.14).\\nWhy only reuse the convolutional base? Coul d you reuse the densely connected classi-\\nfier as well? In general, doing so should be avoided. The reason is that the representa-tions learned by the convolutional base are likely to be more generic and therefore\\nmore reusable: the feature maps of a convnet are presence maps of generic concepts\\nover a picture, which is likely to be usef ul regardless of the computer-vision problem at\\nhand. But the representations learned by the cla ssifier will necessarily be specific to the\\nset of classes on which the model was traine d—they will only contain information about\\nthe presence probability of this or that cla ss in the entire picture. Additionally, repre-\\nsentations found in densely connected layers  no longer contain any information about\\nwhere  objects are located in the input image: th ese layers get rid of the notion of space,\\nwhereas the object location is  still described by convolut ional feature maps. For prob-\\nlems where object location matters, densel y connected features are largely useless.\\n Note that the level of generality (and th erefore reusability) of the representations\\nextracted by specific convolution layers depends on the depth of the layer in the\\nmodel. Layers that come earlier in the mo del extract local, highly generic feature\\nmaps (such as visual edges, colors, and te xtures), whereas layers that are higher up\\nextract more-abstract concepts (such as “cat ear” or “dog eye”). So if your new dataset\\ndiffers a lot from the dataset on which the original model was trained, you may be bet-\\nter off using only the first few layers of th e model to do feature extraction, rather than\\nusing the entire convolutional base.Prediction\\nInputTrained\\nclassifier\\nTrained\\nconvolutional\\nbasePrediction\\nInputTrained\\nclassifier\\nTrained\\nconvolutional\\nbasePrediction\\nInputNew classifier\\n(randomly initialized)\\nTrained\\nconvolutional\\nbase\\n(frozen)\\nFigure 5.14 Swapping classifiers while keeping the same convolutional base\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 166}), Document(page_content=\"145 Using a pretrained convnet\\n In this case, because the ImageNet class set contains multiple dog and cat classes,\\nit’s likely to be beneficial to reuse the information contained in the densely connected\\nlayers of the original model. But we’ll choo se not to, in order to cover the more gen-\\neral case where the class set of the new pr oblem doesn’t overlap the class set of the\\noriginal model. Let’s put this in practice  by using the convolutional base of the VGG16\\nnetwork, trained on ImageNet, to extrac t interesting features from cat and dog\\nimages, and then train a dogs-versus-cats  classifier on top of these features.\\n The VGG16  model, among others, comes prepac kaged with Keras. You can import\\nit from the keras.applications  module. Here’s the list of image-classification\\nmodels (all pretrained on the ImageNet da taset) that are available as part of keras\\n.applications :\\n\\uf0a1Xception\\n\\uf0a1Inception V3\\n\\uf0a1ResNet50\\n\\uf0a1VGG16\\n\\uf0a1VGG19\\n\\uf0a1MobileNet\\nLet’s instantiate the VGG16  model.\\nfrom keras.applications import VGG16\\nconv_base = VGG16(weights='imagenet',\\ninclude_top=False,\\ninput_shape=(150, 150, 3))\\nYou pass three arguments to the constructor:\\n\\uf0a1weights  specifies the weight checkpoint from which to initialize the model.\\n\\uf0a1include_top  refers to including (or not) the densely connected classifier on\\ntop of the network. By default, this de nsely connected classifier corresponds to\\nthe 1,000 classes from ImageNet. Becaus e you intend to use your own densely\\nconnected classifier (w ith only two classes: cat and dog), you don’t need to\\ninclude it.\\n\\uf0a1input_shape  is the shape of the image tensors that you’ll feed to the network.\\nThis argument is purely optional: if you don’t pass it, the network will be able to\\nprocess inputs of any size.\\nHere’s the detail of the architecture of the VGG16  convolutional base. It’s similar to\\nthe simple convnets you’re already familiar with:\\n>>> conv_base.summary()\\nLayer (type) Output Shape Param #\\n================================================================\\ninput_1 (InputLayer) (None, 150, 150, 3) 0Listing 5.16 Instantiating the VGG16 convolutional base\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 167}), Document(page_content='146 CHAPTER  5Deep learning for computer vision\\n________________________________________________________________\\nblock1_conv1 (Convolution2D) (None, 150, 150, 64) 1792\\n________________________________________________________________block1_conv2 (Convolution2D) (None, 150, 150, 64) 36928\\n________________________________________________________________\\nblock1_pool (MaxPooling2D) (None, 75, 75, 64) 0________________________________________________________________\\nblock2_conv1 (Convolution2D) (None, 75, 75, 128) 73856\\n________________________________________________________________block2_conv2 (Convolution2D) (None, 75, 75, 128) 147584\\n________________________________________________________________\\nblock2_pool (MaxPooling2D) (None, 37, 37, 128) 0________________________________________________________________\\nblock3_conv1 (Convolution2D) (None, 37, 37, 256) 295168\\n________________________________________________________________block3_conv2 (Convolution2D) (None, 37, 37, 256) 590080\\n________________________________________________________________\\nblock3_conv3 (Convolution2D) (None, 37, 37, 256) 590080________________________________________________________________\\nblock3_pool (MaxPooling2D) (None, 18, 18, 256) 0\\n________________________________________________________________block4_conv1 (Convolution2D) (None, 18, 18, 512) 1180160________________________________________________________________\\nblock4_conv2 (Convolution2D) (None, 18, 18, 512) 2359808\\n________________________________________________________________block4_conv3 (Convolution2D) (None, 18, 18, 512) 2359808\\n________________________________________________________________\\nblock4_pool (MaxPooling2D) (None, 9, 9, 512) 0________________________________________________________________\\nblock5_conv1 (Convolution2D) (None, 9, 9, 512) 2359808\\n________________________________________________________________block5_conv2 (Convolution2D) (None, 9, 9, 512) 2359808\\n________________________________________________________________\\nblock5_conv3 (Convolution2D) (None, 9, 9, 512) 2359808________________________________________________________________\\nblock5_pool (MaxPooling2D) (None, 4, 4, 512) 0\\n================================================================Total params: 14,714,688\\nTrainable params: 14,714,688\\nNon-trainable params: 0\\nThe final feature map has shape (4, 4, 512) . That’s the feature on top of which you’ll\\nstick a densely connected classifier.\\n At this point, there are two ways you could proceed:\\n\\uf0a1Running the convolutional base over your  dataset, recording its output to a\\nNumpy array on disk, and then using this data as input to a standalone, densely\\nconnected classifier similar to those you sa w in part 1 of this book. This solution\\nis fast and cheap to run, because it only requires running the convolutional\\nbase once for every input image, and the convolutional base is by far the most\\nexpensive part of the pipeline. But for the same reason, this technique won’t\\nallow you to use data augmentation.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 168}), Document(page_content=\"147 Using a pretrained convnet\\n\\uf0a1Extending the model you have ( conv_base ) by adding Dense  layers on top, and\\nrunning the whole thing end to end on the input data. This will allow you to use\\ndata augmentation, because every input image goes through the convolutional\\nbase every time it’s seen by the model. But for the same reason, this technique is\\nfar more expensive than the first.\\nWe’ll cover both techniques. Let’s walk throug h the code required to set up the first\\none: recording the output of conv_base  on your data and using these outputs as\\ninputs to a new model.\\nFAST FEATURE  EXTRACTION  WITHOUT  DATA AUGMENTATION\\nYou’ll start by running instances of the previously introduced ImageDataGenerator  to\\nextract images as Numpy arrays as well as their labels. You’ll extract features from\\nthese images by calling the predict  method of the conv_base  model.\\nimport os\\nimport numpy as npfrom keras.preprocessing.image import ImageDataGenerator\\nbase_dir = '/Users/fchollet/Downloads/cats_and_dogs_small'\\ntrain_dir = os.path.join(base_dir, 'train')\\nvalidation_dir = os.path.join(base_dir, 'validation')test_dir = os.path.join(base_dir, 'test')\\ndatagen = ImageDataGenerator(rescale=1./255)\\nbatch_size = 20\\ndef extract_features(directory, sample_count):\\nfeatures = np.zeros(shape=(sample_count, 4, 4, 512))\\nlabels = np.zeros(shape=(sample_count))generator = datagen.flow_from_directory(\\ndirectory,\\ntarget_size=(150, 150),batch_size=batch_size,\\nclass_mode='binary')\\ni=0for inputs_batch, labels_batch in generator:\\nfeatures_batch = conv_base.predict(inputs_batch)\\nfeatures[i * batch_size : (i + 1) * batch_size] = features_batchlabels[i * batch_size : (i + 1) * batch_size] = labels_batch\\ni+ =1\\nif i * batch_size >= sample_count:\\nbreak\\nreturn features, labels\\ntrain_features, train_labels = extract_features(train_dir, 2000)\\nvalidation_features, validation_labels = extract_features(validation_dir, 1000)\\ntest_features, test_labels = extract_features(test_dir, 1000)\\nThe extracted features are currently of shape (samples,  4, 4, 512) . You’ll feed them\\nto a densely connected classifier, so  first you must flatten them to (samples,  8192) :Listing 5.17 Extracting features using the pretrained convolutional base\\nNote that because generators\\nyield data indefinitely in a loop,\\nyou must brea k after every\\nimage has been seen once.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 169}), Document(page_content=\"148 CHAPTER  5Deep learning for computer vision\\ntrain_features = np.reshape(train_features, (2000, 4*4* 512))\\nvalidation_features = np.reshape(validation_features, (1000, 4*4* 512))\\ntest_features = np.reshape(test_features, (1000, 4*4* 512))\\nAt this point, you can define your densely connected classifier (note the use of drop-\\nout for regularization) and train it on the data and labels that you just recorded.\\nfrom keras import models\\nfrom keras import layersfrom keras import optimizers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\\nmodel.add(layers.Dropout(0.5))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),\\nloss='binary_crossentropy',\\nmetrics=['acc'])\\nhistory = model.fit(train_features, train_labels,\\nepochs=30,batch_size=20,\\nvalidation_data=(validation_features, validation_labels))\\nTraining is very fast, because you only have to deal with two Dense  layers—an epoch\\ntakes less than one second even on CPU.\\n Let’s look at the loss and accuracy curves  during training (see figures 5.15 and\\n5.16).\\nimport matplotlib.pyplot as plt\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']\\nloss = history.history['loss']val_loss = history.history['val_loss']\\nepochs = range(1, len(acc) + 1)\\nplt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')\\nplt.legend()\\nplt.figure()\\nplt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')plt.title('Training and validation loss')\\nplt.legend()\\nplt.show()Listing 5.18 Defining and training the densely connected classifier\\nListing 5.19 Plotting the results\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 170}), Document(page_content='149 Using a pretrained convnet\\nYou reach a validation accuracy of about 90 %—much better than you achieved in the\\nprevious section with the small model trained from scratch. But the plots also indicate\\nthat you’re overfitting almost from the star t—despite using dropout with a fairly large\\nrate. That’s because this technique doesn’t use data augmentation, which is essential\\nfor preventing overfitting with small image datasets. \\nFEATURE  EXTRACTION  WITH DATA AUGMENTATION\\nNow, let’s review the second technique I mentioned for doing feature extraction,\\nwhich is much slower and more  expensive, but which allows you to use data augmenta-\\ntion during traini ng: extending the conv_base  model and running it end to end on\\nthe inputs.\\nNOTE This technique is so expensive that you should only attempt it if you\\nhave access to a GPU—it’s absolutely intractable on CPU. If you can’t run your\\ncode on GPU, then the previous technique is the way to go.\\nFigure 5.15 Training and validation \\naccuracy for simple feature extraction \\nFigure 5.16 Training and validation \\nloss for simple feature extraction \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 171}), Document(page_content=\"150 CHAPTER  5Deep learning for computer vision\\nBecause models behave just like layers, you can add a model (like conv_base ) to a\\nSequential  model just like you would add a layer.\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(conv_base)\\nmodel.add(layers.Flatten())model.add(layers.Dense(256, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nThis is what the model looks like now:\\n>>> model.summary()\\nLayer (type) Output Shape Param #\\n================================================================vgg16 (Model) (None, 4, 4, 512) 14714688________________________________________________________________\\nflatten_1 (Flatten) (None, 8192) 0\\n________________________________________________________________dense_1 (Dense) (None, 256) 2097408\\n________________________________________________________________\\ndense_2 (Dense) (None, 1) 257================================================================\\nTotal params: 16,812,353\\nTrainable params: 16,812,353Non-trainable params: 0\\nAs you can see, the convolutional base of VGG16  has 14,714,688 parameters, which is\\nvery large. The classifier you’re a dding on top has 2 million parameters.\\n Before you compile and train the model, it’s very important to freeze the convolu-\\ntional base. Freezing  a layer or set of layers means pr eventing their weights from being\\nupdated during training. If you don’t do th is, then the representations that were pre-\\nviously learned by the convolutional base wi ll be modified during training. Because\\nthe Dense  layers on top are randomly initialize d, very large weight updates would be\\npropagated through the networ k, effectively destroying the representations previously\\nlearned.\\n In Keras, you freeze a network by setting its trainable  attribute to False :\\n>>> print('This is the number of trainable weights '\\n'before freezing the conv base:', len(model.trainable_weights))\\nThis is the number of trainable weights before freezing the conv base: 30\\n>>> conv_base.trainable = False>>> print('This is the number of trainable weights '\\n'after freezing the conv base:', len(model.trainable_weights))\\nThis is the number of trainable weights after freezing the conv base: 4Listing 5.20 Adding a densely connected classifier on top of the convolutional base\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 172}), Document(page_content=\"151 Using a pretrained convnet\\nWith this setup, only the weights from the two Dense  layers that you added will be\\ntrained. That’s a total of four weight tensors: two per layer (the main weight matrix\\nand the bias vector). Note that  in order for these changes to take effect, you must first\\ncompile the model. If you ever modify weight trainability after compilation, youshould then recompile the model, or these changes will be ignored.\\n Now you can start training your model, with the same data-augmentation configu-\\nration that you used in the previous example.\\nfrom keras.preprocessing.image import ImageDataGenerator\\nfrom keras import optimizers\\ntrain_datagen = ImageDataGenerator(\\nrescale=1./255,\\nrotation_range=40,\\nwidth_shift_range=0.2,height_shift_range=0.2,\\nshear_range=0.2,\\nzoom_range=0.2,horizontal_flip=True,fill_mode='nearest')\\ntest_datagen = ImageDataGenerator(rescale=1./255)\\ntrain_generator = train_datagen.flow_from_directory(\\ntrain_dir,\\ntarget_size=(150, 150),\\nbatch_size=20,class_mode='binary')\\nvalidation_generator = test_datagen.flow_from_directory(\\nvalidation_dir,target_size=(150, 150),\\nbatch_size=20,\\nclass_mode='binary')\\nmodel.compile(loss='binary_crossentropy',\\noptimizer=optimizers.RMSprop(lr=2e-5),\\nmetrics=['acc'])\\nhistory = model.fit_generator(\\ntrain_generator,\\nsteps_per_epoch=100,epochs=30,\\nvalidation_data=validation_generator,\\nvalidation_steps=50)\\nLet’s plot the results again (see figures 5.17 and 5.18). As you can see, you reach a val-\\nidation accuracy of about 96%. This is mu ch better than you achieved with the small\\nconvnet trained from scratch.Listing 5.21 Training the model end to end with a frozen convolutional base\\nNote that the\\nvalidation data\\nshouldn’t be\\naugmented!\\nTarget\\ndirectoryResizes all images to 150 × 150\\nBecause you use \\nbinary_crossentropy \\nloss, you need binary labels.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 173}), Document(page_content='152 CHAPTER  5Deep learning for computer vision\\n     \\n5.3.2 Fine-tuning\\nAnother widely used technique for mo del reuse, complementary to feature\\nextraction, is fine-tuning  (see figure 5.19). Fine-tuning consists of unfreezing a few of\\nthe top layers of a frozen model base used for feature extraction, and jointly training\\nboth the newly added part of the model (in this case, the fully connected classifier)and these top layers. This is called fine-tuning  because it slight ly adjusts the more\\nabstract representations of the model being reused, in order to make them more rele-\\nvant for the problem at hand.\\nFigure 5.17 Training and validation \\naccuracy for feature extraction with data augmentation\\nFigure 5.18 Training and validation \\nloss for feature extraction with data augmentation\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 174}), Document(page_content='153 Using a pretrained convnet\\nDenseDenseFlattenMaxPooling2DConvolution2DConvolution2DConvolution2DMaxPooling2DConvolution2DConvolution2DConvolution2DMaxPooling2DConvolution2DConvolution2DConvolution2DMaxPooling2DConvolution2DConvolution2DMaxPooling2DConvolution2DConvolution2D\\nConv block 1: \\nfrozen\\nConv block 2: \\nfrozen\\nConv block 3: \\nfrozen\\nConv block 4: \\nfrozen\\nWe fine-tune\\nConv block 5.\\nWe fine-tune\\nour own fully \\nconnected \\nclassifier.Figure 5.19 Fine-tuning the last \\nconvolutional block of the VGG16 network\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 175}), Document(page_content='154 CHAPTER  5Deep learning for computer vision\\nI stated earlier that it’s necessary to freeze the convolution base of VGG16  in order to\\nbe able to train a randomly initialized classi fier on top. For the same reason, it’s only\\npossible to fine-tune the top layers of the convolutional base once the classifier on top\\nhas already been trained. If the classifier isn’t already tr ained, then the error signal\\npropagating through the network during traini ng will be too large, and the represen-\\ntations previously learned by the layers bein g fine-tuned will be destroyed. Thus the\\nsteps for fine-tuning a network are as follow:\\n1Add your custom network on top of an already-trained base network.\\n2Freeze the base network.\\n3Train the part you added.\\n4Unfreeze some layers in the base network.\\n5Jointly train both these layers and the part you added.\\nYou already completed the first three steps when doing feature extraction. Let’s pro-\\nceed with step 4: yo u’ll unfreeze your conv_base  and then freeze individual layers\\ninside it.\\n As a reminder, this is what your convolutional base looks like:\\n>>> conv_base.summary()\\nLayer (type) Output Shape Param #\\n================================================================\\ninput_1 (InputLayer) (None, 150, 150, 3) 0\\n________________________________________________________________block1_conv1 (Convolution2D) (None, 150, 150, 64) 1792\\n________________________________________________________________\\nblock1_conv2 (Convolution2D) (None, 150, 150, 64) 36928________________________________________________________________\\nblock1_pool (MaxPooling2D) (None, 75, 75, 64) 0\\n________________________________________________________________block2_conv1 (Convolution2D) (None, 75, 75, 128) 73856\\n________________________________________________________________\\nblock2_conv2 (Convolution2D) (None, 75, 75, 128) 147584________________________________________________________________\\nblock2_pool (MaxPooling2D) (None, 37, 37, 128) 0\\n________________________________________________________________block3_conv1 (Convolution2D) (None, 37, 37, 256) 295168\\n________________________________________________________________\\nblock3_conv2 (Convolution2D) (None, 37, 37, 256) 590080________________________________________________________________\\nblock3_conv3 (Convolution2D) (None, 37, 37, 256) 590080\\n________________________________________________________________block3_pool (MaxPooling2D) (None, 18, 18, 256) 0\\n________________________________________________________________\\nblock4_conv1 (Convolution2D) (None, 18, 18, 512) 1180160________________________________________________________________\\nblock4_conv2 (Convolution2D) (None, 18, 18, 512) 2359808\\n________________________________________________________________block4_conv3 (Convolution2D) (None, 18, 18, 512) 2359808\\n________________________________________________________________\\nblock4_pool (MaxPooling2D) (None, 9, 9, 512) 0\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 176}), Document(page_content=\"155 Using a pretrained convnet\\n________________________________________________________________\\nblock5_conv1 (Convolution2D) (None, 9, 9, 512) 2359808\\n________________________________________________________________block5_conv2 (Convolution2D) (None, 9, 9, 512) 2359808\\n________________________________________________________________\\nblock5_conv3 (Convolution2D) (None, 9, 9, 512) 2359808________________________________________________________________\\nblock5_pool (MaxPooling2D) (None, 4, 4, 512) 0\\n================================================================Total params: 14714688\\nYou’ll fine-tune the last three convolutio nal layers, which means all layers up to\\nblock4_pool  should be frozen, and the layers block5_conv1 , block5_conv2 , and\\nblock5_conv3  should be trainable.\\n Why not fine-tune more layers? Why not fine-tune the entire convolutional base?\\nYou could. But you need to consider the following:\\n\\uf0a1Earlier layers in the convolutional base encode more-generic, reusable features,\\nwhereas layers higher up encode more-specialized features. It’s more useful to\\nfine-tune the more specialized features, because these are the ones that need tobe repurposed on your new problem. Th ere would be fast-decreasing returns in\\nfine-tuning lower layers.\\n\\uf0a1The more parameters you’re training, the more you’re at risk of overfitting.The convolutional base has 15 million parameters, so it would be risky to\\nattempt to train it on your small dataset.\\nThus, in this situation, it’s a good strategy to fine-tune only the top two or three layers\\nin the convolutional base. Let’s set this up, starting from where you left off in the pre-\\nvious example.\\nconv_base.trainable = True\\nset_trainable = False\\nfor layer in conv_base.layers:\\nif layer.name == 'block5_conv1':\\nset_trainable = True\\nif set_trainable:\\nlayer.trainable = True\\nelse:\\nlayer.trainable = False\\nNow you can begin fine-tuning the ne twork. You’ll do this with the RMSP rop opti-\\nmizer, using a very low learning rate. The re ason for using a low learning rate is that\\nyou want to limit the magnitude of the modi fications you make to the representations\\nof the three layers you’re fine-tuning. Up dates that are too large may harm these rep-\\nresentations.\\n Listing 5.22 Freezing all layers up to a specific one\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 177}), Document(page_content=\"156 CHAPTER  5Deep learning for computer vision\\n \\nmodel.compile(loss='binary_crossentropy',\\noptimizer=optimizers.RMSprop(lr=1e-5),\\nmetrics=['acc'])\\nhistory = model.fit_generator(\\ntrain_generator,\\nsteps_per_epoch=100,epochs=100,\\nvalidation_data=validation_generator,\\nvalidation_steps=50)\\nLet’s plot the results using the same plotting  code as before (see figures 5.20 and 5.21).\\nThese curves look noisy. To make them more readable, you can smooth them by\\nreplacing every loss and accura cy with exponential moving averages of these quanti-\\nties. Here’s a trivial utility function to do this (see figures 5.22 and 5.23).Listing 5.23 Fine-tuning the model\\nFigure 5.20 Training and \\nvalidation accuracy for fine-tuning \\nFigure 5.21 Training and \\nvalidation loss for fine-tuning \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 178}), Document(page_content=\"157 Using a pretrained convnet\\n \\ndef smooth_curve(points, factor=0.8):\\nsmoothed_points = []\\nfor point in points:\\nif smoothed_points:\\nprevious = smoothed_points[-1]\\nsmoothed_points.append(previous * factor + point * (1 - factor))\\nelse:\\nsmoothed_points.append(point)\\nreturn smoothed_points\\nplt.plot(epochs,\\nsmooth_curve(acc), 'bo', label='Smoothed training acc')\\nplt.plot(epochs,\\nsmooth_curve(val_acc), 'b', label='Smoothed validation acc')\\nplt.title('Training and validation accuracy')\\nplt.legend()\\nplt.figure()\\nplt.plot(epochs,\\nsmooth_curve(loss), 'bo', label='Smoothed training loss')\\nplt.plot(epochs,\\nsmooth_curve(val_loss), 'b', label='Smoothed validation loss')\\nplt.title('Training and validation loss')\\nplt.legend()\\nplt.show()Listing 5.24 Smoothing the plots\\nFigure 5.22 Smoothed curves for training and validation accuracy \\nfor fine-tuning\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 179}), Document(page_content=\"158 CHAPTER  5Deep learning for computer vision\\nThe validation accuracy curve look much cl eaner. You’re seeing a nice 1% absolute\\nimprovement in accuracy, from about 96% to above 97%.\\n Note that the loss curve doesn’t show any real improvement (in fact, it’s deteriorat-\\ning). You may wonder, how could accuracy st ay stable or improve if the loss isn’t\\ndecreasing? The answer is simple: what you display is an average of pointwise loss val-\\nues; but what matters for accuracy is the di stribution of the loss values, not their aver-\\nage, because accuracy is the result of a bi nary thresholding of the class probability\\npredicted by the model. The model may still be improving even if this isn’t reflected\\nin the average loss.\\n You can now finally evaluate this model on the test data:\\ntest_generator = test_datagen.flow_from_directory(\\ntest_dir,\\ntarget_size=(150, 150),batch_size=20,\\nclass_mode='binary')\\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\\nprint('test acc:', test_acc)\\nHere you get a test accuracy of 97%. In th e original Kaggle competition around this\\ndataset, this would have been one of the top results. But using modern deep-learning\\ntechniques, you managed to reach this result using only  a small fraction of the train-\\ning data available (about 10%). There is a huge difference between being able to train\\non 20,000 samples compared to 2,000 samples!\\n \\nFigure 5.23 Smoothed curves for training and validation loss for fine-tuning\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 180}), Document(page_content='159 Using a pretrained convnet\\n5.3.3 Wrapping up\\nHere’s what you should take  away from the exercises in the past two sections:\\n\\uf0a1Convnets are the best type of machin e-learning models for computer-vision\\ntasks. It’s possible to train one from sc ratch even on a very small dataset, with\\ndecent results.\\n\\uf0a1On a small dataset, overfitting will be the main issue. Data augmentation is a\\npowerful way to fight overfitting when you’re working with image data.\\n\\uf0a1It’s easy to reuse an existing convnet on a new dataset via feature extraction.\\nThis is a valuable technique for working with small image datasets.\\n\\uf0a1As a complement to feature extraction, you can use fine-tuning, which adapts to\\na new problem some of the representations previously learned by an existing\\nmodel. This pushes performance a bit further.\\nNow you have a solid set of tools for deal ing with image-classi fication problems—in\\nparticular with small datasets. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 181}), Document(page_content=\"160 CHAPTER  5Deep learning for computer vision\\n5.4 Visualizing what convnets learn\\nIt’s often said that deep-learning models are “black boxes”: learning representations\\nthat are difficult to extract and present in  a human-readable form. Although this is\\npartially true for certain types of deep-lea rning models, it’s defi nitely not true for\\nconvnets. The representations learned by co nvnets are highly amenable to visualiza-\\ntion, in large part because they’re representations of visual concepts . Since 2013, a wide\\narray of techniques have b een developed for visualizing and interpreting these repre-\\nsentations. We won’t survey all of them, bu t we’ll cover three of the most accessible\\nand useful ones:\\n\\uf0a1Visualizing intermediate convnet outputs (intermediate activations) —Useful for\\nunderstanding how successive convnet la yers transform their input, and for get-\\nting a first idea of the meanin g of individual convnet filters.\\n\\uf0a1Visualizing convnets filters —Useful for understanding precisely what visual pat-\\ntern or concept each filter in a convnet is receptive to.\\n\\uf0a1Visualizing heatmaps of class activation in an image —Useful for understanding\\nwhich parts of an image were identified as  belonging to a given class, thus allow-\\ning you to localize objects in images.\\nFor the first method—activation visualizat ion—you’ll use the small convnet that you\\ntrained from scratch on the dogs-versus-cats classification problem in section 5.2. For\\nthe next two methods, you’ll use the VGG16  model introduced in section 5.3.\\n5.4.1 Visualizing intermediate activations\\nVisualizing intermediate activations consists  of displaying the feature maps that are\\noutput by various convolution and pooling la yers in a network, given a certain input\\n(the output of a layer is often called its activation , the output of the activation func-\\ntion). This gives a view into how an inpu t is decomposed into the different filters\\nlearned by the network. You want to visualize feature maps with three dimensions:\\nwidth, height, and depth (channels). Each  channel encodes relatively independent\\nfeatures, so the proper way to visualize these feature maps is by independently plot-ting the contents of every channel as a \\n2D image. Let’s start by loading the model that\\nyou saved in section 5.2:\\n>>> from keras.models import load_model\\n>>> model = load_model('cats_and_dogs_small_2.h5')\\n>>> model.summary() <1> As a reminder.________________________________________________________________\\nLayer (type) Output Shape Param #\\n================================================================conv2d_5 (Conv2D) (None, 148, 148, 32) 896\\n________________________________________________________________\\nmaxpooling2d_5 (MaxPooling2D) (None, 74, 74, 32) 0________________________________________________________________\\nconv2d_6 (Conv2D) (None, 72, 72, 64) 18496\\n________________________________________________________________maxpooling2d_6 (MaxPooling2D) (None, 36, 36, 64) 0\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 182}), Document(page_content=\"161 Visualizing what convnets learn\\n________________________________________________________________\\nconv2d_7 (Conv2D) (None, 34, 34, 128) 73856\\n________________________________________________________________maxpooling2d_7 (MaxPooling2D) (None, 17, 17, 128) 0\\n________________________________________________________________\\nconv2d_8 (Conv2D) (None, 15, 15, 128) 147584________________________________________________________________\\nmaxpooling2d_8 (MaxPooling2D) (None, 7, 7, 128) 0\\n________________________________________________________________flatten_2 (Flatten) (None, 6272) 0\\n________________________________________________________________\\ndropout_1 (Dropout) (None, 6272) 0________________________________________________________________\\ndense_3 (Dense) (None, 512) 3211776\\n________________________________________________________________dense_4 (Dense) (None, 1) 513\\n================================================================\\nTotal params: 3,453,121Trainable params: 3,453,121\\nNon-trainable params: 0\\nNext, you’ll get an input image—a picture of a cat, not part of the images the network\\nwas trained on.\\nimg_path = '/Users/fchollet/Downloads/cats_and_dogs_small/test/cats/cat.1700.jpg'\\nfrom keras.preprocessing import image\\nimport numpy as np\\nimg = image.load_img(img_path, target_size=(150, 150))\\nimg_tensor = image.img_to_array(img)\\nimg_tensor = np.expand_dims(img_tensor, axis=0)img_tensor /= 255.\\n<1> Its shape is (1, 150, 150, 3)\\nprint(img_tensor.shape)\\nLet’s display the picture (see figure 5.24).\\nimport matplotlib.pyplot as plt\\nplt.imshow(img_tensor[0])\\nplt.show()Listing 5.25 Preprocessing a single image\\nListing 5.26 Displaying the test picturePreprocesses the image \\ninto a 4D tensor\\nRemember that the model \\nwas trained on inputs that were preprocessed this way.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 183}), Document(page_content='162 CHAPTER  5Deep learning for computer vision\\nIn order to extract the feature maps you want  to look at, you’ll create a Keras model\\nthat takes batches of images as input, and outputs the activations of all convolution and\\npooling layers. To do this, you’ll use the Keras class Model . A model is instantiated\\nusing two arguments: an input tensor (or li st of input tensors) and an output tensor\\n(or list of output tensors) . The resulting class is a Keras model, just like the Sequential\\nmodels you’re familiar with, mapping the specified inputs to the specified outputs.\\nWhat sets the Model  class apart is that it allows for models with multiple outputs, unlike\\nSequential . For more information about the Model  class, see section 7.1.\\nfrom keras import models\\nlayer_outputs = [layer.output for layer in model.layers[:8]]\\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\\nWhen fed an image input, this model returns the values of the layer activations in the\\noriginal model. This is the first time you’ve encountered a multi-output model in thisbook: until now, the models you’ve seen have had exactly one input and one output.\\nIn the general case, a model can have any nu mber of inputs and outputs. This one has\\none input and eight outputs: one output per layer activation.\\n \\n \\n  Listing 5.27 Instantiating a model from an input tensor and a list of output tensors\\nFigure 5.24 The test cat picture\\nExtracts the outputs of \\nthe top eight layersCreates a model that will return these\\noutputs, given the model input\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 184}), Document(page_content=\"163 Visualizing what convnets learn\\n \\nactivations = activation_model.predict(img_tensor)\\nFor instance, this is the activation of the first convolution layer for the cat image input:\\n>>> first_layer_activation = activations[0]\\n>>> print(first_layer_activation.shape)\\n(1, 148, 148, 32)\\nIt’s a 148 × 148 feature map with 32 channels. Let’s try plotting the fourth channel of\\nthe activation of the first layer of the original model (see figure 5.25).\\nimport matplotlib.pyplot as plt\\nplt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')\\nThis channel appears to encode a diagonal edge detector. Let’s try the seventh chan-\\nnel (see figure 5.26)—but note that your own channels may vary, because the specific\\nfilters learned by convolution layers aren’t deterministic.\\nplt.matshow(first_layer_activation[0, :, :, 7], cmap='viridis')Listing 5.28 Running the model in predict mode\\nListing 5.29 Visualizing the fourth channel\\nListing 5.30 Visualizing the seventh channelReturns a list of five \\nNumpy arrays: one array per layer activation\\nFigure 5.25 Fourth channel of the activation \\nof the first layer on the test cat picture\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 185}), Document(page_content=\"164 CHAPTER  5Deep learning for computer vision\\nThis one looks like a “bright green dot” dete ctor, useful to encode cat eyes. At this\\npoint, let’s plot a complete visualization of  all the activations in the network (see fig-\\nure 5.27). You’ll extract and plot every cha nnel in each of the eight activation maps,\\nand you’ll stack the results in one big image te nsor, with channels st acked side by side.\\nlayer_names = []\\nfor layer in model.layers[:8]:\\nlayer_names.append(layer.name)\\nimages_per_row = 16for layer_name, layer_activation in zip(layer_names, activations):\\nn_features = layer_activation.shape[-1]\\nsize = layer_activation.shape[1]n_cols = n_features // images_per_row\\ndisplay_grid = np.zeros((size * n_cols, images_per_row * size))\\nfor col in range(n_cols):\\nfor row in range(images_per_row):\\nchannel_image = layer_activation[0,\\n:, :,col * images_per_row + row]\\nchannel_image -= channel_image.mean()channel_image /= channel_image.std()channel_image *= 64channel_image += 128channel_image = np.clip(channel_image, 0, 255).astype('uint8')display_grid[col * size : (col + 1) * size,\\nrow * size : (row + 1) * size] = channel_image\\nscale = 1. / size\\nplt.figure(figsize=(scale * display_grid.shape[1],\\nscale * display_grid.shape[0]))\\nplt.title(layer_name)plt.grid(False)plt.imshow(display_grid, aspect='auto', cmap='viridis')Listing 5.31 Visualizing every channel in every intermediate activation\\nFigure 5.26 Seventh channel of the activation \\nof the first layer on the test cat picture\\nNames of the layers, so you can \\nhave them as part of your plot\\nDisplays the feature maps\\nNumber of\\nfeatures in the\\nfeature mapThe feature map has shape \\n(1, size, size, n_features).\\nTiles the\\nactivation\\nchannels in\\nthis matrixTiles each filter into \\na big horizontal grid\\nPost-processes\\nthe feature to\\nmake it visually\\npalatable\\nDisplays the grid\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 186}), Document(page_content='165 Visualizing what convnets learn\\nFigure 5.27 Every channel of every layer activation on the test cat picture\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 187}), Document(page_content='166 CHAPTER  5Deep learning for computer vision\\nThere are a few things to note here:\\n\\uf0a1The first layer acts as a coll ection of various edge detectors. At that stage, the\\nactivations retain almost all of the information present in the initial picture.\\n\\uf0a1As you go higher, the activations become  increasingly abstra ct and less visually\\ninterpretable. They begin to encode higher -level concepts such as “cat ear” and\\n“cat eye.” Higher presentations carry increasingly less information about the\\nvisual contents of the image, and increa singly more information related to the\\nclass of the image.\\n\\uf0a1The sparsity of the activations increases wi th the depth of the layer: in the first\\nlayer, all filters are activated by the in put image; but in the following layers,\\nmore and more filters are blank. This means the pattern encoded by the filter\\nisn’t found in the input image.\\nWe have just evidenced an important univer sal characteristic of the representations\\nlearned by deep neural networks: the feat ures extracted by a layer become increas-\\ningly abstract with the depth of the layer. The activations of higher layers carry less\\nand less information about the specific in put being seen, and more and more infor-\\nmation about the target (in this case, the cl ass of the image: cat or dog). A deep neu-\\nral network effectively acts as an information distillation pipeline , with raw data going in\\n(in this case, RGB pictures) and being repeat edly transformed so th at irrelevant infor-\\nmation is filtered out (for example, the sp ecific visual appearance of the image), and\\nuseful information is magnified and refine d (for example, the class of the image).\\n This is analogous to the way humans an d animals perceive the world: after observ-\\ning a scene for a few seconds, a human ca n remember which abstract objects were\\npresent in it (bicycle, tree) but can’t re member the specific appearance of these\\nobjects. In fact, if you tried to draw a generic bicycle from memory, chances are you\\ncouldn’t get it even remotely right, even though you’ve seen th ousands of bicycles in\\nyour lifetime (see, for example, figure 5.28). Try it right now: this effect is absolutely\\nreal. You brain has learned to completely abstract its visual  input—to transform it into\\nhigh-level visual concepts while filtering out irrelevant visual details—making it tre-\\nmendously difficult to remember how things around you look.   \\nFigure 5.28 Left: attempts \\nto draw a bicycle from memory. Right: what a \\nschematic bicycle should \\nlook like.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 188}), Document(page_content=\"167 Visualizing what convnets learn\\n5.4.2 Visualizing convnet filters\\nAnother easy way to inspect the filters learne d by convnets is to display the visual pat-\\ntern that each filter is meant to respond to. This can be done with gradient ascent in\\ninput space : applying gradient descent  to the value of the input image of a convnet so as\\nto maximize  the response of a specif ic filter, starting from a blank input image. The\\nresulting input image will be one that the chosen filter is maximally responsive to.\\n The process is simple: you’ ll build a loss function that  maximizes the value of a\\ngiven filter in a given convolution layer,  and then you’ll use stochastic gradient\\ndescent to adjust the values of the input imag e so as to maximize this activation value.\\nFor instance, here’s a loss for the activation of filter 0 in the layer block3_conv1  of the\\nVGG16 network, pretrained on ImageNet.\\nfrom keras.applications import VGG16\\nfrom keras import backend as K\\nmodel = VGG16(weights='imagenet',\\ninclude_top=False)\\nlayer_name = 'block3_conv1'\\nfilter_index = 0\\nlayer_output = model.get_layer(layer_name).output\\nloss = K.mean(layer_output[:, :, :, filter_index])\\nTo implement gradient descent, you’ll need  the gradient of this loss with respect to\\nthe model’s input. To do this, you’ll use the gradients  function packaged with the\\nbackend  module of Keras.\\ngrads = K.gradients(loss, model.input)[0]\\nA non-obvious trick to use to help the grad ient-descent process go smoothly is to nor-\\nmalize the gradient tensor by dividing it by its L2 norm (the square root of the average\\nof the square of the values in the tensor ). This ensures that the magnitude of the\\nupdates done to the input image is  always within the same range.\\ngrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\\nNow you need a way to compute the value of the loss tensor and the gradient tensor,\\ngiven an input image. You can define a Keras backend function to do this: iterate  isListing 5.32 Defining the loss tensor for filter visualization\\nListing 5.33 Obtaining the gradient of the loss with regard to the input\\nListing 5.34 Gradient-normalization trickThe call to gradients returns a list of \\ntensors (of size 1 in this case). Hence, \\nyou keep only the first element—which is a tensor.\\nAdd 1e–5 before dividing \\nto avoid accidentally dividing by 0.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 189}), Document(page_content=\"168 CHAPTER  5Deep learning for computer vision\\na function that takes a Numpy tensor (as a list of tensors of size 1) and returns a list of\\ntwo Numpy tensors: the loss value and the gradient value.\\niterate = K.function([model.input], [loss, grads])\\nimport numpy as np\\nloss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])\\nAt this point, you can define a Python loop to do stochast ic gradient descent.\\ninput_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.\\nstep = 1.\\nfor i in range(40):\\nloss_value, grads_value = iterate([input_img_data])\\ninput_img_data += grads_value * step\\nThe resulting image tensor is a floating-point tensor of shape (1, 150, 150, 3) , with\\nvalues that may not be integers within [0 , 255]. Hence, you need to postprocess this\\ntensor to turn it into a displayable image. You do so with the following straightforward\\nutility function.\\ndef deprocess_image(x):\\nx -= x.mean()\\nx /= (x.std() + 1e-5)\\nx* =0 . 1\\nx+ =0 . 5\\nx = np.clip(x, 0, 1)\\nx* =2 5 5\\nx = np.clip(x, 0, 255).astype('uint8')\\nreturn x\\nNow you have all the pieces. Let’s put them to gether into a Python function that takes\\nas input a layer name and a filter index, and returns a valid imag e tensor representing\\nthe pattern that maximizes the acti vation of the sp ecified filter.Listing 5.35 Fetching Numpy output values given Numpy input values\\nListing 5.36 Loss maximization via stochastic gradient descent\\nListing 5.37 Utility function to convert a tensor into a valid imageStarts from a gray image \\nwith some noise\\nRuns gradient \\nascent for 40 steps\\nComputes the loss value \\nand gradient valueAdjusts the input image in the \\ndirection that maximizes the lossMagnitude of each gradient update\\nNormalizes the tensor: \\ncenters on 0, ensures \\nthat std is 0. 1\\nClips to [0, 1]\\nConverts to an RGB array\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 190}), Document(page_content=\"169 Visualizing what convnets learn\\n \\ndef generate_pattern(layer_name, filter_index, size=150):\\nlayer_output = model.get_layer(layer_name).outputloss = K.mean(layer_output[:, :, :, filter_index])\\ngrads = K.gradients(loss, model.input)[0]grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)iterate = K.function([model.input], [loss, grads])input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.step = 1.\\nfor i in range(40):\\nloss_value, grads_value = iterate([input_img_data])input_img_data += grads_value * step\\nimg = input_img_data[0]\\nreturn deprocess_image(img)\\nLet’s try it (see figure 5.29):\\n>>> plt.imshow(generate_pattern('block3_conv1', 0))\\nIt seems that filter 0 in layer block3_conv1  is responsive to a polka-dot pattern. Now\\nthe fun part: you can start visualizing every f ilter in every layer. For simplicity, you’ll\\nonly look at the first 64 filters in each laye r, and you’ll only look at the first layer of\\neach convolution block ( block1_conv1 , block2_conv1 , block3_conv1 , block4_\\nconv1 , block5_conv1 ). You’ll arrange the outputs on an 8 × 8 grid of 64 × 64 filter pat-\\nterns, with some black margins between ea ch filter pattern (see figures 5.30–5.33).Listing 5.38 Function to generate filter visualizations\\nRuns\\ngradient\\nascent for\\n40 stepsBuilds a loss function that maximizes the activation of th e nth filter of the \\nlayer under considerationComputes the \\ngradient of the \\ninput picture with regard to this loss\\nNormalization \\ntrick: normalizes \\nthe gradient\\nReturns the loss and grads given the input picture\\nStarts from a\\ngray image with\\nsome noise\\nFigure 5.29 Pattern that the zeroth \\nchannel in layer block3_conv1  \\nresponds to maximally\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 191}), Document(page_content=\"170 CHAPTER  5Deep learning for computer vision\\n \\nlayer_name = 'block1_conv1'\\nsize = 64margin = 5\\nresults = np.zeros((8 * siz e+7* margin, 8 * siz e+7* margin, 3))\\nfor i in range(8):\\nfor j in range(8):\\nfilter_img = generate_pattern(layer_name, i + (j * 8), size=size)\\nhorizontal_start =i*s i z e+i* margin\\nhorizontal_end = horizontal_start + size\\nvertical_start =j*s i z e+j* margin\\nvertical_end = vertical_start + sizeresults[horizontal_start: horizontal_end,\\nvertical_start: vertical_end, :] = filter_img\\nplt.figure(figsize=(20, 20))\\nplt.imshow(results)Listing 5.39 Generating a grid of all filter response patterns in a layer\\nEmpty (black) image\\nto store results\\nIterates over the rows of the results grid\\nIterates over the columns of the results grid\\nGenerates the\\npattern for\\nfilter i + (j * 8)\\nin layer_namePuts the result in the square \\n(i, j) of the results grid\\nDisplays the results grid\\nFigure 5.30 Filter patterns for layer block1_conv1\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 192}), Document(page_content='171 Visualizing what convnets learn\\nFigure 5.31 Filter patterns for layer block2_conv1\\nFigure 5.32 Filter patterns for layer block3_conv1\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 193}), Document(page_content='172 CHAPTER  5Deep learning for computer vision\\nThese filter visualizations tell you a lot about how convnet layers see the world: each\\nlayer in a convnet learns a collection of filt ers such that their inputs can be expressed\\nas a combination of the filters. This is similar to how the Fourier transform decom-poses signals onto a bank of cosine function s. The filters in these convnet filter banks\\nget increasingly complex and refined as you go higher in the model:\\n\\uf0a1The filters from the first layer in the model ( block1_conv1 ) encode simple\\ndirectional edges and colors (or colored edges, in some cases).\\n\\uf0a1The filters from block2_conv1  encode simple textures made from combina-\\ntions of edges and colors.\\n\\uf0a1The filters in higher layers begin to resemble textures found in natural images:feathers, eyes, leaves, and so on. \\n5.4.3 Visualizing heatmaps of class activation\\nI’ll introduce one more visualization techni que: one that is useful for understanding\\nwhich parts of a given image led a convnet to  its final classification decision. This is\\nhelpful for debugging th e decision process of a convnet, particularly in the case of a\\nclassification mistake. It al so allows you to locate specific objects in an image.\\n This general category of techniques is called class activation map  (CAM ) visualization,\\nand it consists of producing heatmaps of cla ss activation over input images. A class acti-\\nvation heatmap is a 2D grid of scores associated with a specific output class, computed\\nfor every location in any input image, indi cating how important each location is withFigure 5.33 Filter patterns for layer block4_conv1\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 194}), Document(page_content=\"173 Visualizing what convnets learn\\nrespect to the class under cons ideration. For instance, given an image fed into a dogs-\\nversus-cats convnet, CAM  visualization allows you to ge nerate a heatmap for the class\\n“cat,” indicating how cat-like different parts of the image are, and also a heatmap for the\\nclass “dog,” indicating how dog-like parts of the image are.\\n The specific implementation you’ll  use is the one described in “Grad- CAM : Visual\\nExplanations from Deep Networks via Gradient-based Localization.”2 It’s very simple:\\nit consists of taking the output feature map of a convolution layer, given an input\\nimage, and weighing every channel in that feature map by the gradient of the class\\nwith respect to the channel. In tuitively, one way to understand this trick is that you’re\\nweighting a spatial map of “how intensely the input image activates different chan-\\nnels” by “how important each channel is with regard to the class,” resulting in a spatial\\nmap of “how intensely the input image activates the class.”\\n We’ll demonstrate this technique using the pretrained VGG16  network again.\\nfrom keras.applications.vgg16 import VGG16\\nmodel = VGG16(weights='imagenet')\\nConsider the image of two African elephant s shown in figure 5.34 (under a Creative\\nCommons license), possibly a mother and her calf, strolling on the savanna. Let’s con-\\nvert this image into something the VGG 16 model can read: the model was trained on\\nimages of size 224 × 244, preprocessed acco rding to a few rules that are packaged in\\nthe utility function keras.applications.vgg16.preprocess_input . So you need to\\nload the image, resize it to 2 24 × 224, convert it to a Numpy float32  tensor, and apply\\nthese preprocessing rules.\\n2Ramprasaath R. Selvaraju et al., arXiv (2017), https:/ /arxiv.org/abs/ 1610.02391 .Listing 5.40 Loading the VGG16 network with pretrained weights\\nNote that you include the densely \\nconnected classifier on top; in all \\nprevious cases, you discarded it.\\nFigure 5.34 Test picture of African elephants\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 195}), Document(page_content=\"174 CHAPTER  5Deep learning for computer vision\\nfrom keras.preprocessing import image\\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\\nimport numpy as np\\nimg_path = '/Users/fchollet/Downloads/creative_commons_elephant.jpg'img = image.load_img(img_path, target_size=(224, 224))x = image.img_to_array(img)x = np.expand_dims(x, axis=0)x = preprocess_input(x)\\nYou can now run the pr etrained network on the image and decode its prediction vec-\\ntor back to a huma n-readable format:\\n>>> preds = model.predict(x)\\n>>> print('Predicted:', decode_predictions(preds, top=3)[0])Predicted:', [(u'n02504458', u'African_elephant', 0.92546833),\\n(u'n01871265', u'tusker', 0.070257246),\\n(u'n02504013', u'Indian_elephant', 0.0042589349)]\\nThe top three classes predicted for this image are as follows:\\n\\uf0a1African elephant (wit h 92.5% probability)\\n\\uf0a1Tusker (with 7% probability)\\n\\uf0a1Indian elephant (with 0.4% probability)\\nThe network has recognized the image as containing an undetermined quantity of\\nAfrican elephants. The entry in the predicti on vector that was maximally activated is\\nthe one corresponding to the “Afric an elephant” cla ss, at index 386:\\n>>> np.argmax(preds[0])\\n386\\nTo visualize which parts of the image are th e most African elephant–like, let’s set up\\nthe Grad- CAM  process.\\nafrican_e66lephant_output = model.output[:, 386]\\nlast_conv_layer = model.get_layer('block5_conv3')Listing 5.41 Preprocessing an input image for VGG16\\nListing 5.42 Setting up the Grad-CAM algorithmPython Imaging Library (PIL) image \\nof size 224 × 224\\nLocal path to the target imagefloat32 Numpy array of shape \\n(224, 224, 3)\\nAdds a dimension to transform the array \\ninto a batch of size (1, 224, 224, 3)\\nPreprocesses the batch (this does \\nchannel-wise color normalization)\\n“African elephant” entry in the \\nprediction vectorOutput feature map of the block5_conv3 layer, the last convolutional \\nlayer in VGG16\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 196}), Document(page_content='175 Visualizing what convnets learn\\ngrads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\\npooled_grads = K.mean(grads, axis=(0, 1, 2))iterate = K.function([model.input],\\n[pooled_grads, last_conv_layer.output[0]])\\npooled_grads_value, conv_layer_output_value = iterate([x])for i in range(512):\\nconv_layer_output_value[:, :, i] *= pooled_grads_value[i]\\nheatmap = np.mean(conv_layer_output_value, axis=-1)\\nFor visualization purposes, yo u’ll also normalize the he atmap between 0 and 1. The\\nresult is shown in figure 5.35.\\nheatmap = np.maximum(heatmap, 0)\\nheatmap /= np.max(heatmap)\\nplt.matshow(heatmap)Listing 5.43 Heatmap post-processingGradient of the “African \\nelephant” class with regard to the output feature map of \\nblock5_conv3Vector of shape (512 ,), where each entry\\nis the mean intensity of the gradient\\nover a specific fe ature-map channel\\nValues of these tw o quantities, as \\nNumpy arrays, given the sample image \\nof two elephants\\nLets you access the valu es of the quantities \\nyou just defined: pooled_grads and the output feature map of block5_conv3, given \\na sample imageThe channel-wise mean of\\nthe resulting feature map\\nis the heatmap of the\\nclass activation.Multiplies each\\nchannel in the\\nfeature-map array\\nby “how\\nimportant this\\nchannel is” with\\nregard to the\\n“elephant” class\\n0\\n0\\n2\\n468\\n10\\n122 4 6 8 10 12\\nFigure 5.35 African elephant class  \\nactivation heatmap over the test picture\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 197}), Document(page_content=\"176 CHAPTER  5Deep learning for computer vision\\nFinally, you’ll use OpenCV to generate an image that superimposes the original image\\non the heatmap you just obtained (see figure 5.36).\\nimport cv2\\nimg = cv2.imread(img_path)heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\\nheatmap = np.uint8(255 * heatmap)\\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)superimposed_img = heatmap * 0.4 + img\\ncv2.imwrite('/Users/fchollet/Downloads/elephant_cam.jpg', superimposed_img)\\nThis visualization te chnique answers two important questions:\\n\\uf0a1Why did the network think this imag e contained an African elephant?\\n\\uf0a1Where is the African elepha nt located in the picture?\\nIn particular, it’s interesting to note that th e ears of the elephant calf are strongly acti-\\nvated: this is probably how the network can tell the difference between African and\\nIndian elephants. Listing 5.44 Superimposing the heatmap with the original picture\\nUses cv2 to load the \\noriginal imageResizes the heatmap to\\nbe the same size as the\\noriginal image\\nApplies the heatmap to the \\noriginal imageConverts the \\nheatmap to RGB\\n0.4 here is a heatmap \\nintensity factor.\\nSaves the image to disk\\nFigure 5.36 Superimposing the class activation heatmap on the original picture\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 198}), Document(page_content='177 Visualizing what convnets learn\\nChapter summary\\n\\uf0a1Convnets are the best tool for atta cking visual-classification problems.\\n\\uf0a1Convnets work by learning a hierar chy of modular patterns and concepts\\nto represent the visual world.\\n\\uf0a1The representations they learn are easy to inspect—convnets are theopposite of black boxes!\\n\\uf0a1You’re now capable of training your own convnet from scratch to solve an\\nimage-classification problem.\\n\\uf0a1You understand how to use visual data  augmentation to fight overfitting.\\n\\uf0a1You know how to use a pretrained co nvnet to do feature extraction and\\nfine-tuning.\\n\\uf0a1You can generate visualizations of th e filters learned by your convnets, as\\nwell as heatmaps of class activity.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 199}), Document(page_content='178Deep learning for\\ntext and sequences\\nThis chapter explores deep-learning mode ls that can process text (understood as\\nsequences of word or sequences of charac ters), timeseries, and sequence data in\\ngeneral. The two fundamental deep-learning algorithms for sequence processing\\nare recurrent neural networks  and 1D convnets , the one-dimensional version of the 2D\\nconvnets that we covered in the previous chapters. We’ll discuss both of these\\napproaches in this chapter.\\n Applications of these algo rithms include the following:\\n\\uf0a1Document classification and timeseries classification, such as identifying the\\ntopic of an article or the author of a book\\n\\uf0a1Timeseries comparisons, such as esti mating how closely related two docu-\\nments or two st ock tickers areThis chapter covers\\n\\uf0a1Preprocessing text data into useful \\nrepresentations\\n\\uf0a1Working with recurrent neural networks\\n\\uf0a1Using 1D convnets for sequence processing\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 200}), Document(page_content='179\\n\\uf0a1Sequence-to-sequence learning, such as  decoding an English sentence into\\nFrench\\n\\uf0a1Sentiment analysis, such as classifying th e sentiment of tweets or movie reviews\\nas positive or negative\\n\\uf0a1Timeseries forecasting, such  as predicting the future weather at a certain loca-\\ntion, given recent weather data\\nThis chapter’s examples focus on two na rrow tasks: sentiment analysis on the IMDB\\ndataset, a task we approached earlier in the book, and temperature forecasting. But\\nthe techniques demonstrated for these two tasks are relevant to all the applications\\njust listed, and many more.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 201}), Document(page_content='180 CHAPTER  6Deep learning for text and sequences\\n6.1 Working with text data\\nText is one of the most widespread forms of sequence data. It can be understood as\\neither a sequence of characte rs or a sequence of words, but it’s most common to work\\nat the level of words. The deep-learning sequence-processing mo dels introduced in\\nthe following sections can use text to produce a basic form of natural-language under-\\nstanding, sufficient for applications incl uding document classi fication, sentiment\\nanalysis, author identification, and even question-answering ( QA) (in a constrained\\ncontext). Of course, keep in mind throughout this chapter that none of these deep-\\nlearning models truly understand text in  a human sense; rather, these models can\\nmap the statistical structure of written lang uage, which is sufficient to solve many sim-\\nple textual tasks. Deep learning for natural- language processing is  pattern recognition\\napplied to words, sentences, and paragrap hs, in much the same way that computer\\nvision is pattern recognition applied to pixels.\\n Like all other neural netw orks, deep-learning models don’t take as input raw text:\\nthey only work with numeric tensors. Vectorizing  text is the process of transforming text\\ninto numeric tensors. This can be done in multiple ways:\\n\\uf0a1Segment text into words, and transform each word into a vector.\\n\\uf0a1Segment text into characters, and tran sform each characte r into a vector.\\n\\uf0a1Extract n-grams of words or characters, an d transform each n-gram into a vector.\\nN-grams  are overlapping groups of multiple  consecutive word s or characters.\\nCollectively, the different units into which you can break down text (words, charac-\\nters, or n-grams) are called tokens , and breaking text into such tokens is called tokeniza-\\ntion. All text-vectorization proc esses consist of applying so me tokenization scheme and\\nthen associating numeric vectors with the generated tokens. These vectors, packed\\ninto sequence tensors, are fed into deep neural networks. There are multiple ways to\\nassociate a vector with a to ken. In this section, I’ ll present two major ones: one-hot\\nencoding  of tokens, and token embedding  (typically used exclusively for words, and called\\nword embedding ). The remainder of this section ex plains these techniques and shows\\nhow to use them to go from raw text to a Numpy tensor that you can send to a Kerasnetwork.\\nText\\n“The cat sat on the mat.”\\nTokens\\n“the”, “cat”, “sat”, “on”, “the”, “mat”, “.”\\nVector encoding of the tokens\\n0.0 0.0 0.4 0.0 0.0 1.0 0.0\\n0.5 1.0 0.5 0.2 0.5 0.5 0.0\\n1.0 0.2 1.0 1.0 1.0 0.0 0.0\\nthe cat sat on the mat .Figure 6.1 From text \\nto tokens to vectors\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 202}), Document(page_content='181 Working with text data\\n \\n6.1.1 One-hot encoding of words and characters\\nOne-hot encoding is the most common, most basic way to turn a token into a vector.\\nYou saw it in action in the initial IMDB  and Reuters examples in chapter 3 (done with\\nwords, in that case). It consists of asso ciating a unique integer index with every word\\nand then turning this integer index i into a binary vector of size N (the size of the\\nvocabulary); the vector is  all zeros except for the ith entry, which is 1.\\n Of course, one-hot encoding can be done at the character level, as well. To unam-\\nbiguously drive home what one-hot encoding  is and how to implement it, listings 6.1\\nand 6.2 show two toy examples: one fo r words, the other for characters.Understanding n-grams and bag-of-words\\nWord n-grams are groups of N (or fewer) consecutive words that you can extract from\\na sentence. The same concept may also be applied to characters instead of words.\\nHere’s a simple example. Consider the sentence “The cat sat on the mat.” It may be\\ndecomposed into the following set of 2-grams:\\n{\"The\", \"The cat\", \"cat\", \"cat sat\", \"sat\",\\n\"sat on\", \"on\", \"on the\", \"the\", \"the mat\", \"mat\"}\\nIt may also be decomposed into the following set of 3-grams:\\n{\"The\", \"The cat\", \"cat\", \"cat sat\", \"The cat sat\",\\n\"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", \"the\",\\n\"sat on the\", \"the mat\", \"mat\", \"on the mat\"}\\nSuch a set is called a bag-of-2-grams  or bag-of-3-grams , respectively. The term bag\\nhere refers to the fact that you’re dealing with a set of tokens rather than a list or\\nsequence: the tokens have no specific order. This family of tokenization methods is\\ncalled bag-of-words .\\nBecause bag-of-words isn’t an order-preserving tokenization method (the tokens gen-\\nerated are understood as a set, not a sequ ence, and the general structure of the sen-\\ntences is lost), it tends to be used in shallow language-processing models rather than\\nin deep-learning models. Extracting n-grams is a form of feature engineering, and\\ndeep learning does away with this kind of ri gid, brittle approach, replacing it with hier-\\narchical feature learning. One-dimensional convnets and recurrent neural networks,\\nintroduced later in this chapter, are capable of learning representations for groups of\\nwords and characters without being explicitly  told about the existence of such groups,\\nby looking at continuous word or character sequences. For this reason, we won’t\\ncover n-grams any further in this book. But do keep in mind that they’re a powerful,\\nunavoidable feature-engineerin g tool when using lightweig ht, shallow text-processing\\nmodels such as logistic regression and random forests.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 203}), Document(page_content=\"182 CHAPTER  6Deep learning for text and sequences\\n \\nimport numpy as np\\nsamples = ['The cat sat on the mat.', 'The dog ate my homework.']\\ntoken_index = {}\\nfor sample in samples:\\nfor word in sample.split():\\nif word not in token_index:\\ntoken_index[word] = len(token_index) + 1\\nmax_length = 10\\nresults = np.zeros(shape=(len(samples),\\nmax_length,max(token_index.values()) + 1))\\nfor i, sample in enumerate(samples):\\nfor j, word in list(enumerate(sample.split()))[:max_length]:\\nindex = token_index.get(word)results[i, j, index] = 1.\\nimport string\\nsamples = ['The cat sat on the mat.', 'The dog ate my homework.']\\ncharacters = string.printabletoken_index = dict(zip(range(1, len(characters) + 1), characters))\\nmax_length = 50\\nresults = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))for i, sample in enumerate(samples):\\nfor j, character in enumerate(sample):\\nindex = token_index.get(character)results[i, j, index] = 1.\\nNote that Keras has built-in utilities for doin g one-hot encoding of text at the word level\\nor character level, starting from raw text data. You should use these utilities, because\\nthey take care of a number of important fe atures such as strippi ng special characters\\nfrom strings and only taking into account the N most common words in your dataset (a\\ncommon restriction, to av oid dealing with very large input vector spaces).Listing 6.1 Word-level one-hot encoding (toy example)\\nListing 6.2 Character-level one-hot encoding (toy example)Initial data: one entry per sample (in \\nthis example, a sample is a sentence, \\nbut it could be an entire document)Builds an index of all tokens in the data\\nTokenizes the samples via the split\\nmethod. In real life, you’d also strip\\npunctuation and special characters\\nfrom the samples.\\nAssigns a unique index to each unique word. Note that you don’t \\nattribute index 0 to anything.This is where you\\nstore the results.\\nVectorizes the sa mples. You’ll only\\nconsider the first max_length\\nwords in each sample.\\nAll printable ASCII\\ncharacters\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 204}), Document(page_content=\"183 Working with text data\\n \\nfrom keras.preprocessing.text import Tokenizer\\nsamples = ['The cat sat on the mat.', 'The dog ate my homework.']\\ntokenizer = Tokenizer(num_words=1000)\\ntokenizer.fit_on_texts(samples)\\nsequences = tokenizer.texts_to_sequences(samples)\\none_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')word_index = tokenizer.word_index\\nprint('Found %s unique tokens.' % len(word_index))\\nA variant of one-hot encoding is the so-called one-hot hashing trick , which you can use\\nwhen the number of unique tokens in your vocabulary is too large to handle explicitly.Instead of explicitly assigning an index to each word and keeping a reference of these\\nindices in a dictionary, you can hash words in to vectors of fixed size. This is typically\\ndone with a very lightweight hashing functi on. The main advantage of this method is\\nthat it does away with maintaining an ex plicit word index, wh ich saves memory and\\nallows online encoding of the data (you can generate token vect ors right away, before\\nyou’ve seen all of the available data). The one drawback of this approach is that it’s\\nsusceptible to hash collisions : two different words may end up with the same hash, and\\nsubsequently any machine-learni ng model looking at these ha shes won’t be able to tell\\nthe difference between these words. The li kelihood of hash collisions decreases when\\nthe dimensionality of the hashing space is  much larger than the total number of\\nunique tokens being hashed.\\nsamples = ['The cat sat on the mat.', 'The dog ate my homework.']\\ndimensionality = 1000\\nmax_length = 10\\nresults = np.zeros((len(samples), max_length, dimensionality))\\nfor i, sample in enumerate(samples):\\nfor j, word in list(enumerate(sample.split()))[:max_length]:\\nindex = abs(hash(word)) % dimensionality\\nresults[i, j, index] = 1.Listing 6.3 Using Keras for word-level one-hot encoding\\nListing 6.4 Word-level one-hot encoding with hashing trick (toy example)Creates a tokenizer, configured\\nto only take into account the\\n1,000 most common words\\nTurns strings into lists \\nof integer indices\\nHow you can recover \\nthe word index that was computedYou could also directly get the one-hot \\nbinary representati ons. Vectorization \\nmodes other than one-hot encoding \\nare supported by this tokenizer.Builds\\nthe\\nword\\nindex\\nStores the words as vectors of size 1,000. If you have close \\nto 1,000 words (or more), you’ll see many hash collisions, \\nwhich will decrease the accuracy  of this encoding method.Hashes the word into a \\nrandom integer index \\nbetween 0 and 1,000\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 205}), Document(page_content='184 CHAPTER  6Deep learning for text and sequences\\n6.1.2 Using word embeddings\\nAnother popular and powerful way to associate a vector with a word is the use of dense\\nword vectors , also called word embeddings . Whereas the vectors obtained through one-hot\\nencoding are binary, sparse (mostly made of  zeros), and very hi gh-dimensional (same\\ndimensionality as the number of words in the vocabulary), word embeddings are low-\\ndimensional floating-point ve ctors (that is, dense vectors,  as opposed to sparse vec-\\ntors); see figure 6.2. Unlike the word vectors obtained via one-hot encoding, word\\nembeddings are learned from data. It’s common to see word embeddings that are\\n256-dimensional, 512-dimensio nal, or 1,024-dimensional when dealing with very large\\nvocabularies. On the other hand, one-hot en coding words generall y leads to vectors\\nthat are 20,000-dimensional or greater (capturing a vocabulary of 20,000 tokens, in\\nthis case). So, word embeddings pack more information into far fewer dimensions.\\nThere are two ways to obtain word embeddings:\\n\\uf0a1Learn word embeddings jointly with the ma in task you care about (such as doc-\\nument classification or sent iment prediction). In this setup, you start with ran-\\ndom word vectors and then learn word vectors in the same way you learn the\\nweights of a neural network.\\n\\uf0a1Load into your model word embeddings  that were precomputed using a differ-\\nent machine-learning task than the one yo u’re trying to solve. These are called\\npretrained word embeddings .\\nLet’s look at both.One-hot word vectors:\\n - Sparse - High-dimensional - HardcodedWord embeddings:\\n - Dense - Lower-dimensional - Learned from dataFigure 6.2 Whereas word representations \\nobtained from one-hot encoding or hashing are \\nsparse, high-dimensional, and hardcoded, word \\nembeddings are dense, relatively low-dimensional, and learned from data.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 206}), Document(page_content='185 Working with text data\\nLEARNING  WORD  EMBEDDINGS  WITH THE EMBEDDING  LAYER\\nThe simplest way to associate a dense vector  with a word is to choose the vector at\\nrandom. The problem with this approach is  that the resulting embedding space has\\nno structure: for instance, the words accurate  and exact may end up with completely\\ndifferent embeddings, even though they’re interchangeable in mo st sentences. It’s\\ndifficult for a deep neural network to ma ke sense of such a noisy, unstructured\\nembedding space.\\n To get a bit more abstract, the geomet ric relationships between word vectors\\nshould reflect the semantic relationships between these words. Word embeddings are\\nmeant to map human language into a geomet ric space. For instan ce, in a reasonable\\nembedding space, you would expect synonyms to be embedded into similar word vec-\\ntors; and in general, you would expect the geometric distance (such as L2 distance)\\nbetween any two word vectors to relate to the semantic distance between the associ-\\nated words (words meaning different things  are embedded at points far away from\\neach other, whereas related words are closer ). In addition to distance, you may want\\nspecific directions  in the embedding space to be meanin gful. To make this clearer, let’s\\nlook at a concrete example.\\n In figure 6.3, four words are embedded on a 2D plane:\\ncat, dog, wolf, and tiger. With the vector representations we\\nchose here, some semantic relationships between these\\nwords can be encoded as geometric transformations. Forinstance, the same vector allows us to go from cat to tiger\\nand from dog to wolf: this vector could be interpreted as the\\n“from pet to wild animal” vector. Similarly, another vectorlets us go from dog to cat and from wolf to tiger, which could\\nbe interpreted as a “from canine to feline” vector.\\n In real-world word-embed ding spaces, common exam-\\nples of meaningful geometri c transformations are “gender”\\nvectors and “plural” vectors. For instance, by adding a “female” vector to the vector\\n“king,” we obtain the vector “queen.” By ad ding a “plural” vector, we obtain “kings.”\\nWord-embedding spaces typically feature th ousands of such inte rpretable and poten-\\ntially useful vectors.\\n Is there some ideal word-embedding sp ace that would perf ectly map human lan-\\nguage and could be used for any natural-language-processing task? Possibly, but wehave yet to compute anything of the so rt. Also, there is no such a thing as human lan-\\nguage —there are many different languages, and they aren’t isomorphic, because a lan-\\nguage is the reflection of a specific culture and a specific  context. But more\\npragmatically, what makes a go od word-embedding space depe nds heavily on your task:\\nthe perfect word-embedding space for an English-language movie-review sentiment-\\nanalysis model may look different from th e perfect embedding space for an English-\\nlanguage legal-document-classification model, because the importance of certain\\nsemantic relationships vari es from task to task.1\\n0\\n1 0WolfTiger\\nCatDog\\nX\\nFigure 6.3 A toy example \\nof a word-embedding space\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 207}), Document(page_content='186 CHAPTER  6Deep learning for text and sequences\\n It’s thus reasonable to learn  a new embedding space wi th every new task. Fortu-\\nnately, backpropagation makes this easy, an d Keras makes it even easier. It’s about\\nlearning the weights of a layer: the Embedding  layer.\\nfrom keras.layers import Embedding\\nembedding_layer = Embedding(1000, 64)\\nThe Embedding  l a y e r  i s  b e s t  u n d e r s t o o d  a s  a  d i c t i o n a r y  t h a t  m a p s  i n t e g e r  i n d i c e s\\n(which stand for specific  words) to dense vectors. It take s integers as input, it looks up\\nthese integers in an internal dictionary, and it returns the associated  vectors. It’s effec-\\ntively a dictionary lookup (see figure 6.4).\\nThe Embedding  layer takes as input a 2D tensor of integers, of shape (samples,\\nsequence_length) , where each entry is a sequence of integers. It can embed\\nsequences of variable lengths: for instance, you could feed into the Embedding  layer in\\nthe previous example batches with shapes (32,  10) (batch of 32 sequences of length\\n10) or (64,  15) (batch of 64 sequences of length  15). All sequences in a batch must\\nhave the same length, though (because you need to pack them into a single tensor),\\nso sequences that are shorter than others sh ould be padded with zeros, and sequences\\nthat are longer should be truncated.\\n This layer returns a 3D floating-point tensor of shape (samples,  sequence_\\nlength, embedding_dimensionality) . Such a 3D tensor can then be processed by\\nan RNN  layer or a 1D convolution layer (both will be  introduced in the following\\nsections).\\n When you instantiate an Embedding  layer, its weights (its internal dictionary of\\ntoken vectors) are initially random, just as with any other layer. During training, these\\nword vectors are grad ually adjusted via backpropagat ion, structuring the space into\\nsomething the downstream model can exploi t. Once fully trained, the embedding\\nspace will show a lot of stru cture—a kind of structure spec ialized for the specific prob-\\nlem for which you’re training your model.\\n Let’s apply this idea to the IMDB  movie-review sentimen t-prediction task that\\nyou’re already familiar with. First, you’ll qu ickly prepare the data. You’ll restrict the\\nmovie reviews to the top 10 ,000 most common words (as you did the first time you\\nworked with this dataset) and cut off the re views after only 20 wo rds. The network will\\nlearn 8-dimensional embeddings for each of the 10,000 words, turn the input integerListing 6.5 Instantiating an Embedding  layer\\nThe Embedding layer takes at least two \\narguments: the number of possible tokens (here, 1,000: 1 + maximum word index) \\nand the dimensionality  of the embeddings \\n(here, 64).\\nWord index Embedding layer Corresponding word vecto r\\nFigure 6.4 The Embedding  layer\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 208}), Document(page_content=\"187 Working with text data\\nsequences (2D integer tensor) into embedded sequences ( 3D float tensor), flatten the\\ntensor to 2D, and train a single Dense  layer on top for classification.\\nfrom keras.datasets import imdb\\nfrom keras import preprocessing\\nmax_features = 10000\\nmaxlen = 20\\n(x_train, y_train), (x_test, y_test) = imdb.load_data(\\nnum_words=max_features)\\nx_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen\\nx_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\\nfrom keras.models import Sequential\\nfrom keras.layers import Flatten, Dense\\nmodel = Sequential()\\nmodel.add(Embedding(10000, 8, input_length=maxlen))\\nmodel.add(Flatten())\\nmodel.add(Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])model.summary()\\nhistory = model.fit(x_train, y_train,\\nepochs=10,batch_size=32,\\nvalidation_split=0.2)\\nYou get to a validation accuracy of ~76%, wh ich is pretty good considering that you’re\\nonly looking at the first 20 words in every review. But note that merely flattening the\\nembedded sequences and training a single Dense  layer on top leads to a model that\\ntreats each word in the input sequence separately, without considering inter-word\\nrelationships and sentence structure (for ex ample, this model would likely treat both\\n“this movie is a bomb” and “this movie is the bomb” as being ne gative reviews). It’s\\nmuch better to add recurrent layers or 1D convolutional layers on top of the embed-\\nded sequences to learn features that take into account each sequence as a whole.That’s what we’ll focus on in the next few sections. Listing 6.6 Loading the IMDB data for use with an Embedding  layer\\nListing 6.7 Using an Embedding  layer and classifier on the IMDB dataNumber of words to \\nconsider as featuresCuts off the text after this \\nnumber of words (among the max_features most \\ncommon words)\\nLoads the data as lists of integers\\nTurns the lists of integers into\\na 2D integer tensor of shape\\n(samples, maxlen)\\nSpecifies the maximum input length to the \\nEmbedding layer so you can later flatten the embedded inputs. After the Embedding layer, \\nthe activations have shape (samples, maxlen, 8).Flattens the 3D tensor of \\nembeddings into a 2D \\ntensor of shape (samples, \\nmaxlen * 8)\\nAdds the classifier on top\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 209}), Document(page_content='188 CHAPTER  6Deep learning for text and sequences\\nUSING PRETRAINED  WORD  EMBEDDINGS\\nSometimes, you have so litt le training data available that you can’t use your data\\nalone to learn an appropriat e task-specific embedding of your vocabulary. What do\\nyou do then?\\n Instead of learning word embeddings jo intly with the problem you want to solve,\\nyou can load embedding vectors from a precomputed embedding space that youknow is highly structured and exhibits useful properties—that captures generic\\naspects of language structure. The ration ale behind using pretrained word embed-\\ndings in natural-language processing is mu ch the same as for using pretrained conv-\\nnets in image classification: you don’t ha ve enough data available to learn truly\\npowerful features on your own, but you expe ct the features that you need to be fairly\\ngeneric—that is, common visual features or semantic features. In this case, it makes\\nsense to reuse features learned on a different problem.\\n Such word embeddings are generally co mputed using word-occurrence statistics\\n(observations about what words co-occur in sentences or documents), using a variety of\\ntechniques, some involving ne ural networks, others not. The idea of a dense, low-\\ndimensional embedding space fo r words, computed in an unsupervised way, was ini-\\ntially explored by Bengio et al. in the early 2000s,\\n1 but it only started to take off in\\nresearch and industry applications after the release of one of the most famous and suc-\\ncessful word-embedding scheme s: the Word2vec algorithm ( https:/ /code.google.com/\\narchive/p/word2vec ), developed by Tomas Mikolov at Google in 2013. Word2vec\\ndimensions capture specific semantic properties, such as gender.\\n There are various precomputed databases of word embeddings that you can down-\\nload and use in a Keras Embedding  layer. Word2vec is one of them. Another popular\\none is called Global Vectors for Word Representation (GloVe, https:/ /nlp.stanford\\n.edu/projects/glove ), which was developed by Stanford researchers in 2014. This\\nembedding technique is based on factorizin g a matrix of word co-occurrence statis-\\ntics. Its developers have made availabl e precomputed embeddings for millions of\\nEnglish tokens, obtained from Wikipedia data and Common Crawl data.\\n Let’s look at how you can get started using GloVe embeddings in a Keras model.\\nThe same method is valid for Word2vec embeddings or any other word-embeddingdatabase. You’ll also use this example to  refresh the text-tokenization techniques\\nintroduced a few paragraphs ago: you’ll start from raw text and work your way up. \\n6.1.3 Putting it all together: fr om raw text to word embeddings\\nYou’ll use a model similar to the one we just went over: embedding sentences in\\nsequences of vectors, flatte ning them, and training a Dense  layer on top. But you’ll do\\nso using pretrained word embeddings; and instead of using the pretokenized IMDB\\ndata packaged in Keras, you’ll start from sc ratch by downloading the original text data.\\n1Yoshua Bengio et al., Neural Probabilistic Language Models  (Springer, 2003).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 210}), Document(page_content=\"189 Working with text data\\nDOWNLOADING  THE IMDB DATA AS RAW TEXT\\nFirst, head to http:/ /mng.bz/0tIo  and download the raw IMDB  dataset. Uncompress it.\\n Now, let’s collect the individual training re views into a list of st rings, one string per\\nreview. You’ll also collect the review labels (positive/negative) into a labels  list.  \\nimport os\\nimdb_dir = '/Users/fchollet/Downloads/aclImdb'\\ntrain_dir = os.path.join(imdb_dir, 'train')\\nlabels = []\\ntexts = []\\nfor label_type in ['neg', 'pos']:\\ndir_name = os.path.join(train_dir, label_type)\\nfor fname in os.listdir(dir_name):\\nif fname[-4:] == '.txt':\\nf = open(os.path.join(dir_name, fname))\\ntexts.append(f.read())f.close()if label_type == 'neg':\\nlabels.append(0)\\nelse:\\nlabels.append(1)\\nTOKENIZING  THE DATA\\nLet’s vectorize the text and prepare a traini ng and validation spli t, using the concepts\\nintroduced earlier in this section. Because pretrained word embeddings are meant to\\nbe particularly useful on problems where li ttle training data is available (otherwise,\\ntask-specific embeddings  are likely to outperform them ), we’ll add the following twist:\\nrestricting the training data to the first 200 samples. So you’ll le arn to classify movie\\nreviews after looking at  just 200 examples.\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras.preprocessing.sequence import pad_sequences\\nimport numpy as np\\nmaxlen = 100\\ntraining_samples = 200\\nvalidation_samples = 10000\\nmax_words = 10000\\ntokenizer = Tokenizer(num_words=max_words)\\ntokenizer.fit_on_texts(texts)\\nsequences = tokenizer.texts_to_sequences(texts)Listing 6.8 Processing the labels of the raw IMDB data\\nListing 6.9 Tokenizing the text of the raw IMDB data\\nCuts off reviews after 100 words\\nTrains on 200 samples\\nValidates on 10,000 samples\\nConsiders only the top \\n10,000 words in the dataset\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 211}), Document(page_content=\"190 CHAPTER  6Deep learning for text and sequences\\nword_index = tokenizer.word_index\\nprint('Found %s unique tokens.' % len(word_index))\\ndata = pad_sequences(sequences, maxlen=maxlen)\\nlabels = np.asarray(labels)\\nprint('Shape of data tensor:', data.shape)print('Shape of label tensor:', labels.shape)\\nindices = np.arange(data.shape[0])\\nnp.random.shuffle(indices)data = data[indices]\\nlabels = labels[indices]\\nx_train = data[:training_samples]\\ny_train = labels[:training_samples]\\nx_val = data[training_samples: training_samples + validation_samples]\\ny_val = labels[training_samples: training_samples + validation_samples]\\nDOWNLOADING  THE GLOVE WORD  EMBEDDINGS\\nGo to https:/ /nlp.stanford.edu/projects/glove , and download the precomputed\\nembeddings from 2014 English Wikipedia. It’s an 822 MB zip file called glove.6B.zip,\\ncontaining 100-dimensional embedding vectors for 400,000 words (or nonword\\ntokens). Unzip it. \\nPREPROCESSING  THE EMBEDDINGS\\nLet’s parse the unzipped file (a .txt file) to  build an index that maps words (as strings)\\nto their vector representation (as number vectors).\\nglove_dir = '/Users/fchollet/Downloads/glove.6B'\\nembeddings_index = {}\\nf = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\\nfor line in f:\\nvalues = line.split()\\nword = values[0]\\ncoefs = np.asarray(values[1:], dtype='float32')embeddings_index[word] = coefs\\nf.close()\\nprint('Found %s word vectors.' % len(embeddings_index))\\nNext, you’ll build an embedding ma trix that you can load into an Embedding  layer. It\\nmust be a matrix of shape (max_words, embedding_dim) , where each entry i contains\\nthe embedding_dim -dimensional vector for the word of index i in the reference word\\nindex (built during tokenization). Note that  index 0 isn’t supposed to stand for any\\nword or token—it’s a placeholder.\\n Listing 6.10 Parsing the GloVe word-embeddings fileSplits the data into a training set and a \\nvalidation set, but fi rst shuffles the data, \\nbecause you’re starting with data in which samples are ordered (all negative first, then \\nall positive) \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 212}), Document(page_content=\"191 Working with text data\\n \\nembedding_dim = 100\\nembedding_matrix = np.zeros((max_words, embedding_dim))\\nfor word, i in word_index.items():\\nif i < max_words:\\nembedding_vector = embeddings_index.get(word)\\nif embedding_vector is not None:\\nembedding_matrix[i] = embedding_vector\\nDEFINING  A MODEL\\nYou’ll use the same model architecture as before.  \\nfrom keras.models import Sequential\\nfrom keras.layers import Embedding, Flatten, Dense\\nmodel = Sequential()\\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))model.add(Flatten())\\nmodel.add(Dense(32, activation='relu'))\\nmodel.add(Dense(1, activation='sigmoid'))model.summary()\\nLOADING  THE GLOVE EMBEDDINGS  IN THE MODEL\\nThe Embedding  layer has a single weight matrix: a 2D float matrix where each entry i is\\nthe word vector meant to be associated with index i. Simple enough. Load the GloVe\\nmatrix you prepared into the Embedding  layer, the first layer in the model.\\nmodel.layers[0].set_weights([embedding_matrix])\\nmodel.layers[0].trainable = False\\nAdditionally, you’ll freeze the Embedding  layer (set its trainable  attribute to False ),\\nfollowing the same rationale you’re already familiar with in the context of pretrained\\nconvnet features: when parts of a model are pretrained (like your Embedding  layer)\\nand parts are randomly initialized (like your classifier), the pretra ined parts shouldn’t\\nbe updated during training, to avoid forgetti ng what they already know. The large gra-\\ndient updates triggered by the randomly init ialized layers would be disruptive to the\\nalready-learned features. \\n  \\n Listing 6.11 Preparing the GloVe word-embeddings matrix\\nListing 6.12 Model definition\\nListing 6.13 Loading pretrained word embeddings into the Embedding  layerWords not found in the \\nembedding index will be all zeros. \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 213}), Document(page_content=\"192 CHAPTER  6Deep learning for text and sequences\\nTRAINING  AND EVALUATING  THE MODEL\\nCompile and train the model.\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])\\nhistory = model.fit(x_train, y_train,\\nepochs=10,batch_size=32,validation_data=(x_val, y_val))\\nmodel.save_weights('pre_trained_glove_model.h5')\\nNow, plot the model’s performance ov er time (see figures 6.5 and 6.6).\\nimport matplotlib.pyplot as plt\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']loss = history.history['loss']\\nval_loss = history.history['val_loss']\\nepochs = range(1, len(acc) + 1)plt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')plt.legend()\\nplt.figure()\\nplt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')\\nplt.legend()\\nplt.show()Listing 6.14 Training and evaluation\\nListing 6.15 Plotting the results\\nFigure 6.5 Training and validation loss \\nwhen using pretrained word embeddings\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 214}), Document(page_content=\"193 Working with text data\\nThe model quickly starts overfitting, which is unsurprising given the small number of\\ntraining samples. Validation accuracy has high variance for the same reason, but it\\nseems to reach the high 50s.\\n Note that your mileage may vary: because you have so few traini ng samples, perfor-\\nmance is heavily dependent on exactly which 200 samples you choose—and you’re\\nchoosing them at random. If this works po orly for you, try choosing a different ran-\\ndom set of 200 samples, for the sake of the exercise (in real life, you don’t get to\\nchoose your training data).\\n You can also train the same model with out loading the pretrained word embed-\\ndings and without freezing the embedding laye r. In that case, you’ll learn a task-\\nspecific embedding of the input tokens, which is generally more powerful than\\npretrained word embeddings when lots of da ta is available. But in this case, you have\\nonly 200 training samples. Let’s try it (see figures 6.7 and 6.8).\\nfrom keras.models import Sequential\\nfrom keras.layers import Embedding, Flatten, Dense\\nmodel = Sequential()\\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen))\\nmodel.add(Flatten())\\nmodel.add(Dense(32, activation='relu'))model.add(Dense(1, activation='sigmoid'))\\nmodel.summary()\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])\\nhistory = model.fit(x_train, y_train,\\nepochs=10,batch_size=32,\\nvalidation_data=(x_val, y_val))Listing 6.16 Training the same model without pretrained word embeddings\\nFigure 6.6 Training and validation accuracy when using \\npretrained word embeddings\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 215}), Document(page_content=\"194 CHAPTER  6Deep learning for text and sequences\\nValidation accuracy stalls in the low 50s. So  in this case, pretrained word embeddings\\noutperform jointly learned embeddings. If you increase the number of training sam-\\nples, this will quickly stop being the case—try it as an exercise.\\n Finally, let’s evaluate the model on the test  data. First, you need to tokenize the test\\ndata.\\ntest_dir = os.path.join(imdb_dir, 'test')\\nlabels = []\\ntexts = []\\nfor label_type in ['neg', 'pos']:\\ndir_name = os.path.join(test_dir, label_type)\\nfor fname in sorted(os.listdir(dir_name)):\\nif fname[-4:] == '.txt':\\nf = open(os.path.join(dir_name, fname))\\ntexts.append(f.read())Listing 6.17 Tokenizing the data of the test set\\nFigure 6.7 Training and validation loss without using pretrained word embeddings\\nFigure 6.8 Training and validation \\naccuracy without using pretrained \\nword embeddings\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 216}), Document(page_content=\"195 Working with text data\\nf.close()\\nif label_type == 'neg':\\nlabels.append(0)\\nelse:\\nlabels.append(1)\\nsequences = tokenizer.texts_to_sequences(texts)\\nx_test = pad_sequences(sequences, maxlen=maxlen)\\ny_test = np.asarray(labels)\\nNext, load and evalua te the first model.\\nmodel.load_weights('pre_trained_glove_model.h5')\\nmodel.evaluate(x_test, y_test)\\nYou get an appalling test accuracy of 56%.  Working with just a handful of training\\nsamples is difficult!\\n6.1.4 Wrapping up\\nNow you’re able to do the following:\\n\\uf0a1Turn raw text into something a neural network can process\\n\\uf0a1Use the Embedding  layer in a Keras model to learn task-specific token embed-\\ndings\\n\\uf0a1Use pretrained word embeddings to get an extra boost on small natural-\\nlanguage-processing problems Listing 6.18 Evaluating the model on the test set\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 217}), Document(page_content='196 CHAPTER  6Deep learning for text and sequences\\n6.2 Understanding recurrent neural networks\\nA major characteristic of all neural networks you’ve seen so far, such as densely con-\\nnected networks and convnets, is that th ey have no memory. Each input shown to\\nthem is processed independently, with no st ate kept in between inputs. With such net-\\nworks, in order to pr ocess a sequence or a temporal se ries of data points, you have to\\nshow the entire sequence to the network at on ce: turn it into a single data point. For\\ninstance, this is what you did in the IMDB example: an entire movie review was trans-\\nformed into a single large vector and processed in one go. Such networks are called\\nfeedforward networks .\\n In contrast, as you’re reading the presen t sentence, you’re pr ocessing it word by\\nword—or rather, eye saccade by eye saccade—while keeping memories of what came\\nbefore; this gives you a fluid representation of the meaning conveyed by this sentence.\\nBiological intelligence processes information incrementally while maintaining an\\ninternal model of what it’s processing, built from past information and constantly\\nupdated as new information comes in.\\n A recurrent neural network  (RNN ) adopts the same principle, albeit in an extremely\\nsimplified version: it proce sses sequences by iterating th rough the sequence elements\\nand maintaining a state containing information relative\\nto what it has seen so far. In effect, an RNN  is a type of\\nneural network that has an inte rnal loop (see figure 6.9).\\nThe state of the RNN  is reset between processing two dif-\\nferent, independent sequences (such as two different\\nIMDB  reviews), so you still co nsider one sequence a sin-\\ngle data point: a single input to the network. Whatchanges is that this data point is no longer processed in a\\nsingle step; rather, the ne twork internally loops over\\nsequence elements.\\n To make these notions of loop and state clear, let’s implement the forward pass of a\\ntoy \\nRNN  in Numpy. This RNN  takes as input a sequence of  vectors, which you’ll encode\\nas a 2D tensor of size (timesteps, input_features) . It loops over timesteps, and at\\neach timestep, it consid ers its current state at t and the input at t (of shape (input_\\nfeatures,) , and combines them to obtain the output at t. You’ll then set the state for\\nthe next step to be this previous output. For the first timestep, the previous output\\nisn’t defined; hence, there is no current stat e. So, you’ll initialize the state as an all-\\nzero vector called the initial state  of the network.\\n In pseudocode, this is the RNN .\\nstate_t = 0\\nfor input_t in input_sequence:\\noutput_t = f(input_t, state_t)\\nstate_t = output_tListing 6.19 Pseudocode RNN\\nThe state at t\\nIterates over sequence elements\\nThe previous output becomes th e state for the next iteration.RNN\\nInputOutput\\nRecurrent\\nconnection\\nFigure 6.9 A recurrent \\nnetwork: a network with a loop\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 218}), Document(page_content='197 Understanding recurrent neural networks\\nYou can even flesh out the function f: the transformation of the input and state into an\\noutput will be parameterized by two matrices, W and U, and a bias vector. It’s similar to\\nthe transformation operated by a densely connected layer in a feedforward network.\\nstate_t = 0\\nfor input_t in input_sequence:\\noutput_t = activation(dot(W, input_t) + dot(U, state_t) + b)\\nstate_t = output_t\\nTo make these notions absolutely unambigu ous, let’s write a naive Numpy implemen-\\ntation of the forward pass of the simple RNN .\\nimport numpy as np\\ntimesteps = 100\\ninput_features = 32output_features = 64\\ninputs = np.random.random((timesteps, input_features))\\nstate_t = np.zeros((output_features,))W = np.random.random((output_features, input_features))\\nU = np.random.random((output_features, output_features))\\nb = np.random.random((output_features,))\\nsuccessive_outputs = []\\nfor input_t in inputs:\\noutput_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\\nsuccessive_outputs.append(output_t)\\nstate_t = output_t\\nfinal_output_sequence = np.concatenate(successive_outputs, axis=0)\\nEasy enough: in summary, an RNN  is a for loop that reuses quantities computed\\nduring the previous iteration of the loop , nothing more. Of course, there are many\\ndifferent RNN s fitting this definition that you co uld build—this example is one of the\\nsimplest RNN  formulations. RNN s are characterized by their step function, such as the\\nfollowing function in this  case (see figure 6.10):\\noutput_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)Listing 6.20 More detailed pseudocode for the RNN\\nListing 6.21 Numpy implementation of a simple RNN\\nNumber of timesteps in \\nthe input sequenceDimensionality of the \\ninput feature space\\nDimensionality of the \\noutput feature spaceInput data: random \\nnoise for the sake of \\nthe example\\nInitial state: an \\nall-zero vector\\nCreates random \\nweight matrices\\ninput_t is a vector of \\nshape (input_features,).\\nCombines the input with the current \\nstate (the previous output) to obtain \\nthe current outputStores this output in a list\\nUpdates the state of the\\nnetwork for the next timestepThe final output is a 2D tensor of\\nshape (timesteps, output_features).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 219}), Document(page_content='198 CHAPTER  6Deep learning for text and sequences\\nNOTE In this example, the final outp ut is a 2D tensor of shape (timesteps,\\noutput_features) , where each timestep is the output of the loop at time t.\\nEach timestep t in the output tensor contai ns information about timesteps 0\\nto t in the input sequence—about the entire past. For this reason, in many\\ncases, you don’t need this full sequence of outputs; you just need the last out-\\nput (output_t  at the end of the loop), because it already contains informa-\\ntion about the entire sequence.\\n6.2.1 A recurrent layer in Keras\\nThe process you just naively implemented in  Numpy corresponds to an actual Keras\\nlayer—the SimpleRNN  layer:\\nfrom keras.layers import SimpleRNN\\nThere is one minor difference: SimpleRNN  processes batches of sequences, like all other\\nKeras layers, not a single sequence as in th e Numpy example. This means it takes inputs\\nof shape (batch_size,  timesteps,  input_features) , rather than (timesteps,\\ninput_features) .\\n Like all recurrent layers in Keras, SimpleRNN  can be run in two different modes: it\\ncan return either the full sequences of successive outputs fo r each timestep (a 3D ten-\\nsor of shape (batch_size, timesteps, output_features) ) or only the last output for\\neach input sequence (a 2D tensor of shape (batch_size, output_features) ). These\\ntwo modes are cont rolled by the return_sequences  constructor argument. Let’s look\\nat an example that uses SimpleRNN  and returns only the output at the last timestep:\\n>>> from keras.models import Sequential\\n>>> from keras.layers import Embedding, SimpleRNN>>> model = Sequential()\\n>>> model.add(Embedding(10000, 32))\\n>>> model.add(SimpleRNN(32))>>> model.summary()...output t-1 output t output t+1\\ninput t-1 input t input t+1...\\nState t State t+1output_t =\\n activation(  W•input_t +  U•state_t +  bo)\\nFigure 6.10 A simple RNN, unrolled over time\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 220}), Document(page_content='199 Understanding recurrent neural networks\\n________________________________________________________________\\nLayer (type) Output Shape Param #================================================================embedding_22 (Embedding) (None, None, 32) 320000________________________________________________________________\\nsimplernn_10 (SimpleRNN) (None, 32) 2080\\n================================================================Total params: 322,080Trainable params: 322,080Non-trainable params: 0\\nThe following example return s the full state sequence:\\n>>> model = Sequential()\\n>>> model.add(Embedding(10000, 32))>>> model.add(SimpleRNN(32, return_sequences=True))\\n>>> model.summary()\\n________________________________________________________________Layer (type) Output Shape Param #================================================================embedding_23 (Embedding) (None, None, 32) 320000________________________________________________________________\\nsimplernn_11 (SimpleRNN) (None, None, 32) 2080\\n================================================================Total params: 322,080Trainable params: 322,080Non-trainable params: 0\\nIt’s sometimes useful to stack several recu rrent layers one after the other in order to\\nincrease the representational power of a netw ork. In such a setup, you have to get all\\nof the intermediate layers to return full sequence of outputs:\\n>>> model = Sequential()\\n>>> model.add(Embedding(10000, 32))>>> model.add(SimpleRNN(32, return_sequences=True))>>> model.add(SimpleRNN(32, return_sequences=True))>>> model.add(SimpleRNN(32, return_sequences=True))>>> model.add(SimpleRNN(32))\\n>>> model.summary()\\n________________________________________________________________Layer (type) Output Shape Param #================================================================embedding_24 (Embedding) (None, None, 32) 320000________________________________________________________________\\nsimplernn_12 (SimpleRNN) (None, None, 32) 2080\\n________________________________________________________________simplernn_13 (SimpleRNN) (None, None, 32) 2080________________________________________________________________simplernn_14 (SimpleRNN) (None, None, 32) 2080\\n________________________________________________________________\\nsimplernn_15 (SimpleRNN) (None, 32) 2080================================================================Total params: 328,320Trainable params: 328,320Non-trainable params: 0Last layer only returns \\nthe last output\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 221}), Document(page_content=\"200 CHAPTER  6Deep learning for text and sequences\\nNow, let’s use such  a model on the IMDB  movie-review-classifica tion problem. First,\\npreprocess the data.\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing import sequence\\nmax_features = 10000\\nmaxlen = 500\\nbatch_size = 32\\nprint('Loading data...')\\n(input_train, y_train), (input_test, y_test) = imdb.load_data(\\nnum_words=max_features)\\nprint(len(input_train), 'train sequences')\\nprint(len(input_test), 'test sequences')\\nprint('Pad sequences (samples x time)')\\ninput_train = sequence.pad_sequences(input_train, maxlen=maxlen)\\ninput_test = sequence.pad_sequences(input_test, maxlen=maxlen)\\nprint('input_train shape:', input_train.shape)print('input_test shape:', input_test.shape)\\nLet’s train a simple recu rrent network using an Embedding  layer and a SimpleRNN\\nlayer.\\nfrom keras.layers import Dense\\nmodel = Sequential()\\nmodel.add(Embedding(max_features, 32))\\nmodel.add(SimpleRNN(32))model.add(Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\\nhistory = model.fit(input_train, y_train,\\nepochs=10,\\nbatch_size=128,\\nvalidation_split=0.2)\\nNow, let’s display the training and validation loss and accuracy (see figures 6.11 and 6.12).\\nimport matplotlib.pyplot as plt\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']loss = history.history['loss']\\nval_loss = history.history['val_loss']\\nepochs = range(1, len(acc) + 1)plt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')Listing 6.22 Preparing the IMDB data\\nListing 6.23 Training the model with Embedding  and SimpleRNN  layers\\nListing 6.24 Plotting resultsNumber of words to \\nconsider as features\\nCuts off texts after th is many words (among \\nthe max_features most common words)\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 222}), Document(page_content=\"201 Understanding recurrent neural networks\\nplt.title('Training and validation accuracy')\\nplt.legend()\\nplt.figure()plt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')plt.legend()\\nplt.show()\\nAs a reminder, in chapter 3, the first naive approach to this dataset got you to a test\\naccuracy of 88%. Unfortunately, this sma ll recurrent network doesn’t perform well\\ncompared to this baseline (only 85% validat ion accuracy). Part of the problem is that\\nyour inputs only consider the first 500 word s, rather than full sequences—hence, the\\nRNN  has access to less information than the earlier baseline model. The remainder of\\nthe problem is that SimpleRNN  isn’t good at processing lo ng sequences, such as text.\\nFigure 6.11 Training and validation \\nloss on IMDB with SimpleRNN\\nFigure 6.12 Training and validation \\naccuracy on IMDB with SimpleRNN\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 223}), Document(page_content='202 CHAPTER  6Deep learning for text and sequences\\nOther types of recurrent layers perform much better. Let’s l ook at some more-\\nadvanced layers. \\n6.2.2 Understanding the LSTM and GRU layers\\nSimpleRNN  isn’t the only recurrent layer available in Keras. There are two others: LSTM\\nand GRU. In practice, you’ll always use one of these, because SimpleRNN  is generally too\\nsimplistic to be of real use. SimpleRNN  has a major issue: although  it should theoretically\\nbe able to retain at time t information about inputs s een many timesteps before, in\\npractice, such long-term depe ndencies are impossible to learn. This is due to the van-\\nishing gradient problem , an effect that is similar to what is observed with non-recurrent\\nnetworks (feedforward networks) that are many layers deep: as you keep adding layers\\nto a network, the network eventually becomes untrainable. The theoretical reasons for\\nthis effect were studied by Hochreiter, Sc hmidhuber, and Bengio in the early 1990s.2\\nThe LSTM  and GRU layers are designed to solve this problem.\\n Let’s consider the LSTM  layer. The underlying Lo ng Short-Term Memory ( LSTM )\\nalgorithm was developed by Hoch reiter and Schmidhuber in 1997;3 it was the culmi-\\nnation of their research on the vanishing gradient problem.\\n This layer is a variant of the SimpleRNN  layer you already know about; it adds a way\\nto carry information across many timesteps.  Imagine a conveyor belt running parallel\\nto the sequence you’re processing. Informat ion from the sequence can jump onto the\\nconveyor belt at any point, be transported to a later time step, and jump off, intact,\\nwhen you need it. This is essentially what LSTM  does: it saves information for later,\\nthus preventing older signals from gradually vanishing during processing.\\n To understand this in detail, let’s start from the SimpleRNN  cell (see figure 6.13).\\nBecause you’ll have a lot of weight matrices, index the W and U matrices in the cell with\\nthe letter o (Wo and Uo) for output .\\n2See, for example, Yoshua Bengio, Patrice Simard, and Paolo Frasconi, “Learning Long-Term Dependencies\\nwith Gradient Descent Is Difficult,” IEEE Transactions on Neural Networks  5, no. 2 (1994).\\n3Sepp Hochreiter and Jürgen Schmidhuber, “Long Short-Term Memory,” Neural Computation  9, no. 8 (1997)....output t-1 output t output t+1\\ninput t-1 input t input t+1...\\nState t State t+1output_t =\\n activation(  Wo•input_t +  Uo•state_t +  bo)\\nFigure 6.13 The starting point of an LSTM  layer: a SimpleRNN\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 224}), Document(page_content='203 Understanding recurrent neural networks\\nLet’s add to this picture an additional data  flow that carries information across time-\\nsteps. Call its values at different timesteps Ct, where C stands for carry. This informa-\\nt i o n  w i l l  h a v e  t h e  f o l l o w i n g  i m p a c t  o n  t h e  c e l l :  i t  w i l l  b e  c o m b i n e d  w i t h  t h e  i n p u tconnection and the recurrent connection (via  a dense transformation: a dot product\\nwith a weight matrix followed  by a bias add and the applic ation of an activation func-\\ntion), and it will affect the state being sent  to the next timestep (via an activation\\nfunction an a multiplication  operation). Conceptually, th e carry dataflow is a way to\\nmodulate the next output and the next st ate (see figure 6.14). Simple so far.\\nNow the subtlety: the way the next value of the carry dataflow is computed. It involves\\nthree distinct transf ormations. All three have the form of a \\nSimpleRNN  cell:\\ny = activation(dot(state_t, U) + dot(input_t, W) + b)\\nBut all three transformations have their ow n weight matrices, which you’ll index with\\nthe letters i, f, and k. Here’s what you have so far (it may seem a bit arbitrary, but bear\\nwith me).\\noutput_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo)\\ni_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\\nf_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\\nk_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\\nYou obtain the new carry state (the next c_t) by combining i_t, f_t, and k_t.\\nc_t+1 = i_t * k_t + c_t * f_t\\nAdd this as shown in figure 6.15. And that’s it. Not so complicated—merely a tad\\ncomplex.Listing 6.25 Pseudocode details of the LSTM architecture (1/2)\\nListing 6.26 Pseudocode details of the LSTM architecture (2/2)...output t-1 output t output t+1\\ninput t-1 input t input t+1...\\nState t State t+1Carry track c t+1 c t\\nc t c tc t-1\\noutput_t =\\n activation(  Wo•input_t +  Uo•state_t +  Vo•c_t +   bo)\\nFigure 6.14 Going from a SimpleRNN  to an LSTM : adding a carry track\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 225}), Document(page_content='204 CHAPTER  6Deep learning for text and sequences\\n \\nIf you want to get philosophical, you can interpret what each of these operations is\\nmeant to do. For instance, yo u can say that multiplying c_t and f_t is a way to deliber-\\nately forget irrelevant information in the carry dataflow. Meanwhile, i_t and k_t pro-\\nvide information about the present, updat ing the carry track with new information.\\nBut at the end of the day, these interpreta tions don’t mean much, because what these\\noperations actually  do  is  de te rm i ned  b y the  co nte nt s  of  the  we ight s  par ame t er izi ng\\nthem; and the weights are learned in an end- to-end fashion, starting over with each\\ntraining round, making it impossible to credit this or that operation with a specific\\npurpose. The specification of an RNN  cell (as just described) determines your hypoth-\\nesis space—the space in which you’ll sear ch for a good model configuration during\\ntraining—but it doesn’t determine what the cell does; that is up to the cell weights.\\nThe same cell with different weights can be doing very different things. So the combi-\\nnation of operations making up an RNN  cell is better interpreted as a set of constraints\\non your search, not as a design  in an engineering sense.\\n To a researcher, it seems that the choice of such constraints—the question of how to\\nimplement RNN  cells—is better left to optimization algorithms (like genetic algorithms\\nor reinforcement learning processes) than to human engineers. And in the future,\\nthat’s how we’ll build networks. In summary : you don’t need to understand anything\\nabout the specific architecture of an LSTM  cell; as a human, it shouldn’t be your job to\\nunderstand it. Just keep in mind what the LSTM  cell is meant to do: allow past informa-\\ntion to be reinjected at a later time, thus  fighting the vanishing-gradient problem. \\n6.2.3 A concrete LSTM example in Keras\\nNow let’s switch to more practical co ncerns: you’ll set up a model using an LSTM  layer\\nand train it on the IMDB  data (see figures 6.16 and 6.17). The network is similar to the\\none with SimpleRNN  that was just presented. You on ly specify the ou tput dimensional-\\nity of the LSTM  layer; leave every other argument (there are many) at the Keras...output t-1 output t output t+1\\ninput t-1 input t input t+1...\\nState t State t+1Carry track c t+1 c t\\nc t c tc t-1\\noutput_t =\\n activation(  Wo•input_t +  Uo•state_t +  Vo•c_t +   bo)Compute \\nnew \\ncarryCompute \\nnew \\ncarry\\nFigure 6.15 Anatomy of an LSTM\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 226}), Document(page_content=\"205 Understanding recurrent neural networks\\ndefaults. Keras has good defaults, and things will almost always “just work” without you\\nhaving to spend time tuning parameters by hand.\\nfrom keras.layers import LSTM\\nmodel = Sequential()\\nmodel.add(Embedding(max_features, 32))\\nmodel.add(LSTM(32))model.add(Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])\\nhistory = model.fit(input_train, y_train,\\nepochs=10,batch_size=128,\\nvalidation_split=0.2)Listing 6.27 Using the LSTM  layer in Keras\\nFigure 6.16 Training and validation loss on IMDB with LSTM\\nFigure 6.17 Training and validation \\naccuracy on IMDB with LSTM\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 227}), Document(page_content='206 CHAPTER  6Deep learning for text and sequences\\nThis time, you achieve up to 89% validation  accuracy. Not bad: certainly much better\\nthan the SimpleRNN  network—that’s largely because LSTM  suffers much less from the\\nvanishing-gradient problem—and slightly better than the fully connected approach\\nfrom chapter 3, even though you’re looking at less data than you were in chapter 3.You’re truncating sequences after 500 timesteps, whereas in chapter 3, you were con-\\nsidering full sequences.\\n But this result isn’t groundbreaking  for such a computationally intensive\\napproach. Why isn’t \\nLSTM  performing better? One reason is that you made no effort\\nto tune hyperparameters such as th e embeddings dimensionality or the LSTM  output\\ndimensionality. Another may be lack of re gularization. But honestly, the primary rea-\\nson is that analyzing the global, long -term structure of the reviews (what LSTM  is good\\nat) isn’t helpful for a sentiment-analysis pr oblem. Such a basic problem is well solved\\nby looking at what words occur in each revi ew, and at what freque ncy. That’s what the\\nfirst fully connected approach looked at. But there are far more difficult natural-\\nlanguage-processing pr oblems out there, where the strength of LSTM  will become\\napparent: in particular, question-a nswering and machine translation.\\n6.2.4 Wrapping up\\nNow you understand the following:\\n\\uf0a1What RNN s are and how they work\\n\\uf0a1What LSTM  is, and why it works better on long sequences than a naive RNN\\n\\uf0a1How to use Keras RNN  layers to process sequence data\\nNext, we’ll review a number of  more advanced features of RNN s, which can help you\\nget the most out of your de ep-learning sequence models. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 228}), Document(page_content='207 Advanced use of recurrent neural networks\\n6.3 Advanced use of recurrent neural networks\\nIn this section, we’ll revi ew three advanced techniques for improving the perfor-\\nmance and generalization power of recurren t neural networks. By the end of the sec-\\ntion, you’ll know most of what there is to know about using recurrent networks with\\nKeras. We’ll demonstrate all three concep ts on a temperature-forecasting problem,\\nwhere you have access to a timeseries of da ta points coming from  sensors installed on\\nthe roof of a building, such as temperature, air pressure, and humidity, which you use\\nto predict what the temperature will be 24 ho urs after the last data point. This is a\\nfairly challenging problem that exemplifie s many common difficulties encountered\\nwhen working with timeseries.\\n We’ll cover the following techniques:\\n\\uf0a1Recurrent dropout —This is a specific, built-in way to use dropout to fight overfit-\\nting in recurrent layers.\\n\\uf0a1Stacking recurrent layers —This increases the represen tational power of the net-\\nwork (at the cost of higher computational loads).\\n\\uf0a1Bidirectional recurrent layers —These present the same information to a recurrent\\nnetwork in different ways, in creasing accuracy and miti gating forgetting issues.\\n6.3.1 A temperature-forecasting problem\\nUntil now, the only sequence data we’ve covered has been text data, such as the IMDB\\ndataset and the Reuters dataset. But sequence data is found in many more problems\\nthan just language processing. In all the examples in this section, you’ll play with a\\nweather timeseries dataset re corded at the Weather Statio n at the Max Planck Insti-\\ntute for Biogeochemistry in Jena, Germany.4\\n In this dataset, 14 diff erent quantities (such air te mperature, atmospheric pres-\\nsure, humidity, wind direction,  and so on) were recorded every 10 minutes, over sev-\\neral years. The original data  goes back to 2003, but this example is limited to data\\nfrom 2009–2016. This dataset is perfec t for learning to work with numerical\\ntimeseries. You’ll use it to build a model th at takes as input some data from the recent\\npast (a few days’ worth of data points) and predicts the air temperature 24 hours in\\nthe future.\\n Download and uncompress the data as follows:\\ncd ~/Downloads\\nmkdir jena_climate\\ncd jena_climate\\nwget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zipunzip jena_climate_2009_2016.csv.zip\\nLet’s look at the data.\\n4Olaf Kolle, www.bgc-jena.mpg.de/wetter .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 229}), Document(page_content='208 CHAPTER  6Deep learning for text and sequences\\n \\nimport os\\ndata_dir = \\'/users/fchollet/Downloads/jena_climate\\'\\nfname = os.path.join(data_dir, \\'jena_climate_2009_2016.csv\\')\\nf = open(fname)\\ndata = f.read()\\nf.close()\\nlines = data.split(\\'\\\\n\\')\\nheader = lines[0].split(\\',\\')\\nlines = lines[1:]\\nprint(header)\\nprint(len(lines))\\nThis outputs a count of 420,551 lines of data (each line is a timestep: a record of a\\ndate and 14 weather-related values),  as well as the following header:\\n[\"Date Time\",\\n\"p (mbar)\",\"T (degC)\",\"Tpot (K)\",\\n\"Tdew (degC)\",\\n\"rh (%)\",\"VPmax (mbar)\",\\n\"VPact (mbar)\",\\n\"VPdef (mbar)\",\"sh (g/kg)\",\\n\"H2OC (mmol/mol)\",\\n\"rho (g/m**3)\",\"wv (m/s)\",\\n\"max. wv (m/s)\",\\n\"wd (deg)\"]\\nNow, convert all 420,551 lines of data into a Numpy array.\\nimport numpy as np\\nfloat_data = np.zeros((len(lines), len(header) - 1))\\nfor i, line in enumerate(lines):\\nvalues = [float(x) for x in line.split(\\',\\')[1:]]\\nfloat_data[i, :] = values\\nFor instance, here is the plot of temperatur e (in degrees Celsius) over time (see figure\\n6.18). On this plot, you can clearly se e the yearly periodicity of temperature.Listing 6.28 Inspecting the data of the Jena weather dataset\\nListing 6.29 Parsing the data\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 230}), Document(page_content='209 Advanced use of recurrent neural networks\\n \\nfrom matplotlib import pyplot as plt\\ntemp = float_data[:, 1] <1> temperature (in degrees Celsius)\\nplt.plot(range(len(temp)), temp)\\nHere is a more narrow plot of the first 10 days of temperature data (see figure 6.19).\\nBecause the data is recorded every 10 minutes, you get 144 data points per day.\\nplt.plot(range(1440), temp[:1440])Listing 6.30 Plotting the temperature timeseries\\nListing 6.31 Plotting the first 10 days of the temperature timeseries\\nFigure 6.18 Temperature \\nover the full temporal range of \\nthe dataset (ºC)\\nFigure 6.19 Temperature \\nover the first 10 days of the dataset (ºC)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 231}), Document(page_content='210 CHAPTER  6Deep learning for text and sequences\\nOn this plot, you can see daily periodicity, especially evident for the last 4 days. Also\\nnote that this 10-day period must be coming from a fairly cold winter month.\\n If you were trying to predict average temperature for the next month given a few\\nmonths of past data, the problem would be ea sy, due to the reliable year-scale period-\\nicity of the data. But looking at the data ov er a scale of days, the temperature looks a\\nlot more chaotic. Is this timeseries pred ictable at a daily scale? Let’s find out.\\n6.3.2 Preparing the data\\nThe exact formulation of the problem will be as follows: given data going as far back\\nas lookback  timesteps (a timestep is 10  minutes) and sampled every steps  timesteps,\\ncan you predict the temperature in delay  timesteps? You’ll use the following parame-\\nter values:\\n\\uf0a1lookback = 720 —Observations will go back 5 days.\\n\\uf0a1steps = 6 —Observations will be sampled at one data point per hour.\\n\\uf0a1delay = 144 —Targets will be 24 hours in the future.\\nTo get started, you need to do two things:\\n\\uf0a1Preprocess the data to a format a neural  network can ingest. This is easy: the\\ndata is already numerical, so you don’t need to do any vect orization. But each\\ntimeseries in the data is on a different scale (for example, temperature is typi-\\ncally between -20 and +30, but atmosphe ric pressure, measured in mbar, is\\naround 1,000). You’ll normalize each time series independently so that they all\\ntake small values on a similar scale.\\n\\uf0a1Write a Python generator that takes the current array of float data and yieldsbatches of data from the recent past, along with a target temperature in the\\nfuture. Because the sample s in the dataset are highly redundant (sample N and\\nsample N + 1 will have most of their timest eps in common) , it would be wasteful\\nto explicitly allocate every sample. Inst ead, you’ll generate the samples on the\\nfly using the original data.\\nYou’ll preprocess the data by subtracting the mean of each timese ries and dividing by\\nthe standard deviation. You’re going to use the first 200,000 timesteps as training data,\\nso compute the mean and standard deviatio n only on this fraction of the data.\\nmean = float_data[:200000].mean(axis=0)\\nfloat_data -= mean\\nstd = float_data[:200000].std(axis=0)\\nfloat_data /= std\\nListing 6.33 shows the data generato r you’ll use. It yields a tuple (samples,  targets) ,\\nwhere samples  is one batch of input data and targets  is the corresponding array of\\ntarget temperatures. It ta kes the following arguments:Listing 6.32 Normalizing the data\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 232}), Document(page_content='211 Advanced use of recurrent neural networks\\n\\uf0a1data —The original array of floa ting-point data, which you normalized in listing 6.32.\\n\\uf0a1lookback —How many timesteps back the input data should go.\\n\\uf0a1delay —How many timesteps in the fu ture the target should be.\\n\\uf0a1min_index  and max_index —Indices in the data  array that delimit which time-\\nsteps to draw from. This is useful for keeping a segment of the data for valida-\\ntion and another for testing.\\n\\uf0a1shuffle —Whether to shuffle the samples or draw them in chronological order.\\n\\uf0a1batch_size —The number of samples per batch.\\n\\uf0a1step —The period, in timesteps, at which yo u sample data. You’ ll set it to 6 in\\norder to draw one data point every hour.\\ndef generator(data, lookback, delay, min_index, max_index,\\nshuffle=False, batch_size=128, step=6):\\nif max_index is None:\\nmax_index = len(data) - delay - 1\\ni = min_index + lookback\\nwhile 1:\\nif shuffle:\\nrows = np.random.randint(\\nmin_index + lookback, max_index, size=batch_size)\\nelse:\\nif i + batch_size >= max_index:\\ni = min_index + lookback\\nrows = np.arange(i, min(i + batch_size, max_index))i += len(rows)\\nsamples = np.zeros((len(rows),\\nlookback // step,data.shape[-1]))\\ntargets = np.zeros((len(rows),))\\nfor j, row in enumerate(rows):\\nindices = range(rows[j] - lookback, rows[j], step)\\nsamples[j] = data[indices]\\ntargets[j] = data[rows[j] + delay][1]\\nyield samples, targets\\nNow, let’s use the abstract generator  function to instantiate three generators: one for\\ntraining, one for validation, and one for test ing. Each will look at different temporal\\nsegments of the original data: the training  generator looks at the first 200,000 time-\\nsteps, the validation generator looks at th e following 100,000, and the test generator\\nlooks at the remainder.\\nlookback = 1440\\nstep = 6\\ndelay = 144\\nbatch_size = 128Listing 6.33 Generator yielding timeseries samples and their targets\\nListing 6.34 Preparing the training, validation, and test generators\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 233}), Document(page_content='212 CHAPTER  6Deep learning for text and sequences\\ntrain_gen = generator(float_data,\\nlookback=lookback,\\ndelay=delay,min_index=0,\\nmax_index=200000,\\nshuffle=True,step=step,\\nbatch_size=batch_size)\\nval_gen = generator(float_data,\\nlookback=lookback,\\ndelay=delay,\\nmin_index=200001,max_index=300000,\\nstep=step,\\nbatch_size=batch_size)\\ntest_gen = generator(float_data,\\nlookback=lookback,\\ndelay=delay,min_index=300001,\\nmax_index=None,\\nstep=step,batch_size=batch_size)\\nval_steps = (300000 - 200001 - lookback)\\ntest_steps = (len(float_data) - 300001 - lookback)\\n6.3.3 A common-sense, non-machine-learning baseline\\nBefore you start using black-box deep-learning models to solve the temperature-\\nprediction problem, let’s try a simple, common-sense approach. It will serve as a sanity\\ncheck, and it will establish a baseline that you’ll have to beat in  order to demonstrate\\nthe usefulness of more-advanced machine-le arning models. Such common-sense base-\\nlines can be useful when you’re approa ching a new problem for which there is no\\nknown solution (yet). A classic example is that of unbalanced classification tasks,\\nwhere some classes are much more common th an others. If your dataset contains 90%\\ninstances of class A and 10% instances of class B, then a common-sense approach to\\nthe classification task is to  always predict “A” when pres ented with a new sample. Such\\na classifier is 90% accurate overall, and an y learning-based approach should therefore\\nbeat this 90% score in order to demonstr ate usefulness. Sometimes, such elementary\\nbaselines can prove surpri singly hard to beat.\\n In this case, the temperature timeseries  can safely be assumed to be continuous\\n(the temperatures tomorrow are likely to be  close to the temperatures today) as well\\nas periodical with a daily period. Thus a common-sense approach is to always predict\\nthat the temperature 24 hours from now wi ll be equal to the temperature right now.\\nLet’s evaluate this approach, using the mean absolute error ( MAE) metric:\\nnp.mean(np.abs(preds - targets))How many steps to draw from \\nval_gen in order to see the \\nentire validation set\\nHow many steps to draw \\nfrom test_gen in order to see the entire test set \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 234}), Document(page_content=\"213 Advanced use of recurrent neural networks\\nHere’s the evaluation loop.\\ndef evaluate_naive_method():\\nbatch_maes = []\\nfor step in range(val_steps):\\nsamples, targets = next(val_gen)\\npreds = samples[:, -1, 1]\\nmae = np.mean(np.abs(preds - targets))batch_maes.append(mae)\\nprint(np.mean(batch_maes))\\nevaluate_naive_method()\\nThis yields an MAE  of 0.29. Because the temperature data has been normalized to be\\ncentered on 0 and have a standard deviation of 1, this number is n’t immediately inter-\\npretable. It translates to an av erage absolute error of 0.29 × temperature_std  degrees\\nCelsius: 2.57˚C.\\ncelsius_mae = 0.29 * std[1]\\nThat’s a fairly large average absolute error.  Now the game is to use your knowledge of\\ndeep learning to do better. \\n6.3.4 A basic machine-learning approach\\nIn the same way that it’s useful to establish a common-sense baseline before trying\\nmachine-learning approaches, it’s useful to try simple, cheap machine-learning mod-\\nels (such as small, densely connected networ ks) before looking into complicated and\\ncomputationally expensive models such as RNN s. This is the best way to make sure any\\nfurther complexity you throw at the problem is legitimate and delivers real benefits.\\n The following listing shows a fully connec ted model that starts by flattening the\\ndata and then runs it through two Dense  layers. Note the lack of  activation function on\\nthe last Dense  layer, which is typical for a regression problem. You use MAE as the loss.\\nBecause you evaluate on the exact same data  and with the exact same metric you did\\nwith the common-sense approach, the re sults will be directly comparable.\\nfrom keras.models import Sequential\\nfrom keras import layersfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))model.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(1))Listing 6.35 Computing the common-sense baseline MAE\\nListing 6.36 Converting the MAE back to a Celsius error\\nListing 6.37 Training and evaluating a densely connected model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 235}), Document(page_content=\"214 CHAPTER  6Deep learning for text and sequences\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,epochs=20,\\nvalidation_data=val_gen,\\nvalidation_steps=val_steps)\\nLet’s display the loss curves  for validation and training (see figure 6.20).\\nimport matplotlib.pyplot as plt\\nloss = history.history['loss']\\nval_loss = history.history['val_loss']\\nepochs = range(1, len(loss) + 1)\\nplt.figure()\\nplt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')\\nplt.legend()\\nplt.show()\\nSome of the validation losses are close to the no-learning baseline, but not reliably.\\nThis goes to show the merit of having this baseline in the first place: it turns out to be\\nnot easy to outperform. Your common sens e contains a lot of valuable information\\nthat a machine-learning model doesn’t have access to.\\n You may wonder, if a simple , well-performing model exists to go from the data to\\nthe targets (the common-sense baseline), why doesn’t the model you’re training find it\\nand improve on it? Because this simple soluti on isn’t what your training setup is look-\\ning for. The space of models in which yo u’re searching for a solution—that is, your\\nhypothesis space—is the space of all possibl e two-layer networks with the configuration\\nyou defined. These networks are already fair ly complicated. When you’re looking for aListing 6.38 Plotting results\\nFigure 6.20 Training and validation \\nloss on the Jena temperature- \\nforecasting task with a simple, densely connected network\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 236}), Document(page_content=\"215 Advanced use of recurrent neural networks\\nsolution with a space of complicated models , the simple, well-performing baseline may\\nbe unlearnable, even if it’s technically part of the hypothesis space. That is a pretty sig-\\nnificant limitation of machine learning in  general: unless the learning algorithm is\\nhardcoded to look for a specif ic kind of simple model, parameter learning can some-\\ntimes fail to find a simple so lution to a simple problem. \\n6.3.5 A first recurrent baseline\\nThe first fully connected approach didn’t do well, but that doesn’t mean machine\\nlearning isn’t applicable to this problem.  The previous approach first flattened the\\ntimeseries, which removed the notion of ti me from the input data. Let’s instead look\\nat the data as what it is: a sequence, where causality and order matter. You’ll try a\\nrecurrent-sequence processing  model—it should be the pe rfect fit for such sequence\\ndata, precisely because it exploits the temporal  ordering of data points, unlike the first\\napproach.\\n Instead of the LSTM  layer introduced in the previous section, you’ll use the GRU\\nlayer, developed by Chung et al. in 2014.5 Gated recurrent unit ( GRU ) layers work\\nusing the same principle as LSTM , but they’re somewhat  streamlined and thus\\ncheaper to run (although they may not ha ve as much representational power as\\nLSTM ). This trade-off between computatio nal expensiveness and representational\\npower is seen everywhere  in machine learning.\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.Dense(1))\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,epochs=20,\\nvalidation_data=val_gen,\\nvalidation_steps=val_steps)\\nFigure 6.21 shows the results.  Much better! You can significantly beat the common-\\nsense baseline, demonstrating the value of machine learning as well as the superiority\\nof recurrent networks compared to sequen ce-flattening dense networks on this type\\nof task.\\n5Junyoung Chung et al., “Empirical Evaluation of Gate d Recurrent Neural Networks  on Sequence Modeling,”\\nConference on Neural Informat ion Processing Systems (2014), https:/ /arxiv.org/abs/1412.3555 .Listing 6.39 Training and evaluating a GRU-based model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 237}), Document(page_content='216 CHAPTER  6Deep learning for text and sequences\\n \\nThe new validation MAE of ~0.265 (before you start sign ificantly overfi tting) translates\\nto a mean absolute error of 2.35˚C after de normalization. That’s a solid gain on the\\ninitial error of 2.57˚C, but you probably stil l have a bit of a margin for improvement. \\n6.3.6 Using recurrent dropout to fight overfitting\\nIt’s evident from the training and validation  curves that the model is overfitting: the\\ntraining and validation losses start to diverge considerably after a few epochs. You’re\\nalready familiar with a classic techniqu e for fighting this phenomenon: dropout,\\nwhich randomly zeros out input units of a layer in order to break happenstance cor-\\nrelations in the training data that the laye r is exposed to. But how to correctly apply\\ndropout in recurrent networks  isn’t a trivial question. It has long been known that\\napplying dropout before a recurrent layer hinders learning rather than helping with\\nregularization. In 2015, Yarin Gal, as part of his PhD thesis on Bayesian deep learn-\\ning,6 determined the proper way to use drop out with a recurrent network: the same\\ndropout mask (the same pattern of dropped units) should be applied at every time-step, instead of a dropout ma sk that varies randomly fr om timestep to timestep.\\nWhat’s more, in order to regularize the re presentations formed by  the recurrent gates\\nof layers such as \\nGRU and LSTM , a temporally constant drop out mask should be applied\\nto the inner recurrent activations of the layer (a recurrent  dropout mask). Using the\\nsame dropout mask at every timestep allo ws the network to pr operly propagate its\\nlearning error through time; a temporally  random dropout mask would disrupt this\\nerror signal and be harmfu l to the learning process.\\n Yarin Gal did his research using Keras and helped build this mechanism directly\\ninto Keras recurrent layers. Every recurrent layer in Keras has two dropout-relatedarguments: \\ndropout , a float specifying th e dropout rate for input units of the layer,\\n6See Yarin Gal, “Uncertainty in Deep Le arning (PhD Thesis),” October 13, 2016, http:/ /mlg.eng.cam.ac.uk/\\nyarin/blog_2248.html .\\nFigure 6.21 Training and validation \\nloss on the Jena temperature-forecasting task with a GRU\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 238}), Document(page_content=\"217 Advanced use of recurrent neural networks\\nand recurrent_dropout , specifying the dropout rate of the recurrent units. Let’s add\\ndropout and recurren t dropout to the GRU layer and see how doing so impacts overfit-\\nting. Because networks being regularized with  dropout always take longer to fully con-\\nverge, you’ll train the networ k for twice as many epochs.\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.GRU(32,\\ndropout=0.2,recurrent_dropout=0.2,\\ninput_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.Dense(1))\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,epochs=40,validation_data=val_gen,\\nvalidation_steps=val_steps)\\nFigure 6.22 shows the results. Success! You’re no long er overfitting during the first 30\\nepochs. But although you have more stable evaluation scores, your best scores aren’t\\nmuch lower than they were previously.   \\n6.3.7 Stacking recurrent layers\\nBecause you’re no longer overfitting but seem to have hit a performance bottleneck,\\nyou should consider increasing the capacity  of the network. Recall the description of\\nthe universal machine-learning workflow: it’s  generally a good idea to increase the\\ncapacity of your network until overfitt ing becomes the primary obstacle (assumingListing 6.40 Training and evaluating a dropout-regularized GRU-based model\\nFigure 6.22 Training and validation \\nloss on the Jena temperature-\\nforecasting task with a dropout-regularized GRU\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 239}), Document(page_content=\"218 CHAPTER  6Deep learning for text and sequences\\nyou’re already taking basic steps to mitiga te overfitting, such as using dropout). As\\nlong as you aren’t overfitting too badly, you’re likely under capacity.\\n Increasing network capacity is typically done by increasing the number of units in\\nt h e  l a y e r s  o r  a d d i n g  m o r e  l a y e r s .  R e c u r r e n t layer stacking is a classic way to build\\nmore-powerful recurrent networks: for inst ance, what currently powers the Google\\nTranslate algorithm is a stack of seven large LSTM  layers—that’s huge.\\n To stack recurrent layers on top of each  other in Keras, all intermediate layers\\nshould return their full sequence of outputs (a 3D tensor) rather than their output at\\nthe last timestep. This is done by specifying return_sequences=True .\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.GRU(32,\\ndropout=0.1,\\nrecurrent_dropout=0.5,\\nreturn_sequences=True,input_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.GRU(64, activation='relu',\\ndropout=0.1,recurrent_dropout=0.5))\\nmodel.add(layers.Dense(1))\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,\\nepochs=40,validation_data=val_gen,\\nvalidation_steps=val_steps)\\nFigure 6.23 shows th e results. You can see that the added layer does improve the\\nresults a bit, though not significan tly. You can draw two conclusions:\\n\\uf0a1Because you’re still not overfitting too badly, you could safely increase the size of\\nyour layers in a quest for validation-lo ss improvement. This has a non-negligible\\ncomputational cost, though.\\n\\uf0a1Adding a layer didn’t help by a significan t factor, so you may be seeing diminish-\\ning returns from increasing network capacity at this point.Listing 6.41 Training and evaluating a dropout-regularized, stacked GRU model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 240}), Document(page_content='219 Advanced use of recurrent neural networks\\n   \\n6.3.8 Using bidirectional RNNs\\nThe last technique introduced in this section is called bidirectional RNNs. A bidirec-\\ntional RNN  is a common RNN  variant that can offer grea ter performance than a regu-\\nlar RNN  on certain tasks. It’s frequently us ed in natural-language processing—you\\ncould call it the Swiss Army knife of deep  learning for natural- language processing.\\n RNN s are notably order dependent, or time dependent: they process the timesteps\\nof their input sequences in order, and sh uffling or reversing the timesteps can com-\\npletely change the representations the RNN  extracts from the sequence. This is pre-\\ncisely the reason they perform well on problems where order is  meaningful, such as\\nthe temperature-forecasting problem. A bidirectional RNN  exploits the order sensitiv-\\nity of RNN s :  i t  c o n s i s t s  o f  u s i n g  t w o  r e g u l a r  RNN s ,  s u c h  a s  t h e  GRU and LSTM  layers\\nyou’re already familiar with, each of which processes the input sequence in one direc-\\ntion (chronologically and an tichronologically), and then merging their representa-\\ntions. By processing a sequen ce both ways, a bidirectional RNN  can catch patterns that\\nmay be overlooked by a unidirectional RNN .\\n Remarkably, the fact that the RNN layers in this section have processed sequences in\\nchronological order (older timesteps first) ma y have been an arbitrary decision. At least,\\nit’s a decision we made no attempt to question so far. Could the RNNs have performed\\nwell enough if they processed input sequence s in antichronological order, for instance\\n(newer timesteps first)? Let’s try this in pr actice and see what happens. All you need to\\ndo is write a variant of the data generator where the input sequences are reverted along\\nthe time dimension (replace the last line with yield samples[:, ::-1, :],  targets ).\\nTraining the same one- GRU-layer network that you used in the first experiment in this\\nsection, you get the result s shown in figure 6.24.\\nFigure 6.23 Training and validation \\nloss on the Jena temperature-\\nforecasting task with a stacked GRU network\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 241}), Document(page_content=\"220 CHAPTER  6Deep learning for text and sequences\\n \\nThe reversed-order GRU  strongly underper forms even the common-sense baseline,\\nindicating that in this case, chronological pr ocessing is important to the success of your\\napproach. This makes perfect sense: the underlying GRU layer will typically be better at\\nremembering the recent past than the di stant past, and naturally the more recent\\nweather data points are more predictive than  older data points for the problem (that’s\\nwhat makes the common-sense baseline fairly  strong). Thus the chronological version\\nof the layer is bound to outperform the reve rsed-order version. Importantly, this isn’t\\ntrue for many other problems, including na tural language: intuitively, the importance\\nof a word in understanding a sentence isn’t usually dependent on its position in the sen-\\ntence. Let’s try the same trick on the LSTM  IMDB  example from section 6.2.\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing import sequence\\nfrom keras import layersfrom keras.models import Sequential\\nmax_features = 10000\\nmaxlen = 500\\n(x_train, y_train), (x_test, y_test) = imdb.load_data(\\nnum_words=max_features)\\nx_train = [x[::-1] for x in x_train]\\nx_test = [x[::-1] for x in x_test]\\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\\nmodel = Sequential()\\nmodel.add(layers.Embedding(max_features, 128))\\nmodel.add(layers.LSTM(32))model.add(layers.Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])Listing 6.42 Training and evaluating an LSTM  using reversed sequences\\nFigure 6.24 Training and validation \\nloss on the Jena temperature-\\nforecasting task with a GRU trained on reversed sequences\\nNumber of words \\nto consider as featuresCuts off texts after this \\nnumber of words (among \\nthe max_features most common words)\\nLoads\\ndata Reverses \\nsequences\\nPads \\nsequences\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 242}), Document(page_content=\"221 Advanced use of recurrent neural networks\\nhistory = model.fit(x_train, y_train,\\nepochs=10,\\nbatch_size=128,validation_split=0.2)\\nYou get performance nearly identical to that of the chronological-order LSTM .\\nRemarkably, on such a text dataset, revers ed-order processing works just as well as\\nchronological processing, confirming the hypothesis that, although word order does\\nmatter in understanding language, which  order you use isn’t crucial. Importantly, an\\nRNN  trained on reversed sequences will le arn different representations than one\\ntrained on the original sequen ces, much as you would have different mental models if\\ntime flowed backward in the real world—if you lived a life where you died on your firstday and were born on your last day. In machine learning, representations that are dif-\\nferent  yet useful  are always worth exploiting, and th e more they differ, the better: they\\noffer a new angle from which to  look at your data, capturing aspects of the data that\\nwere missed by other approaches, and thus  they can help boost performance on a\\ntask. This is the intuition behind ensembling , a concept we’ll explore in chapter 7.\\n A bidirectional \\nRNN exploits this idea to improve on  the performance of chronological-\\norder RNN s. It looks at its input sequence both ways (see figure 6.25), obtaining poten-\\ntially richer representations and capturing patterns that may have been missed by the\\nchronological-order version alone.\\nTo instantiate a bidirectional RNN in Keras, you use the Bidirectional  layer, which takes\\nas its first argument a recurrent laye r instance. Bidirectional  creates a second, separate\\ninstance of this recurrent layer and uses on e instance for processing the input sequences\\nin chronological order and the other instan ce for processing the input sequences in\\nreversed order. Let’s try it on the IMDB  sentiment-analysis task.\\nmodel = Sequential()\\nmodel.add(layers.Embedding(max_features, 32))model.add(layers.Bidirectional(layers.LSTM(32)))\\nmodel.add(layers.Dense(1, activation='sigmoid'))Listing 6.43 Training and evaluating a bidirectional LSTMChronological\\nsequenceReversed\\nsequenceMerge (add,\\nconcatenate)Input data\\na, b, c, d, e\\na, b, c, d, ee, d, c, b, aRNN RNN\\nFigure 6.25 How a \\nbidirectional RNN layer works\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 243}), Document(page_content=\"222 CHAPTER  6Deep learning for text and sequences\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\\nhistory = model.fit(x_train, y_train,\\nepochs=10,batch_size=128,\\nvalidation_split=0.2)\\nIt performs slightly better than the regular LSTM  you tried in the previous section,\\nachieving over 89% validation accuracy. It al so seems to overfit more quickly, which is\\nunsurprising because a bidirectional layer ha s twice as many parameters as a chrono-\\nlogical LSTM . With some regularization, the bidi rectional approach would likely be a\\nstrong performer on this task.\\n Now let’s try the same approach on  the temperature-prediction task.\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.Bidirectional(\\nlayers.GRU(32), input_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.Dense(1))\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,\\nepochs=40,validation_data=val_gen,\\nvalidation_steps=val_steps)\\nThis performs about as well as the regular GRU layer. It’s easy to understand why: all the\\npredictive capacity must come from the chro nological half of the network, because the\\nantichronological half is known to be seve rely underperforming on this task (again,\\nbecause the recent past matters much more  than the distant past in this case). \\n6.3.9 Going even further\\nThere are many other things you could try,  in order to improve performance on the\\ntemperature-forecasting problem:\\n\\uf0a1Adjust the number of units in each re current layer in the stacked setup. The\\ncurrent choices are largely arbitr ary and thus probably suboptimal.\\n\\uf0a1Adjust the learning rate used by the RMSprop  optimizer.\\n\\uf0a1Try using LSTM  layers instead of GRU layers.\\n\\uf0a1Try using a bigger densely connected regr essor on top of the recurrent layers:\\nthat is, a bigger Dense  layer or even a stack of Dense  layers.\\n\\uf0a1Don’t forget to eventually run the best -performing models (in terms of valida-\\ntion MAE) on the test set! Otherwise, you’ll develop architectures that are over-\\nfitting to the validation set.Listing 6.44 Training a bidirectional GRU\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 244}), Document(page_content='223 Advanced use of recurrent neural networks\\nAs always, deep learning is more an art th an a science. We can provide guidelines that\\nsuggest what is likely to work or not work on a given problem, but, ultimately, every\\nproblem is unique; you’ll have to evaluate  different strategies empirically. There is\\ncurrently no theory that will tell you in adva nce precisely what you should do to opti-\\nmally solve a problem . You must iterate.\\n6.3.10 Wrapping up\\nHere’s what you should take away from this section:\\n\\uf0a1As you first learned in chapter 4, when approaching a new problem, it’s good to\\nfirst establish common-sense baselines for your metric of choice. If you don’t\\nhave a baseline to beat, you can’t tell  whether you’re making real progress.\\n\\uf0a1Try simple models before expensive on es, to justify the additional expense.\\nSometimes a simple mode l will turn out to be your best option.\\n\\uf0a1When you have data where temporal or dering matters, recurrent networks are\\na great fit and easily outperform models that first flatten the temporal data.\\n\\uf0a1To use dropout with recurrent networks , you should use a time-constant drop-\\nout mask and recurrent dropout mask. Th ese are built into Keras recurrent lay-\\ners, so all you have to do is use the dropout  and recurrent_dropout  arguments\\nof recurrent layers.\\n\\uf0a1Stacked RNN s provide more representational power than a single RNN  layer.\\nThey’re also much more expensive and th us not always worth it. Although they\\noffer clear gains on comple x problems (such as machine translation), they may\\nnot always be relevant to  smaller, simpler problems.\\n\\uf0a1Bidirectional RNN s, which look at a sequence bo th ways, are useful on natural-\\nlanguage processing problems. But they aren’t strong performers on sequence\\ndata where the recent past is much more  informative than the beginning of the\\nsequence.\\nNOTE There are two important concepts we  won’t cover in detail here: recur-\\nrent attention and sequence masking. Both tend to be especially relevant fornatural-language processing, and they ar en’t particularly applicable to the\\ntemperature-forecasting problem. We’ll leave them for future study outside of\\nthis book.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 245}), Document(page_content='224 CHAPTER  6Deep learning for text and sequences\\nMarkets and machine learning\\nSome readers are bound to want to take the techniques we’ve introduced here and\\ntry them on the problem of forecasting the fu ture price of securities on the stock mar-\\nket (or currency exchange rate s, and so on). Markets have very different statistical\\ncharacteristics  than natural phenomena such as weather patterns. Trying to use\\nmachine learning to beat markets, when you only have access to publicly available\\ndata, is a difficult endeavor, and you’re lik ely to waste your time and resources with\\nnothing to show for it.\\nAlways remember that when it comes to markets, past performance is not a good\\npredictor of future returns— looking in the rear-view mirr or is a bad way to drive.\\nMachine learning, on the other hand, is applicable to datasets where the past is a\\ngood predictor of the future. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 246}), Document(page_content='225 Sequence processing with convnets\\n6.4 Sequence processing with convnets\\nIn chapter 5, you learned about convolutio nal neural networks (convnets) and how\\nthey perform particularly well on computer vision problems, due to their ability tooperate convolutionally , extracting features from loca l input patches and allowing for\\nrepresentation modularity and data efficiency. The same properties that make conv-\\nnets excel at computer vision  also make them highly rele vant to sequen ce processing.\\nTime can be treated as a spatial dimension, like the height or width of a \\n2D image.\\n Such 1D convnets can be competitive with RNN s on certain se quence-processing\\nproblems, usually at a considerably cheaper computational cost. Recently, 1D conv-\\nnets, typically used with dilated kernels, ha ve been used with great success for audio\\ngeneration and machine translation. In additi on to these specific successes, it has long\\nbeen known that small 1D convnets can offer a fast alternative to RNN s for simple tasks\\nsuch as text classification and timeseries forecasting.\\n6.4.1 Understanding 1D convolution for sequence data\\nThe convolution layers introduced previously were 2D convolutions, extracting 2D\\npatches from image tensors and applying an  identical transforma tion to every patch.\\nIn the same way, you can use 1D convolutions, extracting local 1D patches (subse-\\nquences) from sequences (see figure 6.26).\\nSuch 1D convolution layers can recognize local patterns in a sequence. Because the\\nsame input transformation is performed on every patch, a pattern learned at a certain\\nposition in a sentence can later be recognized at a different position, making 1D conv-\\nnets translation invariant (for temp oral translations). For instance, a 1D convnet pro-\\ncessing sequences of characters using convol ution windows of size 5 should be able to\\nlearn words or word fragments of length 5 or less, and it should be able to recognizeInput\\nfeaturesInput\\nOutputExtracted\\npatchWindow of\\nsize 5\\nDot product\\nwith weights\\nOutput featuresTime\\nFigure 6.26 How 1D convolution \\nworks: each output timestep is \\nobtained from a temporal patch in the input sequence.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 247}), Document(page_content=\"226 CHAPTER  6Deep learning for text and sequences\\nthese words in any context in an input sequence. A character-level 1D convnet is thus\\nable to learn about word morphology. \\n6.4.2 1D pooling for sequence data\\nYou’re already familiar with 2D pooling operations, such as 2D average pooling and\\nmax pooling, used in convnets to sp atially downsample image tensors. The 2D pooling\\noperation has a 1D equivalent: extracting 1D patches (subsequences) from an input\\nand outputting the maximum value (max poo ling) or average value (average pooling).\\nJust as with 2D convnets, this is used for reducing the length of 1D inputs ( subsampling ). \\n6.4.3 Implementing a 1D convnet\\nIn Keras, you use a 1D convnet via the Conv1D  layer, which has an interface similar to\\nConv2D . It takes as input 3D tensors with shape (samples,  time,  features)  and\\nreturns similarly shaped 3D tensors. The convolution window is a 1D window on the\\ntemporal axis: axis 1 in the input tensor.\\n Let’s build a simple two-layer 1D convnet and apply it to the IMDB  sentiment-\\nclassification task you’re al ready familiar with. As a reminder, this is the code for\\nobtaining and prepro cessing the data.\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing import sequence\\nmax_features = 10000\\nmax_len = 500\\nprint('Loading data...')\\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\\nprint(len(x_train), 'train sequences')\\nprint(len(x_test), 'test sequences')\\nprint('Pad sequences (samples x time)')\\nx_train = sequence.pad_sequences(x_train, maxlen=max_len)\\nx_test = sequence.pad_sequences(x_test, maxlen=max_len)print('x_train shape:', x_train.shape)\\nprint('x_test shape:', x_test.shape)\\n1D convnets are stru ctured in the same way as their 2D counterparts, which you used\\nin chapter 5: they consist of a stack of Conv1D  and MaxPooling1D  layers, ending in\\neither a global pooling layer or a Flatten  layer, that turn the 3D outputs into 2D out-\\nputs, allowing you to add one or more Dense  layers to the model for classification or\\nregression.\\n One difference, though, is the fact that you can afford to use larger convolution\\nwindows with 1D convnets. With a 2D convolution layer, a 3 × 3 convolution window\\ncontains 3 × 3 = 9 feature vectors; but with a 1D convolution layer, a convolution win-\\ndow of size 3 contains only 3 feature vectors. You can thus easily afford 1D convolution\\nwindows of size 7 or 9.Listing 6.45 Preparing the IMDB data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 248}), Document(page_content=\"227 Sequence processing with convnets\\n This is the example 1D convnet for the IMDB  dataset.\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.Embedding(max_features, 128, input_length=max_len))\\nmodel.add(layers.Conv1D(32, 7, activation='relu'))model.add(layers.MaxPooling1D(5))\\nmodel.add(layers.Conv1D(32, 7, activation='relu'))\\nmodel.add(layers.GlobalMaxPooling1D())model.add(layers.Dense(1))\\nmodel.summary()\\nmodel.compile(optimizer=RMSprop(lr=1e-4),\\nloss='binary_crossentropy',\\nmetrics=['acc'])\\nhistory = model.fit(x_train, y_train,\\nepochs=10,batch_size=128,\\nvalidation_split=0.2)\\nFigures 6.27 and 6.28 show the training and validation results. Validation accuracy is\\nsomewhat less than that of the LSTM , but runtime is faster on both CPU and GPU (the\\nexact increase in speed will vary greatly de pending on your exact configuration). At this\\npoint, you could retrain this model for the right number of epoc hs (eight) and run it\\non the test set. This is a convincing demonstration that a 1D convnet can offer a fast,\\ncheap alternative to a recurren t network on a word-level sent iment-classification task.  Listing 6.46 Training and evaluating a simple 1D convnet on the IMDB data\\nFigure 6.27 Training and \\nvalidation loss on IMDB with a \\nsimple 1D convnet\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 249}), Document(page_content=\"228 CHAPTER  6Deep learning for text and sequences\\n6.4.4 Combining CNNs and RNNs to process long sequences\\nBecause 1D convnets process input patches independ ently, they aren’t sensitive to the\\norder of the timesteps (beyond a local scal e, the size of the convolution windows),\\nunlike RNN s. Of course, to recogn ize longer-term patterns, you can stack many convo-\\nlution layers and pooling layers, resulting in  upper layers that will see long chunks of\\nthe original inputs—but that’s still a fairly  weak way to induce order sensitivity. One\\nway to evidence this weakness is to try 1D convnets on the temperature-forecasting\\nproblem, where order-sensitivity is key to producing good predictions. The following\\nexample reuses the following variables defined previously: float_data , train_gen ,\\nval_gen , and val_steps .\\nfrom keras.models import Sequential\\nfrom keras import layersfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.Conv1D(32, 5, activation='relu',\\ninput_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.MaxPooling1D(3))\\nmodel.add(layers.Conv1D(32, 5, activation='relu'))model.add(layers.MaxPooling1D(3))\\nmodel.add(layers.Conv1D(32, 5, activation='relu'))\\nmodel.add(layers.GlobalMaxPooling1D())model.add(layers.Dense(1))\\nmodel.compile(optimizer=RMSprop(), loss='mae')\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,\\nepochs=20,\\nvalidation_data=val_gen,validation_steps=val_steps)Listing 6.47 Training and evaluating a simple 1D convnet on the Jena data\\nFigure 6.28 Training and validation accuracy on IMDB \\nwith a simple 1D convnet\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 250}), Document(page_content='229 Sequence processing with convnets\\nFigure 6.29 shows the training and validation MAE s.\\nThe validation MAE stays in the 0.40s: you can’t ev en beat the common-sense baseline\\nusing the small convnet. Again, this is because the convnet looks for patterns any-where in the input timeseries and has no kn owledge of the temporal position of a pat-\\ntern it sees (toward the beginning, toward the end, and so on). Because more recent\\ndata points should be interpreted differently from older data points in the case of this\\nspecific forecasting problem,  the convnet fails at produc ing meaningful results. This\\nlimitation of convnets isn’t an issue with the \\nIMDB  data, because patterns of keywords\\nassociated with a positive or negative sentiment are informative independently of\\nwhere they’re found in the input sentences.\\n One strategy to combine the speed and light ness of convnets with the order-sensitivity\\nof RNNs is to use a 1D convnet as a preprocessing step before an RNN (see figure 6.30).\\nThis is especially beneficial when you’re deal-ing with sequences that are so long they can’t\\nrealistically be processed with \\nRNNs, such as\\nsequences with thousands of steps. The conv-\\nnet will turn the long input sequence into\\nmuch shorter (downsampled) sequences of\\nhigher-level features. This sequence ofextracted features then becomes the input to\\nthe \\nRNN  part of the network.\\n This technique isn’t seen often in\\nresearch papers and pr actical applications,\\npossibly because it isn’t well known. It’s effec-\\ntive and ought to be more common. Let’s tryit on the temperature-forecasting dataset.\\nBecause this strategy allows you to manipu-\\nlate much longer sequences, you can either\\nFigure 6.29 Training and \\nvalidation loss on the Jena temperature-forecasting task \\nwith a simple 1D convnet\\nRNN\\n1D CNN\\nLong sequenceShorter\\nsequenceCNN features\\nFigure 6.30 Combining a 1D convnet and \\nan RNN for processing long sequences\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 251}), Document(page_content=\"230 CHAPTER  6Deep learning for text and sequences\\nlook at data from longer  ago (by increasing the lookback  parameter of the data gen-\\nerator) or look at high-resolutio n timeseries (by decreasing the step  parameter of the\\ngenerator). Here, somewhat arbitrarily, you’ll use a step  that’s half as large, resulting\\nin a timeseries twice as long, where the temperature data is sampled at a rate of\\n1 point per 30 minutes. The example reuses the generator  function defined earlier.\\nstep = 3\\nlookback = 720delay = 144\\ntrain_gen = generator(float_data,\\nlookback=lookback,delay=delay,\\nmin_index=0,\\nmax_index=200000,shuffle=True,\\nstep=step)\\nval_gen = generator(float_data,\\nlookback=lookback,delay=delay,\\nmin_index=200001,\\nmax_index=300000,step=step)\\ntest_gen = generator(float_data,\\nlookback=lookback,delay=delay,\\nmin_index=300001,\\nmax_index=None,step=step)\\nval_steps = (300000 - 200001 - lookback) // 128\\ntest_steps = (len(float_data) - 300001 - lookback) // 128\\nThis is the model, starting with two Conv1D  layers and following up with a GRU layer.\\nFigure 6.31 shows the results.\\nfrom keras.models import Sequential\\nfrom keras import layers\\nfrom keras.optimizers import RMSprop\\nmodel = Sequential()\\nmodel.add(layers.Conv1D(32, 5, activation='relu',\\ninput_shape=(None, float_data.shape[-1])))\\nmodel.add(layers.MaxPooling1D(3))model.add(layers.Conv1D(32, 5, activation='relu'))\\nmodel.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\\nmodel.add(layers.Dense(1))\\nmodel.summary()\\nmodel.compile(optimizer=RMSprop(), loss='mae')Listing 6.48 Preparing higher-resolution data generators for the Jena dataset\\nListing 6.49 Model combining a 1D convolutional base and a GRU layerPreviously set to 6 ( 1 point per hour); \\nnow 3 ( 1 point per 30 min) Unchanged\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 252}), Document(page_content='231 Sequence processing with convnets\\nhistory = model.fit_generator(train_gen,\\nsteps_per_epoch=500,\\nepochs=20,validation_data=val_gen,\\nvalidation_steps=val_steps)\\nJudging from the validation loss, this setup isn’t as good as the regularized GRU alone,\\nbut it’s significantly faster. It  looks at twice as much data, which in this case doesn’t\\nappear to be hugely he lpful but may be important for other datasets. \\n6.4.5 Wrapping up\\nHere’s what you should take away from this section:\\n\\uf0a1In the same way that 2D convnets perform well for pr ocessing visual patterns in\\n2D space, 1D convnets perform well for proc essing temporal patterns. They\\noffer a faster alternative to RNN s on some problems, in  particular natural-\\nlanguage processing tasks.\\n\\uf0a1Typically, 1D convnets are structured much like their 2D equivalents from the\\nworld of computer vision: they consist of stacks of Conv1D  layers and Max-\\nPooling1D  layers, ending in a global pooling operation or flattening operation.\\n\\uf0a1Because RNN s are extremely expensive for proce ssing very long sequences, but\\n1D convnets are cheap, it can be a good idea to use a 1D convnet as a prepro-\\ncessing step before an RNN , shortening the sequence and extracting useful rep-\\nresentations for the RNN  to process. \\n \\n \\n \\n  \\n  \\nFigure 6.31 Training and validation \\nloss on the Jena temperature-forecasting task with a 1D convnet followed by a \\nGRU\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 253}), Document(page_content='232 CHAPTER  6Deep learning for text and sequences\\nChapter summary\\n\\uf0a1In this chapter, you learned the fo llowing techniques, which are widely\\napplicable to any dataset of sequence data, from text to timeseries:\\n– How to tokenize text– What word embeddings are, and how to use them\\n– What recurrent networks are, and how to use them\\n– How to stack RNN layers and use bidi rectional RNNs to build more-power-\\nful sequence-processing models\\n– How to use 1D convnets for sequence processing– How to combine 1D convnets and RNNs to process long sequences\\n\\uf0a1You can use RNNs for timeseries regr ession (“predicti ng the future”),\\ntimeseries classification, anomaly de tection in timeseries, and sequence\\nlabeling (such as identifying names or dates in sentences).\\n\\uf0a1Similarly, you can use 1D convnets for machine translation (sequence-to-\\nsequence convolutional models, like SliceNeta), document classification,\\nand spelling correction.\\n\\uf0a1If global order matters  in your sequence data, then it’s preferable to use a\\nrecurrent network to process it. This is typically the case for timeseries,\\nwhere the recent past is likely to be more informative than the distant\\npast.\\n\\uf0a1If global ordering isn’t fundamentally meaningful , then 1D convnets will turn\\nout to work at least as well and are ch eaper. This is often the case for text\\ndata, where a keyword found at the be ginning of a sentence is just as\\nmeaningful as a keyword found at the end.\\na See https://arxiv.org/abs/1706.03059 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 254}), Document(page_content='233Advanced deep-learning\\nbest practices\\nThis chapter explores a number of powerful tools that will bring you closer to\\nbeing able to develop state-of-the-art mode ls on difficult problems. Using the Keras\\nfunctional API, you can build graph-like models , share a layer across different\\ninputs, and use Keras models just like Py thon functions. Keras callbacks and the\\nTensorBoard browser-based vi sualization tool let you monitor models during train-\\ning. We’ll also discuss several other best  practices including batch normalization,\\nresidual connections, hyperparameter optimization, and model ensembling.This chapter covers\\n\\uf0a1The Keras functional API\\n\\uf0a1Using Keras callbacks\\n\\uf0a1Working with the TensorBoard visualization tool\\n\\uf0a1Important best practices for developing state-of-\\nthe-art models\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 255}), Document(page_content='234 CHAPTER  7Advanced deep-learning best practices\\n7.1 Going beyond the Sequential model: \\nthe Keras functional API\\nUntil now, all neural networks introduced in this book\\nhave been implemented using the Sequential  model.\\nThe Sequential  model makes the assumption that the\\nnetwork has exactly one input and exactly one output, and\\nthat it consists of a linear st ack of layers (see figure 7.1).\\n This is a commonly verifi ed assumption; the configu-\\nration is so common that we’ve been able to cover many\\ntopics and practical applications in these pages so farusing only the \\nSequential  model class. But this set of\\nassumptions is too in flexible in a numb er of cases. Some\\nnetworks require several independent inputs, others\\nrequire multiple outputs, an d some networks have inter-\\nnal branching between layers that makes them look like\\ngraphs  of layers rather than linear stacks of layers.\\n Some tasks, for instance, require multimodal  inputs: they merge data coming from\\ndifferent input sources, processing each ty pe of data using different kinds of neural\\nlayers. Imagine a deep-learnin g model trying to predict the most likely market price of\\na second-hand piece of clothing, using th e following inputs: user-provided metadata\\n(such as the item’s brand, age, and so on),  a user-provided text description, and a pic-\\nture of the item. If you had only the metadata available, you could one-hot encode itand use a densely connected network to pred ict the price. If you had only the text\\ndescription available, you could use an \\nRNN  or a 1D convnet. If you had only the pic-\\nture, you could use a 2D convnet. But how can you use all three at the same time? A\\nnaive approach would be to train three sepa rate models and then do a weighted aver-\\nage of their predictions. But this may be suboptimal, because the information\\nextracted by the models may be redundant. A better way is to jointly  learn a more accu-\\nrate model of the data by using a model that can see all available input modalities\\nsimultaneously: a model with three input branches (see figure 7.2).\\nMerging\\nmodulePrice prediction\\nText description Metadata PictureDense module RNN module Convnet module\\nFigure 7.2 A multi-input modelLayerOutput\\nInputSequentialLayer\\nLayer\\nFigure 7.1 A Sequential  \\nmodel: a linear stack of layers\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 256}), Document(page_content='235 Going beyond the Sequential model: the Keras functional API\\nSimilarly, some tasks need to predict multiple target attributes of input data. Given the\\ntext of a novel or short story, you might want  to automatically classify it by genre (such\\nas romance or thriller) but also predict the approximate date it was written. Of course,\\nyou could train two separate models: one for the genre and one for the date. But\\nbecause these attributes aren’t statistically independent, you could build a better\\nmodel by learning to jointly predict both genre and date at th e same time. Such a\\njoint model would then have two outputs, or heads  (see figure 7.3). Due to correla-\\ntions between genre and date, knowing the date of a novel would help the model\\nlearn rich, accurate representations of th e space of novel genres, and vice versa.\\nAdditionally, many recently developed ne ural architectures require nonlinear net-\\nwork topology: networks structured as dire cted acyclic graphs. The Inception family of\\nnetworks (developed by Sz egedy et al. at Google),1 for instance, relies on Inception\\nmodules , where the input is processed by severa l parallel convolutional branches whose\\noutputs are then merged back into a single tensor (see figure 7.4). There’s also the\\nrecent trend of adding residual connections  to a model, which started with the ResNet\\nfamily of networks (developed by He et al. at Microsoft).2 A residual connection con-\\nsists of reinjecting pr evious representations into the downstream flow of data by add-\\ning a past output tensor to a later output tensor (see figure 7.5), which helps prevent\\ninformation loss along the data-processing flow. There are many other examples of\\nsuch graph-like networks.\\n1Christian Szegedy et al., “Going Deeper with Convolut ions,” Conference on Computer Vision and Pattern\\nRecognition (2014), https:/ /arxiv.org/abs/1409.4842 .\\n2Kaiming He et al., “Deep Residual Learning for Image Recognition,” Conference on Computer Vision and\\nPattern Recognition (2015), https:/ /arxiv.org/abs/1512.03385 .Date\\nDate\\nregressorGenre\\nGenre\\nclassifier\\nText-processing\\nmodule\\nNovel text\\nFigure 7.3 A multi-output (or multihead) model\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 257}), Document(page_content='236 CHAPTER  7Advanced deep-learning best practices\\n \\nThese three important use cases—multi-input models, multi-output models, and\\ngraph-like models—aren’t possible when using only the Sequential  model class in\\nKeras. But there’s another far more general and flexible way to use Keras: the func-\\ntional API. This section explains in detail what it is, what it can do, and how to use it.\\n7.1.1 Introduction to the functional API\\nIn the functional API, you directly manipulate tensors, and you use layers as functions\\nthat take tensors and return  tensors (hence, the name functional API):\\nfrom keras import Input, layers\\ninput_tensor = Input(shape=(32,))Conv2D\\n3 × 3, strides=2\\nConv2D\\n3 × 3, strides=2Conv2D\\n3 × 3Conv2D\\n3 × 3\\nConv2D\\n1 × 1, strides=2Conv2D\\n1 × 1AvgPool2D\\n3 × 3, strides=2Conv2D\\n1 × 1ConcatenateOutput\\nInput\\nFigure 7.4 An Inception module: a subgraph of layers with several \\nparallel convolutional branches\\nLayer\\nResidual\\nconnection+\\nLayer\\nLayer\\nLayerFigure 7.5 A residual connection: \\nreinjection of prior information downstream via feature-map addition\\nA tensor\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 258}), Document(page_content=\"237 Going beyond the Sequential model: the Keras functional API\\ndense = layers.Dense(32, activation='relu')\\noutput_tensor = dense(input_tensor)\\nLet’s start with a minimal example th at shows side by side a simple Sequential  model\\nand its equivalent in the functional API:\\nfrom keras.models import Sequential, Model\\nfrom keras import layers\\nfrom keras import Input\\nseq_model = Sequential()\\nseq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\\nseq_model.add(layers.Dense(32, activation='relu'))\\nseq_model.add(layers.Dense(10, activation='softmax'))\\ninput_tensor = Input(shape=(64,))\\nx = layers.Dense(32, activation='relu')(input_tensor)\\nx = layers.Dense(32, activation='relu')(x)output_tensor = layers.Dense(10, activation='softmax')(x)\\nmodel = Model(input_tensor, output_tensor)\\nmodel.summary()\\nThis is what the call to model.summary()  displays:\\n_________________________________________________________________\\nLayer (type) Output Shape Param #\\n=================================================================input_1 (InputLayer) (None, 64) 0\\n_________________________________________________________________\\ndense_1 (Dense) (None, 32) 2080_________________________________________________________________\\ndense_2 (Dense) (None, 32) 1056\\n_________________________________________________________________dense_3 (Dense) (None, 10) 330\\n=================================================================\\nTotal params: 3,466Trainable params: 3,466\\nNon-trainable params: 0\\n_________________________________________________________________\\nThe only part that may seem a bit magical at this point is instantiating a Model  object\\nusing only an input tensor and an output tensor. Behind the scenes, Keras retrieves\\nevery layer involved in going from input_tensor  to output_tensor , bringing them\\ntogether into a graph-like data structure—a Model . Of course, the reason it works is\\nthat output_tensor  was obtained by repeatedly transforming input_tensor . If you\\ntried to build a model from inputs and outputs that weren’t related, you’d get a Run-\\ntimeError :\\n>>> unrelated_input = Input(shape=(32,))\\n>>> bad_model = model = Model(unrelated_input, output_tensor)A layer is a function.\\nA layer may be called on a \\ntensor, and it returns a tensor.\\nSequential model, which \\nyou already know about\\nIts functional \\nequivalent\\nThe Model class turns an input tensor \\nand output tensor into a model. Let’s look at it!\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 259}), Document(page_content='238 CHAPTER  7Advanced deep-learning best practices\\nRuntimeError: Graph disconnected: cannot\\nobtain value for tensor\\n➥Tensor(\"input_1:0\", shape=(?, 64), dtype=float32) at layer \"input_1\".\\nThis error tells you, in essenc e, that Keras couldn’t reach input_1  from the provided\\noutput tensor.\\n When it comes to compiling, training, or evaluating such an instance of Model , the\\nAPI is the same as that of Sequential :\\nmodel.compile(optimizer=\\'rmsprop\\', loss=\\'categorical_crossentropy\\')\\nimport numpy as np\\nx_train = np.random.random((1000, 64))\\ny_train = np.random.random((1000, 10))\\nmodel.fit(x_train, y_train, epochs=10, batch_size=128)score = model.evaluate(x_train, y_train)\\n7.1.2 Multi-input models\\nThe functional API can be used to build models that have multiple inputs. Typically,\\nsuch models at some point me rge their different input bran ches using a layer that can\\ncombine several tensors: by adding them, concatenating them, and so on. This is usu-\\nally done via a Keras me rge operation such as keras.layers.add , keras.layers\\n.concatenate , and so on. Let’s look at a very si mple example of a multi-input model:\\na question-answering model.\\n A typical question-answering model has two inputs: a natural-language question\\nand a text snippet (such as a news articl e) providing information to be used for\\nanswering the question. The model must then  produce an answer: in the simplest pos-\\nsible setup, this is a one- word answer obtained via a softmax over some predefined\\nvocabulary (see figure 7.6).Compiles \\nthe modelGenerates dummy Numpy \\ndata to train on\\nTrains the model \\nfor 10 epochsEvaluates \\nthe model \\nDenseAnswer\\nConcatenate\\nLSTM LSTM\\nReference text QuestionEmbedding Embedding\\nFigure 7.6 A question-answering model\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 260}), Document(page_content=\"239 Going beyond the Sequential model: the Keras functional API\\nFollowing is an example of how you can build such a model with the functional API.\\nYou set up two independent branches, encoding the text input and the question input\\nas representation vectors; then, concaten ate these vectors; and finally, add a softmax\\nclassifier on top of the co ncatenated representations.\\nfrom keras.models import Model\\nfrom keras import layers\\nfrom keras import Input\\ntext_vocabulary_size = 10000\\nquestion_vocabulary_size = 10000\\nanswer_vocabulary_size = 500\\ntext_input = Input(shape=(None,), dtype='int32', name='text')embedded_text = layers.Embedding(\\n64, text_vocabulary_size)(text_input)\\nencoded_text = layers.LSTM(32)(embedded_text)question_input = Input(shape=(None,),\\ndtype='int32',\\nname='question')\\nembedded_question = layers.Embedding(\\n32, question_vocabulary_size)(question_input)\\nencoded_question = layers.LSTM(16)(embedded_question)\\nconcatenated = layers.concatenate([encoded_text, encoded_question],\\naxis=-1)\\nanswer = layers.Dense(answer_vocabulary_size,\\nactivation='softmax')(concatenated)\\nmodel = Model([text_input, question_input], answer)\\nmodel.compile(optimizer='rmsprop',\\nloss='categorical_crossentropy',\\nmetrics=['acc'])\\nNow, how do you train this two-input model? There are two possible APIs: you can feed\\nthe model a list of Numpy arrays as inputs, or you can feed it a dictionary that maps\\ninput names to Numpy arrays. Naturally, the latter option is available only if you give\\nnames to your inputs.\\nimport numpy as np\\nnum_samples = 1000\\nmax_length = 100\\ntext = np.random.randint(1, text_vocabulary_size,\\nsize=(num_samples, max_length))Listing 7.1 Functional API implementation of a two-input question-answering model\\nListing 7.2 Feeding data to a multi-input modelThe text input is a variable-\\nlength sequence of integers.\\nNote that you can optionally\\nname the inputs.\\nEmbeds the inputs \\ninto a sequence of \\nvectors of size 64\\nEncodes the vectors in a \\nsingle vector via an LSTM\\nSame process (with different layer \\ninstances) for the question\\nConcatenates the encoded \\nquestion and encoded text\\nAdds a softmax \\nclassifier on top\\nAt model instantiation, you specify \\nthe two inputs and the output.\\nGenerates dummy\\nNumpy data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 261}), Document(page_content=\"240 CHAPTER  7Advanced deep-learning best practices\\nquestion = np.random.randint(1, question_vocabulary_size,\\nsize=(num_samples, max_length))\\nanswers = np.random.randint(0, 1,\\nsize=(num_samples, answer_vocabulary_size))\\nmodel.fit([text, question], answers, epochs=10, batch_size=128)\\nmodel.fit({'text': text, 'question': question}, answers,\\nepochs=10, batch_size=128)\\n7.1.3 Multi-output models\\nIn the same way, you can use the functional API to build models wi th multiple outputs\\n(or multiple heads ). A simple example is a network that attempts to simultaneously\\npredict different properties of  the data, such as a network that takes as input a series\\nof social media posts from a single anonymou s person and tries to predict attributes of\\nthat person, such as age, gender, and income level (see figure 7.7).\\nfrom keras import layers\\nfrom keras import Input\\nfrom keras.models import Model\\nvocabulary_size = 50000\\nnum_income_groups = 10\\nposts_input = Input(shape=(None,), dtype='int32', name='posts')\\nembedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\\nx = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\\nx = layers.MaxPooling1D(5)(x)x = layers.Conv1D(256, 5, activation='relu')(x)\\nx = layers.Conv1D(256, 5, activation='relu')(x)\\nx = layers.MaxPooling1D(5)(x)x = layers.Conv1D(256, 5, activation='relu')(x)\\nx = layers.Conv1D(256, 5, activation='relu')(x)\\nx = layers.GlobalMaxPooling1D()(x)x = layers.Dense(128, activation='relu')(x)\\nage_prediction = layers.Dense(1, name='age')(x)\\nincome_prediction = layers.Dense(num_income_groups,\\nactivation='softmax',\\nname='income')(x)\\ngender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\\nmodel = Model(posts_input,\\n[age_prediction, income_prediction, gender_prediction])Listing 7.3 Functional API implementation of a three-output modelAnswers are one-\\nhot encoded,\\nnot integers\\nFitting using a list of inputs Fitting using a dictionary of\\ninputs (only if inputs are named)\\nNote that the output \\nlayers are given names.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 262}), Document(page_content=\"241 Going beyond the Sequential model: the Keras functional API\\nImportantly, training such a mo del requires the ability to specify different loss func-\\ntions for different heads of the network: for instance, age prediction  is a scalar regres-\\nsion task, but gender predicti on is a binary classification  task, requiring a different\\ntraining procedure. But because gradient descent requires you to minimize a scalar ,\\nyou must combine these losses into a single  value in order to train the model. The\\nsimplest way to combine different losses is to sum them all. In Keras, you can use\\neither a list or a dictionary of losses in compile  to specify different objects for different\\noutputs; the resulting loss va lues are summed into a glob al loss, which is minimized\\nduring training.\\nmodel.compile(optimizer='rmsprop',\\nloss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\\nmodel.compile(optimizer='rmsprop',\\nloss={'age': 'mse',\\n'income': 'categorical_crossentropy','gender': 'binary_crossentropy'})\\nNote that very imbalanced loss contributi ons will cause the model representations to\\nbe optimized preferentially fo r the task with the largest in dividual loss, at the expense\\nof the other tasks. To remedy this, you can assign different levels of importance to theloss values in their contribution to the final loss. This is useful in particular if the\\nlosses’ values use different scales. For instance, the mean squared error (\\nMSE) loss\\nused for the age-regression task typically takes a value around 3–5, whereas the cross-\\nentropy loss used for the gender-c lassification task can be as low as 0.1. In such a situa-\\ntion, to balance the contributi on of the different losses, yo u can assign a weight of 10\\nto the crossentropy loss and a weight of 0.25 to the MSE loss.\\nmodel.compile(optimizer='rmsprop',\\nloss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\\nloss_weights=[0.25, 1., 10.])Listing 7.4 Compilation options of a multi-output model: multiple losses\\nListing 7.5 Compilation options of a multi-output model: loss weightingGender\\nSocial media postsDenseIncome\\nDenseAge\\nDense\\n1D convnet\\nFigure 7.7 A social media \\nmodel with three heads\\nEquivalent (possible \\nonly if you give names to the output layers)\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 263}), Document(page_content=\"242 CHAPTER  7Advanced deep-learning best practices\\nmodel.compile(optimizer='rmsprop',\\nloss={'age': 'mse',\\n'income': 'categorical_crossentropy','gender': 'binary_crossentropy'},\\nloss_weights={'age': 0.25,\\n'income': 1.,'gender': 10.})\\nMuch as in the case of mu lti-input models, you can pass Numpy data to the model for\\ntraining either via a list of arrays  or via a dictionary of arrays.\\nmodel.fit(posts, [age_targets, income_targets, gender_targets],\\nepochs=10, batch_size=64)\\nmodel.fit(posts, {'age': age_targets,\\n'income': income_targets,'gender': gender_targets},\\nepochs=10, batch_size=64)\\n7.1.4 Directed acyclic graphs of layers\\nWith the functional API, not only can you build models with multiple inputs and mul-\\ntiple outputs, but you can also implement networks with a complex internal topology.\\nNeural networks in Keras ar e allowed to be arbitrary directed acyclic graphs  of layers. The\\nqualifier acyclic  is important: these graphs can’t have cycles. It’s impossible for a tensor\\nx to become the input of one of the layers that generated x. The only processing loops\\nthat are allowed (that is, recurrent connections) are those internal to recurrent layers.\\n Several common neural-network compon ents are implemented as graphs. Two\\nnotable ones are Inception mo dules and residual connecti ons. To better understand\\nhow the functional API can be used to build graphs of layers, let’s take a look at how\\nyou can implement both of them in Keras.\\nINCEPTION  MODULES\\nInception3 is a popular type of network architec ture for convolutiona l neural networks;\\nit was developed by Christian Szegedy and his colleagues at Google in 2013–2014,\\ninspired by the earlier network-in-network  architecture.4 It consists of a stack of modules\\nthat themselves look like small independ ent networks, split into several parallel\\nbranches. The most basic form of an Ince ption module has three to four branches\\nstarting with a 1 × 1 convolution, followed by a 3 × 3 convolution, and ending with the\\nconcatenation of the resulting features. This  setup helps the netw ork separately learnListing 7.6 Feeding data to a multi-output model\\n3https://arxiv.org/abs/1409.4842.\\n4Min Lin, Qiang Chen, and Shuicheng Yan, “Network in Network,” International Conference on Learning\\nRepresentations (2013), https:/ /arxiv.org/abs/1312.4400 .Equivalent (possible \\nonly if you give names to the output layers)\\nage_targets, income_targets, and \\ngender_targets are assumed to be \\nNumpy arrays.Equivalent (possible only if you give names to the output layers) \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 264}), Document(page_content='243 Going beyond the Sequential model: the Keras functional API\\nspatial features and channel-wi se features, which is more efficient than learning them\\njointly. More-complex versions of an Ince ption module are also  possible, typically\\ninvolving pooling operations, different spatial convolution sizes (for example, 5 × 5\\ninstead of 3 × 3 on some branches), and br anches without a spatial convolution (only\\na 1 × 1 convolution). An example of such  a module, taken from Inception V3, is\\nshown in figure 7.8.\\nHere’s how you’d implement the module feat ured in figure 7.8 using the functional\\nAPI. This example assumes the existence of a 4D input tensor x:Conv2D\\n3 × 3, strides=2\\nConv2D\\n3 × 3, strides=2Conv2D\\n3 × 3Conv2D\\n3 × 3\\nConv2D\\n1 × 1, strides=2Conv2D\\n1 × 1AvgPool2D\\n3 × 3, strides=2Conv2D\\n1 × 1ConcatenateOutput\\nInputFigure 7.8 An Inception \\nmodule\\nThe purpose of 1 × 1 convolutions\\nYou already know that convol utions extract spatial patc hes around every tile in an\\ninput tensor and apply the same transformation to each patch. An edge case is when\\nthe patches extracted consist of a single tile. The convolution operation then\\nbecomes equivalent to running each tile vector through a Dense  layer: it will compute\\nfeatures that mix together information from  the channels of the input tensor, but it\\nwon’t mix information across space (because it’s looking at one tile at a time). Such\\n1 × 1 convolutions (also called pointwise convolutions ) are featured in Inception mod-\\nules, where they contribute to factoring out channel-wise feature learning and space-\\nwise feature learning—a reasonable thing to do if you assume that each channel is\\nhighly autocorrelated across space, but different channels may not be highly cor-related with each other.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 265}), Document(page_content=\"244 CHAPTER  7Advanced deep-learning best practices\\nfrom keras import layers\\nbranch_a = layers.Conv2D(128, 1,\\nactivation='relu', strides=2)(x)\\nbranch_b = layers.Conv2D(128, 1, activation='relu')(x)branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\\nbranch_c = layers.AveragePooling2D(3, strides=2)(x)\\nbranch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\\nbranch_d = layers.Conv2D(128, 1, activation='relu')(x)\\nbranch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\\nbranch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\\noutput = layers.concatenate(\\n[branch_a, branch_b, branch_c, branch_d], axis=-1)\\nNote that the full Inception V3 architecture is available in Keras as keras.applications\\n.inception_v3.InceptionV3 , including weights pretrain ed on the ImageNet dataset.\\nAnother closely related model available as part of the Keras applications module is\\nXception .5 Xception, which stands for extreme inception , is a convnet architecture loosely\\ninspired by Inception. It take s the idea of separating the learning of channel-wise and\\nspace-wise features to its logical extreme,  and replaces Inception modules with depth-\\nwise separable convolutions consisting of a depthwise convolutio n (a spatial convolu-\\ntion where every input channel is handle d separately) followed by a pointwise\\nconvolution (a 1 × 1 convolution)—effectivel y, an extreme form of an Inception mod-\\nule, where spatial features and channel-wise features are fully separated. Xception has\\nroughly the same number of  parameters as Inception V3, but it shows better runtime\\nperformance and higher accura cy on ImageNet as well as  other large-scale datasets,\\ndue to a more efficient use of model parameters. \\nRESIDUAL  CONNECTIONS\\nResidual connections  are a common graph-li ke network component found in many post-\\n2015 network architectures, including Xception. They were introduced by He et al.from Microsoft in their winning entry in the \\nILSVRC  ImageNet challenge in late 2015.6\\nThey tackle two common pr oblems that plague any larg e-scale deep-learning model:\\nvanishing gradients and repres entational bottlenecks. In ge neral, adding residual con-\\nnections to any model that has more than 10 layers is likely to be beneficial.\\n5François Chollet, “Xception: Deep Learning with De pthwise Separable Convolutions,” Conference on Com-\\nputer Vision and Pattern Recognition (2017), https:/ /arxiv.org/abs/1610.02357 .\\n6He et al., “Deep Residual Learning for Image Recognition,” https://arxiv.org/abs/1512.03385 .Every branch has the sa me stride value (2), \\nwhich is necessary to keep all branch outputs \\nthe same size so you can concatenate them.In this branch, the striding occurs\\nin the spatial convolution layer.\\nIn this branch, th e striding occurs \\nin the average pooling layer.Concatenates the \\nbranch outputs to \\nobtain the module \\noutput\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 266}), Document(page_content=\"245 Going beyond the Sequential model: the Keras functional API\\n A residual connection consists of making the output of an earlier layer available as\\ninput to a later layer, effectively creating a shortcut in a sequen tial network. Rather\\nthan being concatenated to th e later activation, the earlier output is summed with the\\nlater activation, which assumes that both acti vations are the same size. If they’re differ-\\nent sizes, you can use a linear transformation to reshape the earlier activation into the\\ntarget shape (for example, a Dense  layer without an activati on or, for convolutional\\nfeature maps, a 1 × 1 convolution without an activation).\\n Here’s how to implement a residual co nnection in Keras when the feature-map\\nsizes are the same, using identity residual connections. This exam ple assumes the exis-\\ntence of a 4D input tensor x:\\nfrom keras import layers\\nx = ...\\ny = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\\ny = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\\ny = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\\ny = layers.add([y, x])\\nAnd the following implements a residual connection when the feature-map sizes dif-\\nfer, using a linear residual connectio n (again, assuming the existence of a 4D input\\ntensor x):\\nfrom keras import layers\\nx = ...\\ny = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\\ny = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\\ny = layers.MaxPooling2D(2, strides=2)(y)\\nresidual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\\ny = layers.add([y, residual])Applies a transformation to x\\nAdds the original x back to \\nthe output features\\nUses a 1 × 1 convolution to\\nlinearly downsample the original\\nx tensor to the same shape as y\\nAdds the residual tensor back to the output features\\nRepresentational bottlenecks in deep learning\\nIn a Sequential  model, each successive representation layer is built on top of the\\nprevious one, which means it only has acce ss to information contained in the activa-\\ntion of the previous layer. If one layer is too small (for example,  it has features that\\nare too low-dimensional), t hen the model will be constr ained by how much informa-\\ntion can be crammed into the activations of this layer.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 267}), Document(page_content='246 CHAPTER  7Advanced deep-learning best practices\\n7.1.5 Layer weight sharing\\nOne more important feature of the functional API is the ability to reuse a layer\\ninstance several times. When you call a layer instance twice, instead of instantiating a\\nnew layer for each call, you reuse the same weights with every call. This allows you to\\nbuild models that have shared branches—s everal branches that all share the same\\nknowledge and perform the same operations. That is, they share the same representa-\\ntions and learn these representations simultaneously for different sets of inputs.\\n For example, consider a model that a ttempts to assess the semantic similarity\\nbetween two sentences. The model has two inputs (the two sentences to compare)\\nand outputs a score between 0 and 1, wher e 0 means unrelated sentences and 1 means\\nsentences that are either identical or reformulations of each other. Such a modelcould be useful in many applications, in cluding deduplicating natural-language que-\\nries in a dialog system.\\n In this setup, the two input sentences ar e interchangeable, because semantic simi-\\nlarity is a symmetrical relationship: the simila rity of A to B is iden tical to the similarity\\nof \\nB to A. For this reason, it wouldn’t make sense to learn two independent models for(continued)\\nYou can grasp this concept with a signal-processing analogy: if you have an audio-\\nprocessing pipeline that consists of a series of operations, each of which takes as\\ninput the output of the previous operation, then if one operation crops your signal to\\na low-frequency range (for ex ample, 0–15 kHz), the operations down stream will never\\nbe able to recover the dropped frequencies. Any loss of information is permanent.\\nResidual connections, by reinjecting earlier information downstream, partially solve\\nthis issue for deep-learning models.\\nVanishing gradients in deep learning\\nBackpropagation, the master algorithm used to train deep neural networks, works by\\npropagating a feedback signal from the output  loss down to earlier layers. If this feed-\\nback signal has to be propagated through a deep stack of layers, the signal may\\nbecome tenuous or even be lost entirely, rendering the network untrainable. This\\nissue is known as vanishing gradients .\\nThis problem occurs both with deep networks and with recurrent networks over very\\nlong sequences—in both cases, a feedback signal must be propagated through along series of operations . You’re already familiar wi th the soluti on that the \\nLSTM layer\\nuses to address this problem in recurrent networks: it introduces a carry track  that\\npropagates information parallel to the main processing track. Residual connectionswork in a similar way in feedforward deep networks, but they’re even simpler: they\\nintroduce a purely linea r information carry track parallel to the main layer stack, thus\\nhelping to propagate gradients through arbitrarily deep stacks of layers. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 268}), Document(page_content=\"247 Going beyond the Sequential model: the Keras functional API\\nprocessing each input sent ence. Rather, you want to process both with a single LSTM\\nlayer. The representations of this LSTM  layer (its weights) are learned based on both\\ninputs simultaneously. This is what we call a Siamese LSTM  model or a shared LSTM .\\n Here’s how to implement such a model using layer sharing (layer reuse) in the\\nKeras functional API:\\nfrom keras import layers\\nfrom keras import Input\\nfrom keras.models import Model\\nlstm = layers.LSTM(32)left_input = Input(shape=(None, 128))\\nleft_output = lstm(left_input)\\nright_input = Input(shape=(None, 128))\\nright_output = lstm(right_input)\\nmerged = layers.concatenate([left_output, right_output], axis=-1)\\npredictions = layers.Dense(1, activation='sigmoid')(merged)\\nmodel = Model([left_input, right_input], predictions)\\nmodel.fit([left_data, right_data], targets)\\nNaturally, a layer instance ma y be used more than once—it can be called arbitrarily\\nmany times, reusing the same  set of weights every time. \\n7.1.6 Models as layers\\nImportantly, in the functional API, models can be used as you’d use layers—effectively,\\nyou can think of a model as a “bigger layer.” This is true of both the Sequential  and\\nModel  classes. This means you can call a model on an input tensor and retrieve an out-\\nput tensor:\\ny = model(x)\\nIf the model has multiple input tensors an d multiple output te nsors, it should be\\ncalled with a list of tensors:\\ny1, y2 = model([x1, x2])\\nWhen you call a model instance, you’re reus ing the weights of the model—exactly like\\nwhat happens when you call a layer instance. Calling an in stance, whether it’s a layer\\ninstance or a model instance, will always re use the existing learned representations of\\nthe instance—which is intuitive.\\n One simple practical example of what yo u can build by reusing a model instance is\\na vision model that uses a dual camera as its input: two parallel cameras, a few centi-\\nmeters (one inch) apart. Su ch a model can perceive dept h, which can be useful in\\nmany applications. You shouldn’t need tw o independent models to extract visualInstantiates a single \\nLSTM layer, once\\nBuilding the left branch of the \\nmodel: inputs ar e variable-length \\nsequences of vectors of size 128.\\nBuilding the right branch of the model: \\nwhen you call an existing layer \\ninstance, you reuse its weights.\\nBuilds the classifier on top Instantiating and training  the model: when you\\ntrain such a model, the weights of the LSTM layer\\nare updated based on both inputs.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 269}), Document(page_content='248 CHAPTER  7Advanced deep-learning best practices\\nfeatures from the left camera and the ri ght camera before merging the two feeds.\\nSuch low-level processing can be shared across the two inpu ts: that is, done via layers\\nthat use the same weights and thus share th e same representations. Here’s how you’d\\nimplement a Siamese vision model (shared convolutional base) in Keras:\\nfrom keras import layers\\nfrom keras import applicationsfrom keras import Input\\nxception_base = applications.Xception(weights=None,\\ninclude_top=False)\\nleft_input = Input(shape=(250, 250, 3))\\nright_input = Input(shape=(250, 250, 3))\\nleft_features = xception_base(left_input)\\nright_input = xception_base(right_input)\\nmerged_features = layers.concatenate(\\n[left_features, right_input], axis=-1)\\n7.1.7 Wrapping up\\nThis concludes our introducti on to the Keras functional API—an essential tool for\\nbuilding advanced deep neur al network architectures. Now you know the following:\\n\\uf0a1To step out of the Sequential  API whenever you need anything more than a lin-\\near stack of layers\\n\\uf0a1How to build Keras models with severa l inputs, several outputs, and complex\\ninternal network topology, using the Keras functional API\\n\\uf0a1How to reuse the weights of a layer or model across di fferent processing\\nbranches, by calling the same laye r or model instance several times The base image-processing\\nmodel is the Xception network\\n(convolutional base only).\\nThe inputs are 250 × 250 \\nRGB images.\\nCalls the same vision \\nmodel twice\\nThe merged features contain \\ninformation from the right visual feed and the left visual feed. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 270}), Document(page_content='249 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\n7.2 Inspecting and monitoring deep-learning models using \\nKeras callbacks and TensorBoard\\nIn this section, we’ll review ways to gain  greater access to and control over what goes\\non inside your model during training. Laun ching a training run on a large dataset for\\ntens of epochs using model.fit()  or model.fit_generator()  can be a bit like\\nlaunching a paper airplane: past the initia l impulse, you don’t have any control over\\nits trajectory or its landing spot. If you want to avoid bad outcomes (and thus wasted\\npaper airplanes), it’s smarter to use not a paper plane, but a drone that can sense its\\nenvironment, send data back to its oper ator, and automatically make steering deci-\\nsions based on its curr ent state. The techniques we pres ent here will transform the call\\nto model.fit()  from a paper airplane into a smart , autonomous drone that can self-\\nintrospect and dynamically take action.\\n7.2.1 Using callbacks to act on a model during training\\nWhen you’re training a model, there are ma ny things you can’t predict from the start.\\nIn particular, you can’t tell how many epochs will be needed to get to an optimal vali-\\ndation loss. The examples so far have ad opted the strategy of training for enough\\nepochs that you begin overfitting, using the first run to figure out the proper number\\nof epochs to train for, and then finally launching a new training run from scratch\\nusing this optimal number. Of cour se, this approach is wasteful.\\n A much better way to handle this is to stop training when you measure that the val-\\nidation loss in no longer improving. This can be achieved using a Keras callback. Acallback  is an object (a class instance implemen ting specific methods) that is passed to\\nthe model in the call to \\nfit and that is called by the model at various points during\\ntraining. It has access to all the available da ta about the state of the model and its per-\\nformance, and it can take action: interrupt training, save a model, load a different\\nweight set, or otherwise alter the state of the model.\\n Here are some examples of ways you can use callbacks:\\n\\uf0a1Model checkpointing —Saving the current weights of the model at different points\\nduring training.\\n\\uf0a1Early stopping —Interrupting training when the validation loss is no longer\\nimproving (and of course, saving th e best model obtained during training).\\n\\uf0a1Dynamically adjusting the value of certain parameters during training —Such as the\\nlearning rate of the optimizer.\\n\\uf0a1Logging training and validation metrics duri ng training, or visualizing the representa-\\ntions learned by the model as they’re updated —The Keras progress bar that you’re\\nfamiliar with is a callback!\\nThe keras.callbacks  module includes a number of bu ilt-in callbacks (this is not an\\nexhaustive list):\\nkeras.callbacks.ModelCheckpoint\\nkeras.callbacks.EarlyStopping\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 271}), Document(page_content=\"250 CHAPTER  7Advanced deep-learning best practices\\nkeras.callbacks.LearningRateScheduler\\nkeras.callbacks.ReduceLROnPlateau\\nkeras.callbacks.CSVLogger\\nLet’s review a few of them to give you an idea of how to use them: ModelCheckpoint ,\\nEarlyStopping , and ReduceLROnPlateau .\\nTHE MODELCHECKPOINT  AND EARLYSTOPPING  CALLBACKS\\nYou can use the EarlyStopping  callback to interrupt training once a target metric\\nbeing monitored has stopped improving for a fixed number of epochs. For instance,\\nthis callback allows you to interrupt trai ning as soon as you start overfitting, thus\\navoiding having to retrain your model for a smaller number of epochs. This callback is\\ntypically used in combination with ModelCheckpoint , which lets you continually save\\nthe model during training (and, optionally, save only the current best model so far:\\nthe version of the model that achieved the best performance at the end of an epoch):\\nimport keras\\ncallbacks_list = [\\nkeras.callbacks.EarlyStopping(\\nmonitor='acc',\\npatience=1,\\n),keras.callbacks.ModelCheckpoint(\\nfilepath='my_model.h5',\\nmonitor='val_loss',save_best_only=True,\\n)\\n]\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',\\nmetrics=['acc'])\\nmodel.fit(x, y,\\nepochs=10,\\nbatch_size=32,callbacks=callbacks_list,\\nvalidation_data=(x_val, y_val))\\nTHE REDUCE LRO NPLATEAU  CALLBACK\\nYou can use this callback to reduce the learning rate when the validation loss has\\nstopped improving. Reducing or increasi ng the learning rate in case of a loss plateau  is\\nis an effective strategy to get out of loca l minima during training. The following exam-\\nple uses the ReduceLROnPlateau  callback:\\n \\n Callbacks are passed to the model via the \\ncallbacks argument in fit,  which takes a list of \\ncallbacks. You can pass any number of callbacks.Interrupts training when \\nimprovement stops\\nMonitors the model’s validation accuracy\\nInterrupts training when accuracy has stopped improving for more than one \\nepoch (that is, two epochs)\\nSaves the current weights after every epoch\\nPath to the destination model file\\nThese two arguments mean you won’t overwrite the \\nmodel file unless val_loss has improved, which allows \\nyou to keep the best mode l seen during training.\\nYou monitor accuracy, so it should \\nbe part of the model’s metrics.\\nNote that because the callback will \\nmonitor validation loss and validation accuracy , you need to pass \\nvalidation_data to the call to fit. \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 272}), Document(page_content=\"251 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\ncallbacks_list = [\\nkeras.callbacks.ReduceLROnPlateau(\\nmonitor='val_loss'factor=0.1,\\npatience=10,\\n)\\n]\\nmodel.fit(x, y,\\nepochs=10,batch_size=32,\\ncallbacks=callbacks_list,\\nvalidation_data=(x_val, y_val))\\nWRITING  YOUR OWN CALLBACK\\nIf you need to take a specific action during  training that isn’t covered by one of the\\nbuilt-in callbacks, you can write your own callback. Callbacks are implemented by sub-\\nclassing the class keras.callbacks.Callback . You can then implement any number\\nof the following transparently named meth ods, which are called at various points\\nduring training:\\non_epoch_begin\\non_epoch_end\\non_batch_begin\\non_batch_end\\non_train_begin\\non_train_end\\nThese methods all are called with a logs  argument, which is a dictionary containing\\ninformation about the previous batch, epoch,  or training run: training and validation\\nmetrics, and so on. Additionally, the callba ck has access to the following attributes:\\n\\uf0a1self.model —The model instance from whic h the callback is being called\\n\\uf0a1self.validation_data —The value of what was passed to fit as validation data\\nHere’s a simple example of a custom callback  that saves to disk (as Numpy arrays) the\\nactivations of every layer of the model at the end of every epoch, computed on the\\nfirst sample of the validation set:\\nimport keras\\nimport numpy as np\\nclass ActivationLogger(keras.callbacks.Callback):\\ndef set_model(self, model):\\nself.model = model\\nlayer_outputs = [layer.output for layer in model.layers]self.activations_model = keras.models.Model(model.input,\\nlayer_outputs)\\ndef on_epoch_end(self, epoch, logs=None):\\nif self.validation_data is None:\\nraise RuntimeError('Requires validation_data.')Monitors th e model’s \\nvalidation loss\\nDivides the learning rate by 10 when triggered\\nThe callback is triggere d after the validation \\nloss has stopped improving for 10 epochs.\\nBecause the callback will \\nmonitor the validation loss, you \\nneed to pass validation_data to the call to fit. \\nCalled at the start of every epoch\\nCalled at the end of every epoch\\nCalled right before processing each batch\\nCalled right after processing each batch\\nCalled at the start of training\\nCalled at the end of training\\nCalled by the parent model \\nbefore training, to inform the callback of what model \\nwill be calling it\\nModel instance\\nthat returns the\\nactivations of\\nevery layer\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 273}), Document(page_content=\"252 CHAPTER  7Advanced deep-learning best practices\\nvalidation_sample = self.validation_data[0][0:1]\\nactivations = self.activations_model.predict(validation_sample)f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')\\nnp.savez(f, activations)\\nf.close()\\nThis is all you need to know about callbacks—the rest is technical details, which you\\ncan easily look up. Now you’re equipped to  perform any sort of logging or prepro-\\ngrammed intervention on a Keras model during training. \\n7.2.2 Introduction to TensorBoard: \\nthe TensorFlow visualization framework\\nTo do good research or deve lop good models, you need rich, frequent feedback about\\nwhat’s going on inside your models during your experiments. That ’s the point of run-\\nning experiments: to get information about how well a model performs—as much\\ninformation as possible.  Making progress is an iterative process, or loop: you start with\\nan idea and express it as an experiment, atte mpting to validate or invalidate your idea.\\nYou run this experiment and process the info rmation it generates. This inspires your\\nnext idea. The more iterations  of this loop you’re able to run, the more refined and\\npowerful your ideas become. Keras helps you go from idea to experiment in the least\\npossible time, and fast GPUs can help you get from experi ment to result as quickly as\\npossible. But what about processing the ex periment results? That’s where Tensor-\\nBoard comes in.\\nThis section introduces TensorBoard, a br owser-based visualizat ion tool that comes\\npackaged with TensorFlow. Note that it’s only available for Keras models when you’re\\nusing Keras with the TensorFlow backend.\\n The key purpose of TensorBoard is to he lp you visually monitor everything that\\ngoes on inside your model during training . If you’re monitori ng more information\\nthan just the model’s final loss, you can de velop a clearer vision of what the model\\ndoes and doesn’t do, and you can make prog ress more quickly. Te nsorBoard gives you\\naccess to several neat feat ures, all in your browser:Obtains the first input sample \\nof the vali dation dataSaves arrays to disk\\nIdea\\nVisualization\\nframework:\\nTensorBoardDeep-learning\\nframework:\\nKeras\\nInfrastructureResults Experiment\\nFigure 7.9 The loop of progress\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 274}), Document(page_content=\"253 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\n\\uf0a1Visually monitoring metrics during training\\n\\uf0a1Visualizing your model architecture\\n\\uf0a1Visualizing histograms of activations and gradients\\n\\uf0a1Exploring embeddings in 3D\\nLet’s demonstrate these features on a simple example. You’ll train a 1D convnet on\\nthe IMDB  sentiment-analysis task.\\n The model is similar to the one you saw in  the last section of chapter 6. You’ll con-\\nsider only the top 2,000 words in the IMDB  vocabulary, to make visualizing word\\nembeddings more tractable.\\nimport keras\\nfrom keras import layersfrom keras.datasets import imdb\\nfrom keras.preprocessing import sequence\\nmax_features = 2000\\nmax_len = 500\\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\\nx_train = sequence.pad_sequences(x_train, maxlen=max_len)\\nx_test = sequence.pad_sequences(x_test, maxlen=max_len)\\nmodel = keras.models.Sequential()\\nmodel.add(layers.Embedding(max_features, 128,\\ninput_length=max_len,name='embed'))\\nmodel.add(layers.Conv1D(32, 7, activation='relu'))\\nmodel.add(layers.MaxPooling1D(5))model.add(layers.Conv1D(32, 7, activation='relu'))\\nmodel.add(layers.GlobalMaxPooling1D())\\nmodel.add(layers.Dense(1))model.summary()\\nmodel.compile(optimizer='rmsprop',\\nloss='binary_crossentropy',metrics=['acc'])\\nBefore you start using TensorBoard, you need  to create a directory where you’ll store\\nthe log files it generates.\\n$ mkdir my_log_dir\\nLet’s launch the training with a TensorBoard  callback instance. This callback will write\\nlog events to disk at the specified location.Listing 7.7 Text-classification model to use with TensorBoard\\nListing 7.8 Creating a directory for TensorBoard log filesNumber of words to \\nconsider as features\\nCuts off texts after this number \\nof words (among max_features most common words)\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 275}), Document(page_content=\"254 CHAPTER  7Advanced deep-learning best practices\\n \\ncallbacks = [\\nkeras.callbacks.TensorBoard(\\nlog_dir='my_log_dir',\\nhistogram_freq=1,\\nembeddings_freq=1,\\n)\\n]\\nhistory = model.fit(x_train, y_train,\\nepochs=20,\\nbatch_size=128,\\nvalidation_split=0.2,callbacks=callbacks)\\nAt this point, you can launch the Te nsorBoard server fr om the command line,\\ninstructing it to read the logs the callback is currently writing. The tensorboard  utility\\nshould have been automatically installed on your machine the moment you installed\\nTensorFlow (for example, via pip):\\n$ tensorboard --logdir=my_log_dir\\nYou can then browse to http://localhost:6 006 and look at your model training (see\\nfigure 7.10). In addition to live graphs of  the training and validation metrics, you get\\naccess to the Histograms tab, where you can find pretty visualizat ions of histograms of\\nactivation values taken by yo ur layers (see figure 7.11).Listing 7.9 Training the model with a TensorBoard  callback\\nLog files will be written \\nat this location.\\nRecords activation histograms every 1 epoch\\nRecords embedding \\ndata every 1 epoch\\nFigure 7.10 TensorBoard: metrics monitoring\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 276}), Document(page_content='255 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\nThe Embeddings tab gives you a way to in spect the embedding locations and spatial\\nrelationships of the 10,000 words in the in put vocabulary, as learned by the initial\\nEmbedding  layer. Because the embedding space is 128-dimensional, TensorBoard auto-\\nmatically reduces it to 2D or 3D using a dimensionality-reduction algorithm of your\\nchoice: either principal component analysis ( PCA) or t-distributed stochastic neighbor\\nembedding (t- SNE). In figure 7.12, in the point cloud, you can clearly see two clusters:\\nwords with a positive connotation and words with a negative connotation. The visual-\\nization makes it immediately obvious that embeddings trained jointly with a specific\\nobjective result in mo dels that are completely specific  to the underlying task—that’s\\nthe reason using pretrained generic word embeddings is rarely a good idea.\\nFigure 7.11 TensorBoard: activation histograms\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 277}), Document(page_content='256 CHAPTER  7Advanced deep-learning best practices\\n \\nThe Graphs tab shows an interactive visualiz ation of the graph of low-level TensorFlow\\noperations underlying your Keras model (see fi gure 7.13). As you can see, there’s a lot\\nmore going on than you would expect. Th e model you just built may look simple\\nwhen defined in Keras—a small stack of basic layers—but under the hood, you need\\nto construct a fairly complex graph structure to make it work. A lot of it is related to\\nthe gradient-descent process.  This complexity differential between what you see and\\nwhat you’re manipulating is the key motivati on for using Keras as your way of building\\nmodels, instead of working with raw Tensor Flow to define ever ything from scratch.\\nKeras makes your workflow  dramatically simpler.\\nFigure 7.12 TensorBoard: interactive 3D word-embedding visualization\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 278}), Document(page_content=\"257 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\n \\nNote that Keras also provides  another, cleaner way to plot models as graphs of layers\\nrather than graphs of Tensor Flow operations: the utility keras.utils.plot_model .\\nUsing it requires that you’ve installed the Python pydot  and pydot-ng  libraries as well\\nas the graphviz  library. Let’s take a quick look:\\nfrom keras.utils import plot_model\\nplot_model(model, to_file='model.png')\\nThis creates the PNG image shown in figure 7.14.\\nFigure 7.13 TensorBoard: TensorFlow graph visualization\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 279}), Document(page_content=\"258 CHAPTER  7Advanced deep-learning best practices\\n \\nYou also have the option of displaying sh ape information in the graph of layers. This\\nexample visualizes model topology using plot_model  and the show_shapes  option\\n(see figure 7.15):\\nfrom keras.utils import plot_model\\nplot_model(model, show_shapes=True, to_file='model.png')\\nFigure 7.14 A model plot as a graph of layers, \\ngenerated with plot_model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 280}), Document(page_content='259 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\\n7.2.3 Wrapping up\\n\\uf0a1Keras callbacks provide a simple way to  monitor models during training and\\nautomatically take action based on the state of the model.\\n\\uf0a1When you’re using TensorFlow, TensorBo ard is a great way to visualize model\\nactivity in your browser. You can use it in Keras models via the TensorBoard  call-\\nback. Figure 7.15 A model plot with shape information\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 281}), Document(page_content='260 CHAPTER  7Advanced deep-learning best practices\\n7.3 Getting the most out of your models\\nTrying out architectures blindly works well  enough if you just need something that\\nworks okay. In this section, we’ll go beyond “works okay” to “works great and winsmachine-learning competitions” by offering  you a quick guide to a set of must-know\\ntechniques for building state-of -the-art deep-learning models.\\n7.3.1 Advanced architecture patterns\\nWe covered one important design pattern in  detail in the previous section: residual\\nconnections. There are two more design patt erns you should know about: normaliza-\\ntion and depthwise separable convolution.  These patterns are especially relevant\\nwhen you’re building high-performing de ep convnets, but they’re commonly found\\nin many other types of architectures as well.\\nBATCH NORMALIZATION\\nNormalization  is a broad category of methods that  seek to make different samples seen\\nby a machine-learning model more similar to each other, which helps the model learnand generalize well to new data. The most common form of data normalization is one\\nyou’ve seen several times in this book alread y: centering the data on 0 by subtracting\\nthe mean from the data, and gi ving the data a unit standard deviation by dividing the\\ndata by its standard deviatio n. In effect, this makes the assumption that the data fol-\\nlows a normal (or Gaussian) distribution an d makes sure this distribution is centered\\nand scaled to unit variance:\\nnormalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\\nPrevious examples normalized data before feeding it into models. But data normaliza-\\ntion should be a concern after every transf ormation operated by the network: even if\\nthe data entering a Dense  or Conv2D  network has a 0 mean and unit variance, there’s\\nno reason to expect a priori that this will be the case for the data coming out.\\n Batch normalization is a type of layer ( BatchNormalization  in Keras) introduced\\nin 2015 by Ioffe and Szegedy;7 it can adaptively normalize data even as the mean and\\nvariance change over time during training. It works by internally maintaining an expo-\\nnential moving average of the batch-wise me an and variance of the data seen during\\ntraining. The main effect of batch normalizat ion is that it helps with gradient propa-\\ngation—much like residual connections—and  thus allows for deeper networks. Some\\nvery deep networks can only be trained if they include multiple BatchNormalization\\nlayers. For instance, BatchNormalization  is used liberally in many of the advanced\\nconvnet architectures that come packaged with Keras, such as ResNet50, Inception\\nV3, and Xception.\\n \\n7Sergey Ioffe and Christian Szegedy, “Batch Normalizat ion: Accelerating Deep Network Training by Reducing\\nInternal Covariate Shift,” Proceedings of the 32nd  International Conference on Machine Learning  (2015),\\nhttps:/ /arxiv.org/abs/1502.03167 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 282}), Document(page_content='261 Getting the most out of your models\\n The BatchNormalization  layer is typically used after a convolutional or densely\\nconnected layer:\\nconv_model.add(layers.Conv2D(32, 3, activation=\\'relu\\'))\\nconv_model.add(layers.BatchNormalization())\\ndense_model.add(layers.Dense(32, activation=\\'relu\\'))\\ndense_model.add(layers.BatchNormalization())\\nThe BatchNormalization  layer takes an axis  argument, which specifies the feature\\naxis that should be normalized . This argument defaults to -1, the last axis in the input\\ntensor. This is the correct value when using Dense  layers, Conv1D  layers, RNN  layers,\\nand Conv2D  layers with data_format  set to \"channels_last\" . But in the niche use case\\nof Conv2D  layers with data_format  set to \"channels_first\" , the features axis is axis 1;\\nthe axis  argument in BatchNormalization  should accordingly be set to 1.\\nDEPTHWISE  SEPARABLE  CONVOLUTION\\nWhat if I told you that there’s a layer you can use as a drop-in replacement for Conv2D\\nthat will make your model lighter (fewer  trainable weight parameters) and faster\\n(fewer floating-point operations) and cause it to perform a few percentage points bet-\\nter on its task? That is precisely what the depthwise separable convolution  layer does\\n(SeparableConv2D ). This layer performs a spatial convolution on each channel of its\\ninput, independently, before mixing output  channels via a pointwise convolution (a\\n1 × 1 convolution), as shown in  figure 7.16. This is equiva lent to separating the learn-\\ning of spatial features and the learning of  channel-wise features, which makes a lot of\\nsense if you assume that spatial locations in  the input are highly correlated, but differ-\\nent channels are fairly independent. It re quires significantly fewer parameters and\\ninvolves fewer computations, thus resulting in smaller, sp eedier models. And because\\nit’s a more representationally efficient way to perform convolution,  it tends to learn\\nbetter representations using less data, resulting in better-performing models.After a Conv layer\\nAfter a Dense layer\\nBatch renormalization\\nA recent improvement over re gular batch normalization is batch renormalization , intro-\\nduced by Ioffe in 2017.a It offers clears benefits over batch normalization, at no appar-\\nent cost. At the time of writing, it’s too early to tell whether it will supplant batch\\nnormalization—but I think it’s likely. Even more recently, Klambauer et al. introduced\\nself-normalizing neural networks ,b which manage to keep data normalized after going\\nthrough any Dense  layer by using a specific activation function ( selu) and a specific ini-\\ntializer (lecun_normal ). This scheme, although highly interesting, is limited to densely\\nconnected networks for now, and its usef ulness hasn’t yet been broadly replicated. \\na Sergey Ioffe, “Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-\\nNormalized Models” (2017), https://arxiv.o rg/abs/1702.03275 .\\nb Günter Klambauer et al., “Self-Normalizing Neural Networks,” Conference on Neural Informa-\\ntion Processing Systems (2017), https://arxiv.o rg/abs/1706.02515 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 283}), Document(page_content=\"262 CHAPTER  7Advanced deep-learning best practices\\n \\nThese advantages become especially impo rtant when you’re training small models\\nfrom scratch on limited data. For instance , here’s how you can build a lightweight,\\ndepthwise separable convnet for an image-cla ssification task (softmax categorical clas-\\nsification) on a small dataset:\\nfrom keras.models import Sequential, Model\\nfrom keras import layers\\nheight = 64\\nwidth = 64\\nchannels = 3\\nnum_classes = 10\\nmodel = Sequential()\\nmodel.add(layers.SeparableConv2D(32, 3,\\nactivation='relu',input_shape=(height, width, channels,)))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.MaxPooling2D(2))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.SeparableConv2D(128, 3, activation='relu'))\\nmodel.add(layers.MaxPooling2D(2))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.SeparableConv2D(128, 3, activation='relu'))\\nmodel.add(layers.GlobalAveragePooling2D())\\nmodel.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(num_classes, activation='softmax'))\\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\\nWhen it comes to larger-scale models, dept hwise separable convolutions are the basis\\nof the Xception architectu re, a high-performing convne t that comes packaged with\\nKeras. You can read more about the theo retical grounding for depthwise separable1 × 1 conv\\n(pointwise conv)\\nDepthwise co nvolutio n: \\nindepe ndent spatial \\nconvs pe r channelConcatenate\\nSplit channels3 × 3 conv 3 × 3 conv 3 × 3 conv 3 × 3 conv\\nFigure 7.16 Depthwise separable \\nconvolution: a depthwise convolution \\nfollowed by a pointwise convolution\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 284}), Document(page_content='263 Getting the most out of your models\\nconvolutions and Xception in my paper “X ception: Deep Learning with Depthwise\\nSeparable Convolutions.”8\\n7.3.2 Hyperparameter optimization\\nWhen building a deep-learning model, you have to make many seemingly arbitrary\\ndecisions: How many layers should you stac k? How many units or filters should go in\\neach layer? Should you use relu  as activation, or a different function? Should you use\\nBatchNormalization  after a given layer? How much dropout should you use? And so\\non. These architecture-level parameters are called hyperparameters  to distinguish them\\nfrom the parameters of a model, wh ich are trained vi a backpropagation.\\n In practice, experienced machine-learni ng engineers and researchers build intu-\\nition over time as to what  works and what doesn’t when it comes to these choices—\\nthey develop hyperparameter-tuning skills. Bu t there are no formal rules. If you want\\nto get to the very limit of what can be achieved on a given task, you can’t be content\\nwith arbitrary choices made by a fallible human. Your initial decisions are almost\\nalways suboptimal, even if you have good intuition. You can refine your choices by\\ntweaking them by hand and retraining the model repeatedly—that’s what machine-\\nlearning engineers and resear chers spend most of their ti me doing. But it shouldn’t\\nbe your job as a human to fiddle with hyperp arameters all day—that is better left to a\\nmachine.\\n Thus you need to explore the space of po ssible decisions auto matically, systemati-\\ncally, in a principled way. You need to sear ch the architecture sp ace and find the best-\\nperforming ones empirically. That’s what the field of automatic hyperparameter opti-\\nmization is about: it’s an entire fi eld of research, and an important one.\\n The process of optimizing hyperpar ameters typically looks like this:\\n1Choose a set of hyperparameters (automatically).\\n2Build the corresponding model.\\n3Fit it to your training data, and meas ure the final performance on the valida-\\ntion data.\\n4Choose the next set of hyperparameters to try (automatically).\\n5Repeat.\\n6Eventually, measure performance on your test data.\\nThe key to this process is the algorithm that uses this history of validation perfor-\\nmance, given various sets of  hyperparameters, to choose the next set of hyperparame-\\nters to evaluate. Many different techniqu es are possible: Bayesian optimization,\\ngenetic algorithms, simple random search, and so on.\\n Training the weights of a model is relati vely easy: you compute a loss function on a\\nmini-batch of data and then use the Back propagation algorithm to move the weights\\n8See note 5 above.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 285}), Document(page_content='264 CHAPTER  7Advanced deep-learning best practices\\nin the right direction. Updating hyperpar ameters, on the other hand, is extremely\\nchallenging. Consider the following:\\n\\uf0a1Computing the feedback signal (does th is set of hyperparameters lead to a\\nhigh-performing model on this task?) ca n be extremely expensive: it requires\\ncreating and training a new mode l from scratch on your dataset.\\n\\uf0a1The hyperparameter space is typically made  of discrete decisions and thus isn’t\\ncontinuous or differentiable. Hence, yo u typically can’t do gradient descent in\\nhyperparameter space. Inst ead, you must rely on gradient-free optimization\\ntechniques, which naturally are far le ss efficient than gradient descent.\\nBecause these challenges are difficult and th e field is still young, we currently only\\nhave access to very limited tools to optimi ze models. Often, it turns out that random\\nsearch (choosing hyperparameters to evaluate  at random, repeatedly) is the best solu-\\ntion, despite being the most naive one. But one tool I have found reliably better than\\nrandom search is Hyperopt ( https:/ /github.com/hyperopt/hyperopt ), a Python\\nlibrary for hyperparameter opti mization that internally uses trees of Parzen estimators\\nto predict sets of hyperparameters that ar e likely to work well. Another library called\\nHyperas ( https:/ /github.com/maxpumperla/hyperas ) integrates Hyperopt for use\\nwith Keras models. Do check it out.\\nNOTE One important issue to keep in mi nd when doing automatic hyperpa-\\nrameter optimization at scale is validation-set overfitting. Because you’reupdating hyperparameters based on a signal that is computed using your vali-dation data, you’re effectively training them on the validation data, and thusthey will quickly overfit to the valida tion data. Always keep this in mind.\\nOverall, hyperparameter optimization is a powerful technique that is an absolute\\nrequirement to get to state-of-the-art mode ls on any task or to win machine-learning\\ncompetitions. Think about it: once upon a ti me, people handcrafted the features that\\nwent into shallow machine-learning mode ls. That was very much suboptimal. Now,\\ndeep learning automates the task of hier archical feature engineering—features are\\nlearned using a feedback signal, not hand-t uned, and that’s the way it should be. In\\nthe same way, you shouldn’t handcraft your  model architectures;  you should optimize\\nthem in a principled way. At the time of writing, the field of automatic hyperparame-\\nter optimization is very young and immature, as deep learning was some years ago, but\\nI expect it to boom in the next few years. \\n7.3.3 Model ensembling\\nAnother powerful technique for obtaining the best possible results on a task is model\\nensembling . Ensembling consists of pooling togeth er the predictions of a set of differ-\\nent models, to produce better  predictions. If you look at machine-learning competi-\\ntions, in particular on Kaggle, you’ll see that the winners use very large ensembles of\\nmodels that inevitably beat any si ngle model, no matter how good.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 286}), Document(page_content='265 Getting the most out of your models\\n Ensembling relies on the assumption th at different good models trained inde-\\npendently are likely to be good for different reasons : each model looks at slightly differ-\\nent aspects of the data to make  its predictions, getting part  of the “truth” but not all of\\nit. You may be familiar with the ancient pa rable of the blind men and the elephant: a\\ngroup of blind men come across an elephant  for the first time and try to understand\\nwhat the elephant is by touching it. Each  man touches a different part of the ele-\\nphant’s body—just one part, su ch as the trunk or a leg. Then the men describe to\\neach other what an elephant is: “It’s like a snake,” “Like a pillar or  a tree,” and so on.\\nThe blind men are essentially machine-learning models tryi ng to understand the man-\\nifold of the training data, each from its own perspective, using its own assumptions\\n(provided by the unique architecture of th e model and the unique random weight ini-\\ntialization). Each of them gets part of the truth of the data, but not the whole truth. Bypooling their perspectives together, you can get a far more accurate description of thedata. The elephant is a combination of part s: not any single blind man gets it quite\\nright, but, interviewed together, they can tell a fairly accurate story.\\n Let’s use classification as an  example. The easiest way to pool the predictions of a set\\nof classifiers (to ensemble the classifiers ) is to average their pred ictions at inference time:\\npreds_a = model_a.predict(x_val)\\npreds_b = model_b.predict(x_val)preds_c = model_c.predict(x_val)\\npreds_d = model_d.predict(x_val)\\nfinal_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)\\nThis will work only if the cl assifiers are more or less equally good. If one of them is sig-\\nnificantly worse than the others, the final predictions may not be as good as the best\\nclassifier of the group.\\n A smarter way to ensemble classifiers is to do a weighted average, where the\\nweights are learned on the validation data—t ypically, the better classifiers are given a\\nhigher weight, and the worse classifiers are given a lower weight. To search for a good\\nset of ensembling weights, you can use random  search or a simple optimization algo-\\nrithm such as Nelder-Mead:\\npreds_a = model_a.predict(x_val)\\npreds_b = model_b.predict(x_val)\\npreds_c = model_c.predict(x_val)\\npreds_d = model_d.predict(x_val)\\nfinal_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d\\nThere are many possible variants: you can do an average of an exponential of the pre-\\ndictions, for instance. In general, a simple  weighted average with weights optimized\\non the validation data provides a very strong baseline.\\n The key to making ensembling work is the diversity  of the set of classifiers. Diversity\\nis strength. If all the blind men only touc hed the elephant’s trunk, they would agreeUse four different models to compute initial predictions.\\nThis new prediction array\\nshould be more accurate\\nthan any of the initial ones.\\nThese weights (0.5, 0.25,\\n0.1, 0.15) are assumed to\\nbe learned empirically.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 287}), Document(page_content='266 CHAPTER  7Advanced deep-learning best practices\\nthat elephants are like snakes, and they woul d forever stay ignorant of the truth of the\\nelephant. Diversity is what makes ensembling  work. In machine-lear ning terms, if all\\nof your models are biased in the same way,  then your ensemble will retain this same\\nbias. If your models are biased in different ways , the biases will cancel each other out,\\nand the ensemble will be more  robust and more accurate.\\n For this reason, you should ensemble models that are as good as possible  while being\\nas different as possible . This typically means using very  different architectures or even\\ndifferent brands of machin e-learning approaches. One thing that is largely not worth\\ndoing is ensembling the same  network trained several times independently, from dif-\\nferent random initializations. If the only di fference between your models is their ran-\\ndom initialization and the order in which they  were exposed to the training data, then\\nyour ensemble will be low-diversity and will  provide only a tiny improvement over any\\nsingle model.\\n One thing I have found to work well in practice—but that doesn’t generalize to\\nevery problem domain—is the use of an ense mble of tree-based methods (such as ran-\\ndom forests or gr adient-boosted trees) and deep ne ural networks. In 2014, partner\\nAndrei Kolev and I took fourth place in the Higgs Boson decay detection challenge\\non Kaggle (www.kaggle.com/ c/higgs-boson) using an ensemble of various tree mod-\\nels and deep neural networks . Remarkably, one of the mode ls in the ensemble origi-\\nnated from a different method than the others (it was a regularized greedy forest) and\\nhad a significantly worse score than the othe rs. Unsurprisingly, it was assigned a small\\nweight in the ensemble. But to our surpri se, it turned out to improve the overall\\nensemble by a large factor, because it was so  different from every other model: it pro-\\nvided information that the other models di dn’t have access to. That’s precisely the\\npoint of ensembling. It’s not so much abou t how good your best model is; it’s about\\nthe diversity of your set of candidate models.\\n In recent times, one style of basic ensemb le that has been very successful in prac-\\ntice is the wide and deep  category of models, blending de ep learning with shallow learn-\\ning. Such models consist of jointly training  a deep neural network with a large linear\\nmodel. The joint training of a family of  diverse models is yet another option to\\nachieve model ensembling. \\n7.3.4 Wrapping up\\n\\uf0a1When building high-performing deep convne ts, you’ll need to use residual con-\\nnections, batch normalization, and dept hwise separable convolutions. In the\\nfuture, it’s likely that depthwise separabl e convolutions will completely replace\\nregular convolutions, whether for 1D, 2D, or 3D applications, due to their\\nhigher representational efficiency.\\n\\uf0a1Building deep networks requires making many small hyperparameter and\\narchitecture choices, which together define how good your model will be.\\nRather than basing these choices on in tuition or random chance, it’s better to\\nsystematically search hyperparameter sp ace to find optimal choices. At this\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 288}), Document(page_content='267 Getting the most out of your models\\ntime, the process is expensive, and the t ools to do it aren’t very good. But the\\nHyperopt and Hyperas libraries may be ab le to help you. When doing hyperpa-\\nrameter optimization, be mindful of validation-set overfitting!\\n\\uf0a1Winning machine-learning competitions or otherwise obtaining the best possi-\\nble results on a task can only be done  with large ensembles of models. Ensem-\\nbling via a well-optimized weighted aver age is usually good enough. Remember:\\ndiversity is strength. It’s largely pointl ess to ensemble very similar models; the\\nbest ensembles are sets of models that are as dissimila r as possible (while having\\nas much predictive power as possible, naturally). \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 289}), Document(page_content='268 CHAPTER  7Advanced deep-learning best practices\\nChapter summary\\n\\uf0a1In this chapter, you learned the following:\\n– How to build models as arbitrary gr aphs of layers, reuse layers (layer\\nweight sharing), and use models as Python functions (model templating).\\n– You can use Keras callbacks to monitor your models during training and\\ntake action based on model state.\\n– TensorBoard allows you to visualize metrics, activation histograms, and\\neven embedding spaces.\\n– What batch normalization, depthwis e separable convolution, and resid-\\nual connections are.\\n– Why you should use hype rparameter optimization  and model ensembling.\\n\\uf0a1With these new tools, you’re better eq uipped to use deep learning in the\\nreal world and start buil ding highly competitive deep-learning models.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 290}), Document(page_content='269Generative deep learning\\nThe potential of artificial intelligence  to emulate human thought processes goes\\nbeyond passive tasks such as object recogn ition and mostly reactive tasks such as\\ndriving a car. It extends well  into creative activities. When I first made the claim that\\nin a not-so-distant future, mo st of the cultural content that we consume will be cre-\\nated with substantial help from AIs, I was met with utter di sbelief, even from long-\\ntime machine-learning practi tioners. That was in 2014. Fast-forward three years,\\nand the disbelief has receded—at an incr edible speed. In th e summer of 2015, we\\nwere entertained by Google’s DeepDream algorithm turning an image into a psy-\\nchedelic mess of dog eyes and pareidolic artifacts; in 2016, we used the Prisma appli-\\ncation to turn photos into paintings of various styles. In the summer of 2016, an\\nexperimental short movie, Sunspring , was directed using a script written by a Long\\nShort-Term Memory ( LSTM ) algorithm—complete with dialogue. Maybe you’ve\\nrecently listened to musi c that was tentatively gene rated by a neural network.This chapter covers\\n\\uf0a1Text generation with LSTM\\n\\uf0a1Implementing DeepDream\\n\\uf0a1Performing neural style transfer\\n\\uf0a1Variational autoencoders\\n\\uf0a1Understanding generative adversarial networks\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 291}), Document(page_content='270 CHAPTER  8Generative deep learning\\n Granted, the artistic pr oductions we’ve seen from AI so far have been fairly low\\nquality. AI isn’t anywhere close to rivaling  human screenwriters, painters, and compos-\\ners. But replacing humans was always beside  the point: artificial intelligence isn’t\\nabout replacing our own intelligence with some thing else, it’s abou t bringing into our\\nlives and work more intelligence—intelligence of a di fferent kind. In many fields, but\\nespecially in creative ones, AI will be used by humans as a tool to augment their own\\ncapabilities: more augmented  intelligence than artificial  intelligence.\\n A large part of artistic creation consists  of simple pattern recognition and technical\\nskill. And that’s precisely the part of the pr ocess that many find less attractive or even\\ndispensable. That’s where AI comes in. Our perceptual modalities, our language, and\\nour artwork all have statistica l structure. Learning this st ructure is what deep-learning\\nalgorithms excel at. Machine-learning  models can learn the statistical latent space  of\\nimages, music, and stories, and they can then sample  from this space, creating new art-\\nworks with characteristics similar to those th e model has seen in its training data. Nat-\\nurally, such sampling is hardly an act of artistic creation in itself. It’s a mere\\nmathematical operation: th e algorithm has no groundin g in human life, human emo-\\ntions, or our experience of the world; instead, it learns from an experience that has lit-tle in common with ours. It’s only our in terpretation, as human spectators, that will\\ngive meaning to what the model generates. But in the hands of a skilled artist, algo-\\nrithmic generation can be steered to be come meaningful—and beautiful. Latent\\nspace sampling can become a brush that em powers the artist, augments our creative\\naffordances, and expands the space of what we can imagine. What’s more, it can make\\nartistic creation more accessible by elimin ating the need for tec hnical skill and prac-\\ntice—setting up a new medium of pure ex pression, factoring art apart from craft.\\n Iannis Xenakis, a visionary pioneer of el ectronic and algorith mic music, beauti-\\nfully expressed this same idea in the 1960s, in the context of the application of auto-mation technology to music composition:\\n1\\nFreed from tedious calculations, the composer is able to devote himself to the general\\nproblems that the new musical form poses and to explore the nooks and crannies of this\\nform while modifying the values of the in put data. For example,  he may test all\\ninstrumental combinations from soloists to chamber orchestras, to large orchestras. With\\nthe aid of electronic computers  the composer becomes a sort of  pilot: he presses the buttons,\\nintroduces coordinates, and supervises the cont rols of a cosmic vessel sailing in the space\\nof sound, across sonic constellations and ga laxies that he could formerly glimpse only as\\na distant dream.\\nIn this chapter, we’ll explore from variou s angles the potential of deep learning to\\naugment artistic creation. We’ll review sequ ence data generation (which can be used\\nto generate text or music), DeepDream, and image generation using both variational\\nautoencoders and generative adversarial ne tworks. We’ll get your computer to dream\\nup content never seen before; and maybe we’ll get you to dream, too, about the fan-tastic possibilities that lie at the intersecti on of technology and art. Let’s get started.\\n1Iannis Xenakis, “Musiques formelles:  nouveaux principes form els de composition musicale,” special issue of La\\nRevue musicale , nos. 253 -254 (1963).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 292}), Document(page_content='271 Text generation with LSTM\\n8.1 Text generation with LSTM\\nIn this section, we’ll explor e how recurrent neural networ ks can be used to generate\\nsequence data. We’ll use text generation as an example, but the exact same tech-\\nniques can be generalized to any kind of sequence data: you could apply it to\\nsequences of musical notes in order to gene rate new music, to timeseries of brush-\\nstroke data (for example, re corded while an artist pain ts on an iPad) to generate\\npaintings stroke by stroke, and so on.\\n Sequence data generation is in no way limited to artistic content generation. It\\nhas been successfully applied to speech synthesis and to dialogue generation for chat-\\nbots. The Smart Reply fe ature that Google released in 2016, capable of automatically\\ngenerating a selection of quick replies to em ails or text messages,  is powered by simi-\\nlar techniques.\\n8.1.1 A brief history of generative recurrent networks\\nIn late 2014, few people had ever seen the initials LSTM , even in the machine-learning\\ncommunity. Successful applications of sequence data generation with recurrent net-\\nworks only began to appear in the mainstre am in 2016. But these techniques have a\\nfairly long history, starting with the development of the LSTM  algorithm in 1997.2 This\\nnew algorithm was used early on to ge nerate text character by character.\\n In 2002, Douglas Eck, then at Schm idhuber’s lab in Switzerland, applied LSTM  to\\nmusic generation for the first time, with pr omising results. Eck is now a researcher at\\nGoogle Brain, and in 2016 he started a new research group there, called Magenta,\\nfocused on applying modern deep-learnin g techniques to produce engaging music.\\nSometimes, good ideas take  15 years to get started.\\n In the late 2000s and early 2010s, Alex Graves did important pioneering work on\\nusing recurrent networks for sequence data  generation. In particular, his 2013 work\\non applying recurrent mixtur e density networks to generate human-like handwriting\\nusing timeseries of pen positions is seen by some as a turning point.3 This specific\\napplication of neural networks at that spec ific moment in time captured for me the\\nnotion of machines that dream  and was a significant insp iration around the time I\\nstarted developing Keras. Graves left a similar commented-out remark hidden in a\\n2013 LaTeX file uploaded to the preprint se rver arXiv: “generating sequential data is\\nthe closest computers get to dreaming.” Several years later, we take a lot of these devel-\\nopments for granted; but at the time, it wa s difficult to watch Graves’s demonstrations\\nand not walk away awe-insp ired by the possibilities.\\n Since then, recurrent neural  networks have been succe ssfully used for music gener-\\nation, dialogue generation, image generation, speech synthe sis, and mole cule design.\\nThey were even used to produce a movie scri pt that was then cast with live actors. \\n2Sepp Hochreiter and Jürgen Schmidhuber, “Long Short-Term Memory,” Neural Computation  9, no. 8 (1997).\\n3Alex Graves, “Generating Sequences With Recurrent Neural Networks,” arXiv (2013), https:/ /arxiv.org/\\nabs/1308.0850 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 293}), Document(page_content='272 CHAPTER  8Generative deep learning\\n8.1.2 How do you generate sequence data?\\nThe universal way to generate sequence data in  deep learning is to train a network (usu-\\nally an RNN  or a convnet) to predict the next to ken or next few tokens in a sequence,\\nusing the previous tokens as input. For inst ance, given the input “the cat is on the ma,”\\nthe network is trained to predict the target t, the next character. As usual when working\\nwith text data, tokens  are typically words or characters , and any network that can model\\nthe probability of the next token give n the previous ones is called a language model . A\\nlanguage model captures the latent space  of language: its statistical structure.\\n Once you have such a trained language model, you can sample  from it (generate\\nnew sequences): you feed it an initial string of text (called conditioning data ), ask it to\\ngenerate the next character or the next word  (you can even generate several tokens at\\nonce), add the generated output back to the input data, and repeat the process many\\ntimes (see figure 8.1). This loop allows yo u to generate sequences of arbitrary length\\nthat reflect the structure of  the data on which the mode l was trained: sequences that\\nlook almost  like human-written sentences. In th e example we present in this section,\\nyou’ll take a LSTM  layer, feed it strings of N characters extracted from a text corpus,\\nand train it to predict character N + 1. The output of the model will be a softmax over\\nall possible characters: a probability dist ribution for the next character. This LSTM  is\\ncalled a character-level neural language model . \\n8.1.3 The importance of the sampling strategy\\nWhen generating text, the way you choose the next character is crucially important. A\\nnaive approach is greedy sampling , consisting of always choosing the most likely next\\ncharacter. But such an approach results in  repetitive, predictable strings that don’t\\nlook like coherent language. A more intere sting approach makes slightly more sur-\\nprising choices: it introduces randomness in  the sampling proce ss, by sampling from\\nthe probability distribution for the next character. This is called stochastic sampling\\n(recall that stochasticity  is what we call randomness  in this field). In such a setup, if e has\\na probability 0.3 of being the next characte r, according to the model, you’ll choose itLanguage\\nmodelInitial textProbability\\ndistribution for the\\nnext character Initial textSampled next\\ncharacter\\nSampling\\nstrategya The cat sat on the m\\nLanguage\\nmodel\\n...Sampling\\nstrategyt The cat sat on the ma\\nFigure 8.1 The process of character-by-charact er text generation using a language model\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 294}), Document(page_content='273 Text generation with LSTM\\n30% of the time. Note that greedy sampling ca n be also cast as sampling from a prob-\\nability distribution: one where a certain char acter has probability 1 and all others have\\nprobability 0.\\n Sampling probabilistically from the softma x output of the mode l is neat: it allows\\neven unlikely characters to be sampled some of the time, generating more interesting-\\nlooking sentences and sometime s showing creativity by comi ng up with new, realistic-\\nsounding words that didn’t occur in the tr aining data. But there’ s one issue with this\\nstrategy: it doesn’t offer a way to control the amount of randomness  in the sampling process.\\n Why would you want more or less rand omness? Consider an extreme case: pure\\nrandom sampling, where you draw the next character from a unif orm probability dis-\\ntribution, and every characte r is equally likely. This scheme has maximum random-\\nness; in other words, this probability distri bution has maximum entropy. Naturally, it\\nwon’t produce anything interesting. At th e other extreme, greedy sampling doesn’t\\nproduce anything interesting, either, an d has no randomness: the corresponding\\nprobability distribution has minimum entropy. Sampling from the “real” probability\\ndistribution—the distribution  that is output by the mo del’s softmax fu nction—consti-\\ntutes an intermediate point between thes e two extremes. But there are many other\\nintermediate points of higher or lower entropy that you may want to explore. Less\\nentropy will give the generated sequences a more predictable structure (and thus they\\nwill potentially be more realistic looking) , whereas more entropy will result in more\\nsurprising and creative sequen ces. When sampling from generative models, it’s always\\ngood to explore different amounts of rand omness in the generation process. Because\\nwe—humans—are the ultimate judges of how interesting the generated data is, inter-\\nestingness is highly subjective, and there’ s no telling in advance where the point of\\noptimal entropy lies.\\n In order to control the amount of stochast icity in the sampling process, we’ll intro-\\nduce a parameter called the softmax temperature  that characterizes the entropy of the\\nprobability distribution used for sampling: it characterizes how su rprising or predict-\\nable the choice of the next character will be. Given a temperature  value, a new proba-\\nbility distribution is comp uted from the original one (the softmax output of the\\nmodel) by reweighting it  in the following way.\\nimport numpy as np\\ndef reweight_distribution(original_distribution, temperature=0.5):\\ndistribution = np.log(original_distribution) / temperature\\ndistribution = np.exp(distribution)return distribution / np.sum(distribution)Listing 8.1 Reweighting a probability distribution to a different temperature\\noriginal_distribution is a 1D Numpy array \\nof probability values that must sum to 1. \\ntemperature is a factor quantifying the \\nentropy of the outp ut distribution.Returns a reweighted version of \\nthe original distribution. The sum of the distribution  may no longer \\nbe 1, so you divide it by its sum to \\nobtain the new distribution.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 295}), Document(page_content=\"274 CHAPTER  8Generative deep learning\\nHigher temperatures result in sampling distributions of higher entropy that will generate more\\nsurprising and unstructured generated data, whereas a lower temperature will result in less ran-\\ndomness and much more predictable generated data (see figure 8.2). \\n8.1.4 Implementing character- level LSTM text generation\\nLet’s put these ideas into pr actice in a Keras implementa tion. The first thing you need\\nis a lot of text data that you can use to learn a language model. You can use any suffi-\\nciently large text file or set of text files—Wikipedia, The Lord of the Rings , and so on. In\\nthis example, you’ll use some of the writings of Nietzsche, the late-nineteenth century\\nGerman philosopher (translated into Englis h). The language model you’ll learn will\\nthus be specifically a model of Nietzsche’s writing style and topics of choice, ratherthan a more generic model of the English language.\\nPREPARING  THE DATA\\nLet’s start by downloading the corpus  and converting it to lowercase.\\nimport keras\\nimport numpy as np\\npath = keras.utils.get_file(\\n'nietzsche.txt',\\norigin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\\ntext = open(path).read().lower()print('Corpus length:', len(text))Listing 8.2 Downloading and parsing the initial text file\\ntemperature = 0.01 temperature = 0.2 temperature = 0.4\\ntemperature = 0.6Discrete elements (characters)Probability of sampling element\\ntemperature = 0.8 temperature = 1.0\\nFigure 8.2 Different reweightings of one probability distribution. Low temperature = more \\ndeterministic, high temperature = more random.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 296}), Document(page_content=\"275 Text generation with LSTM\\nNext, you’ll extract partially overlapping sequences of length maxlen , one-hot encode\\nthem, and pack them in a 3D Numpy array x of shape (sequences,  maxlen,\\nunique_characters) . Simultaneously, you’ll prepare an array y containing the corre-\\nsponding targets: the one-hot-encoded char acters that come after each extracted\\nsequence.\\nmaxlen = 60\\nstep = 3\\nsentences = []next_chars = []\\nfor i in range(0, len(text) - maxlen, step):\\nsentences.append(text[i : i + maxlen])\\nnext_chars.append(text[i + maxlen])\\nprint('Number of sequences:', len(sentences))\\nchars = sorted(list(set(text)))\\nprint('Unique characters:', len(chars))char_indices = dict((char, chars.index(char)) for char in chars)\\nprint('Vectorization...')\\nx = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)y = np.zeros((len(sentences), len(chars)), dtype=np.bool)for i, sentence in enumerate(sentences):\\nfor t, char in enumerate(sentence):\\nx[i, t, char_indices[char]] = 1\\ny[i, char_indices[next_chars[i]]] = 1\\nBUILDING  THE NETWORK\\nThis network is a single LSTM  layer followed by a Dense  classifier and softmax over all\\npossible characters. But note that recurrent neural networks aren’t the only way to do\\nsequence data generation; 1D convnets also have proven extremely successful at this\\ntask in recent times.\\nfrom keras import layers\\nmodel = keras.models.Sequential()\\nmodel.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))model.add(layers.Dense(len(chars), activation='softmax'))Listing 8.3 Vectorizing sequences of characters\\nListing 8.4 Single-layer LSTM model for next-character predictionYou’ll extract sequences \\nof 60 characters.\\nYou’ll sample a new sequence \\nevery three characters.\\nHolds the extracted sequences\\nHolds the targets (the \\nfollow-up characters)\\nList of unique characters \\nin the corpus\\nOne-hot encodes \\nthe characters into binary arraysDictionary that maps\\nunique characters to their\\nindex in the list “chars”\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 297}), Document(page_content='276 CHAPTER  8Generative deep learning\\nBecause your targets are one-hot encoded, you’ll use categorical_crossentropy  as\\nthe loss to train the model. \\noptimizer = keras.optimizers.RMSprop(lr=0.01)\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=optimizer)\\nTRAINING  THE LANGUAGE  MODEL  AND SAMPLING  FROM IT\\nGiven a trained model and a seed text snippet, you can generate new text by doing the\\nfollowing repeatedly:\\n1Draw from the model a probability distribu tion for the next character, given the\\ngenerated text available so far.\\n2Reweight the distribution to a certain temperature.\\n3Sample the next character at random ac cording to the reweig hted distribution.\\n4Add the new character at the end of the available text.\\nThis is the code you use to reweight the or iginal probability dist ribution coming out\\nof the model and draw a char acter index from it (the sampling function ).\\ndef sample(preds, temperature=1.0):\\npreds = np.asarray(preds).astype(\\'float64\\')\\npreds = np.log(preds) / temperatureexp_preds = np.exp(preds)\\npreds = exp_preds / np.sum(exp_preds)\\nprobas = np.random.multinomial(1, preds, 1)return np.argmax(probas)\\nFinally, the following loop repeatedly trai ns and generates text. You begin generating\\ntext using a range of different temperatures after every epoch. This allows you to see\\nhow the generated text evolves as the model begins to converge, as well as the impactof temperature in the sampling strategy.\\nimport random\\nimport sys\\nfor epoch in range(1, 60):\\nprint(\\'epoch\\', epoch)\\nmodel.fit(x, y, batch_size=128, epochs=1)start_index = random.randint(0, len(text) - maxlen - 1)\\ngenerated_text = text[start_index: start_index + maxlen]\\nprint(\\'--- Generating with seed: \"\\' + generated_text + \\'\"\\')\\nfor temperature in [0.2, 0.5, 1.0, 1.2]:\\nprint(\\'------ temperature:\\', temperature)sys.stdout.write(generated_text)Listing 8.5 Model compilation configuration\\nListing 8.6 Function to sample the next character given the model’s predictions\\nListing 8.7 Text-generation loop\\nTrains the model for 60 epochs\\nFits the model for one iteration \\non the data \\nSelects a text \\nseed at \\nrandom\\nTries a range of different sampling temperatures\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 298}), Document(page_content='277 Text generation with LSTM\\nfor i in range(400):\\nsampled = np.zeros((1, maxlen, len(chars)))for t, char in enumerate(generated_text):\\nsampled[0, t, char_indices[char]] = 1.\\npreds = model.predict(sampled, verbose=0)[0]\\nnext_index = sample(preds, temperature)\\nnext_char = chars[next_index]\\ngenerated_text += next_char\\ngenerated_text = generated_text[1:]\\nsys.stdout.write(next_char)\\nHere, we used the random seed text “new faculty, and the jubilation reached its cli-\\nmax when kant.” Here’s what you get at epoch 20, long before the model has fully\\nconverged, with temperature=0.2 :\\nnew faculty, and the jubilation reached its climax when kant and such a man\\nin the same time the spirit of the surely and the such the suchas a man is the sunligh and subject the present to the superiority of thespecial pain the most man and strange the subjection of the\\nspecial conscience the special and nature and such men the subjection of the\\nspecial men, the most surely the subjection of the specialintellect of the subjection of the same things and\\nHere’s the result with temperature=0.5 :\\nnew faculty, and the jubilation reached its climax when kant in the eternedand such man as it\\'s also become himself the condition of theexperience of off the basis the superiory and the special morty of the\\nstrength, in the langus, as which the same time life and \"even who\\ndiscless the mankind, with a subject and fact all you have to be the standand lave no comes a troveration of the man and surely the\\nconscience the superiority, and when one must be w\\nAnd here’s what you get with temperature=1.0 :\\nnew faculty, and the jubilation reached its climax when kant, as a\\nperiliting of manner to all definites and transpects it it so\\nhicable and ont him artiar resull\\ntoo such as if ever the proping to makes as cnecience. to been juden,all every could coldiciousnike hother aw passife, the plies like\\nwhich might thiod was account, indifferent germin, that everythery\\ncertain destrution, intellect into the deteriorablen origin of moralian,and a lessority o\\nAt epoch 60, the model has most ly converged, and the text starts to look significantly\\nmore coherent. Here’s the result with temperature=0.2 :\\ncheerfulness, friendliness and kindness of a heart are the sense of the\\nspirit is a man with the sense of the sense of the world of the\\nself-end and self-concerning the subjection of the strengthorixes--theGenerates 400\\ncharacters,\\nstarting from\\nthe seed textOne-hot encodes \\nthe characters \\ngenerated so far\\nSamples \\nthe next \\ncharacter\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 299}), Document(page_content='278 CHAPTER  8Generative deep learning\\nsubjection of the subjection of the subjection of the\\nself-concerning the feelings in the superiority in the subjection of the\\nsubjection of the spirit isn\\'t to be a man of the sense of thesubjection and said to the strength of the sense of the\\nHere’s temperature=0.5 :\\ncheerfulness, friendliness and kindness of a heart are the part of the soulwho have been the art of the philosophers, and which the onewon\\'t say, which is it the higher the and with religion of the frences.\\nthe life of the spirit among the most continuess of the\\nstrengther of the sense the conscience of men of precisely before enoughpresumption, and can mankind, and something the conceptions, the\\nsubjection of the sense and suffering and the\\nAnd here’s temperature=1.0 :\\ncheerfulness, friendliness and kindness of a heart are spiritual by the\\nciuture for the\\nentalled is, he astraged, or errors to our you idstood--and it needs,\\nto think by spars to whole the amvives of the newoatly, prefectlyraals! it wasname, for example but voludd atu-especity\"--or rank onee, or even all\\n\"solett increessic of the world and\\nimplussional tragedy experience, transf, or insiderar,--must hastif desires of the strubction is be stronges\\nAs you can see, a low temperature value resu lts in extremely repetitive and predictable\\ntext, but local structure is highly re alistic: in particular, all words (a word being a local\\npattern of characters) are real English wo rds. With higher te mperatures, the gener-\\nated text becomes more inte resting, surprising, even cr eative; it sometimes invents\\ncompletely new words that sound somewhat plausible (such as eterned  and troveration ).\\nWith a high temperature, th e local structure starts to break down, and most words\\nlook like semi-random strings of characters. Without a doubt, 0.5 is the most interest-\\ning temperature for text generation in this  specific setup. Al ways experiment with\\nmultiple sampling strategies! A clever bala nce between learned st ructure and random-\\nness is what makes generation interesting.\\n Note that by training a bigger model, longer, on more data, you can achieve gen-\\nerated samples that look mu ch more coherent and realistic than this one. But, of\\ncourse, don’t expect to ever generate an y meaningful text, other than by random\\nchance: all you’re doing is sampling data from a statistical model of which characters\\ncome after which characters. Language is  a communication channel, and there’s a\\ndistinction between what communications are about and the statistical structure of\\nthe messages in which communi cations are encoded. To evidence this distinction,\\nhere’s a thought experiment: what if huma n language did a better job of compressing\\ncommunications, much like computers do with most digital communications?\\nLanguage would be no less meaningful, but it  would lack any intrinsic statistical struc-\\nture, thus making it impossible to learn a language model as you just did. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 300}), Document(page_content='279 Text generation with LSTM\\n8.1.5 Wrapping up\\n\\uf0a1You can generate discrete sequence data by training a model to predict the next\\ntokens(s), given previous tokens.\\n\\uf0a1In the case of text, such a model is called a language model . It can be based on\\neither words or characters.\\n\\uf0a1Sampling the next token requires balanc e between adhering to what the model\\njudges likely, and introducing randomness.\\n\\uf0a1One way to handle this is the notion of softmax temperature. Always experi-\\nment with different temperatur es to find the right one. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 301}), Document(page_content='280 CHAPTER  8Generative deep learning\\n8.2 DeepDream\\nDeepDream  is an artistic image-modification te chnique that uses the representations\\nlearned by convolutional neural networks. It  was first released by Google in the sum-\\nmer of 2015, as an implementation written using the Caffe deep-learning library (this\\nwas several months before the firs t public release of TensorFlow).4 It quickly became\\nan internet sensation thanks to the trippy pictures it could generate (see, for example,figure 8.3), full of algorithmic pareidolia  artifacts, bird feathers, and dog eyes—a\\nbyproduct of the fact that the DeepDream convnet was trained on ImageNet, wheredog breeds and bird species are vastly overrepresented.\\nThe DeepDream algorithm is almost identical to the convnet filter-visualization tech-\\nnique introduced in chapter 5, consisting of running a convnet in reverse: doing gra-\\ndient ascent on the input to the convnet in  order to maximize the activation of a\\nspecific filter in an upper layer of the conv net. DeepDream uses this same idea, with a\\nfew simple differences:\\n\\uf0a1With DeepDream, you try to maximize the activation of entire layers ratherthan that of a specific fi lter, thus mixing together visualizations of large num-\\nbers of features at once.\\n4Alexander Mordvintsev, Christopher Olah, and Mike Tyka, “DeepDream: A Code Example for Visualizing\\nNeural Networks,” Google Research Blog , July 1, 2015, http:/ /mng.bz/xXlM .\\nFigure 8.3 Example of a DeepDream output image\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 302}), Document(page_content=\"281 DeepDream\\n\\uf0a1You start not from blank, slightly nois y input, but rather from an existing\\nimage—thus the resulting effects latch on to preexisting visual patterns, distort-\\ning elements of the image in a somewhat artistic fashion.\\n\\uf0a1The input images are processed at different scales (called octaves ), which\\nimproves the quality of the visualizations.\\nLet’s make some DeepDreams.\\n8.2.1 Implementing DeepDream in Keras\\nYou’ll start from a convnet pretrained on Ima geNet. In Keras, many such convnets are\\navailable: VGG16 , VGG19 , Xception, ResNet50, and so on. You can implement Deep-\\nDream with any of them, but your convnet of choice will naturally affect your visualiza-\\ntions, because different convne t architectures result in di fferent learned features. The\\nconvnet used in the original DeepDream rele ase was an Inception model, and in prac-\\ntice Inception is known to produce nice-looking DeepDreams, so you’ll use the Incep-\\ntion V3 model that comes with Keras.\\nfrom keras.applications import inception_v3\\nfrom keras import backend as K\\nK.set_learning_phase(0)\\nmodel = inception_v3.InceptionV3(weights='imagenet',\\ninclude_top=False)\\nNext, you’ll compute the loss: the quantity you’ll seek to maximize during the gradient-ascent\\nprocess. In chapter 5, for filter visualization, you tried to maximize the value of a specific filter\\nin a specific layer. Here, you’ll simultaneously maximize the activation of all filters in a numberof layers. Specifically, you’ll maximize a weighted sum of the L2 norm of the activations of a setof high-level layers. The exact set of layers you choose (as well as their contribution to the final\\nloss) has a major influence on the visuals you’ll be able to produce, so you want to make these\\nparameters easily configurable. Lower layers result in geometric patterns, whereas higher layersresult in visuals in which you can recognize some classes from ImageNet (for example, birds or\\ndogs). You’ll start from a somewhat arbitrary configuration involving four layers—but you’ll\\ndefinitely want to explore many different configurations later.\\nlayer_contributions = {\\n'mixed2': 0.2,\\n'mixed3': 3.,'mixed4': 2.,\\n'mixed5': 1.5,\\n}Listing 8.8 Loading the pretrained Inception V3 model\\nListing 8.9 Setting up the DeepDream configurationYou won’t be training the model, so \\nthis command disab les all training-\\nspecific operations.\\nBuilds the Inception V3 network, \\nwithout its convolutional base. \\nThe model will be loaded with \\npretrained ImageNet weights.\\nDictionary mapping layer names to a coefficient quantifying \\nhow much the layer’s activati on contributes to the loss \\nyou’ll seek to maximize. Note  that the layer names are \\nhardcoded in the built-in Ince ption V3 application. You can \\nlist all layer names using model.summary().\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 303}), Document(page_content=\"282 CHAPTER  8Generative deep learning\\nNow, let’s define a tensor th at contains the loss: the weighted sum of the L2 norm of\\nthe activations of the layers in listing 8.9.\\nlayer_dict = dict([(layer.name, layer) for layer in model.layers])\\nloss = K.variable(0.)\\nfor layer_name in layer_contributions:\\ncoeff = layer_contributions[layer_name]\\nactivation = layer_dict[layer_name].output\\nscaling = K.prod(K.cast(K.shape(activation), 'float32'))\\nloss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling\\nNext, you can set up the gradient-ascent process.\\ndream = model.input\\ngrads = K.gradients(loss, dream)[0]\\ngrads /= K.maximum(K.mean(K.abs(grads)), 1e-7)outputs = [loss, grads]\\nfetch_loss_and_grads = K.function([dream], outputs)\\ndef eval_loss_and_grads(x):\\nouts = fetch_loss_and_grads([x])\\nloss_value = outs[0]\\ngrad_values = outs[1]return loss_value, grad_values\\ndef gradient_ascent(x, iterations, step, max_loss=None):\\nfor i in range(iterations):\\nloss_value, grad_values = eval_loss_and_grads(x)\\nif max_loss is not None and loss_value > max_loss:\\nbreak\\nprint('...Loss value at', i, ':', loss_value)\\nx += step * grad_values\\nreturn x\\nFinally: the actual DeepDream algorith m. First, you define a list of scales  (also called\\noctaves ) at which to process the images. Each su ccessive scale is larger than the previ-\\nous one by a factor of 1.4 (it’s 40% larger):  you start by processi ng a small image and\\nthen increasingly scale it up (see figure 8.4).Listing 8.10 Defining the loss to be maximized\\nListing 8.11 Gradient-ascent processCreates a dictionary that maps \\nlayer names to layer instances\\nYou’ll define the loss by adding \\nlayer contributions to this \\nscalar variable.\\nRetrieves the layer’s outputAdds the L2 norm of the features of a layer\\nto the loss. You avoi d border artifacts by\\nonly involving nonborde r pixels in the loss.\\nThis tensor holds the \\ngenerated image: the dream. Computes the gradients of the \\ndream with regard to the loss\\nNormalizes the gradients  \\n(important trick)\\nSets up a Keras function \\nto retrieve the value of \\nthe loss and gradients, given an input image\\nThis function runs \\ngradient ascent for a \\nnumber of iterations.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 304}), Document(page_content=\"283 DeepDream\\n \\nFor each successive scale, from the smallest to the largest, you run gradient ascent to\\nmaximize the loss you previously defined, at that scale. After each  gradient ascent run,\\nyou upscale the resu lting image by 40%.\\n To avoid losing a lot of image detail af ter each successive sc ale-up (resulting in\\nincreasingly blurry or pixelated images), yo u can use a simple trick: after each scale-\\nup, you’ll reinject the lost details back in to the image, which is possible because you\\nknow what the original image should look lik e at the larger scale. Given a small image\\nsize S and a larger image size L, you can compute the difference between the original\\nimage resized to size L and the original resized to size S—this difference quantifies the\\ndetails lost when going from S to L.\\nimport numpy as np\\nstep = 0.01\\nnum_octave = 3\\noctave_scale = 1.4\\niterations = 20\\nmax_loss = 10.base_image_path = '...'img = preprocess_image(base_image_path)Listing 8.12 Running gradient ascent over different successive scales\\nDream\\nOctave 1\\nOctave 2\\nOctave 3UpscaleDetail\\nreinjectionDetail\\nreinjection\\nDream Upscale Dream\\nFigure 8.4 The DeepDream process: successive scales of  spatial processing (octaves) and detail reinjection \\nupon upscaling\\nPlaying with these hyperparameters \\nwill let you achieve new effects.\\nNumber of scales at which to run \\ngradient ascent\\nSize ratio between scales\\nNumber of ascent steps to \\nrun at each scale\\nIf the loss grows larger than 10, you’ll interrupt \\nthe gradient-ascent process to avoid ugly artifacts.\\nFill this with the path to the image you want to use.Gradient ascent step size\\nLoads the base image into a Numpy \\narray (function is defined in listing 8. 13)\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 305}), Document(page_content=\"284 CHAPTER  8Generative deep learning\\noriginal_shape = img.shape[1:3]\\nsuccessive_shapes = [original_shape]\\nfor i in range(1, num_octave):\\nshape = tuple([int(dim / (octave_scale ** i))\\n   for dim in original_shape])\\nsuccessive_shapes.append(shape)\\nsuccessive_shapes = successive_shapes[::-1]\\noriginal_img = np.copy(img)\\nshrunk_original_img = resize_img(img, successive_shapes[0])\\nfor shape in successive_shapes:\\nprint('Processing image shape', shape)\\nimg = resize_img(img, shape)\\nimg = gradient_ascent(img,\\niterations=iterations,\\nstep=step,\\nmax_loss=max_loss)\\nupscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\\nsame_size_original = resize_img(original_img, shape)\\nlost_detail = same_size_original - upscaled_shrunk_original_img\\nimg += lost_detail\\nshrunk_original_img = resize_img(original_img, shape)save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\\nsave_img(img, fname='final_dream.png')\\nNote that this code uses the following straightforward auxiliary Numpy functions,\\nwhich all do as their names suggest. They  require that you have SciPy installed.\\nimport scipy\\nfrom keras.preprocessing import image\\ndef resize_img(img, size):\\nimg = np.copy(img)\\nfactors = (1,\\nfloat(size[0]) / img.shape[1],float(size[1]) / img.shape[2],\\n1)\\nreturn scipy.ndimage.zoom(img, factors, order=1)\\ndef save_img(img, fname):\\npil_img = deprocess_image(np.copy(img))\\nscipy.misc.imsave(fname, pil_img)\\ndef preprocess_image(image_path):\\nimg = image.load_img(image_path)\\nimg = image.img_to_array(img)Listing 8.13 Auxiliary functionsPrepares a list of shape \\ntuples defining the different \\nscales at which to run gradient ascent\\nReverses the list of \\nshapes so they’re in \\nincreasing order\\nResizes the Numpy\\narray of the image\\nto the smallest scaleScales up\\nthe\\ndream\\nimage\\nRuns gradient\\nascent, altering\\nthe dreamScales up the smaller\\nversion of the original\\nimage: it will be pixellated.\\nComputes the high-quality version \\nof the original image at this sizeThe difference between the two is the\\ndetail that was lost when scaling up.Reinjects lost detail into the dream\\nUtil function to open, resize, and \\nformat pictures  into tensors \\nthat Inception V3 can process\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 306}), Document(page_content=\"285 DeepDream\\nimg = np.expand_dims(img, axis=0)\\nimg = inception_v3.preprocess_input(img)\\nreturn img\\ndef deprocess_image(x):\\nif K.image_data_format() == 'channels_first':\\nx = x.reshape((3, x.shape[2], x.shape[3]))x = x.transpose((1, 2, 0))\\nelse:\\nx = x.reshape((x.shape[1], x.shape[2], 3))\\nx/ =2 .\\nx+ =0 . 5\\nx *= 255.x = np.clip(x, 0, 255).astype('uint8')\\nreturn x\\nNOTE Because the original Inception V3 network was trained to recognize\\nconcepts in images of size 299 × 299, and given that the process involves scal-\\ning the images down by a reasonable factor, the DeepDream implementationproduces much better results on imag es that are somewhere between 300 ×\\n300 and 400 × 400. Regardless, you can run the same code on images of anysize and any ratio.\\nStarting from a photograph taken in the small hills between San Francisco Bay and\\nthe Google campus, we obtained the DeepDream shown in figure 8.5.\\nWe strongly suggest that yo u explore what you can do by adjusting which layers you\\nuse in your loss. Layers that are lower in  the network contain more-local, less-abstract\\nrepresentations and lead to dream patterns th at look more geometri c. Layers that are\\nhigher up lead to more-recognizable vi sual patterns based on the most common\\nobjects found in ImageNet, such as dog ey es, bird feathers, and so on. You can useUtil function to convert a \\ntensor into a valid image\\nUndoes preprocessing that \\nwas performed by \\ninception_v3.preprocess_\\ninput\\nFigure 8.5 Running the DeepDream code on an example image\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 307}), Document(page_content='286 CHAPTER  8Generative deep learning\\nrandom generation of the parameters in the layer_contributions  dictionary to\\nquickly explore many different layer combinat ions. Figure 8.6 shows a range of results\\nobtained using different layer configuratio ns, from an image of a delicious home-\\nmade pastry. \\n8.2.2 Wrapping up\\n\\uf0a1DeepDream consists of running a convnet in reverse to generate inputs based\\non the representations learned by the network.\\n\\uf0a1The results produced are fun and somewh at similar to the visual artifacts\\ninduced in humans by the disruption of  the visual cortex via psychedelics.\\n\\uf0a1Note that the process isn’t specific to im age models or even to convnets. It can\\nbe done for speech , music, and more. \\nFigure 8.6 Trying a range of DeepDream configurations on an example image\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 308}), Document(page_content='287 Neural style transfer\\n8.3 Neural style transfer\\nIn addition to DeepDream, another major development in deep-learning-driven\\nimage modification is neural style transfer , introduced by Leon Gatys et al. in the sum-\\nmer of 2015.5 The neural style transfer algori thm has undergone many refinements\\nand spawned many variations since its origin al introduction, and it has made its way\\ninto many smartphone photo apps. For simpli city, this section focuses on the formula-\\ntion described in the original paper.\\n Neural style transfer consis ts of applying the style of a reference image to a target\\nimage while conserving the content of the ta rget image. Figure 8.7 shows an example.\\nIn this context, style essentially means textur es, colors, and visual patterns in the image, at\\nvarious spatial scales; and the content  is the higher-level macrostructure of the image.\\nFor instance, blue-and-yellow circular brushstr okes are considered to be the style in fig-\\nure 8.7 (using Starry Night  by Vincent Van Gogh), and the buildings in the Tübingen\\nphotograph are considered to be the content.\\n The idea of style transfer, which is tightl y related to that of texture generation, has\\nhad a long history in the image-processi ng community prior to the development of\\nneural style transfer in 2015. But as it tu rns out, the deep-learning-based implementa-\\ntions of style transfer offer results unparalleled by what had been previously achieved\\nwith classical computer-vision techniques, and they triggered an amazing renaissance\\nin creative applications of computer vision.\\n The key notion behind implementing style transfer is the same idea that’s central\\nto all deep-learning algorithms: you define a loss function to spec ify what you want to\\nachieve, and you minimize this loss. You kn ow what you want to achieve: conserving\\nthe content of the original image while adop ting the style of the reference image. If\\nwe were able to mathematically define content  and style, then an appropriate loss func-\\ntion to minimize would be the following:\\nloss = distance(style(reference_image) - style(generated_image)) +\\ndistance(content(original_image) - content(generated_image))\\n5Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge , “A Neural Algorithm of Artistic Style,” arXiv (2015),\\nhttps:/ /arxiv.org/abs/1508.06576 .\\nContent target Style reference Combination image\\nFigure 8.7 A style transfer example\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 309}), Document(page_content='288 CHAPTER  8Generative deep learning\\nHere, distance  is a norm function such as the L2 norm, content  is a function that\\ntakes an image and computes a representation of its content, and style  is a function\\nthat takes an image and computes a repres entation of its style. Minimizing this\\nloss causes style(generated_image)  to be close to style(reference_image) , and\\ncontent(generated_image)  is close to content(generated_image) , thus achieving\\nstyle transfer as we defined it.\\n A fundamental observation made by Gatys et al. was that deep convolutional neu-\\nral networks offer a way to mathematically define the style  and content  functions.\\nLet’s see how.\\n8.3.1 The content loss\\nAs you already know, activations from earlier layers in a network contain local informa-\\ntion about the image, wherea s activations from higher layers contain increasingly global ,\\nabstract  information. Formulated in a different way, the activations of the different lay-\\ners of a convnet provide a decomposition of th e contents of an image over different spa-\\ntial scales. Therefore, you’d expect the content of an image, which is more global and\\nabstract, to be captured by the represen tations of the upper layers in a convnet.\\n A good candidate for content loss is thus  the L2 norm between the activations of\\nan upper layer in a pretrained convnet, comp uted over the target image, and the acti-\\nvations of the same layer computed over th e generated image. This guarantees that, as\\nseen from the upper layer, the generated imag e will look similar to the original target\\nimage. Assuming that what the upper layers  of a convnet see is really the content of\\ntheir input images, then this works as  a way to preserve image content. \\n8.3.2 The style loss\\nThe content loss only uses a single upper la yer, but the style loss as defined by Gatys\\net al. uses multiple layers of a convnet: yo u try to capture the appearance of the style-\\nreference image at all spatial scales extracte d by the convnet, not just a single scale.\\nFor the style loss, Gatys et al. use the Gram matrix  of a layer’s activations: the inner\\nproduct of the feature maps of a given laye r. This inner product can be understood as\\nrepresenting a map of the correlations betw een the layer’s features. These feature cor-\\nrelations capture the statistics of the patterns  of a particular spat ial scale, which empir-\\nically correspond to the appearance of the textures found at this scale.\\n Hence, the style loss aims to preserve simi lar internal correlations within the activa-\\ntions of different layers, across the style- reference image and the generated image. In\\nturn, this guarantees that the textures foun d at different spatial scales look similar\\nacross the style-reference image and the generated image.\\n In short, you can use a pretrained convnet to define a loss that will do the following:\\n\\uf0a1Preserve content by maintaining similar high-level layer activations between the\\ntarget content image and the generated image. The convnet should “see” both\\nthe target image and the generated im age as containing the same things.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 310}), Document(page_content=\"289 Neural style transfer\\n\\uf0a1Preserve style by maintaining similar correlations  within activations for both low-\\nlevel layers and high-level layers. Feature correlations capture textures : the gen-\\nerated image and the style-reference im age should share the same textures at\\ndifferent spatial scales.\\nNow, let’s look at a Keras implementation of the original 2015 neural style transfer\\nalgorithm. As you’ll see, it shares many similarities with the DeepDream implementa-\\ntion developed in the previous section. \\n8.3.3 Neural style transfer in Keras\\nNeural style transfer can be implemented using any pretrained convnet. Here, you’ll\\nuse the VGG19  network used by Gatys et al. VGG19  is a simple variant of the VGG16  net-\\nwork introduced in chapter 5, with  three more convolutional layers.\\n This is the general process:\\n1Set up a network that computes VGG19  layer activations for the style-reference\\nimage, the target image, and the generated image at the same time.\\n2Use the layer activations computed over these three images to define the loss\\nfunction described earlier, which you’ll  minimize in order to achieve style\\ntransfer.\\n3Set up a gradient-descent process to minimize this loss function.\\nLet’s start by defining the paths to the st yle-reference image and the target image. To\\nmake sure that the processed images are a similar size (widel y different sizes make\\nstyle transfer more difficult), you’ll later resize them all to a shared height of 400 px.\\nfrom keras.preprocessing.image import load_img, img_to_array\\ntarget_image_path = 'img/portrait.jpg'\\nstyle_reference_image_path = 'img/transfer_style_reference.jpg'\\nwidth, height = load_img(target_image_path).size\\nimg_height = 400img_width = int(width * img_height / height)\\nYou need some auxili ary functions for loading, prepro cessing, and post processing the\\nimages that go in and out of the VGG19  convnet.\\nimport numpy as np\\nfrom keras.applications import vgg19\\ndef preprocess_image(image_path):\\nimg = load_img(image_path, target_size=(img_height, img_width))\\nimg = img_to_array(img)img = np.expand_dims(img, axis=0)img = vgg19.preprocess_input(img)return imgListing 8.14 Defining initial variables\\nListing 8.15 Auxiliary functionsPath to the image you \\nwant to transform\\nPath to the \\nstyle image\\nDimensions of the \\ngenerated picture\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 311}), Document(page_content=\"290 CHAPTER  8Generative deep learning\\ndef deprocess_image(x):\\nx[:, :, 0] += 103.939x[:, :, 1] += 116.779\\nx[:, :, 2] += 123.68\\nx = x[:, :, ::-1]x = np.clip(x, 0, 255).astype('uint8')\\nreturn x\\nLet’s set up the VGG19  network. It takes as input a batch of three images: the style-\\nreference image, the target image, and a pl aceholder that will contain the generated\\nimage. A placeholder is a symbolic tensor, the values of which are provided externally\\nvia Numpy arrays. The style-reference and ta rget image are static and thus defined\\nusing K.constant , whereas the values contained in the placeholder of the generated\\nimage will change over time.\\nfrom keras import backend as K\\ntarget_image = K.constant(preprocess_image(target_image_path))\\nstyle_reference_image = K.constant(preprocess_image(style_reference_image_path))combination_image = K.placeholder((1, img_height, img_width, 3))\\ninput_tensor = K.concatenate([target_image,\\nstyle_reference_image,\\ncombination_image], axis=0)\\nmodel = vgg19.VGG19(input_tensor=input_tensor,\\nweights='imagenet',\\ninclude_top=False)\\nprint('Model loaded.')\\nLet’s define the content loss, which will make sure the top layer of the VGG19  convnet\\nhas a similar view of the target image and the generated image.\\ndef content_loss(base, combination):\\nreturn K.sum(K.square(combination - base))\\nNext is the style loss. It uses an auxiliary function to compute the Gram matrix of an\\ninput matrix: a map of the correlations found in the original feature matrix.\\ndef gram_matrix(x):\\nfeatures = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\\ngram = K.dot(features, K.transpose(features))return gramListing 8.16 Loading the pretrained VGG19 network and applying it to the three images\\nListing 8.17 Content loss\\nListing 8.18 Style lossZero-centering by removi ng the mean pixel value \\nfrom ImageNet. This reve rses a transformation \\ndone by vgg 19.preprocess_input.\\nConverts images fro m 'BGR' to 'RGB'. \\nThis is also part of the reversal of \\nvgg19.preprocess_input.\\nPlaceholder that will contain\\nthe generated image\\nCombines the three \\nimages in a single batch\\nBuilds the VGG 19 network with \\nthe batch of three images as \\ninput. The model will be loaded \\nwith pretrained ImageNet weights.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 312}), Document(page_content=\"291 Neural style transfer\\ndef style_loss(style, combination):\\nS = gram_matrix(style)\\nC = gram_matrix(combination)channels = 3\\nsize = img_height * img_width\\nreturn K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\\nTo these two loss components, you add a third: the total variation loss , which operates\\non the pixels of the generated combination image. It encourages spatial continuity in\\nthe generated image, thus avoiding overly pi xelated results. You can interpret it as a\\nregularization loss.\\ndef total_variation_loss(x):\\na = K.square(\\nx[:, :img_height - 1, :img_width - 1, :] -\\n        x[:, 1:, :img_width - 1, :])\\nb = K.square(\\nx[:, :img_height - 1, :img_width - 1, :] -\\n       x[:, :img_height - 1, 1:, :])\\nreturn K.sum(K.pow(a + b, 1.25))\\nThe loss that you minimize is a weighted av erage of these three losses. To compute the\\ncontent loss, you use only one upper layer—the block5_conv2  layer—whereas for the\\nstyle loss, you use a list of layers than sp ans both low-level and high-level layers. You\\nadd the total variation loss at the end.\\n Depending on the style-reference image and content image you’re using, you’ll\\nlikely want to tune the content_weight  coefficient (the contribution of the content\\nloss to the total loss). A higher content_weight  means the target content will be more\\nrecognizable in the generated image.\\noutputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\\ncontent_layer = 'block5_conv2'style_layers = ['block1_conv1',\\n'block2_conv1',\\n'block3_conv1','block4_conv1',\\n'block5_conv1']\\ntotal_variation_weight = 1e-4style_weight = 1.\\ncontent_weight = 0.025Listing 8.19 Total variation loss\\nListing 8.20 Defining the final loss that you’ll minimize\\nDictionary that maps layer \\nnames to activation tensors\\nLayer used for content loss\\nLayers used for style loss\\nWeights in the weighted average \\nof the loss components\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 313}), Document(page_content=\"292 CHAPTER  8Generative deep learning\\nloss = K.variable(0.)\\nlayer_features = outputs_dict[content_layer]\\ntarget_image_features = layer_features[0, :, :, :]\\ncombination_features = layer_features[2, :, :, :]loss += content_weight * content_loss(target_image_features,\\ncombination_features)\\nfor layer_name in style_layers:\\nlayer_features = outputs_dict[layer_name]\\nstyle_reference_features = layer_features[1, :, :, :]\\ncombination_features = layer_features[2, :, :, :]sl = style_loss(style_reference_features, combination_features)\\nloss += (style_weight / len(style_layers)) * sl\\nloss += total_variation_weight * total_variation_loss(combination_image)\\nFinally, you’ll set up the gradient-descent pr ocess. In the original  Gatys et al. paper,\\noptimization is performed using the L-BFGS  algorithm, so that’s what you’ll use here.\\nThis is a key difference from the D eepDream example in section 8.2. The L-BFGS  algo-\\nrithm comes packaged with SciPy, but there are two slight limitations with the SciPy\\nimplementation:\\n\\uf0a1It requires that you pass the value of th e loss function and the value of the gra-\\ndients as two separate functions.\\n\\uf0a1It can only be applied to flat vector s, whereas you have a 3D image array.\\nIt would be inefficient to compute the valu e of the loss function and the value of the\\ngradients independently, because doing so would lead to a lot of redundant computa-\\ntion between the two; the process would be  almost twice as sl ow as computing them\\njointly. To bypass this, you’ll set up a Python class named Evaluator  that computes\\nboth the loss value and the gradients value at  once, returns the loss value when called\\nthe first time, and caches the gradients for the next call.\\ngrads = K.gradients(loss, combination_image)[0]\\nfetch_loss_and_grads = K.function([combination_image], [loss, grads])\\nclass Evaluator(object):\\ndef __init__(self):\\nself.loss_value = None\\nself.grads_values = None\\ndef loss(self, x):\\nassert self.loss_value is None\\nx = x.reshape((1, img_height, img_width, 3))outs = fetch_loss_and_grads([x])Listing 8.21 Setting up the gradient-descent processAdds\\nthe\\ncontent\\nlossYou’ll define the loss by \\nadding all components to this scalar variable.\\nAdds a style loss \\ncomponent for each target layer\\nAdds the\\ntotal\\nvariation\\nloss\\nFunction to fetch\\nthe values of\\nthe current loss\\nand the current\\ngradients\\nThis class wraps fetch_loss_and_grads\\nin a way that lets you retrieve the losses and\\ngradients via two separate  method calls, which is\\nrequired by the SciPy optimizer you'll use.Gets the\\ngradients\\nof the\\ngenerated\\nimage with\\nregard to\\nthe loss\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 314}), Document(page_content=\"293 Neural style transfer\\nloss_value = outs[0]\\ngrad_values = outs[1].flatten().astype('float64')\\nself.loss_value = loss_valueself.grad_values = grad_values\\nreturn self.loss_value\\ndef grads(self, x):\\nassert self.loss_value is not None\\ngrad_values = np.copy(self.grad_values)\\nself.loss_value = Noneself.grad_values = None\\nreturn grad_values\\nevaluator = Evaluator()\\nFinally, you can run the gradient-ascent process using SciPy’s L-BFGS  algorithm, saving\\nthe current generated image at each iteratio n of the algorithm (here, a single itera-\\ntion represents 20 steps of gradient ascent).\\nfrom scipy.optimize import fmin_l_bfgs_b\\nfrom scipy.misc import imsave\\nimport time\\nresult_prefix = 'my_result'\\niterations = 20\\nx = preprocess_image(target_image_path)\\nx = x.flatten()\\nfor i in range(iterations):\\nprint('Start of iteration', i)\\nstart_time = time.time()\\nx, min_val, info = fmin_l_bfgs_b(evaluator.loss,\\n                                     x,\\n        fprime=evaluator.grads,\\n                                     maxfun=20)\\nprint('Current loss value:', min_val)\\nimg = x.copy().reshape((img_height, img_width, 3))\\nimg = deprocess_image(img)fname = result_prefix + '_at_iteration_%d.png' % i\\nimsave(fname, img)\\nprint('Image saved as', fname)end_time = time.time()\\nprint('Iteration %d completed in %ds' % (i, end_time - start_time))\\nF i g u r e  8 . 8  s h o w s  w h a t  y o u  g e t .  K e e p  i n  m i n d  t h a t  w h a t  t h i s  t e c h n i q u e  a c h i e v e s  i s\\nmerely a form of image retexturing, or te xture transfer. It works best with style-\\nreference images that are strongly textured  and highly self-similar, and with content\\ntargets that don’t require high levels of detail in order to be recognizable. It typically\\ncan’t achieve fairly abstract feats such as  transferring the style of one portrait to\\nanother. The algorithm is closer to classical sign al processing than to AI, so don’t\\nexpect it to work like magic!Listing 8.22 Style-transfer loop\\nThis is the initial state: \\nthe target image.\\nYou flatten the image because \\nscipy.optimize.fmin_l_bfgs_b \\ncan only process flat vectors.\\nRuns L-BFGS optimization \\nover the pixels of the generated image to \\nminimize the neural style \\nloss. Note that you have to pass the function that \\ncomputes the loss and the \\nfunction that computes the gradients as two \\nseparate arguments.\\nSaves the current \\ngenerated image.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 315}), Document(page_content='294 CHAPTER  8Generative deep learning\\n \\nFigure 8.8 Some example results\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 316}), Document(page_content='295 Neural style transfer\\nAdditionally, note that running this style-tr ansfer algorithm is slow. But the transfor-\\nmation operated by the setup is simple enough that it ca n be learned by a small, fast\\nfeedforward convnet as well—as long as you have appropriate training data available.\\nFast style transfer can thus be achieved by  first spending a lot of compute cycles to\\ngenerate input-output training examples for a fixed style-reference image, using the\\nmethod outlined here, and then training a simple convnet to learn this style-specific\\ntransformation. Once that’s done, stylizing a given image is instantaneous: it’s just a\\nforward pass of this small convnet. \\n8.3.4 Wrapping up\\n\\uf0a1Style transfer consists of creating a new image that preserves the contents of a\\ntarget image while also capturin g the style of a reference image.\\n\\uf0a1Content can be captured by the high-level activations of a convnet.\\n\\uf0a1Style can be captured by the internal corr elations of the activations of different\\nlayers of a convnet.\\n\\uf0a1Hence, deep learning allows  style transfer to be form ulated as an optimization\\nprocess using a loss defined with a pretrained convnet.\\n\\uf0a1Starting from this basic idea, many variants and refinements are possible. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 317}), Document(page_content='296 CHAPTER  8Generative deep learning\\n8.4 Generating images with variational autoencoders\\nSampling from a latent space of images to cr eate entirely new images or edit existing\\nones is currently the most popular an d successful application of creative AI. In this sec-\\ntion and the next, we’ll review some high-l evel concepts pertaining to image genera-\\ntion, alongside implementations details rela tive to the two main techniques in this\\ndomain: variational autoencoders  (VAEs) and generative adversarial networks  (GAN s). The\\ntechniques we present here aren’t specific  to images—you could develop latent spaces\\nof sound, music, or  even text, using GAN s and VAEs—but in practice, the most inter-\\nesting results have been obtained with pi ctures, and that’s what we focus on here.\\n8.4.1 Sampling from latent spaces of images\\nThe key idea of image generation is to develop a low-dimensional latent space  of repre-\\nsentations (which naturally is a vector sp ace) where any point can be mapped to a\\nrealistic-looking image. The module capable of realizing this mapping, taking as input\\na latent point and outputting an image (a grid of pixels), is called a generator  (in the\\ncase of GANs) or a decoder  (in the case of VAEs). Once such a latent space has been\\ndeveloped, you can sample points from it, either deliberately or at random, and, by\\nmapping them to image space, generate images that have never been seen before (seefigure 8.9).\\nGAN s and VAEs are two different strategies for lear ning such latent spaces of image\\nrepresentations, each with  its own characteristics. VAEs are great for learning latent\\nspaces that are well structured , where specific directions encode a meaningful axis of\\nvariation in the data. GANs generate images that can potentially be highly realistic, but\\nthe latent space they come from may not have as much struct ure and continuity.Generator / Decoder\\nTraining data\\nLatent space\\nof images\\n(a vector space)Vector from the \\nlatent spaceArtificial\\nimageLearning\\nprocess?\\nFigure 8.9 Learning a latent vector space of images, and using it to sample new images\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 318}), Document(page_content='297 Generating images with variational autoencoders\\n  \\n8.4.2 Concept vectors for image editing\\nWe already hinted at the idea of a concept vector  when we covered word embeddings in\\nchapter 6. The idea is still the same: give n a latent space of representations, or an\\nembedding space, certain directions in the space may encode interesting axes of vari-\\nation in the original data. In a latent space of images of faces, for instance, there may\\nbe a smile vector s, such that if latent point z is the embedded representation of a cer-\\ntain face, then latent point z + s  is the embedded representation of the same face,\\nsmiling. Once you’ve identified such a vect or, it then becomes po ssible to edit images\\nby projecting them into the latent space, moving their representation in a meaningful\\nw a y ,  a n d  t h e n  d e c o d i n g  t h e m  b a c k  t o  i m age space. There are concept vectors for\\nessentially any independent dimension of variation in image space—in the case of\\nfaces, you may discover vectors for adding su nglasses to a face, remo ving glasses, turn-\\ning a male face into as female face, and so on. Figure 8.11 is an example of a smile vec-\\ntor, a concept vector discovered by Tom Wh ite from the Victoria University School of\\nDesign in New Zealand, using VAEs trained on a dataset of faces of celebrities (the\\nCelebA dataset).\\nFigure 8.10 A continuous space of faces generated by Tom White using VAEs\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 319}), Document(page_content='298 CHAPTER  8Generative deep learning\\n  \\n8.4.3 Variational autoencoders\\nVariational autoencoders, simultaneously  discovered by Kingma and Welling in\\nDecember 20136 and Rezende, Mohamed, and Wierstra in January 2014,7 are a kind\\nof generative model that’s es pecially appropriate for the ta sk of image editing via con-\\ncept vectors. They’re a modern take on autoencoders—a type of network that aims to\\nencode an input to a low-dimensional late nt space and then decode it back—that\\nmixes ideas from deep learni ng with Bayesian inference.\\n A classical image autoencoder takes an imag e, maps it to a latent vector space via\\nan encoder module, and then decodes it back to an out put with the same dimensions\\nas the original image, via a decoder modu le (see figure 8.12). It’s then trained by\\nusing as target data the same images  as the input images, meaning the autoencoder\\nlearns to reconstruct the original inputs. By imposing various constraints on the code\\n(the output of the encoder), you can get the autoencoder to learn more-or-less inter-esting latent representations of the data. Most commonly, you’ll constrain the code to\\nbe low-dimensional and sparse (mostly zeros) , in which case the encoder acts as a way\\nto compress the input data into fewer bits of information.\\n6Diederik P. Kingma and Max Welling, “Auto- Encoding Variational Bayes, arXiv (2013), https:/ /arxiv.org/\\nabs/1312.6114 .\\n7Danilo Jimenez Rezende, Shakir Mohamed, and Daan  Wierstra, “Stochastic Backpropagation and Approxi-\\nmate Inference in Deep Genera tive Models,” arXiv (2014), https:/ /arxiv.org/abs/1401.4082 .\\nFigure 8.11 The smile vector\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 320}), Document(page_content=\"299 Generating images with variational autoencoders\\n \\nIn practice, such classical au toencoders don’t lead to particularly useful or nicely\\nstructured latent spaces. They’re not much good at compression, either. For these rea-\\nsons, they have largely fallen out of fashion. VAEs, however, augm ent autoencoders\\nwith a little bit of statistical magic that fo rces them to learn continuous, highly struc-\\ntured latent spaces. They have turned out to  be a powerful tool for image generation.\\n A VAE, instead of compressing its input image into a fixed code in the latent space,\\nturns the image into the parameters of a st atistical distribution: a mean and a vari-\\nance. Essentially, this means you’re assuming  the input image has been generated by a\\nstatistical process, and that the randomne ss of this process should be taken into\\naccounting during encoding and decoding. The VAE then uses the mean and variance\\nparameters to randomly sample one element of the distribution, and decodes that ele-\\nment back to the original input (see figure  8.13). The stochasticity of this process\\nimproves robustness and forces the latent space to encode meaningful representa-\\ntions everywhere: every point sampled in the latent space is decoded to a valid output.\\n \\n Figure 8.12 An autoencoder: mapping an input x to a compressed representation \\nand then decoding it back as x'\\nOriginal\\ninput xCompressed\\nrepresentationReconstructed\\ninput x\\nEncoder Decoder\\nInput image\\nReconstructed\\nimageDistribution over latent\\nspace defined by z_mean\\nand z_log_var\\nPoint randomly\\nsampled from\\nthe distribution\\nEncoder\\nDecoder\\nFigure 8.13 A VAE maps an image to two vectors, z_mean  and z_log_sigma , which define \\na probability distribution over the latent space, used to sample a latent point to decode.\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 321}), Document(page_content='300 CHAPTER  8Generative deep learning\\n In technical terms, here’s how a VAE works:\\n1An encoder module turns the input samples input_img  into two parameters in\\na latent space of representations, z_mean  and z_log_variance .\\n2You randomly sample a point z from the latent normal distribution that’s\\nassumed to generate the input image, via z = z_mean  + exp(z_log_variance)  *\\nepsilon , where epsilon  is a random tensor of small values.\\n3A decoder module maps this point in the latent space back to the original input\\nimage.\\nBecause epsilon  is random, the process ensures that every point that’s close to the latent loca-\\ntion where you encoded input_img  (z-mean ) can be decoded to something similar to\\ninput_img , thus forcing the latent space to be continuously meaningful. Any two close points\\nin the latent space will decode to highly similar images. Continuity, combined with the low\\ndimensionality of the latent space, forces every direction in the latent space to encode a mean-\\ningful axis of variation of the data, making the latent space very structured and thus highly suit-able to manipulation via concept vectors.\\n The parameters of a VAE are trained via two loss functions: a reconstruction loss  that\\nforces the decoded samples to match the initial inputs, and a regularization loss  that\\nhelps learn well-formed latent spaces and reduce overfitting to the training data. Let’s\\nquickly go over a Kera s implementation of a VAE. Schematically, it looks like this:\\nz_mean, z_log_variance = encoder(input_img)\\nz = z_mean + exp(z_log_variance) * epsilonreconstructed_img = decoder(z)model = Model(input_img, reconstructed_img)\\nYou can then train the model using the reco nstruction loss and the regularization loss.\\n The following listing shows the encoder ne twork you’ll use, mapping images to the\\nparameters of a probability distribution over  the latent space. It ’s a simple convnet\\nthat maps the input image x to two vectors, z_mean  and z_log_var .\\nimport keras\\nfrom keras import layers\\nfrom keras import backend as Kfrom keras.models import Model\\nimport numpy as np\\nimg_shape = (28, 28, 1)\\nbatch_size = 16\\nlatent_dim = 2\\ninput_img = keras.Input(shape=img_shape)Listing 8.23 VAE encoder networkEncodes the input into a \\nmean and variance parameter\\nDraws a latent point using \\na small random epsilonDecodes\\nz back to\\nan image Instantiates the autoencoder \\nmodel, which maps an input image \\nto its reconstruction\\nDimensionality of the \\nlatent space: a 2D plane\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 322}), Document(page_content=\"301 Generating images with variational autoencoders\\nx = layers.Conv2D(32, 3,\\npadding='same', activation='relu')(input_img)\\nx = layers.Conv2D(64, 3,\\npadding='same', activation='relu',\\nstrides=(2, 2))(x)\\nx = layers.Conv2D(64, 3,\\npadding='same', activation='relu')(x)\\nx = layers.Conv2D(64, 3,\\npadding='same', activation='relu')(x)\\nshape_before_flattening = K.int_shape(x)\\nx = layers.Flatten()(x)\\nx = layers.Dense(32, activation='relu')(x)\\nz_mean = layers.Dense(latent_dim)(x)\\nz_log_var = layers.Dense(latent_dim)(x)\\nNext is the code for using z_mean  and z_log_var , the parameters of the statistical dis-\\ntribution assumed to  have produced input_img , to generate a latent space point z.\\nHere, you wrap some ar bitrary code (built on top of Keras backend primitives) into a\\nLambda  layer. In Keras, everything needs to be a layer, so code that isn’t part of a built-\\nin layer should be wrapped in a Lambda  (or in a custom layer).\\ndef sampling(args):\\nz_mean, z_log_var = args\\nepsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\\nmean=0., stddev=1.)\\nreturn z_mean + K.exp(z_log_var) * epsilon\\nz = layers.Lambda(sampling)([z_mean, z_log_var])\\nThe following listing shows the decoder implementation. You reshape the vector z to\\nthe dimensions of an image and then use a few convolution layers to obtain a final\\nimage output that has the same  dimensions as the original input_img .\\ndecoder_input = layers.Input(K.int_shape(z)[1:])\\nx = layers.Dense(np.prod(shape_before_flattening[1:]),\\nactivation='relu')(decoder_input)\\nx = layers.Reshape(shape_before_flattening[1:])(x)\\nx = layers.Conv2DTranspose(32, 3,\\npadding='same',\\n                           activation='relu',\\nstrides=(2, 2))(x)\\nx = layers.Conv2D(1, 3,\\npadding='same',\\n                  activation='sigmoid')(x)Listing 8.24 Latent-space-sampling function\\nListing 8.25 VAE decoder network, mapping latent space points to imagesThe input image ends up \\nbeing encoded into these two parameters.\\nInput where you’ll feed z\\nUpsamples the input\\nUses a Conv2DTranspose \\nlayer and Conv2D layer to \\ndecode z into a feature map \\nthe same size as the original image input\\nReshapes z into a feature map of the same shape as the feature map just before the last Flat ten layer in the encoder model\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 323}), Document(page_content=\"302 CHAPTER  8Generative deep learning\\ndecoder = Model(decoder_input, x)\\nz_decoded = decoder(z)\\nThe dual loss of a VAE doesn’t fit the traditional expe ctation of a sample-wise function\\nof the form loss(input,  target) . Thus, you’ll set up the loss by writing a custom\\nlayer that internally uses the built-in add_loss  layer method to create an arbitrary loss.\\nclass CustomVariationalLayer(keras.layers.Layer):\\ndef vae_loss(self, x, z_decoded):\\nx = K.flatten(x)\\nz_decoded = K.flatten(z_decoded)xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\\nkl_loss = -5e-4 * K.mean(\\n1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\\nreturn K.mean(xent_loss + kl_loss)\\ndef call(self, inputs):\\nx = inputs[0]\\nz_decoded = inputs[1]\\nloss = self.vae_loss(x, z_decoded)self.add_loss(loss, inputs=inputs)\\nreturn x\\ny = CustomVariationalLayer()([input_img, z_decoded])\\nFinally, you’re ready to inst antiate and train the model. Because the loss is taken care\\nof in the custom layer, you don’t spec ify an external loss at compile time ( loss=None ),\\nwhich in turn means you won’t pass target data during training (as you can see, you\\nonly pass x_train  to the model in fit).\\nfrom keras.datasets import mnist\\nvae = Model(input_img, y)\\nvae.compile(optimizer='rmsprop', loss=None)\\nvae.summary()\\n(x_train, _), (x_test, y_test) = mnist.load_data()\\nx_train = x_train.astype('float32') / 255.\\nx_train = x_train.reshape(x_train.shape + (1,))x_test = x_test.astype('float32') / 255.\\nx_test = x_test.reshape(x_test.shape + (1,))\\nvae.fit(x=x_train, y=None,\\nshuffle=True,\\nepochs=10,\\nbatch_size=batch_size,validation_data=(x_test, None))Listing 8.26 Custom layer used to compute the VAE loss\\nListing 8.27 Training the VAEInstantiates the decoder model, \\nwhich turns “decoder_input” \\ninto the decoded imageApplies it to z to \\nrecover the decoded z\\nYou implement custom layers \\nby writing a call method.You don't use\\nthis output,\\nbut the layer\\nmust return\\nsomething.Calls the custom layer on \\nthe input and the decoded output to obtain \\nthe final model output\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 324}), Document(page_content=\"303 Generating images with variational autoencoders\\nOnce such a model is trained—on MNIST , in this case—you can use the decoder  net-\\nwork to turn arbitrary latent  space vectors into images.\\nimport matplotlib.pyplot as plt\\nfrom scipy.stats import norm\\nn=1 5\\ndigit_size = 28figure = np.zeros((digit_size * n, digit_size * n))grid_x = norm.ppf(np.linspace(0.05, 0.95, n))grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\\nfor i, yi in enumerate(grid_x):\\nfor j, xi in enumerate(grid_y):\\nz_sample = np.array([[xi, yi]])z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)x_decoded = decoder.predict(z_sample, batch_size=batch_size)digit = x_decoded[0].reshape(digit_size, digit_size)\\nfigure[i * digit_size: (i + 1) * digit_size,\\nj * digit_size: (j + 1) * digit_size] = digit\\nplt.figure(figsize=(10, 10))\\nplt.imshow(figure, cmap='Greys_r')plt.show()\\n \\nThe grid of sampled digits (see fig-\\nure 8.14) shows a completely contin-\\nuous distribution of the differentdigit classes, with one digit morphinginto another as you follow a path\\nthrough latent space. Specific direc-\\ntions in this space have a meaning:for example, there’s a direction for\\n“four-ness,” “one-ness,” and so on.\\n In the next section, we’ll cover in\\ndetail the other major tool for gener-\\nating artificial images: generative\\nadversarial networks (\\nGAN s). \\n \\n \\n Listing 8.28 Sampling a grid of points from the 2D latent space and decoding them to images\\nYou’ll display a grid of 15 × 15 \\ndigits (255 di gits total).\\nTransforms linearly spaced \\ncoordinates using the SciPy ppf \\nfunction to produce values of the \\nlatent variable z (because the prior of the latent space is Gaussian)\\nRepeats z multiple times to\\nform a complete batch\\nReshapes the first digit in\\nthe batch from 28 × 28 × 1\\nto 28 × 28\\nDecodes the batch\\ninto digit images\\nFigure 8.14 Grid of digits decoded from the latent \\nspace\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 325}), Document(page_content='304 CHAPTER  8Generative deep learning\\n8.4.4 Wrapping up\\n\\uf0a1Image generation with deep learning is do ne by learning latent spaces that cap-\\nture statistical information about a da taset of images. By sampling and decod-\\ning points from the latent space, you can generate never-before-seen images.\\nThere are two major tools to do this: VAEs and GAN s.\\n\\uf0a1VAEs result in highly structured, continuous  latent representations. For this rea-\\nson, they work well for doing all sorts of image editing in latent space: face\\nswapping, turning a frowning face into a smiling face, and so on. They also work\\nnicely for doing latent-space-based animat ions, such as animating a walk along a\\ncross section of the latent space, showin g a starting image sl owly morphing into\\ndifferent images in a continuous way.\\n\\uf0a1GAN s enable the generation of realistic single-frame images but may not induce\\nlatent spaces with solid st ructure and high continuity.\\nMost successful practical applications I have seen with images rely on VAEs, but GAN s\\nare extremely popular in the world of ac ademic research—at least, circa 2016–2017.\\nYou’ll find out how they work and how to implement one in the next section.\\nTIP To play further with image generati on, I suggest working with the Large-\\nscale Celeb Faces Attributes (CelebA) da taset. It’s a free-to-download image\\ndataset containing more than 200,000 cele brity portraits. It’s great for experi-\\nmenting with concept vectors in part icular—it definitely beats MNIST. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 326}), Document(page_content='305 Introduction to generative adversarial networks\\n8.5 Introduction to generative adversarial networks\\nGenerative adversarial networks ( GAN s), introduced in 2014 by Goodfellow et al.,8 are\\nan alternative to VAEs for learning latent spaces of images. They enable the generation\\nof fairly realistic synthetic images by forcing the generated images to be statistically\\nalmost indistinguishable from real ones.\\n An intuitive way to understand GAN s is to imagine a forger trying to create a fake\\nPicasso painting. At first, the forger is pr etty bad at the task. He mixes some of his\\nfakes with authentic Picassos and shows them all to an art dealer. The art dealer makes\\nan authenticity assessment for each painting  and gives the forger  feedback about what\\nmakes a Picasso look like a Picasso. The forger  goes back to his studio to prepare some\\nnew fakes. As times goes on, the forger be comes increasingly competent at imitating\\nthe style of Picasso, and the art dealer beco mes increasingly expert  at spotting fakes.\\nIn the end, they have on their hands some excellent fake Picassos.\\n That’s what a GAN is: a forger network and an expe rt network, each being trained\\nto best the other. As such, a GAN is made of two parts:\\n\\uf0a1Generator network —Takes as input a random vect or (a random point in the\\nlatent space), and decodes it into a synthetic image\\n\\uf0a1Discriminator network (or adversary) —Takes as input an image (real or synthetic),\\nand predicts whether the image came fr om the training set or was created by\\nthe generator network.\\nThe generator network is trained to be able  to fool the discriminator network, and\\nthus it evolves toward generating increasingly  realistic images as training goes on: arti-\\nficial images that look indistinguishable from  real ones, to the extent that it’s impossi-\\nble for the discriminator network to tell th e two apart (see figu re 8.15). Meanwhile,\\nthe discriminator is constantly adapting to the gradually improving capabilities of the\\ngenerator, setting a high bar of realism for the generated images. Once training is\\nover, the generator is capable of turning an y point in its input space into a believable\\nimage. Unlike VAEs, this latent space has fewer ex plicit guarantees of meaningful\\nstructure; in particular, it isn’t continuous.\\n8Ian Goodfellow et al., “Generative Ad versarial Networks,” arXiv (2014), https:/ /arxiv.org/abs/1406.2661 .\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 327}), Document(page_content='306 CHAPTER  8Generative deep learning\\n \\nRemarkably, a GAN  is a system where the optimization minimum isn’t fixed, unlike in\\nany other training setup you’ ve encountered in this book . Normally, gradient descent\\nconsists of rolling down hills in a static loss landscape. But with a GAN, every step\\ntaken down the hill changes the entire land scape a little. It’s a dynamic system where\\nthe optimization process is seeking not a minimum, but an equi librium between two\\nforces. For this reason, GAN s are notoriously difficult to train—getting a GAN  to work\\nrequires lots of careful tuning of the mo del architecture and training parameters.\\nGenerator (decoder)\\nDiscriminator “Real,” “Fake”Random vector\\nfrom the \\nlatent spaceGenerated\\n(decoded)\\nimage\\nMix of real \\nand fake imagesTraining\\nfeedback\\nFigure 8.15 A generator transforms random latent  vectors into images, and a discriminator \\nseeks to tell real images from generated ones. Th e generator is trained to fool the discriminator.\\nFigure 8.16 Latent space dwellers. Images generated by Mike Tyka using \\na multistaged GAN trained on a dataset of faces ( www.miketyka.com ).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 328}), Document(page_content='307 Introduction to generative adversarial networks\\n8.5.1 A schematic GAN implementation\\nIn this section, we’ll explain how to implement a GAN in Keras, in its barest form—\\nbecause GAN s are advanced, diving d eeply into the technical details would be out of\\nscope for this book. The spec ific implementation is a deep convolutional GAN (DCGAN ):\\na GAN  where the generator and discriminator ar e deep convnets. In particular, it uses\\na Conv2DTranspose  layer for image upsampling in the generator.\\n You’ll train the GAN o n im age s  fr om  CIFAR10 , a dataset of 50,000 32 × 32 RGB\\nimages belonging to 10 classes (5,000 images per class). To make things easier, you’ll\\nonly use images belonging to the class “frog.”\\n Schematically, the GAN looks like this:\\n1A generator  network maps vectors of shape (latent_dim,)  to images of shape\\n(32,  32, 3).\\n2A discriminator  network maps images of shape (32,  32, 3) to a binary score\\nestimating the probability that the image is real.\\n3A gan network chains the generator and the discriminator together: gan(x) =\\ndiscriminator(generator(x)) . Thus this gan network maps latent space vec-\\ntors to the discriminator’ s assessment of the realism of these latent vectors as\\ndecoded by the generator.\\n4You train the discriminator using examples  of real and fake images along with\\n“real”/“fake” labels, just as you train any regular image-classification model.\\n5To train the generator, you use the gr adients of the generator’s weights with\\nregard to the loss of the gan model. This means, at every step, you move the\\nweights of the generator in a direction that makes the discriminator more likely\\nto classify as “real” the images decoded by the generator. In other words, you\\ntrain the generator to fool the discriminator. \\n8.5.2 A bag of tricks\\nThe process of training GANs and tuning GAN implementations is notoriously diffi-\\ncult. There are a number of known tricks yo u should keep in mi nd. Like most things\\nin deep learning, it’s more  alchemy than science: thes e tricks are heuristics, not\\ntheory-backed guidelines. They’re supported by a level of intuitive understanding of\\nthe phenomenon at hand, and they’re known to work well empirically, although not\\nnecessarily in every context.\\n Here are a few of the tricks us ed in the implementation of the GAN generator and\\ndiscriminator in this section. It isn’t an exhaustive list of GAN-related tips; you’ll find\\nmany more across the GAN  literature:\\n\\uf0a1We use tanh  as the last activation in the generator, instead of sigmoid , which is\\nmore commonly found in other types of models.\\n\\uf0a1We sample points from the latent space using a normal distribution  (Gaussian dis-\\ntribution), not a uniform distribution.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 329}), Document(page_content='308 CHAPTER  8Generative deep learning\\n\\uf0a1Stochasticity is good to induce robustness. Because GAN training results in a\\ndynamic equilibrium, GANs are likely to get stuck in all sorts of ways. Introduc-\\ning randomness during training helps prevent this. We introduce randomness\\nin two ways: by using dropout in the di scriminator and by adding random noise\\nto the labels for the discriminator.\\n\\uf0a1Sparse gradients can hinder GAN training. In deep learni ng, sparsity is often a\\ndesirable property, but not in GANs. Two things can induce gradient sparsity:\\nmax pooling operations and ReLU  activations. Instead of  max pooling, we rec-\\nommend using strided convolutions for downsampling, and we recommend\\nusing a LeakyReLU  layer instead of a ReLU  activation. It’s similar to ReLU , but it\\nrelaxes sparsity constraints by allowi ng small negative activation values.\\n\\uf0a1In generated images, it’s common to see checkerboard artifacts caused by\\nunequal coverage of the pixel space in the generator (see figure 8.17). To fix\\nthis, we use a kernel size that’s divisibl e by the stride size whenever we use a\\nstrided Conv2DTranpose  or Conv2D  in both the generator and the discriminator. \\n8.5.3 The generator\\nFirst, let’s develop a generator  model that turns a vector (from the latent space—\\nd u r i n g  t r a i n i n g  i t  w i l l  b e  s a m p l e d  a t  r a ndom) into a candidate image. One of the\\nmany issues that commonly arise with GAN s is that the generator gets stuck with gener-\\nated images that look like noise. A possibl e solution is to use dropout on both the dis-\\ncriminator and the generator.\\nimport keras\\nfrom keras import layers\\nimport numpy as np\\nlatent_dim = 32\\nheight = 32\\nwidth = 32\\nchannels = 3Listing 8.29 GAN generator network\\nFigure 8.17 Checkerboard artifacts caused by mismatching strides and kernel sizes, resulting in unequal pixel-space coverage: one of the many gotchas of GANs\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 330}), Document(page_content=\"309 Introduction to generative adversarial networks\\ngenerator_input = keras.Input(shape=(latent_dim,))\\nx = layers.Dense(128 * 16 * 16)(generator_input)\\nx = layers.LeakyReLU()(x)x = layers.Reshape((16, 16, 128))(x)\\nx = layers.Conv2D(256, 5, padding='same')(x)\\nx = layers.LeakyReLU()(x)\\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\\nx = layers.LeakyReLU()(x)x = layers.Conv2D(256, 5, padding='same')(x)\\nx = layers.LeakyReLU()(x)\\nx = layers.Conv2D(256, 5, padding='same')(x)\\nx = layers.LeakyReLU()(x)\\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\\ngenerator = keras.models.Model(generator_input, x)\\ngenerator.summary()\\n8.5.4 The discriminator\\nNext, you’ll develop a discriminator  model that takes as input a candidate image\\n(real or synthetic) and classifi es it into one of two classes: “generated image” or “real\\nimage that comes from the training set.”\\ndiscriminator_input = layers.Input(shape=(height, width, channels))\\nx = layers.Conv2D(128, 3)(discriminator_input)x = layers.LeakyReLU()(x)\\nx = layers.Conv2D(128, 4, strides=2)(x)\\nx = layers.LeakyReLU()(x)x = layers.Conv2D(128, 4, strides=2)(x)\\nx = layers.LeakyReLU()(x)\\nx = layers.Conv2D(128, 4, strides=2)(x)x = layers.LeakyReLU()(x)\\nx = layers.Flatten()(x)\\nx = layers.Dropout(0.4)(x)x = layers.Dense(1, activation='sigmoid')(x)\\ndiscriminator = keras.models.Model(discriminator_input, x)\\ndiscriminator.summary()\\ndiscriminator_optimizer = keras.optimizers.RMSprop(\\n    lr=0.0008,\\n    clipvalue=1.0,    decay=1e-8)\\ndiscriminator.compile(optimizer=discriminator_optimizer,\\nloss='binary_crossentropy')Listing 8.30 The GAN discriminator networkTransforms the input into \\na 16 × 16 128-channel \\nfeature map\\nUpsamples \\nto 32 × 32\\nInstantiates the generator mo del, which maps the input \\nof shape (latent_dim,) into an image of shape (32, 32, 3)Produces a 32 × 32 1-channel feature\\nmap  (shape of a CIFAR 10 image)\\nOne dropout layer: \\nan important trick!\\nClassification layer\\nInstantiates the discrim-\\ninator model, which turns \\na (32, 32, 3) input into a \\nbinary classifi-cation decision (fake/real)\\nUses gradient clipping (by value) in the optimizer\\nTo stabilize training, \\nuses learning-rate decay\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 331}), Document(page_content=\"310 CHAPTER  8Generative deep learning\\n8.5.5 The adversarial network\\nFinally, you’ll set up the GAN , which chains the generator and the discriminator.\\nWhen trained, this model will move the generator in a direction that improves its abil-ity to fool the discriminator. This model tu rns latent-space points into a classification\\ndecision—“fake” or “real”—and it’s meant to  be trained with labels that are always\\n“these are real images.” So, training \\ngan will update the weights of generator  in a way\\nthat makes discriminator  more likely to predict “real” when looking at fake images.\\nIt’s very important to note that you set th e discriminator to be frozen during training\\n(non-trainable): its weights wo n’t be updated when training gan. If the discriminator\\nweights could be updated during this proces s, then you’d be training the discrimina-\\ntor to always predict “real, ” which isn’t what you want!\\ndiscriminator.trainable = False\\ngan_input = keras.Input(shape=(latent_dim,))\\ngan_output = discriminator(generator(gan_input))\\ngan = keras.models.Model(gan_input, gan_output)\\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\\n8.5.6 How to train your DCGAN\\nNow you can begin training. To recapitulate, this is what the training loop looks like\\nschematically. For each epoch, you do the following:\\n1Draw random points in the latent space (random noise).\\n2Generate images with generator  using this random noise.\\n3Mix the generated images with real ones.\\n4Train discriminator  using these mixed images, with corresponding targets:\\neither “real” (for the real images) or  “fake” (for the generated images).\\n5Draw new random points in the latent space.\\n6Train gan using these random vectors, with targets that all sa y “these are real\\nimages.” This updates the weights of th e generator (only, because the discrimi-\\nnator is frozen inside gan) to move them toward getting the discriminator to\\npredict “these are real images” for gene rated images: this trains the generator\\nto fool the discriminator.\\nLet’s implement it.\\nimport os\\nfrom keras.preprocessing import image\\n(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()Listing 8.31 Adversarial network\\nListing 8.32 Implementing GAN trainingSets discriminator weights to \\nnon-trainable (t his will only \\napply to the gan model) \\nLoads CIFAR 10 data\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 332}), Document(page_content=\"311 Introduction to generative adversarial networks\\nx_train = x_train[y_train.flatten() == 6]\\nx_train = x_train.reshape(\\n(x_train.shape[0],) +(height, width, channels)).astype('float32') / 255.\\niterations = 10000\\nbatch_size = 20\\nsave_dir = 'your_dir'\\nstart = 0\\nfor step in range(iterations):\\nrandom_latent_vectors = np.random.normal(size=(batch_size,\\nlatent_dim))\\ngenerated_images = generator.predict(random_latent_vectors)stop = start + batch_size\\nreal_images = x_train[start: stop]combined_images = np.concatenate([generated_images, real_images])\\nlabels = np.concatenate([np.ones((batch_size, 1)),\\nnp.zeros((batch_size, 1))])\\nlabels += 0.05 * np.random.random(labels.shape)\\nd_loss = discriminator.train_on_batch(combined_images, labels)random_latent_vectors = np.random.normal(size=(batch_size,\\nlatent_dim))\\nmisleading_targets = np.zeros((batch_size, 1))\\na_loss = gan.train_on_batch(random_latent_vectors,\\nmisleading_targets)\\nstart += batch_size\\nif start > len(x_train) - batch_size:\\nstart = 0\\nif step % 100 == 0:\\ngan.save_weights('gan.h5')\\nprint('discriminator loss:', d_loss)\\nprint('adversarial loss:', a_loss)\\nimg = image.array_to_img(generated_images[0] * 255., scale=False)\\nimg.save(os.path.join(save_dir,\\n                      'generated_frog' + str(step) + '.png'))\\nimg = image.array_to_img(real_images[0] * 255., scale=False)\\nimg.save(os.path.join(save_dir,\\n                      'real_frog' + str(step) + '.png'))Selects frog images (class 6)\\nNormalizes data\\nSpecifies where you want \\nto save generated images\\nSamples random \\npoints in the latent space\\nDecodes\\nthem to\\nfake\\nimagesCombines them\\nwith real images\\nAssembles labels, discrim-\\ninating real from fake images\\nAdds random \\nnoise to the \\nlabels—an important trick!Trains the\\ndiscriminator\\nSamples random \\npoints in the \\nlatent space Assembles\\nlabels that\\nsay “these\\nare all real\\nimages”\\n (it’s a lie!)Trains the generator (via the \\ngan model, wher e the discrim-\\ninator weights are frozen)\\nOccasionally saves and \\nplots (every 100 steps)\\nSaves model weights\\nPrints metricsSaves one\\ngenerated image\\nSaves one real image\\nfor comparison\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 333}), Document(page_content='312 CHAPTER  8Generative deep learning\\nWhen training, you may see the adversarial loss begin to increase considerably, while\\nthe discriminative loss tends to zero—the discriminator may end up dominating the\\ngenerator. If that’s the case, try reducing the discriminator learning rate, and increase\\nthe dropout rate of the discriminator. \\n8.5.7 Wrapping up\\n\\uf0a1A GAN consists of a generator network coupled with a discriminator network.\\nThe discriminator is trained to differenci ate between the output of the generator\\nand real images from a trai ning dataset, and the genera tor is trained to fool the\\ndiscriminator. Remarkably, the generator nevers sees images from the training\\nset directly; the information it has abou t the data comes from the discriminator.\\n\\uf0a1GAN s are difficult to train, because training a GAN  is a dynamic process rather\\nthan a simple gradient de scent process with a fixed loss landscape. Getting a\\nGAN  to train correctly requires using a nu mber of heuristic tricks, as well as\\nextensive tuning.\\n\\uf0a1GAN s can potentially produce highly realistic images. But unlike VAEs, the\\nlatent space they learn doesn’t have a neat continuous structure and thus may\\nnot be suited for certain practical applic ations, such as image editing via latent-\\nspace concept vectors.\\nFigure 8.18 Play the discriminator: in each row, two images were dreamed up by the GAN, \\nand one image comes from the training set. C an you tell them apart? (Answers: the real \\nimages in each column are middle, top, bottom, middle.)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 334}), Document(page_content='313 Introduction to generative adversarial networks\\nChapter summary\\n\\uf0a1With creative applications of deep  learning, deep ne tworks go beyond\\nannotating existing content and star t generating their own. You learned\\nthe following:\\n– How to generate sequence data, one ti mestep at a time. This is applicable\\nto text generation and also to note-b y-note music generation or any other\\ntype of timeseries data.\\n– How DeepDream works: by maximizing  convnet layer ac tivations through\\ngradient ascent in input space.\\n– How to perform style transfer, where a content image and a style image are\\ncombined to produce interesting-looking results.\\n–W h a t  GAN s and VAEs are, how they can be us ed to dream up new images,\\nand how latent-space concept vector s can be used for image editing.\\n\\uf0a1These few techniques cover only the ba sics of this fast-expanding field.\\nThere’s a lot more to discover out there—generative deep learning is\\ndeserving of an entire book of its own. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 335}), Document(page_content='314Conclusions\\nYou’ve almost reache d the end of this book. This last chapter will summarize and\\nreview core concepts while also expanding your horizons beyond the relatively basic\\nnotions you’ve learned so far. Understanding deep learning and AI is a journey, and\\nfinishing this book is merely the first step on it. I want to make  sure you realize this\\nand are properly equipped to  take the next steps of this journey on your own.\\n We’ll start with a bird’s-eye view of wh at you should take away from this book.\\nThis should refresh your memory regarding some of the concepts you’ve learned.Next, we’ll present an overview of some ke y limitations of deep learning. To use a\\ntool appropriately, you should not only understand what it can do but also be aware\\nof what it can’t do. Finally, I’ll offer some specul ative thoughts about the future evo-\\nlution of the fields of deep learning, machine learning, and \\nAI. This should be\\nespecially interesting to you if you’d li ke to get into fundamental research. The\\nchapter ends with a short list of resource s and strategies for learning further about\\nAI and staying up to date with new advances.This chapter covers\\n\\uf0a1Important takeaways from this book\\n\\uf0a1The limitations of deep learning\\n\\uf0a1The future of deep learning, machine learning, \\nand AI\\n\\uf0a1Resources for learning further and working in the field\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 336}), Document(page_content='315 Key concepts in review\\n9.1 Key concepts in review\\nThis section briefly synthesizes the key take aways from this book. If you ever need a\\nquick refresher to help you recall what yo u’ve learned, you can read these few pages.\\n9.1.1 Various approaches to AI\\nFirst of all, deep learning isn’t synonymous with AI or even with machine learning.\\nArtificial intelligence  is an ancient, broad field that can generally be defined as “all\\nattempts to automate cognitive proce sses”—in other words, the automation of\\nthought. This can range from the very basic,  such as an Excel spreadsheet, to the very\\nadvanced, like a humanoid robot that can walk and talk.\\n Machine learning  is a specific subfield of AI that aims at auto matically developing\\nprograms (called models ) purely from exposure to traini ng data. This process of turn-\\ning data into a program is called learning . Although machine learning has been\\naround for a long time, it only started to take off in the 1990s.\\n Deep learning  is one of many branches of machine learning, where the models are\\nlong chains of geometric functions, applie d one after the other. These operations are\\nstructured into modules called layers : deep-learning models are typically stacks of lay-\\ners—or, more generally, graphs of laye rs. These layers are parameterized by weights ,\\nwhich are the parameters learned during training. The knowledge  of a model is stored\\nin its weights, and the process of learning consists of finding good values for these\\nweights.\\n Even though deep learning is just one among many approaches to machine learn-\\ning, it isn’t on an equal footing with the others. Deep learning is a breakout success.\\nHere’s why. \\n9.1.2 What makes deep learning special \\nwithin the field of machine learning\\nIn the span of only a few years, deep learning has achieved  tremendous break-\\nthroughs across a wide range of tasks th at have been histor ically perceived as\\nextremely difficult for comput ers, especially in the area of machine perception:\\nextracting useful information from images , videos, sound, and more. Given sufficient\\ntraining data (in particular, training data appropriately labeled by  humans), it’s possi-\\nble to extract from perceptual data almost anythi ng that a human could extract.\\nHence, it’s sometimes said  that deep learning has solved perception , although that’s true\\nonly for a fairly narrow definition of perception .\\n Due to its unprecedented technical succ esses, deep learning has singlehandedly\\nbrought about the third and by far the largest AI summer : a period of intense interest,\\ninvestment, and hype in the field of AI. As this book is being written, we’re in the middle\\nof it. Whether this period will end in the ne ar future, and what happens after it ends,\\nare topics of debate. One thing is certain: in stark contrast with previous AI summers,\\ndeep learning has provided enormous business value to a number of large technology\\ncompanies, enabling human-le vel speech recognition, sma rt assistants, human-level\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 337}), Document(page_content='316 CHAPTER  9Conclusions\\nimage classification, vastly improved mach ine translation, and more. The hype may\\n(and likely will) recede, but the sustained economic and technological impact of deep\\nlearning will remain. In that sense, deep learning could be anal ogous to the internet:\\nit may be overly hyped up for a few years, but in the longer term it will still be a major\\nrevolution that will transf orm our economy and our lives.\\n I’m particularly optimistic about deep learning because even if we were to make no\\nfurther technological progre ss in the next decade, deploying existing algorithms to\\nevery applicable problem would be a game changer for most industries. Deep learn-\\ning is nothing short of a revolution, and pr ogress is currently happening at an incred-\\nibly fast rate, due to an exponential investment in resources and headcount. From\\nwhere I stand, the future l ooks bright, although short-te rm expectations are somewhat\\noveroptimistic; deploying deep learning to the full extent of its potential will take well\\nover a decade. \\n9.1.3 How to think about deep learning\\nThe most surprising thing abou t deep learning is how simp le it is. Ten years ago, no\\none expected that we would achieve such  amazing results on machine-perception\\nproblems by using simple parametric models trained with gradient descent. Now, itturns out that all you need is sufficiently large parametric models  trained with gradi-\\nent descent on sufficiently many examples. As Feynman once said about the universe,\\n“It’s not complicated, it’s just a lot of it.”\\n1\\n In deep learning, everything is a vector: everything is a point  in a geometric space .\\nModel inputs (text, images, and so on) and targets are first vectorized : turned into an\\ninitial input vector space and target vector space. Each layer in a deep-learning model\\noperates one simple geometric transformati on on the data that goes through it.\\nTogether, the chain of layers in the mode l forms one complex geometric transforma-\\ntion, broken down into a series of simple  ones. This complex transformation attempts\\nto map the input space to the target space, one point at a time. Th is transformation is\\nparameterized by the weights of the layers, which are iteratively updated based on how\\nwell the model is currently performing. A key characteristic of this geometric transfor-\\nmation is that it must be differentiable , which is required in order for us to be able to\\nlearn its parameters via gradient descent. Intuitively, this means the geometric morph-\\ning from inputs to outputs must be smoot h and continuous—a significant constraint.\\n The entire process of applying this comp lex geometric transformation to the input\\ndata can be visualized in 3D by imagining a person trying to uncrumple a paper ball:\\nthe crumpled paper ball is th e manifold of the input data that the model starts with.\\nEach movement operated by the person on the paper ball is similar to a simple geo-\\nmetric transformation operat ed by one layer. The full uncrumpling gesture sequence\\nis the complex transformation of the enti re model. Deep-learning models are mathe-\\nmatical machines for uncrumpling complicat ed manifolds of high-dimensional data.\\n1Richard Feynman, interview, The World from Another Point of View , Yorkshire Television, 1972.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 338}), Document(page_content='317 Key concepts in review\\n That’s the magic of deep learning: turn ing meaning into vectors, into geometric\\nspaces, and then incrementally learning co mplex geometric transformations that map\\none space to another. All you need are spaces of sufficiently high dimensionality in\\norder to capture the full scope of the re lationships found in the original data.\\n The whole thing hinges on a single core idea: that meaning is derived from the pairwise\\nrelationship between things  (between words in a language , between pixels in an image,\\nand so on) and that these relationships can be capt ured by a distance function . But note that\\nwhether the brain implements meaning via geometric spaces is an entirely separate\\nquestion. Vector spaces are efficient to work with from a co mputational standpoint,\\nbut different data structures for intelligence can easily be envisioned—in particular,graphs. Neural networks initially emerged fr om the idea of using graphs as a way to\\nencode meaning, which is why they’re named neural networks ; the surrounding field of\\nr e s e a r c h  u s e d  t o  b e  c a l l e d  connectionism . Nowadays the name neural network  exists\\npurely for historical reasons—it’s an extr emely misleading name because they’re nei-\\nther neural nor networks. In particular, ne ural networks have hardly anything to do\\nwith the brain. A more appropriate name would have been layered representations learn-\\ning or hierarchical representations learning , or maybe even deep differentiable models  or\\nchained geometric transforms , to emphasize the fact that continuous geometric space\\nmanipulation is at their core. \\n9.1.4 Key enabling technologies\\nThe technological revolution that’s currently unfolding didn’t start with any singlebreakthrough invention. Rather, like any ot her revolution, it’s the product of a vast\\naccumulation of enabling fact ors—slowly at first, and then suddenly. In the case of\\ndeep learning, we can point out the following key factors:\\n\\uf0a1Incremental algorithmic innovations, fi rst spread over two decades (starting\\nwith backpropagation) and then happe ning increasingly faster as more\\nresearch effort was poured in to deep learning after 2012.\\n\\uf0a1The availability of large amounts of perc eptual data, which is a requirement in\\norder to realize that sufficiently large mo dels trained on sufficiently large data\\nare all we need. This is in turn a byprod uct of the rise of the consumer internet\\nand Moore’s law applie d to storage media.\\n\\uf0a1The availability of fast, highly parall el computation hardwa re at a low price,\\nespecially the GPUs produced by NVIDIA —first gaming GPUs and then chips\\ndesigned from the ground up for deep learning. Early on, NVIDIA  CEO Jensen\\nHuang took note of the deep-learning boom and decided to bet the company’s\\nfuture on it.\\n\\uf0a1A complex stack of software layers that makes this computational power available\\nto humans: the CUDA  language, frameworks like TensorFlow that do automatic\\ndifferentiation, and Keras, which makes d eep learning accessibl e to most people.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 339}), Document(page_content='318 CHAPTER  9Conclusions\\nIn the future, deep learning will not only be  used by specialists— researchers, graduate\\nstudents, and engineers with an  academic profile—but will also be a tool in the tool-\\nbox of every developer, much like web te chnology today. Ever yone needs to build\\nintelligent apps: just as every business toda y needs a website, every product will need\\nto intelligently make sense of user-generat ed data. Bringing a bout this future will\\nrequire us to build tools that make deep le arning radically easy to use and accessible\\nto anyone with basic coding abilities. Keras is the first major step in that direction. \\n9.1.5 The universal machine-learning workflow\\nHaving access to an extremely powerful tool  for creating models that map any input\\nspace to any target space is great, but the difficult part of the machine-learning work-\\nflow is often everything that comes before  designing and training such models (and,\\nfor production models, what comes afte r, as well). Understanding the problem\\ndomain so as to be able to determine what to attempt to predict, given what data, and\\nhow to measure success, is a prerequisite  for any successful a pplication of machine\\nlearning, and it isn’t something that adva nced tools like Keras and TensorFlow can\\nhelp you with. As a reminder, here’s a qu ick summary of the typical machine-learning\\nworkflow as described in chapter 4:\\n1Define the problem: What data is availa ble, and what are you trying to predict?\\nWill you need to collect more data or hi re people to manually label a dataset?\\n2Identify a way to reliably measure succe ss on your goal. For simple tasks, this\\nmay be prediction accuracy, but in many cases it will require sophisticated\\ndomain-specific metrics.\\n3Prepare the validation process that you’ll use to evaluate your models. In partic-\\nular, you should define a training set, a validation set, and a test set. The valida-\\ntion- and test-set labels shouldn’t leak into the training data: for instance, with\\ntemporal prediction, the validation and test data should be  posterior to the\\ntraining data.\\n4Vectorize the data by turning it into ve ctors and preprocessing  it in a way that\\nmakes it more easily approachable by a neural network (normalization, and so\\non).\\n5Develop a first model that beats a triv ial common-sense base line, thus demon-\\nstrating that machine learning can work  on your problem. This may not always\\nbe the case!\\n6Gradually refine your mode l architecture by tuning  hyperparameters and add-\\ning regularization. Make changes based on performance on the validation data\\nonly, not the test data or the training data. Remember that you should get your\\nmodel to overfit (thus identifying a model capacity level that’s greater than youneed) and only then begin to add regularization or downsize your model.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 340}), Document(page_content='319 Key concepts in review\\n7Be aware of validation-set overfitting when turning hyperparameters: the fact\\nthat your hyperparameters may end up being overspecialized to the validation\\nset. Avoiding this is the purpos e of having a separate test set!\\n9.1.6 Key network architectures\\nThe three families of networ k architectures that you should be familiar with are densely\\nconnected networks , convolutional networks , and recurrent networks . Each type of network is\\nmeant for a specific input modality: a ne twork architecture (dense, convolutional,\\nrecurrent) encodes assumptions  about the structure of the data: a hypothesis space  within\\nwhich the search for a good model will proceed. Whether a given architecture will\\nwork on a given problem depends entirely on the match between the structure of the\\ndata and the assumptions of  the network architecture.\\n These different network ty pes can easily be combined to achieve larger multi-\\nmodal networks, much as you combine LEGO  bricks. In a way, deep-learning layers are\\nLEGO  bricks for information processing. He re’s a quick overvi ew of the mapping\\nbetween input modalities and a ppropriate networ k architectures:\\n\\uf0a1Vector data —Densely connected network ( Dense  layers).\\n\\uf0a1Image data —2D convnets.\\n\\uf0a1Sound data (for ex ample, waveform) —Either 1D convnets (preferred) or RNN s.\\n\\uf0a1Text data —Either 1D convnets (preferred) or RNN s.\\n\\uf0a1Timeseries data —Either RNN s (preferred) or 1D convnets.\\n\\uf0a1Other types of sequence data —Either RNN s or 1D convnets. Prefer RNN s if data\\nordering is strongly meaningful (for ex ample, for timeseries, but not for text).\\n\\uf0a1Video data —Either 3D convnets (if you need to capture motion effects) or a\\ncombination of a frame-level 2D convnet for feature extraction followed by\\neither an RNN  or a 1D convnet to process the resulting sequences.\\n\\uf0a1Volumetric data —3D convnets.\\nNow, let’s quickly review the specific ities of each network architecture.\\nDENSELY  CONNECTED  NETWORKS\\nA densely connected ne twork is a stack of Dense  layers, meant to process vector data\\n(batches of vectors). Such networks assume no specific structure in the input features:they’re called densely connected  because the units of a \\nDense  layer are connected to every\\nother unit. The layer attempts to map relati onships between any two input features; this\\nis unlike a 2D convolution layer, for instance, which only looks at local relationships.\\n Densely connected networks are most commonly used for categorical data (for\\nexample, where the input features are lists of  attributes), such as the Boston Housing\\nPrice dataset used in chapter 3. They’re also used as the final classification or regres-\\nsion stage of most networks. For instance, the convnets covered in chapter 5 typically\\nend with one or two Dense  layers, and so do the recurrent networks in chapter 6.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 341}), Document(page_content=\"320 CHAPTER  9Conclusions\\n Remember: to perform binary classification , end your stack of layers with a Dense\\nlayer with a single unit and a sigmoid  activation, and use binary_crossentropy  as the\\nloss. Your targets shou ld be either 0 or 1:\\nfrom keras import models\\nfrom keras import layers\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\\nmodel.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(1, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy')\\nTo perform single-label catego rical classification  (where each sample has exactly one class,\\nno more), end your stack of layers with a Dense  layer with a number of units equal to the\\nnumber of classes, and a softmax  activation. If your targets are one-hot encoded, use\\ncategorical_crossentropy  as the loss; if they’re integers, use sparse_categorical_\\ncrossentropy :\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\\nmodel.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(num_classes, activation='softmax'))\\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\\nTo perform multilabel categori cal classification  (where each sample  can have several\\nclasses), end your stac k of layers with a Dense  layer with a number of units equal to the\\nnumber of classes and a sigmoid  activation, and use binary_crossentropy  as the loss.\\nYour targets should  be k-hot encoded:\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\\nmodel.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(num_classes, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy')\\nTo perform regression  toward a vector of continuous values, end your stack of layers\\nwith a Dense  layer with a number of units equal to  the number of values you’re trying\\nto predict (often a single one, such as the price of a house), and no activation. Several\\nlosses can be used for re gression, most commonly mean_squared_error  (MSE) and\\nmean_absolute_error  (MAE):\\nmodel = models.Sequential()\\nmodel.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\\nmodel.add(layers.Dense(32, activation='relu'))model.add(layers.Dense(num_values))\\nmodel.compile(optimizer='rmsprop', loss='mse')\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 342}), Document(page_content=\"321 Key concepts in review\\nCONVNETS\\nConvolution layers look at spatially local patterns by applying the same geometric\\ntransformation to different spatial locations ( patches ) in an input tensor. This results\\nin representations that are translation invariant , making convolution layers highly data\\nefficient and modular. This idea is appl icable to spaces of  any dimensionality: 1D\\n(sequences), 2D (images), 3D (volumes), and so on. You can use the Conv1D  layer to\\nprocess sequences (especially text—it doesn’t work as well on timeseries, which often\\ndon’t follow the translation- invariance assumption), the Conv2D  layer to process\\nimages, and the Conv3D  layers to process volumes.\\n Convnets , or convolutional networks , consist of stacks of convolution and max-pooling\\nlayers. The pooling layers let you spatially downsample the data, which is required to\\nkeep feature maps to a reason able size as the number of features grows, and to allow\\nsubsequent convolution layers to “see” a gr eater spatial extent of the inputs. Convnets\\nare often ended with either a Flatten  operation or a global pooling layer, turning spa-\\ntial feature maps into vectors, followed by Dense  layers to achieve classification or\\nregression.\\n Note that it’s highly likely that regular convolutions will soon be mostly (or com-\\npletely) replaced by an equivalent but fast er and representational ly efficient alterna-\\ntive: the depthwise separable convolution  (SeparableConv2D  layer). This is true for 3D,\\n2D, and 1D inputs. When you’re building a new network from scratch, using depth-\\nwise separable convolutions is definitely the way to go. The SeparableConv2D  layer\\ncan be used as a drop-in replacement for Conv2D , resulting in a smaller, faster network\\nthat also performs better on its task.\\n Here’s a typical image-classification ne twork (categorical classification, in this\\ncase):\\nmodel = models.Sequential()\\nmodel.add(layers.SeparableConv2D(32, 3, activation='relu',\\n        input_shape=(height, width, channels)))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.MaxPooling2D(2))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.SeparableConv2D(128, 3, activation='relu'))\\nmodel.add(layers.MaxPooling2D(2))\\nmodel.add(layers.SeparableConv2D(64, 3, activation='relu'))\\nmodel.add(layers.SeparableConv2D(128, 3, activation='relu'))\\nmodel.add(layers.GlobalAveragePooling2D())\\nmodel.add(layers.Dense(32, activation='relu'))\\nmodel.add(layers.Dense(num_classes, activation='softmax'))\\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\\nRNN S\\nRecurrent neural networks  (RNN s) work by processing sequen ces of inputs one timestep at\\na time and maintaining a state throughout (a state is typica lly a vector or set of vectors:\\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 343}), Document(page_content=\"322 CHAPTER  9Conclusions\\na point in a geometric space of states). They should be used preferentially over 1D conv-\\nnets in the case of sequences where pattern s of interest aren’t invariant by temporal\\ntranslation (for instance, timeseries data wh ere the recent past is more important than\\nthe distant past).\\n Three RNN  layers are available in Keras: SimpleRNN , GRU, and LSTM . For most prac-\\ntical purposes, you should use either GRU or LSTM . LSTM  is the more powerful of the\\ntwo but is also more expensive; you can think of GRU as a simpler, cheaper alternative\\nto it.\\n In order to stack multiple RNN  layers on top of each other, each layer prior to the\\nlast layer in the stack should return the fu ll sequence of its ou tputs (each input time-\\nstep will correspond to an output timestep ); if you aren’t st acking any further RNN  lay-\\ners, then it’s common to return only th e last output, which contains information\\nabout the entire sequence.\\n Following is a single RNN  layer for binary classification of vector sequences:\\nmodel = models.Sequential()\\nmodel.add(layers.LSTM(32, input_shape=(num_timesteps, num_features)))model.add(layers.Dense(num_classes, activation='sigmoid'))\\n50model.compile(optimizer='rmsprop', loss='binary_crossentropy')\\nAnd this is a stacked RNN  layer for binary classification of vector sequences: \\nmodel = models.Sequential()\\nmodel.add(layers.LSTM(32, return_sequences=True,\\ninput_shape=(num_timesteps, num_features)))\\nmodel.add(layers.LSTM(32, return_sequences=True))\\nmodel.add(layers.LSTM(32))\\nmodel.add(layers.Dense(num_classes, activation='sigmoid'))\\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy')\\n9.1.7 The space of possibilities\\nWhat will you build with deep learning? Re member, building deep-learning models is\\nlike playing with LEGO  bricks: layers can be plugged together to map essentially any-\\nthing to anything, given that you have approp riate training data available and that the\\nmapping is achievable via a continuous ge ometric transformation of reasonable com-\\nplexity. The space of possibilities is infi nite. This section offers a few examples to\\ninspire you to think beyond the basic classifi cation and regression tasks that have tra-\\nditionally been the bread an d butter of machine learning.\\n I’ve sorted my suggested applications by input and ou tput modalities. Note that\\nquite a few of them stretch the limits of what is possible—although a model could be\\ntrained on all of these tasks, in some ca ses such a model probabl y wouldn’t generalize\\nfar from its training data. Sections 9.2 and 9.3 will address how these limitations could\\nbe lifted in the future.\\n \\nLicensed to   <null>\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 344}), Document(page_content='323 Key concepts in review\\n\\uf0a1Mapping vector data to vector data\\n–Predictive healthcare —Mapping patient medical records to predictions of\\npatient outcomes\\n–Behavioral targeting —Mapping a set of website attributes with data on how\\nlong a user will spend on the website\\n–Product quality control —Mapping a set of attributes re lative to an instance of a\\nmanufactured product with the probabilit y that the product will fail by next\\nyear\\n\\uf0a1Mapping image data to vector data\\n–Doctor assistant —Mapping slides of medical im ages with a prediction about\\nthe presence of a tumor\\n–Self-driving vehicle —Mapping car dash-cam vide o frames to steering wheel\\nangle commands\\n–Board game AI—Mapping Go and chess boards to the next player move\\n–Diet helper —Mapping pictures of a dish to its calorie count\\n–Age prediction —Mapping selfies to the age of the person\\n\\uf0a1Mapping timeseries data to vector data\\n–Weather prediction —Mapping timeseries of weather data in a grid of locations\\nof weather data the following week at a specific location\\n–Brain-computer interfaces —Mapping timeseries of magnetoencephalogram\\n(MEG ) data to computer commands\\n–Behavioral targeting —Mapping timeseries of user interactions on a website to\\nthe probability that a user will buy something\\n\\uf0a1Mapping text to text\\n–Smart reply —Mapping emails to possible one-line replies\\n–Answering questions —Mapping general-knowledge questions to answers\\n–Summarization —Mapping a long article to a short summary of the article\\n\\uf0a1Mapping images to text\\n–Captioning —Mapping images to short captio ns describing the contents of\\nthe images\\n\\uf0a1Mapping text to images\\n–Conditioned image generation —Mapping a short text description to images\\nmatching the description\\n–Logo generation/selection —Mapping the name and description of a company\\nto the company’s logo\\n\\uf0a1Mapping images to images\\n–Super-resolution —Mapping downsized images to higher-resolution versions of\\nthe same images\\n–Visual depth sensing —Mapping images of indoor environments to maps of\\ndepth predictions\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 345}), Document(page_content='324 CHAPTER  9Conclusions\\n\\uf0a1Mapping images and text to text\\n–Visual QA—Mapping images and natural-la nguage questions about the con-\\ntents of images to natural-language answers\\n\\uf0a1Mapping video and text to text\\n–Video QA—Mapping short videos and natura l-language questions about the\\ncontents of videos to natural-language answers\\nAlmost  anything is possible—but not quite anything . Let’s see in the next section what\\nwe can’t do with deep learning. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 346}), Document(page_content='325 The limitations of deep learning\\n9.2 The limitations of deep learning\\nThe space of applications that can be im plemented with deep learning is nearly\\ninfinite. And yet, many applications are completely out of reach for current deep-learning techniques—even gi ven vast amounts of human- annotated data. Say, for\\ninstance, that you could assemble a data set of hundreds of thousands—even mil-\\nlions—of English-language descriptions of the features of a software product, written\\nby a product manager, as well as the corr esponding source code  developed by a team\\nof engineers to meet these requirements. Even with this data, you could not train a\\ndeep-learning model to read a product description and generate the appropriatecodebase. That’s just one example among ma ny. In general, anything that requires\\nreasoning—like programming or applying the scientific method—long-term plan-\\nning, and algorithmic data manipulation is  out of reach for deep-learning models, no\\nmatter how much data you throw at them. Even learning a sorting algorithm with a\\ndeep neural network is tremendously difficult.\\n This is because a deep-learning model is just a chain of simple, co ntinuous geometric\\ntransformations  mapping one vector space into another. All it can do is map one data\\nmanifold \\nX into another manifold Y, assuming the existence of a learnable continuous\\ntransform from X to Y. A deep-learning model can be interpreted as a kind of pro-\\ngram; but, inversely, most programs can’t be expressed as deep-learning models —for most\\ntasks, either there exists no corresponding deep-neural network that  solves the task or,\\neven if one exists, it may not be learnable : the corresponding geometric transform may\\nbe far too complex, or there may not be appropriate data ava ilable to learn it.\\n Scaling up current deep-learning techniqu e s  b y  s t a c k i n g  m o r e  l a y e r s  a n d  u s i n g\\nmore training data can only superficially pa lliate some of these issues. It won’t solve\\nthe more fundamental problems that deep-learning models are limited in what they\\ncan represent and that most of  the programs you may wish to learn can’t be expressed\\nas a continuous geometric mo rphing of a data manifold.\\n9.2.1 The risk of anthropomorphizing machine-learning models\\nOne real risk with contemporary AI is misinterpreting what deep-learning models do\\nand overestimating their abilities. A fundamental feature of humans is our theory of\\nmind : our tendency to project intentions, beli efs, and knowledge on the things around\\nus. Drawing a smiley face on a rock suddenly  makes it “happy”—in  our minds. Applied\\nto deep learning, this means that, for inst ance, when we’re able to somewhat success-\\nfully train a model to generate captions to describe pictures, we’re led to believe that\\nthe model “understands” the contents of the pictures and the captions it generates.\\nThen we’re surprised when any slight departur e from the sort of images present in the\\ntraining data causes the model to generate co mpletely absurd captions (see figure 9.1).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 347}), Document(page_content='326 CHAPTER  9Conclusions\\n \\nIn particular, this is highlighted by adversarial examples , which are samples fed to a\\ndeep-learning network that are designed to  trick the model into misclassifying them.\\nYou’re already aware that, for instance, it’s possible to do  gradient ascent in input\\nspace to generate inputs that maximize the activation of some convnet filter—this is\\nthe basis of the filter-visualization techniqu e introduced in chapter 5, as well as the\\nDeepDream algorithm in chapter 8. Simila rly, through gradie nt ascent, you can\\nslightly modify an image in order to maximi ze the class prediction  for a given class. By\\ntaking a picture of a panda and adding to it a gibbon gradient, we can get a neural\\nnetwork to classify the panda as a gibbon (s ee figure 9.2). This evidences both the brit-\\ntleness of these models and the deep diff erence between their input-to-output map-\\nping and our hu man perception.\\nThe boy is holding a baseball bat.Figure 9.1 Failure of an image-captioning \\nsystem based on deep learning\\nGibbon\\nclass gradient\\nPandaPandaf(x)\\nAdversarial exampleGibbon!f(x)\\nFigure 9.2 An adversarial example: imperceptible changes in an image can \\nupend a model’s classification of the image.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 348}), Document(page_content='327 The limitations of deep learning\\nIn short, deep-learning models don’t have any understanding of their input—at least,\\nnot in a human sense. Our own understand ing of images, sounds, and language is\\ngrounded in our sensorimotor experience as humans. Machine-learning models have\\nno access to such experiences and thus ca n’t understand their inputs in a human-\\nrelatable way. By annotating large numbers of training exam ples to feed into our mod-\\nels, we get them to learn a geometric tran sform that maps data to human concepts on\\na specific set of examples, but this mapping is a simplistic sketch of the original model\\nin our minds—the one developed from our ex perience as embodied agents. It’s like a\\ndim image in a mirror (see figure 9.3).\\nAs a machine-learning practitioner, always be  mindful of this, and never fall into the\\ntrap of believing that neural networks un derstand the task they perform—they don’t,\\nat least not in a way that would make sense to  us. They were trained on a different, far\\nnarrower task than the one we wanted to teach them: that of mapping training inputs\\nto training targets, point by point. Show them anything th at deviates from their train-\\ning data, and they will break in absurd ways. \\n9.2.2 Local generalization vs. extreme generalization\\nThere are fundamental differences betwee n the straightforward geometric morphing\\nfrom input to output that deep-learning models do, and the way humans think and\\nlearn. It isn’t only the fact that humans  learn by themselves from embodied experi-\\nence instead of being presented with explicit  training examples. In addition to the dif-\\nferent learning processes, th ere’s a basic difference in the nature of the underlying\\nrepresentations.\\n Humans are capable of far more than mapping immediate stimuli to immediate\\nresponses, as a deep network, or maybe an insect, would. We maintain complex, abstract\\nmodels  of our current situation, of ourselves,  and of other people, and can use these\\nmodels to anticipate different possible futures and perform long-term planning. We\\ncan merge together known concepts to re present something we’ve never experienced\\nReal worldEmbodied\\nhuman experienceAbstract concepts \\nin human mindLabeled data\\nexemplifying\\nthese concepts\\nMay not always \\ntransfer well to \\nthe real worldDoesn’t match the\\nhuman mental model \\nit came fromMatches the\\ntraining dataMachine-learning\\nmodel\\nf(x)\\nFigure 9.3 Current machine-learning models: like a dim image in a mirror\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 349}), Document(page_content='328 CHAPTER  9Conclusions\\nbefore—like picturing a horse wearing jeans,  for instance, or imagining what we’d do\\nif we won the lottery. This ab ility to handle hypotheticals,  to expand ou r mental model\\nspace far beyond what we can experience directly—to perform abstraction  and reason-\\ning—is arguably the defining characterist ic of human cognition. I call it extreme general-\\nization : an ability to adapt to nove l, never-before-experienced situations using little data\\nor even no new data at all.\\n This stands in sharp contrast with what deep nets do, which I call local generalization\\n(see figure 9.4). The mapping from inputs to outputs performed by a deep net quickly\\nstops making sense if new inputs differ even slightly from what the net saw at training\\ntime. Consider, for instance, the problem of  learning the appropriate launch parame-\\nters to get a rocket to land on the moon. If you used a deep net for this task and trained\\nit using supervised learning or reinforcemen t learning, you’d have to feed it thousands\\nor even millions of launch trials : you’d need to expose it to a dense sampling  of the input\\nspace, in order for it to le arn a reliable mapping from inpu t space to output space. In\\ncontrast, as humans we can use our power of abstraction to come up  with physical mod-\\nels—rocket science—and derive an exact solution that will land the rocket on the moon\\nin one or a few trials. Similarly, if you developed a deep net controlling a human body,\\nand you wanted it to learn to safely navigate  a city without getting hit by cars, the net\\nwould have to die many thousands of times in  various situations until it could infer that\\ncars are dangerous, and deve lop appropriate avoidance beha viors. Dropped into a new\\ncity, the net would have to relearn most of  what it knows. On the other hand, humans\\nare able to learn safe behaviors without havi ng to die even once—again, thanks to our\\npower of abstract modeling of  hypothetical situations.\\nIn short, despite our progress on machin e perception, we’re still far from human-\\nlevel AI. Our models can only perform local generalization, adapting to new situa-\\ntions that must be similar to past da ta, whereas human cognition is capable of\\nThe same set of\\ndata points\\nor experience\\nLocal generalization:\\ngeneralization power of\\npattern recognitionExtreme generalization:\\ngeneralization power\\nachieved via abstraction\\nand reasoningFigure 9.4 Local generalization \\nvs. extreme generalization\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 350}), Document(page_content='329 The limitations of deep learning\\nextreme generalization, quickly adapting to  radically novel situations and planning\\nfor long-term future situations. \\n9.2.3 Wrapping up\\nHere’s what you should  remember: the only real succe ss of deep learning so far has\\nbeen the ability to map spac e X to space Y using a continuous geometric transform,\\ngiven large amounts of human-annotated data . Doing this well is a game-changer for\\nessentially every industry, but it’s still a long way from human-level AI.\\n To lift some of the limitation s we have discussed and create AI that can compete\\nwith human brains, we need to move away  from straightforward input-to-output map-\\npings and on to reasoning  and abstraction . A likely appropriate substrate for abstract\\nmodeling of various situations  and concepts is that of computer programs. We said\\npreviously that machine-learning models can be defined as learnable programs ; cur-\\nrently we can only learn programs that belo ng to a narrow and specific subset of all\\npossible programs. But what if we could learn any program, in a modular and reusable\\nway? Let’s see in the next section what the road ahead may look like. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 351}), Document(page_content='330 CHAPTER  9Conclusions\\n9.3 The future of deep learning\\nThis is a more speculative section aimed at opening horizons for people who want to\\njoin a research program or begin doing independent resear ch. Given what we know of\\nhow deep nets work, their limi tations, and the current stat e of the research landscape,\\ncan we predict where things are headed in the medium term? Following are some\\npurely personal thoughts. Note that I don’t ha ve a crystal ball, so a lot of what I antici-\\npate may fail to become reality. I’m shar ing these predictions not because I expect\\nthem to be proven completely right in th e future, but because they’re interesting and\\nactionable in the present.\\n At a high level, these are the main directions in which I see promise:\\n\\uf0a1Models closer to general-purpose computer programs , built on top of far richer primi-\\ntives than the current differentiable  layers. This is how we’ll get to reasoning  and\\nabstraction , the lack of which is the fundam ental weakness of current models.\\n\\uf0a1New forms of learning that make the previous point possible , allowing models to move\\naway from differentiable transforms.\\n\\uf0a1Models that require less involvement from human engineers . It shouldn’t be your job to\\ntune knobs endlessly.\\n\\uf0a1Greater, systematic reuse of previously learned features and architectures , such as meta-\\nlearning systems using reusable and modular program subroutines.\\nAdditionally, note that these considerations aren’t specific to the sort of supervised\\nlearning that has been the bread and butter of deep learning so far—rather, they’re\\napplicable to any form of machine learni ng, including unsupervised, self-supervised,\\nand reinforcement learning. It isn’t fundam entally important where your labels come\\nfrom or what your training loop looks like ; these different branch es of machine learn-\\ning are different facets of the same construct. Let’s dive in.\\n9.3.1 Models as programs\\nAs noted in the previous section, a nece ssary transformational development that we\\ncan expect in the field of machine learning is a move away from models that perform\\npurely pattern recognition  and can only achieve local generalization , toward models capa-\\nble of abstraction  and reasoning  that can achieve extreme generalization . Current AI pro-\\ngrams that are capable of basic forms of  reasoning are all hardcoded by human\\nprogrammers: for instan ce, software that relies on search algorithms, graph manipula-\\ntion, and formal logic. In D eepMind’s AlphaGo, for example, most of the intelligence\\non display is designed and hardcoded by expert programmers (such as Monte Carlo\\nTree Search); learning from data happens only in specialized submodules (value net-\\nworks and policy networks). But in the futu re, such AI systems may be fully learned,\\nwith no human involvement.\\n What path could make this happen? Consider a well-known type of network: RNN s.\\nIt’s important to note that RNN s have slightly fewer limitations than feedforward net-\\nworks. That’s because RNN s are a bit more than mere  geometric transformations:\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 352}), Document(page_content='331 The future of deep learning\\nthey’re geometric transformations repeatedly applied inside a for loop. The temporal for\\nloop is itself hardcoded by  human developers: it’s a bu ilt-in assumption of the net-\\nwork. Naturally, RNN s are still extremely limited in what they can represent, primarily\\nbecause each step they perform is a differ entiable geometric transformation, and they\\ncarry information from step to step via points in a continuous geometric space (state\\nvectors). Now imagine a neural  network that’s augmented in a similar way with pro-\\ngramming primitives—but inst ead of a single hardcoded for l o o p  w i t h  h a r d c o d e d\\ngeometric memory, the network includes a large set of  programming primitives that\\nthe model is free to manipulate to ex pand its processing function, such as if\\nbranches, while  statements, variable creation, di sk storage for long-term memory,\\nsorting operators, advanced data structures (such as lis ts, graphs, and hash tables),\\nand many more. The space of programs that  such a network could represent would be\\nfar broader than what can be represented with current deep-learning models, andsome of these programs could achieve superior generalization power.\\n We’ll move away from having, on one hand, hardcoded algorithmic intelligence\\n(handcrafted software) and, on the other hand, learned geometric intelligence (deep\\nlearning). Instead, we’ll have a blend of formal algorithmic modu les that provide rea-\\nsoning and abstraction capabilities, and geometric modules that provide informal\\nintuition and pattern-recognition capabiliti es. The entire system will be learned with\\nlittle or no human involvement.\\n A related subfield of \\nAI that I think may be about to take off in a big way is program\\nsynthesis , in particular neural program synthesi s. Program synthesis consists of auto-\\nmatically generating simple programs by us ing a search algorithm (possibly genetic\\nsearch, as in genetic programming) to ex plore a large space of possible programs.\\nThe search stops when a program is found that matches the required specifications,\\noften provided as a set of input-output pair s. This is highly reminiscent of machine\\nlearning: given training data provided as input-output pairs, we find a program that\\nmatches inputs to outputs and can generalize to new inputs. The difference is thatinstead of learning parameter values in a hardcoded program (a neural network), we\\ngenerate source code via a discrete search process.\\n I definitely expect this subfield to see a wave of renewed interest in the next few\\nyears. In particular, I expect the emerge nce of a crossover su bfield between deep\\nlearning and program synthesis, where inst ead of generating programs in a general-\\npurpose language, we’ll generate neural ne tworks (geometric data-processing flows)\\naugmented with a rich set of al gorithmic primitives, such as \\nfor loops and many oth-\\ners (see figure 9.5). This sh ould be far more tractable an d useful than directly gener-\\nating source code, and it wi ll dramatically expand the sc ope of problems that can be\\nsolved with machine learning—the space of programs that we can generate automati-\\ncally, given appropriate training data. Contemporary RNN s can be seen as a prehis-\\ntoric ancestor of such hybrid algorithmic-geometric models.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 353}), Document(page_content='332 CHAPTER  9Conclusions\\n  \\n9.3.2 Beyond backpropagation and differentiable layers\\nIf machine-learning models be come more like programs, then  they will mostly no lon-\\nger be differentiable—these programs will sti ll use continuous geometric layers as sub-\\nroutines, which will be differentiable, but the model as a whole won’t be. As a result,using backpropagation to adjust weight valu es in a fixed, hardcoded network can’t be\\nthe method of choice for training models in  the future—at least, it can’t be the entire\\nstory. We need to figure out how to trai n non-differentiable syst ems efficiently. Cur-\\nrent approaches include genetic algorithms,  evolution strategies, certain reinforce-\\nment-learning methods, and alternatin g direction method of multipliers (\\nADMM ).\\nNaturally, gradient descent isn’t going an ywhere; gradient information will always be\\nuseful for optimizing differentiable parametric functions. But our models will become\\nincreasingly more ambitious than mere diff erentiable parametric functions, and thus\\ntheir automatic development (the learning  in machine learning ) will require more than\\nbackpropagation.\\n In addition, backpropagation is end to end, which is a great thing for learning\\ngood chained transformations but is comput ationally inefficient because it doesn’t\\nfully take advantage of the modularity of  deep networks. To make something more\\nefficient, there’s one universa l recipe: introduce modularity and hierarchy. So we can\\nmake backpropagation more efficient by introducing decoupled training modules\\nwith a synchronization mechanism between th em, organized in a hierarchical fashion.\\nThis strategy is somewhat re flected in DeepMind’s recent work on synthetic gradients.\\nI expect more along these lines in the near  future. I can imagine a future where mod-\\nels that are globally non-differentiable (but  feature differentiable parts) are trained—\\ngrown—using an efficient search process th at doesn’t use gradients, whereas the dif-\\nferentiable parts are trained even faster by  taking advantage of gradients using a more\\nefficient version of backpropagation. \\n9.3.3 Automated machine learning\\nIn the future, model architectures will be le arned rather than be handcrafted by engi-\\nneer-artisans. Learning architectures goes ha nd in hand with the use of richer sets of\\nprimitives and program-like machine-learning models.Modular task-level program \\nlearned on the fly to solve\\na specific taskData and\\nfeedback\\nActionsGeometric\\nsubroutineAlgorithmic\\nsubroutine\\nGeometric\\nsubroutineAlgorithmic\\nsubroutineTask #002456Figure 9.5 A learned program relying \\non both geometric primitives (pattern \\nrecognition, intuition) and algorithmic \\nprimitives (reasoning, search, memory)\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 354}), Document(page_content='333 The future of deep learning\\n Currently, most of the job of a deep-l earning engineer consists of munging data\\nwith Python scripts and then tuning the architecture and hype rparameters of a deep\\nnetwork at length to get a working model—or even to get a state-of-the-art model, if\\nthe engineer is that ambitious.  Needless to say, that isn’t an optimal setup. But AI can\\nhelp. Unfortunately, the data-munging part  is tough to automate, because it often\\nrequires domain knowledge as well as a cl ear, high-level understanding of what the\\nengineer wants to achieve. Hyperparameter tuning, however, is a simple search proce-\\ndure; and in that case we know what the engineer wants to achieve: it’s defined by the\\nloss function of the network being tuned. It ’s already common practi ce to set up basic\\nAutoML  systems that take care of most model knob tuning. I even set up my own, years\\nago, to win Kaggle competitions.\\n At the most basic level, such a system wo uld tune the number of layers in a stack,\\ntheir order, and the number of units or fi lters in each layer. This is commonly done\\nwith libraries such as  Hyperopt, which we discussed in  chapter 7. But we can also be\\nfar more ambitious and attempt to learn an  appropriate architecture from scratch,\\nwith as few constraints as possible: for inst ance, via reinforcement learning or genetic\\nalgorithms.\\n Another important AutoML direction involv es learning model architecture jointly\\nwith model weights. Because training a ne w model from scratch every time we try a\\nslightly different architecture is tremendo usly inefficient, a truly powerful AutoML\\nsystem would evolve architectures at the same time the featur es of the model were\\nbeing tuned via backpropagation on the tr aining data. Such approaches are begin-\\nning to emerge as I write these lines.\\n When this starts to happen, the jobs of machine-learning engineers won’t disap-\\npear—rather, engineers will move up the valu e-creation chain. They will begin to put\\nmuch more effort into crafting complex lo ss functions that truly reflect business goals\\nand understanding how their models impact the digital ecosystems in which they’re\\ndeployed (for example, the users who co nsume the model’s predictions and generate\\nthe model’s training data)— problems that only the larg est companies can afford to\\nconsider at present. \\n9.3.4 Lifelong learning and modular subroutine reuse\\nIf models become more complex and are built  on top of richer algorithmic primitives,\\nthen this increased complexity will requir e higher reuse between tasks, rather than\\ntraining a new model from scratch every ti me we have a new task or a new dataset.\\nMany datasets don’t contain enough inform ation for us to develop a new, complex\\nmodel from scratch, and it will be necessary to use information from previously\\nencountered datasets (much as you don’t learn English from scratch every time youopen a new book—that would be impossible). Training models from scratch on every\\nnew task is also inefficient due to the la rge overlap between the current tasks and pre-\\nviously encoun tered tasks.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 355}), Document(page_content='334 CHAPTER  9Conclusions\\n A remarkable observation has been made re peatedly in recent years: training the\\nsame model to do several loosely connected ta sks at the same time  results in a model\\nthat’s better at each task . For instance, training the sa me neural machine-translation\\nmodel to perform both English-to-German translation and French-to-Italian transla-\\ntion will result in a model that’s better at  each language pair. Similarly, training an\\nimage-classification model jo intly with an image-segmen tation model, sharing the\\nsame convolutional base, results in a model th at’s better at both tasks. This is fairly\\nintuitive: there’s always some information overlap between seemingly disconnected\\ntasks, and a joint model has access to a greater amount of in formation about each\\nindividual task than a model traine d on that specific task only.\\n Currently, when it comes to model reuse across tasks, we use pr etrained weights for\\nmodels that perform common fu nctions, such as visual feature extraction. You saw\\nthis in action in chapter 5. In the future, I expect a generalized version of this to be\\ncommonplace: we’ll use not only previously learned features (sub model weights) but\\nalso model architectures and training procedures. As mo dels become more like pro-\\ngrams, we’ll begin to reuse program subroutines  like the functions and classes found in\\nhuman programming languages.\\n Think of the process of soft ware development today: once an engineer solves a spe-\\ncific problem ( HTTP  queries in Python, for instance), they package it as an abstract,\\nreusable library. Engineers wh o face a similar problem in the future will be able to\\nsearch for existing libraries, download one, and use it in their own project. In a similar\\nway, in the future, metalearni ng systems will be able to assemble new programs by sift-\\ning through a global library of high-level re usable blocks. When the system finds itself\\ndeveloping similar program su broutines for several differe nt tasks, it can come up\\nwith an abstract, reusable version of the subroutine and store it in the global library\\n(see figure 9.6). Such a process will implement abstraction : a necessary component for\\nachieving extreme generalization. A subroutine  that’s useful across different tasks and\\ndomains can be said to abstract  some aspect of problem solving. This definition of\\nabstraction is similar to the notion of ab straction in software engineering. These sub-\\nroutines can be either geometric (deep-learning modules with pretrained representa-\\ntions) or algorithmic (closer to the libra ries that contemporary software engineers\\nmanipulate).\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 356}), Document(page_content='335 The future of deep learning\\n  \\n9.3.5 The long-term vision\\nIn short, here’s my long-ter m vision for machine learning:\\n\\uf0a1Models will be more like programs and will have capabilities that go far beyond\\nthe continuous geometric transformation s of the input data we currently work\\nwith. These programs will arguably be much closer to the abstract mental mod-\\nels that humans maintain about their surroundings and themselves, and they\\nwill be capable of stronger generalizati on due to their rich algorithmic nature.\\n\\uf0a1In particular, models will blend algorithmic modules  providing formal reasoning,\\nsearch, and abstraction capabilities with geometric modules  providing informal\\nintuition and pattern-recognition capabili ties. AlphaGo (a system that required\\na lot of manual software engineering and human-made design decisions) pro-\\nvides an early example of what such a bl end of symbolic and geometric AI could\\nlook like.\\n\\uf0a1Such models will be grown  automatically rather than  hardcoded by human engi-\\nneers, using modular parts stored in a gl obal library of reusable subroutines—a\\nlibrary evolved by learning  high-performing models on thousands of previous\\ntasks and datasets. As frequent problem- solving patterns are identified by the\\nmeta-learning system, they will be turn ed into reusable subroutines—much like\\nfunctions and classes in software engi neering—and added to the global library.\\nThis will achieve abstraction .\\n\\uf0a1This global library and associated model-gr owing system will be able to achieve\\nsome form of human-like extreme generalization: give n a new task or situation,Modular task-level program \\nlearned on the fly to solve\\na specific taskData and\\nfeedback\\nActionsGeometric\\nsubroutineAlgorithmic\\nsubroutine\\nGeometric\\nsubroutineAlgorithmic\\nsubroutineGlobal library of\\nabstract subroutines\\nGeometric\\nsubroutineAlgorithmic\\nsubroutineAlgorithmic\\nsubroutine\\nGeometric\\nsubroutineAlgorithmic\\nsubroutineAlgorithmic\\nsubroutine\\nGeometric\\nsubroutineAlgorithmic\\nsubroutineAlgorithmic\\nsubroutinePerpetual meta-learner\\ncapable of quickly growing\\na task-level model\\nacross a variety of tasksPush\\nreusable\\nsubroutines\\nData and\\nfeedbackDesign\\nchoicesFetch\\nrelevant\\nsubroutines\\nTask #002456Task #002455Task #002454Task #002453\\nFigure 9.6 A meta-learner capable of quickly developi ng task-specific models using reusable primitives \\n(both algorithmic and geometric), t hus achieving extreme generalization\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 357}), Document(page_content='336 CHAPTER  9Conclusions\\nthe system will be able to assemble a new working model appropriate for the\\ntask using very little data, thanks to rich program-like primitives that generalize\\nwell, and extensive experience  with similar tasks. In the same way, humans can\\nquickly learn to play a complex new vide o game if they have experience with\\nmany previous games, because the models  derived from this previous experi-\\nence are abstract and prog ram-like, rather than a basic mapping between stim-\\nuli and action.\\n\\uf0a1As such, this perpetually learning model-growing system can be interpreted asan artificial general intelligence  (\\nAGI). But don’t expect an y singularitarian robot\\napocalypse to ensue: that’s pure fantasy,  coming from a long series of profound\\nmisunderstandings of both  intelligence and technology. Such a critique, how-\\never, doesn’t belong in this book. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 358}), Document(page_content='337 Staying up to date in a fast-moving field\\n9.4 Staying up to date in a fast-moving field\\nAs final parting words, I want to give you some pointers about how to keep learning\\nand updating your knowledge and skills after you’ve turned the last page of this book.The field of modern deep learning, as we know  it today, is only a few years old, despite\\na long, slow prehistory stre tching back decades. With an exponential increase in\\nfinancial resources and research headcount since 2013, the field as a whole is now\\nmoving at a frenetic pace. What you’ve le arned in this book won’t stay relevant for-\\never, and it isn’t all you’ll need for the rest of your career.\\n Fortunately, there are plenty of free onlin e resources that you can use to stay up to\\ndate and expand your horizons. Here are a few.\\n9.4.1 Practice on real-world problems using Kaggle\\nOne effective way to acquire real-world expe rience is to try your hand at machine-\\nlearning competitions on Kaggle ( https:/ /kaggle.com ). The only real way to learn is\\nthrough practice and actual coding—that’s the philosophy of this book, and Kaggle\\ncompetitions are the natural continuation of  this. On Kaggle, you’ll find an array of\\nconstantly renewed data-science competitio ns, many of which involve deep learning,\\nprepared by companies intere sted in obtaining novel solutions to some of their most\\nchallenging machine-learning problems. Fairly large monetary prizes are offered to\\ntop entrants.\\n Most competitions are won using either the XGBoost library (for shallow machine\\nlearning) or Keras (for deep le arning). So you’ll fit right in! By participating in a few\\ncompetitions, maybe as part of a team, you’ll  become more familiar  with the practical\\nside of some of the advanced best practice s described in this book, especially hyperpa-\\nrameter tuning, avoiding validation-set  overfitting, and model ensembling. \\n9.4.2 Read about the latest  developments on arXiv\\nDeep-learning research, in cont rast with some other scientif ic fields, takes places com-\\npletely in the open. Papers are made publicly  and freely accessible as soon as they’re\\nfinalized, and a lot of related software is open source. arXiv ( https:/ /arxiv.org )—pro-\\nnounced “archive” (the X stands for the Greek chi)—is an open-access preprint server\\nfor physics, mathematics, and computer sc ience research papers. It has become the\\nde facto way to stay up to date on the bl eeding edge of machine learning and deep\\nlearning. The large majority of deep-learning researchers upload any paper they write\\nto arXiv shortly after completion. This allows  them to plant a flag and claim a specific\\nfinding without waiting for a conference ac ceptance (which takes months), which is\\nnecessary given the fast pace of research and the intense competition in the field. It\\nalso allows the field to move extremely fast : all new findings are immediately available\\nfor all to see and to build on.\\n An important downside is that the sheer quantity of new papers posted every day\\non arXiv makes it impossible to even skim th em all; and the fact that they aren’t peer\\nreviewed makes it difficult to identify thos e that are both important and high quality.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 359}), Document(page_content='338 CHAPTER  9Conclusions\\nIt’s difficult, and becoming in creasingly more so, to find the signal in the noise. Cur-\\nrently, there isn’t a good solution to this problem. But some tools can help: an auxil-\\niary website called arXiv Sanity Preserver ( http:/ /arxiv-sanity.com ) serves as a\\nrecommendation engine for new papers and can help you keep track of new develop-\\nments within a specific narr ow vertical of deep learni ng. Additionally, you can use\\nGoogle Scholar ( https:/ /scholar.google.com ) to keep track of publications by your\\nfavorite authors. \\n9.4.3 Explore the Keras ecosystem\\nWith about 200,000 users as of November 2017 and growing fast, Keras has a largeecosystem of tutorials, guides, and related open source projects:\\n\\uf0a1Your main reference for working with  Keras is the online documentation at\\nhttps:/ /keras.io . The Keras source code can be found at https:/ /github.com/\\nfchollet/keras .\\n\\uf0a1You can ask for help and join deep-lea rning discussions on the Keras Slack\\nchannel: https://kerasteam.slack.com .\\n\\uf0a1The Keras blog, https:/ /blog.keras.io , offers Keras tutorials and other articles\\nrelated to deep learning.\\n\\uf0a1You can follow me on Twitter: @fchollet. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 360}), Document(page_content='339 Final words\\n9.5 Final words\\nThis is the end of Deep Learning with Python ! I hope you’ve learned a thing or two about\\nmachine learning, deep learning, Keras, an d maybe even cognition in general. Learn-\\ning is a lifelong journey, especially in the field of AI, where we have far more unknowns\\non our hands than certitudes. So please go on learning, questioning, and researching.\\nNever stop. Because even give n the progress made so far, most of the fundamental\\nquestions in AI remain unanswered. Many haven’t even been properly asked yet.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 361}), Document(page_content='340appendix A\\nInstalling Keras and its\\ndependencies on Ubuntu\\nThe process of setting up a deep-learning wo rkstation is fairly involved and consists\\nof the following steps, which this  appendix will cover in detail:\\n1Install the Python scientific suite— Numpy and SciPy—and make sure you\\nhave a Basic Linear Algebra Subprogram ( BLAS ) library installed so your\\nmodels run fast on CPU.\\n2Install two extras packages that come in handy when using Keras: HDF5  (for\\nsaving large neural-network files) an d Graphviz (for visualizing neural-\\nnetwork architectures).\\n3Make sure your GPU can run deep-learning code, by installing CUDA  drivers\\nand cuDNN.\\n4Install a backend for Keras: TensorFlow, CNTK , or Theano.\\n5Install Keras.\\nIt may seem like a daunting process. In fa ct, the only difficult part is setting up GPU\\nsupport—otherwise, the entire process can be done with a few commands and\\ntakes only a couple of minutes.\\n We’ll assume you have a fresh in stallation of Ubuntu, with an NVIDIA  GPU avail-\\nable. Before you start,  make sure you have pip installed and that your package man-\\nager is up to date:\\n$ sudo apt-get update\\n$ sudo apt-get upgrade\\n$ sudo apt-get install python-pip python-dev\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 362}), Document(page_content='341 Installing the Python scientific suite\\nA.1 Installing the Python scientific suite\\nIf you use a Mac, we recommend that you in stall the Python scientific suite via Ana-\\nconda, which you can get at www.continuu m.io/downloads. Note that this won’t\\ninclude HDF5  and Graphviz, which you have to install manually. Following are the\\nsteps for a manual  installation of the Python scientific suite on Ubuntu:\\n1Install a BLAS library (Open BLAS , in this case), to ensure that you can run fast\\ntensor operations on your CPU:\\n$ sudo apt-get install build-essential cmake git unzip \\\\\\npkg-config libopenblas-dev liblapack-dev\\n2Install the Python scientific suite: Nump y, SciPy and Matplotlib. This is neces-\\nsary in order to perform any kind of ma chine learning or scientific computing\\nin Python, regardless of whether you’re doing deep learning:\\n$ sudo apt-get install python-numpy python-scipy python- matplotlib\\n ➥python-yaml\\n3Install HDF5 . This library, originally developed by NASA , stores large files of\\nnumeric data in an efficient binary format . It will allow you to save your Keras\\nmodels to disk quickly and efficiently:\\n$ sudo apt-get install libhdf5-serial-dev python-h5py\\n4Install Graphviz and pydot-ng, two packag es that will let you visualize Keras\\nmodels. They aren’t necessary to run Ke ras, so you could skip this step and\\ninstall these packages when you need them. Here are the commands:\\n$ sudo apt-get install graphviz\\n$ sudo pip install pydot-ng\\n5Install additional packages  that are used in some of our code examples:\\n$ sudo apt-get install python-opencvPython 2 vs. Python 3\\nBy default, Ubuntu uses Python 2 when it installs Python packages such as python-\\npip. If you wish to use Python 3 instead, you should use the python3  prefix instead\\nof python . For instance:\\n$ sudo apt-get install python3-pip python3-dev\\nWhen you’re insta lling packages using pip, keep in mind that by default, it targets\\nPython 2. To target Python 3, you should use pip3:\\n$ sudo pip3 install tensorflow-gpu\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 363}), Document(page_content='342 APPENDIX  A Installing Keras and its dependencies on Ubuntu\\nA.2 Setting up GPU support\\nUsing a GPU isn’t strictly necessary, but it’s strongly recommended. All the code exam-\\nples found in this book can be run on a laptop CPU, but you may sometimes have to wait\\nfor several hours for a model to train,  instead of mere minutes on a good GPU. If you\\ndon’t have a modern NVIDIA  GPU, you can skip this step and go directly to section A.3.\\n To use your NVIDIA  GPU for deep learning, you need to install two things:\\n\\uf0a1CUDA —A set of drivers for your GPU that allows it to run a low-level program-\\nming language for parallel computing.\\n\\uf0a1cuDNN—A library of highly optimized primitives for deep learning. When using\\ncuDNN  and running on a GPU, you can typically increase the training speed of\\nyour models by 50% to 100%.\\nTensorFlow depends on particular versions of CUDA  and the cu DNN  library. At the\\ntime of writing, it uses CUDA  version 8 and cu DNN  version 6. Please consult the\\nTensorFlow website for detail ed instructions ab out which versions are currently rec-\\nommended: www.tensorflow.o rg/install/install_linux.\\n Follow these steps:\\n1Download CUDA . For Ubuntu (and other Linux flavors), NVIDIA  provides a\\nready-to-use package that you can download from https:/ /developer\\n.nvidia.com/cuda-downloads :\\n$ wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/\\n➥x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n2Install CUDA . The easiest way to do so is to use Ubuntu’s apt on this package.\\nThis will allow you to easily install updates via apt as they become available:\\n$ sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n$ sudo apt-key adv --fetch-keys\\n➥http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/\\n➥x86_64/7fa2af80.pub\\n$ sudo apt-get update\\n$ sudo apt-get install cuda-8-0\\n3Install cuDNN:\\naRegister for a free NVIDIA  developer account (unfortunately, this is necessary\\nin order to gain access to the cu DNN  download), and download cu DNN  at\\nhttps:/ /developer. NVIDIA .com/cudnn  (select the version of cu DNN  compati-\\nble with TensorFlow). Like CUDA , NVIDIA  provides packages for different\\nLinux flavors—we’ll use the version for Ubuntu 16.04. Note that if you’re\\nworking with an EC2 install, you won’t be able to download the cu DNN\\narchive directly to your instance; instea d, download it to your local machine\\nand then upload it to your EC2 instance (via scp).\\nbInstall cu DNN :\\n$ sudo dpkg -i dpkg -i libcudnn6*.deb\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 364}), Document(page_content='343 Installing Keras\\n4Install TensorFlow:\\naTensorFlow with or without GPU support can be installed from PyPI using\\nPip. Here’s the command without GPU support:\\n$ sudo pip install tensorflow\\nbHere’s the command to install TensorFlow with GPU support:\\n$ sudo pip install tensorflow-gpu\\nA.3 Installing Theano (optional)\\nBecause you’ve already installed TensorFlow, you don’t have to install Theano in order\\nto run Keras code. But it ca n sometimes be useful to switch back and forth from\\nTensorFlow to Theano wh en building Keras models.\\n Theano can also be installed from PyPI:\\n$ sudo pip install theano\\nIf you’re using a GPU, then you should configure Theano to use your GPU. You can\\ncreate a Theano configuration file with this command:\\nnano ~/.theanorc\\nThen, fill in the file with the following configuration:\\n[global]\\nfloatX = float32\\ndevice = gpu0\\n[nvcc]\\nfastmath = True\\nA.4 Installing Keras\\nYou can install Keras from PyPI:\\n$ sudo pip install keras\\nAlternatively, you can insta ll Keras from GitHub. Doing so will allow you to access the\\nkeras/examples folder, which contains many  example scripts for you to learn from:\\n$ git clone https://github.com/fchollet/keras\\n$ cd keras\\n$ sudo python setup.py install\\nYou can now try to run a Ke ras script, such as this MNIST  example:\\npython examples/mnist_cnn.py\\nNote that running this example to completion  may take a few minutes, so feel free to\\nforce-quit it (Ctrl-C) once you’ve verified that it’s working normally.\\n After you’ve run Keras at least once, th e Keras configuration file can be found at\\n~/.keras/keras.json. You can edit it to select the backend that Keras runs on: tensorflow ,\\ntheano , or cntk . Your configuration file should like this:\\n \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 365}), Document(page_content='344 APPENDIX  A Installing Keras and its dependencies on Ubuntu\\n{\\n\"image_data_format\": \"channels_last\",\\n\"epsilon\": 1e-07,\"floatx\": \"float32\",\\n\"backend\": \"tensorflow\"\\n}\\nWhile the Keras script examples/mnist _cnn.py is running, you can monitor GPU utili-\\nzation in a different shell window:\\n$ watch -n 5 NVIDIA-smi -a --display=utilization\\nYou’re all set! Congratulations—you can no w begin building deep-l earning applications. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 366}), Document(page_content='345appendix B\\nRunning Jupyter notebooks\\non an EC2 GPU instance\\nThis appendix provides a step-by-step gu ide to running deep-l earning Jupyter note-\\nbooks on an AWS GPU instance and editing the note books from anywhere in your\\nbrowser. This is the perfect setup for deep-learning research if you don’t have a\\nGPU on your local machine. The original (and up-to-date) version of this guide can\\nbe found at https:/ /blog.keras.io .\\nB.1 What are Jupyter notebooks? \\nWhy run Jupyter notebooks on AWS GPUs?\\nA Jupyter notebook  is a web app that allows you to write and annotate Python code\\ninteractively. It’s a great way to experi ment, do research, and share what you’re\\nworking on.\\n Many deep-learning applications are ve ry computationally intensive and can take\\nhours or even days when running on a laptop’s CPU cores. Running on a GPU can\\nspeed up training and inference by a consid erable factor (often 5 to 10 times, when\\ngoing from a modern CPU to a single modern GPU). But you may not have access to\\na GPU on your local machine. Ru nning Jupyter notebooks on AWS gives you the same\\nexperience as running on your local machine, while allowing you to use one or sev-\\neral GPUs on AWS. And you only pay for what you use, which can compare favorably\\nto investing in your own GPU(s) if you use deep learning only occasionally. \\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 367}), Document(page_content='346 APPENDIX  B Running Jupyter notebooks on an EC2 GPU instance\\nB.2 Why would you not want to use Jupyter \\non AWS for deep learning?\\nAWS GPU instances can quickly become expe nsive. The one we suggest using costs\\n$0.90 per hour. This is fine for occasional use; but if you’re go ing to run experiments\\nfor several hours per day every day, then you’re better off building your own deep-\\nlearning machine with a TITAN X  or GTX 1080 Ti.\\n In summary, use the Jupyter-on-EC2 setu p if you don’t have access to a local GPU or\\ni f  y o u  d o n ’ t  w a n t  t o  d e a l  w i t h  i n s t a lling Keras dependencies, in particular GPU\\ndrivers. If you have a access to a local GPU, we recommend running your models\\nlocally, instead. In that case, use th e installation guide in appendix A.\\nNOTE You’ll need an active AWS account. Some familiarity with AWS EC2 will\\nhelp, but it isn’t mandatory. \\nB.3 Setting up an AWS GPU instance\\nThe following setup process wi ll take 5 to 10 minutes:\\n1Navigate to the EC2 control panel at https:/ /console.aws. amazon.com/ec2/v2 ,\\nand click the Launch Instance link (see figure B.1).\\n2Select AWS Marketplace (see figure B.2), and search for “deep learning” in the\\nsearch box. Scroll down until you find the AMI named Deep Learning AMI\\nUbuntu Version (see figure B.3); select it.\\nFigure B.1 The EC2 \\ncontrol panel\\nFigure B.2 The EC2 AMI Marketplace\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 368}), Document(page_content='347 Setting up an AWS GPU instance\\n3Select the p2.xlarge instance (see figure B.4). This instance type provides access\\nto a single GPU and costs $0.90 per hour of usage (as of March 2017).\\n4You can keep the default configuration for the steps Config ure Instance, Add\\nStorage, and Add Tags, but you’ll custom ize the Configure Security Group step.\\nCreate a custom TCP rule to allow port 8888 (see figure B.5): this rule can be\\nallowed either for your current public IP (such as that of your laptop) or for any\\nIP (such as 0.0.0.0/0) if the former isn’ t possible. Note that if you allow port\\n8888 for any IP, then literally anyone will be able to listen to that port on your\\ninstance (which is where you’ll run IPython notebooks). You’ll add password\\nprotection to the notebooks to mitigate the risk of random strangers modifying\\nthem, but that may be pretty weak protec tion. If at all possible, you should con-\\nsider restricting a ccess to a specific IP. But if your IP address changes constantly,\\nthen that isn’t a practical choice. If yo u’re going to leave access open to any IP,\\nthen remember not to leave sensitive data on the instance.\\nFigure B.3 The EC2 Deep Learning AMI\\nFigure B.4 The p2.xlarge instance\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 369}), Document(page_content='348 APPENDIX  B Running Jupyter notebooks on an EC2 GPU instance\\nNOTE At the end of the launch process, you’ll be asked if you want to create\\nnew connection keys or if yo u want to reuse existing keys. If you’ve never used\\nEC2 before, create new keys and download them.\\n5To connect to your instance, select it on the EC2 control panel, click the Con-\\nnect button, and follow the instructions (see figure B.6). Note that it may take a\\nfew minutes for the instance to boot up. If you can’t connect at first, wait a bitand try again.\\n6Once you’re logged in to the instance via SSH, create an ssl directory at the root\\nof the instance, and cd to it (not mandatory, but cleaner):\\n$ mkdir ssl\\n$ cd ssl\\nFigure B.5 Configure a new security group.\\nFigure B.6 Connection instructions\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 370}), Document(page_content='349 Setting up an AWS GPU instance\\n7Create a new SSL certificate using Open SSL, and create cert.key and cert.pem\\nfiles in the current ssl directory:\\n$ openssl req -x509 -nodes -days 365 -newkey rsa:1024 -keyout \"cert.key\" -out\\n➥\"cert.pem\" -batch\\n2.3.1 Configuring Jupyter\\nBefore you use Jupyter, you need to touch up its default configuration. Follow these\\nsteps:\\n1Generate a new Jupyter config file  (still on the remote instance):\\n$ jupyter notebook --generate-config\\n2Optionally, you can generate a Jupyter password for your notebooks. Because\\nyour instance may be configur ed to be accessible from any IP (depending on\\nthe choice you made when configuring the security group), it’s better to restrict\\naccess to Jupyter via a password. To gene rate a password, open  an IPython shell\\n(ipython  command) and run the following:\\nfrom IPython.lib import passwd\\npasswd()\\nexit\\n3The passwd()  command will ask you to enter and verify a password. After you\\ndo, it will display a hash of your password. Copy that hash—you’ll need it soon.\\nIt looks something like this:\\nsha1:b592a9cf2ec6:b99edb2fd3d0727e336185a0b0eab561aa533a43\\nNote that this is a hash of the word password , which isn’t a password you should\\nbe using.\\n4Use vi (or your favorite available text editor) to edit the Jupyter config file:\\n$ vi ~/.jupyter/jupyter_notebook_config.py\\n5The config file is a Python file with al l lines commented out.  Insert the follow-\\ning lines of Python code at the beginning of the file:\\nc = get_config()\\nc.NotebookApp.certfile = u\\'/home/ubuntu/ssl/cert.pem\\'c.NotebookApp.keyfile = u\\'/home/ubuntu/ssl/cert.key\\'c.IPKernelApp.pylab = \\'inline\\'\\nc.NotebookApp.ip = \\'*\\'\\nc.NotebookApp.open_browser = False\\nc.NotebookApp.password =\\n➥\\'sha1:b592a9cf2ec6:b99edb2fd3d0727e336185a0b0eab561aa533a43\\'Path to the private key you \\ngenerated for the certificate\\nPath to the certificate \\nyou generatedServes the\\nnotebooks locally\\nInline figure when\\nusing Matplotlib Gets the config object\\nDon’t open a browser window by \\ndefault when using notebooks.Password hash you\\ngenerated earlier\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 371}), Document(page_content='350 APPENDIX  B Running Jupyter notebooks on an EC2 GPU instance\\nNOTE In case you aren’t accustomed to using vi, remember that you need to\\npress I to begin inserting content. When you’re finished, press Esc, enter :wq,\\nand press Enter to quit vi and save your changes ( :wq stands for write-quit ). \\nB.4 Installing Keras\\nYou’re almost ready to start using Jupyter. But first, you need to update Keras. A ver-\\nsion of Keras is preinstalled on the AMI, but it may not necessarily be up to date. On\\nthe remote instance , run this command:\\n$ sudo pip install keras --upgrade\\nBecause you’ll probably use Python 3 (the notebooks provided with this book use\\nPython 3), you should also update Keras using pip3 :\\n$ sudo pip3 install keras --upgrade\\nIf there’s an existing Keras configuration file on the inst ance (there shouldn’t be, but\\nthe AMI may have changed since I wrote this), yo u should delete it, just in case. Keras\\nwill re-create a standard co nfiguration file when it’s launched for the first time.\\n If the following code snippet returns an e rror saying that the file doesn’t exist, you\\ncan ignore it:\\n$ rm -f ~/.keras/keras.json\\nB.5 Setting up local port forwarding\\nIn a shell on your local machine  (not the remote instance), st art forwarding your local\\nport 443 (the HTTPS  port) to port 8888 of  the remote instance:\\n$ sudo ssh -i awsKeys.pem -L local_port:local_machine:remote_port remote_machine\\nIn my case, it would look like the following:\\n$ sudo ssh -i awsKeys.pem -L\\n➥ 443:127.0.0.1:8888 ubuntu@ec2-54-147-126-214.compute-1.amazonaws.com\\nB.6 Using Jupyter from  your local browser\\nOn the remote instance, clone the GitHub repository containing the Jupyter note-\\nbooks associated with this book:\\n$ git clone https://github.com/fchollet/deep-learning-with-python-notebooks.git\\ncd deep-learning-with-python-notebooks\\nStart Jupyter Notebook by running this command, still on the remote instance:\\n$ jupyter notebook\\nThen, in your local browser, navigate to the local address you’re forwarding to the\\nremote notebook process ( https:/ /127.0.0.1 ). Be sure you use HTTPS  in the address,\\nor you’ll get an SSL error.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 372}), Document(page_content='351 Using Jupyter from your local browser\\n You should see the safety wa rning shown in figure B.7. This warning is due to the\\nfact that the SSL certificate you generated isn’t veri fied by a trusted authority (obvi-\\nously—you generated your own). Click Advanced, and proc eed to navigate.\\nYou should be prompted to enter your Jupyte r password. You’ll then arrive at the Jupy-\\nter dashboard (see figure B.8).\\n \\n \\n \\nChoose New > Notebook to get started (see fig-ure B.9). You can use the Python version of yourchoice. All set!\\nFigure B.7 A safety warning you can ignore\\nFigure B.8 The Jupyter dashboard\\nFigure B.9 Create a new notebook.\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 373}), Document(page_content='Licensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 374}), Document(page_content='353Symbols\\n* operator 40\\n+ operator 99\\nNumerics\\n0D tensors. See scalars\\n1D convolutions 225–227\\n1D pooling, for sequence \\ndata 226\\n1D tensors. See vectors\\n2D tensors. See matrices\\n3D embeddings 253\\nA\\nactivation 160activation functions 22\\nad targeting 12\\nadd_loss method 302ADMM (alternating direction \\nmethod of \\nmultipliers) 332\\nadversarial networks 310\\nSee also generative deep \\nlearning; generative \\nadversarial networks\\nadversary network 305affine transformations 72\\nAmazon Web Services. See AWS\\nAMD 20\\nAnalytical Engine 4\\nannotations 94, 96\\napplication program interfaces. \\nSee functional APIsarchitecture of networks\\n319–322\\nconvnets 321densely connected networks\\n319–320\\nrecurrent neural networks\\n321–322\\narchitecture patterns of \\nmodels 260–263\\nbatch normalization\\n260–261\\ndepthwise separable \\nconvolution 261–263\\nresidual connections\\n235–236, 244–246\\narrow of time 100artificial intelligence 3–13, \\n270\\nexpectations for 13history of 12–13\\narXiv preprint server 271, \\n337–338\\nassembling datasets 111–112augmented intelligence 270augmenting data 138–142\\nfeature extraction with\\n149–152\\nfeature extraction without\\n147–149\\nautoencoders. See VAEs (varia-\\ntional autoencoders)\\nAutoML systems 333autonomous driving 12AWS (Amazon Web Services)\\nGPU instances\\nrunning Jupyter on 350setting up 346–350\\nusing Jupyter on 346B\\nBabbage, Charles 4\\nbackend engine, Keras 62backpropagation algorithm\\n11, 51–52, 246\\nbackward pass 49bag-of-2-grams 181\\nbag-of-3-grams 181\\nbag-of-words 181Baidu 22batch axis 35\\nbatch normalization 22\\nBatchNormalization layer 260batch_size 211\\nBengio, Yoshua 17, 188, 202\\nbidirectional layers 207binary classifications 68–77, \\n96\\nbinary crossentropy 60, 72\\nblack boxes 160BLAS (Basic Linear Algebra \\nSubprograms) 39, 340\\nborder effects 125–126broadcasting operations\\n39–40\\nbrowsers, local, using Jupyter \\nfrom 350–351\\nC\\ncallbacks, writing 251–252\\nCAM (class activation map)\\n172\\ncategorical encoding 79\\ncategorical_crossentropy \\nfunction 53, 80, 83index\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 375}), Document(page_content='354 INDEX\\nCERN 17\\nchannels axis 123channels-first convention 36channels-last convention 36character-level neural language \\nmodel 272\\nCiresan, Dan 17, 20class activation, visualizing heat-\\nmaps of 172–176\\nclasses 27, 96classification 60cloud, running jobs in 66clustering 94CNNs. See convnets (convolu-\\ntional neural networks)\\nCNTK (Microsoft Cognitive \\nToolkit) 62\\ncompilation step 29concept vectors, for editing \\nimages 297–298\\nconditioning data 272Connect button, EC2 control \\npanel 348\\nconnections, residual 244–246\\ncontent loss 288Conv1D layer 226Conv2D layer 120, 122, 124convnets (convolutional neural \\nnetworks) 321\\n1D 226–227combining with recurrent \\nneural networks\\n228–231\\noverview 120–129\\nconvolution operations\\n122–127\\nmax-pooling operations\\n127–129\\nprocessing sequences with\\n225–231\\ntraining on small datasets\\n130–142\\nbuilding networks\\n133–135\\ndata preprocessing\\n135–138\\nrelevance for small-data \\nproblems 130–131\\nusing data augmentation\\n138–142\\nusing pretrained convnets\\n143–159\\nfeature extraction\\n143–152\\nfine-tuning 152–158visualizing convnet learning\\n160–176\\nconvnet filters 167–172heatmaps of class \\nactivation 172–176\\nintermediate activations\\n160–166\\nconvnets filters 160convolution base 143–144convolution operations\\n122–127\\nborder effects 125–126convolution strides 127paddling 125–126\\nconvolution strides 127convolutions\\n1D 225–226\\ndepthwise separable\\n261–263\\nCortes, Corinna 15crossentropy 73CUDA drivers 20, 340, 342cuDNN library 62, 340, 342curvature 48\\nD\\ndata\\naugmenting 138–142\\nfeature extraction with\\n149–152\\nfeature extraction without\\n147–149\\nbatches of 34–35\\ngenerating sequence data\\n272\\nheterogeneous 101\\nhomogenous 101learning representations \\nfrom 6–8\\nmissing 102\\npreparing 112–113\\nfor character-level LSTM \\ntext generation 274\\nfor recurrent neural \\nnetworks 210–212\\npreprocessing 101–103,\\n135–138\\nredundancy 100representations for neural \\nnetworks 31–37\\n3D tensors 32data batches 34–35\\nexamples of data tensors\\n35higher-dimensional \\ntensors 32\\nimage data 36–37\\nkey attributes of tensors\\n32–33\\nmanipulating tensors in \\nNumpy 34\\nmatrices (2D tensors)\\n31–32\\nscalars (0D tensors) 31sequence data 35–36timeseries data 35–36vector data 35vectors (1D tensors) 31\\nvideo data 37\\nshuffling 98, 100splitting 98tokenizing 189–190transformations 10transforming 6\\nvectorization 101\\ndata augmentation 130data distillation 28data points 27, 220data representativeness 100\\ndata tensors, examples of 35\\ndatasets, assembling 111–112DCGANs (deep convolutional \\nGANs)\\noverview 307training 310–312\\ndecision boundaries 15\\ndecision trees 16–17deep convnets 266deep learning 3, 6–13\\naccomplishments of 11–12achievements of 315–316\\ndemocratization of 23\\nenabling technologies\\n317–318\\nfuture of 23–24, 330–336\\nautomated machine \\nlearning 332–333\\nlifelong learning 333–335\\nlong-term vision 335–336models as programs\\n330–332\\nmodular subroutine reuse\\n333–335\\ngeometric interpretation of\\n44–45\\nhardware and 20–21investment in 22–23limitations of 325–329\\nlocal generalization vs. \\nextreme generalization327–329\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 376}), Document(page_content='355 INDEX\\ndeep learning, limitations of \\n(continued)\\nrisk of anthropomorphiz-\\ning machine-learning \\nmodels 325–327\\noverview 9–11, 316–317possible uses of 322–324reasons for interest in 20–24See also generative deep \\nlearning\\nDeep Learning AMI, EC2 66DeepDream technique\\n280–286\\noverview 280implementing in Keras\\n281–286\\nDeepMind, Google 22, 95\\nDense layers 28, 38, 53, 69–70, \\n122, 187, 213, 321\\ndense sampling 328densely connected networks\\n319–320\\ndepthwise separable \\nconvolution 321\\nderivatives, defined 47–48developer account, NVIDIA\\n342\\ndigital assistants 12\\ndimension 31dimensionality 31, 94directed acyclic graphs of \\nlayers 242–246\\ninception modules 242–244\\nresidual connections\\n244–246\\ndiscriminator networks\\noverview 305implementing 307–309\\ndistance function 288dot operations 40–42\\ndot product 38\\ndownloading\\nGloVe word embeddings 190raw text 189\\nDropout layer 140dtype attribute 32–33\\nE\\nEarlyStopping callbacks 250Eck, Douglas 271editing images, concept vectors \\nfor 297–298\\nEigen 62element-wise operations 38–39\\nembedding layers, learning \\nword embeddings with 185–187\\nengineering features 101–103\\nensembling models 264–266\\nepochs 53, 74, 76, 82\\nepsilon 300\\nevaluating models 192–195\\nevaluation protocols, choosing\\n100, 112\\nexpert systems 4\\nextreme generalization, local \\ngeneralization vs.\\n327–329\\nextreme inception 244\\nF\\nfeature engineering 16, 18feature learning 101–103\\nfeature maps 123, 129\\nfeatures\\nengineering 101–103\\nextracting 143–152\\nwith data augmentation\\n149–152\\nwithout data augmentation\\n147–149\\nfeatures axis 35\\nfeedforward networks 196, 202\\nFeynman, Richard 316fill_mode 139\\nfilter visualizations 172\\nfilters\\noverview 124\\nconvnets, visualizing 167–172\\nfine-tuning 152–158\\nfit method 29\\nfit_generator method 136\\nFlatten layer 133\\nFlickr 21\\nfloat32 29, 101, 173for loop 38, 197, 331\\nforward pass 46\\nfreezing layers 150\\nfully connected layers 58\\nfunctional APIs, Keras 234–248\\ndirected acyclic graphs of \\nlayers 242–246\\nlayer weight sharing 246–247\\nmodels as layers 247–248\\nmulti-input models 238–240\\nmulti-output models 240–242G\\nGal, Yarin 216\\nGANs (generative adversarial \\nnetworks) 296, 305\\ngated recurrent unit layers.\\nSee GRU layers\\nGatys, Leon 287Gaussian distribution 307generalization 104, 327–329generative deep learning\\ngenerating images with varia-\\ntional autoencoders\\n296–304\\nconcept vectors for image \\nediting 297–298\\nsampling from latent \\nspaces of images296–297\\ngenerating text with LSTM\\n271–279\\ngenerating sequence data\\n272\\nhistory of generative recur-\\nrent networks 271\\nimplementing character-\\nlevel LSTM text generation 274–279\\nsampling strategy 272–274\\ngenerative adversarial \\nnetworks 305–313\\nadversarial networks 310discriminator networks\\n307–309\\ngenerator networks\\n307–308\\nschematic implementa-\\ntion of 307\\ntraining DCGANs 310–312\\nneural style transfer 287–295\\ncontent loss 288in Keras 289–295\\nstyle loss 288–289\\ngenerative deep learning, \\nDeepDream 280–286\\ngenerative recurrent networks, \\nhistory of 271\\ngenerator function 211, 230\\ngenerator networks, \\nimplementing 307–308\\ngeometric interpretation\\nof deep learning 44–45of tensor operations 43–44\\ngeometric space 316\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 377}), Document(page_content='356 INDEX\\nGloVe (Global Vectors for Word \\nRepresentation)\\ndownloading word \\nembeddings 190\\nloading embeddings in \\nmodels 191\\nGoodfellow, Ian 305GPUs (graphics processing \\nunits)\\ninstalling on AWS 350instances, on AWS 346–350overview 20selecting 66–67support, setting up on \\nUbuntu 342–343\\ngradient boosting machines\\n16–17\\ngradient descent 167\\ngradient propagation 22gradient-based optimization\\n46–52\\nbackpropagation algorithm\\n51–52\\nderivatives, defined 47–48gradients 48stochastic gradient descent\\n48–51\\ngradients 48Gram matrix 288graphs, directed acyclic of \\nlayers 242–246\\nGraphviz 257, 340–341Graves, Alex 271greedy sampling 272ground-truth 96GRU (gated recurrent unit) \\nlayers 202–204, 215\\nH\\nhandwriting transcription 11\\nhardware 20–21hash collisions 183HDF5 340heatmaps\\nof class activation, visualizing\\n172–176\\noverview 160\\nheight_shift range 139heterogeneous data 101hidden layers 77hidden unit 70hierarchical representation \\nlearning 8Hinton, Geoffrey 17, 109\\nHochreiter, Sepp 202\\nhold-out validation 98–99\\nhomogenous data 101horizontal_flip 139HSV (hue-saturation-value) \\nformat 6\\nHyperas library 264\\nHyperopt 264hyperparameters\\noptimizing 263–264overview 98\\ntuning 114–115\\nhyperplanes 15hypothesis space 59, 72, 319\\nI\\nIDSIA 17\\nILSVRC (ImageNet Large Scale \\nVisual Recognition \\nChallenge) 21\\nimage classification 11image data 36–37, 319\\nimage segmentation 94\\nimage-classification task 262ImageDataGenerator class 135, \\n139, 147\\nImageNet class 17, 145, 281\\nimages\\nediting concept vectors for\\n297–298\\nflipping 139generating with variational \\nautoencoders 296–304\\nconcept vectors for image \\nediting 297–298\\noverview 296\\nsampling from latent spaces \\nof 296–297\\ninception blocks 59Inception modules 235,\\n242–244, 281\\ninclude_top argument 145information bottlenecks 80, 84information distillation \\npipeline 166\\ninformation leaks 97initial state 196\\ninput data 6–7, 58, 95\\ninput_shape argument 145input_tensor 237\\ninstalling\\nCUDA 342cuDNN 342Keras 343–344, 350\\nOpenBLAS 341\\nOpenCV 341\\nPython scientific suite on \\nUbuntu 341\\nTensorFLow 343\\nTheano on Ubuntu 343\\nIntel 22intermediate activations, \\nvisualizing 160–166\\ninvestments in deep learning\\n22–23\\nipython command 349\\nJ\\njoint feature learning 18\\nJupyter notebooks 65\\nconfiguring 349–350overview 345\\nrunning on AWS GPU \\ninstances\\ninstalling Keras 350\\nsetting up AWS GPU \\ninstances 346–350\\nsetting up local port \\nforwarding 350\\nusing from local browsers\\n350–351\\nusing on AWS 346\\nK\\nK80, NVIDIA 21\\nKaggle platform\\noverview 16, 19, 266practice on real-world prob-\\nlems using 337\\nKeras API 234–248\\ndirected acyclic graphs of \\nlayers 242–246\\nexploring 338\\nfunctional APIs 236–238\\nimplementing DeepDream \\nin 281–286\\ninstalling 343–344, 350layer weight sharing 246–247\\nmodels as layers 247–248\\nmulti-input models 238–240multi-output models\\n240–242\\nneural style transfer in\\n289–295\\nrecurrent layers in 198–202using callbacks 249–259\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 378}), Document(page_content='357 INDEX\\nKeras framework 61–64\\nCNTK 62\\ndeveloping with 62–64\\nrunning 66\\nTensorFlow 62\\nTheano 62\\nKeras library 27\\nkeras.applications module 145\\nkeras.callbacks module 249, \\n251\\nkeras.preprocessing.image 135\\nkernel methods 15–16\\nkernel trick 15\\nK-fold validation, iterated with \\nshuffling 99–100\\nKingma, Diederik P. 298\\nKrizhevsky, Alex 20\\nL\\nL1 regularization 107\\nL2 regularization 107\\nlabel 27, 96\\nLambda layer 301\\nlanguage models\\nsampling from 276–278\\ntraining 276–278\\nlast-layer activation 113\\nlatent spaces\\nof images, sampling from\\n296–297\\noverview 270\\nlayer compatibility 59\\nlayered representations \\nlearning 8\\nlayers\\ndifferentiable 332\\ndirected acyclic graphs of\\n242–246\\ninception modules\\n242–244\\nresidual connections\\n244–246\\nfreezing 150\\nmodels as 247–248overview 8, 58–59\\nrecurrent\\nin Keras 198–202\\nstacking 217–219\\nunfreezing 154\\nweight sharing 246–247\\nlayer-wise pretraining 22\\nLeakyReLU layer 308\\nLeCun, Yann 15, 17LeNet network 15\\nLHC (Large Hadron Collider)\\n17\\nlifelong learning 333–335\\nlinear transformations 72\\nlocal generalization, extreme \\ngeneralization vs.327–329\\nlocal port forwarding, setting \\nup 350\\nlogistic regression algorithm\\n85\\nlogreg (logistic regression) 14logs argument 251\\nlookback parameter 230\\nlookback timesteps 210loss function 10, 29, 58, 60, 113loss plateau 250\\nloss value 96\\nLovelace, Ada 5LSTM (long short-term \\nmemory) 58, 202–204\\ngenerating text with 271–279\\ngenerating sequence data\\n272\\nhistory of generative recur-\\nrent networks 271\\nimplementing character-\\nlevel text generation\\n274–279\\nsampling strategy 272–274\\noverview 20, 269\\nM\\nmachine learning\\nautomated 332–333\\nbasic approaches 213–215branches of 94–96\\nreinforcement learning\\n95–96\\nself-supervised learning\\n94–95\\nsupervised learning 94\\nunsupervised learning 94\\ndata preprocessing 101–103\\ndeep learning vs. 17–18\\nevaluating models of 97–100\\nchoosing evaluation \\nprotocols 100\\ntest sets 97–100\\ntraining sets 97–100validation sets 97–100\\nfeature engineering 101–103\\nfeature learning 101–103history of 14–19\\ndecision trees 16–17gradient boosting \\nmachines 16–17\\nkernel methods 15–16neural networks 14–15, 17probabilistic modeling 14random forests 16–17\\nlearning representations \\nfrom data 6–8\\nmodels, risk of anthropo-\\nmorphizing 325–327\\noverfitting and underfitting\\n104–110\\nadding dropout 109–110\\nadding weight \\nregularization 107–108\\nreducing network size\\n104–107\\nworkflow of 111–115,\\n318–319\\nassembling datasets\\n111–112\\nchoosing evaluation \\nprotocol 112\\nchoosing measure of \\nsuccess 112\\ndefining problems\\n111–112\\ndeveloping models\\n113–114\\npreparing data 112–113regularizing models\\n114–115\\ntuning hyperparameters\\n114–115\\nSee also non-machine learn-\\ning\\nMAE (mean absolute error)\\n87, 91, 212, 320\\nMatplotlib library 33, 74, 349matrices (2D tensors) 31–32maximum operation 40max-pooling operations\\n127–129\\nMaxPooling1D layer 226, 231MaxPooling2D layer 120, 122, \\n127\\nmean_squared_error 73memorization capacity 104metrics 29metrics, logging 249Microsoft Cognitive Toolkit.\\nSee CNTK\\nMikolov, Tomas 188\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 379}), Document(page_content='358 INDEX\\nmini-batch 96\\nmini-batch SGD (mini-batch \\nstochastic gradient \\ndescent) 49\\nMinsky, Marvin 12MNIST dataset 27, 68model checkpointing 249Model class 162model depth 8model plot 258model.fit() function 249model.fit_generator() function\\n249\\nModelCheckpoint callbacks\\n250\\nmodels\\narchitecture patterns\\n260–263\\nbatch normalization\\n260–261\\ndepthwise separable \\nconvolution 261–263\\nresidual connections\\n235–236, 244–246\\nas layers 247–248\\nas programs 330–332defining 191developing\\nachieving statistical power\\n113–114\\ndetermining capacity 114\\nensembling 264–266evaluating 192–195hyperparameter optimization\\n263–264\\nlanguage\\nsampling from 276–278training 276–278\\nloading GloVe embeddings \\nin 191\\nmachine learning, risk of \\nanthropomorphizing 3\\n25–327\\nmulti-input 238–240multi-output 240–242regularizing 114–115training 192–195using Keras callbacks\\n249–259\\nusing TensorBoard 249–259\\nmodular subroutines, reusing\\n333–335\\nmodules, inception 242–244momentum 50Moore’s law 21, 317MSE (mean squared error) 77, \\n87, 91, 241, 320\\nmulticlass classifications 78–84\\nmultihead networks 59multi-input models 238–240multilabel classification 78, 96, \\n320\\nmultimodal inputs 234\\nmulti-output models 240–242\\nN\\nN classes 84\\nNaive Bayes algorithm 14naive_add 39National Institute of Standards \\nand Technology.See NIST\\nndim attribute 31Nervana Systems 22neural layers 22neural networks\\nanatomy of 58–60\\nlayers 58–59loss functions 60models 59–60optimizers 60\\nbinary classifications 68–77breakthroughs in 17data preprocessing for\\n101–102\\nhandling missing values\\n102\\nvalue normalization\\n101–102\\nvectorization 101\\ndata representations for\\n31–37\\n3D tensors 32data batches 34–35examples of data tensors\\n35\\nhigher-dimensional \\ntensors 32\\nimage data 36–37key attributes of tensors\\n32–33\\nmanipulating tensors in \\nNumpy 34\\nmatrices (2D tensors)\\n31–32\\nscalars (0D tensors) 31sequence data 35–36timeseries data 35–36vector data 35\\nvectors (1D tensors) 31video data 37\\ngradient-based optimization\\n46–52\\nbackpropagation \\nalgorithm 51–52\\nderivatives 47–48\\ngradients 48stochastic gradient \\ndescent 48–51\\nKeras 61–64\\nCNTK 62\\ndeveloping with 62–64\\nTensorFlow 62Theano 62\\nmulticlass classifications\\n78–84\\nregression 85–91\\nsetting up workstations\\n65–67\\nGPUs for deep learning\\n66–67\\nJupyter notebooks 65\\nrunning jobs in cloud 66\\nrunning Keras 66\\ntensor operations 38–45\\nbroadcasting 39–40dot 40–42element-wise 38–39geometric interpretation \\nof 43–44\\ngeometric interpretation \\nof deep learning 44–45\\nreshaping 42–43\\nneural style transfer 287–295\\ncontent loss 288\\nin Keras 289–295style loss 288–289\\nN-grams 180NIST (National Institute of \\nStandards and \\nTechnology) 27\\nnon-linearity function 72non-machine learning, \\nbaselines 212–213\\nnonstationary problems 111\\nnormalizing batches 260–261normalizing values 101–102Numpy arrays 28, 31Numpy library, manipulating \\ntensors in 34\\nNumpy matrix 31\\nNumpy tensors 53NVIDIA 20, 66\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 380}), Document(page_content='359 INDEX\\nO\\nobject detection 94\\nobjective function 10, 60\\nOccam’s razor principle 107octaves 281–282\\none-hot encoding\\nof characters 181–183\\nof words 181–183\\noverview 79, 84, 101\\nonline documentation, Keras\\n338\\noptimization 22, 50, 104, 113, \\n263–264\\noptimizer argument 11, 29, 58, \\n73\\noptimizers 60\\noutput\\nclasses 77\\noverview 95tensor 237\\noverfitting\\nadding dropout 109–110\\nadding weight regularization\\n107–108\\nreducing network size\\n104–107\\nusing recurrent dropout to \\nfight 216–217\\nP\\npadding 125–126\\nparameterized layers 10parameters\\nadjusting 249overview 97\\npartitions 99\\npasswd() command 349PCA (principal component \\nanalysis) 255\\nPichai, Sundar 22pip 350plot_model 258\\nplotting code 156\\npointwise convolutions 243pooling 1D, for sequence data\\n226\\npredict method 76, 83, 147prediction error 95–96predictions 83\\npreparing data 112–113\\npreprocessing\\ndata 101–103, 135–138\\nfor neural networks\\n101–102overview 135–138\\nembeddings 190–191\\npretrained convnets 143–159\\nfeature extraction 143–152\\nwith data augmentation\\n149–152\\nwithout data augmentation\\n147–149\\nfine-tuning 152–158with small datasets 159\\npretrained networks 130, 143\\npretrained word embeddings\\n184\\nprobabilistic modeling 14\\nprobability distribution 80problems, defining 111–112processing sequences with \\nconvnets 225–231\\n1D convolution for sequence \\ndata 225–226\\n1D pooling for sequence data\\n226\\ncombining with recurrent \\nneural networks to pro-cess long sequences\\n228–231\\nimplementing 1D convnets\\n226–227\\nprogram subroutines 334program synthesis 331PyCharm 65\\npydot library 257\\npydot-ng 341Python\\ninstalling scientific suite on \\nUbuntu 341\\noverview 19\\npython-pip package 341\\nQ\\nquestion-answering model 238\\nR\\nrandom forests 16–17\\nrandomly shuffle data 100randomness 272rank 31recurrent dropout 207, 216\\nrecurrent layers, bidirectional\\n207recurrent neural networks\\n196–224, 319, 321–322\\nbasic machine-learning \\napproach 213–215\\nbidirectional 219–222combining with \\nconvnets 228–231\\nfirst recurrent baseline\\n215–216\\ngenerative, history of 271GRU layers 202–204LSTM layers 202–204non-machine-learning \\nbaselines 212–213\\npreparing data for 210–212\\nrecurrent layers in Keras\\n198–202\\nstacking recurrent layers\\n217–219\\nusing recurrent dropout to \\nfight overfitting216–217\\nReduceLROnPlateau callbacks\\n250–251\\nregression 60, 85–91, 320\\nregularization loss function\\n300\\nregularizing models 114–115reinforcement learning 95–96relu (rectified linear unit) 71representations\\nextracting 28\\noverview 6\\nreshaping tensors 42–43residual connections 235response map 124return_sequences argument\\n198\\nreusability 23\\nreverse-mode differentiation\\n52\\nRGB (red-green-blue) format 6RMSProp optimizer 53, 73, 77, \\n135, 155, 222\\nRNN (recurrent neural \\nnetwork) 196\\nrotation_range 139\\nS\\nsamples axis 34\\nsamples dimension 34sampling\\nfrom language models\\n276–278\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 381}), Document(page_content='360 INDEX\\nsampling (continued)\\nfrom latent spaces of images\\n296–297\\nstrategies 272–274\\nSanity Preserver, arXiv 338scalar regression 86, 96scalar tensor 31scalars (0D tensors) 31schematic implementation, of \\nGAN 307\\nSchmidhuber, Jürgen 202Scikit-Learn 63SciPy 284, 341self-supervised learning 94–95selu function 261\\nSeparableConv2D layer 261, \\n321\\nseparation hyperplane 15sequence data\\ngenerating 272overview 35–36\\nsequence generation 94\\nsequence prediction 60sequences, processing with \\nconvnets 225–231\\n1D convolution for sequence \\ndata 225–226\\n1D pooling for sequence \\ndata 226\\ncombining with recurrent \\nneural networks\\n228–231\\nimplementing 1D convnets\\n226–227\\nSequential class 63, 248\\nSequential model 150, 234SGD (stochastic gradient \\ndescent) 48–51, 60\\nshallow learning 8shared LSTM 247\\nshear_range 139\\nshow_shapes option 258shuffling, iterated K-fold valida-\\ntion with 100\\nSiamese LSTM model 247sigmoid function 71, 86, 320\\nSimonyan, Karen 143\\nSimpleRNN layer 198, 322single-label\\ncategorical classification 320multiclass classification 78\\nsliding windows 124Smart Reply feature, Google\\n271\\nsmile vector 297softmax 28, 80, 84, 273, 320\\nsound data 319sparse_categorical_crossentropy\\n83–84\\nspatially hierarchical patterns\\n123\\nspeech recognition 11ssl directory 348stacking recurrent layers\\n217–219\\nstatistical power, developing \\nmodels with 113–114\\nsteps_per_epoch 136stochastic gradient descent.\\nSee SGD\\nstochastic sampling 272\\nstochasticity 272, 308\\nstrided convolutions 127strides 125style function 288\\nstyle loss 288–289\\nsubroutines, reusing modular\\n333–335\\nsupervised learning 94SVM (support vector machine)\\n15\\nsymbolic AI 4, 12\\nsymbolic differentiation 52syntax tree prediction 94\\nSzegedy, Christian 235\\nT\\ntanh activation 77\\ntarget 95temporal leak 100temporally supervised learning\\n95\\nTensorBoard applications 233, \\n249–259\\nTensorFlow visualization \\nframework 252–258\\ntensors\\nhigher-dimensional 32\\nkey attributes of 32–33\\nmanipulating in Numpy 34operations of 38–45\\nbroadcasting 39–40dot 40–42element-wise 38–39geometric interpretation \\nof 43–44\\ngeometric interpretation \\nof deep learning 44–45\\nreshaping 42–43reshaping 42\\nslicing 34See also data tensors\\ntest sets 97–100\\nhold-out validation 98–99iterated K-fold validation \\nwith shuffling 100\\nK-fold validation 99\\ntext data 180–195, 319\\ndownloading raw text\\n188–195\\none-hot encoding of words \\nand characters\\n181–183\\nword embeddings 184–195\\ndefining models 191downloading GloVe word \\nembeddings 190\\nlearning with embedding \\nlayers 185–187\\nloading GloVe embeddings \\nin models 191\\npreprocessing 190–191pretrained 188tokenizing data 189–190training and evaluating \\nmodels 192–195\\ntext, generating with LSTM\\n271–279\\ngenerating sequence data\\n272\\nhistory of generative recur-\\nrent networks 271\\nimplementing character-level \\ntext generation 274–279\\nsampling strategy 272–274\\ntext-to-speech conversion 12Theano\\ninstalling on Ubuntu 343overview 23, 62\\ntimeseries data 35–36, 319timesteps 210TITAN X, NVIDIA 21token embedding 180tokenizing data, word \\nembeddings 189–190\\ntotal variation loss 291TPU (tensor processing unit)\\n21\\ntrainable attribute 150training\\nconvnets on small datasets\\n130–142\\nbuilding networks\\n133–135\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 382}), Document(page_content='361 INDEX\\ntraining, convnets on small \\ndatasets (continued)\\ndata preprocessing\\n135–138\\ndownloading data\\n131–133\\nrelevance for small-data \\nproblems 130–131\\nusing data augmentation\\n138–142\\ninterrupting 249language models 276–278\\nmodels 192–195\\ntraining loop 11, 46training sets 97–100\\nhold-out validation 98–99iterated K-fold validation \\nwith shuffling 100\\nK-fold validation 99\\ntrain_labels variable 27, 68\\ntranslation-invariant patterns\\n123, 321\\ntransposition 43\\nTuring test 5\\nTuring, Alan 5two-branch networks 59Tyka, Mike 280, 306\\nU\\nUbuntu\\ninstalling Keras on 343–344installing Python scientific \\nsuite on 341\\ninstalling Theano on 343setting up GPU support\\n342–343\\nunderfitting 104–110\\nadding dropout 109–110\\nadding weight regularization\\n107–108\\nreducing network size\\n104–107\\nunfreezing layers 154\\nUnix workstation 65\\nunsupervised learning 94\\nV\\nVAEs (variational autoencod-\\ners), generating images \\nwith 296–304\\nconcept vectors for image editing 297–298\\nsampling from latent spaces \\nof images 296–297\\nvalidation scores 100validation sets 97–100\\nhold-out validation 98–99\\niterated K-fold validation \\nwith shuffling 100\\nK-fold validation 99\\noverfitting 97overview 73\\nvalidation_data argument 74, \\n137\\nvalidation_steps argument 137\\nvalues\\nhandling missing 102normalizing 101–102\\nvanishing gradient problem\\n202\\nVapnik, Vladimir 15vector data 35, 319\\nvector regression 96\\nvectorization 101vectorized data 69\\nvectorized implementations 38\\nvectorizing text 180vectors (1D tensors) 31\\nversatility 23\\nvi 350video data 37, 319\\nvisual concepts 160\\nvisualizing\\nconvnet filters 167–172convnet learning 160–176\\nheatmaps of class activation\\n172–176\\nintermediate activations\\n160–166\\nvolumetric data 319\\nW\\nweight decay 107\\nweight regularization, \\nadding 107–108\\nweight sharing of layers\\n246–247\\nweight-initialization schemes\\n22\\nweights argument, VGG16 58, \\n145\\nweights, layers 10\\nWelling, Max 298\\nwidth_shift range 139word embeddings 184–195\\ndefining models 191\\ndownloading GloVe word \\nembeddings 190\\nevaluating models 192–195\\nlearning embedding layers\\n185–187\\nloading GloVe embeddings \\nin models 191\\npreprocessing embeddings\\n190–191\\ntokenizing data 189–190\\ntraining models 192–195\\nusing pretrained word \\nembeddings 188\\nword vectors 184\\nWord2vec algorithm 188\\nword-embedding space 185\\nword_index 69workflow of machine learning\\n111–115, 318–319\\nassembling datasets 111–112\\nchoosing evaluation protocol\\n112\\nchoosing measure of success\\n112\\ndefining problems 111–112developing models 113–114\\npreparing data 112–113\\nregularizing models 114–115\\ntuning hyperparameters\\n114–115\\nworkflows 18\\nworkstations, setting up 65–67\\nJupyter notebooks 65running jobs in cloud 66\\nrunning Keras 66\\nselecting GPUs 66–67\\nwriting callbacks 251–252\\nX\\nXception 244, 248XGBoost library 19, 337\\nY\\nyield operator 136\\nZ\\nZisserman, Andrew 143zoom_range 139\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 383}), Document(page_content='For ordering information go to www.manning.com\\nMachine Learning with TensorFlow\\nby Nishant Shukla\\nISBN: 9781617293870\\n325 pages, $44.99December 2017\\nThe Quick Python Book, Third Edition\\nby Naomi Ceder\\nISBN: 9781617294037\\n400 pages, $39.99December 2017\\nR in Action, Second Edition\\nData analysis and graphics with R\\nby Robert I. Kabacoff\\nISBN: 9781617291388\\n608 pages, $59.99May 2015\\nPractical Data Science with R\\nby Nina Zumel and John Mount\\nISBN: 9781617291562\\n416 pages, $49.99March 2014RELATED MANNING TITLES\\nLicensed to   <null>', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 384}), Document(page_content='François Chollet\\nMachine learning has made remarkable progress in recent \\nyears. We went from near-unusable speech and image recognition, to near-human accuracy. We went from \\nmachines that couldn’t beat a serious Go player, to defeating a world champion. Behind this progress is deep learning—a combination of engineering advances, best practices, and theory that enables a wealth of previously impossible smart applications.\\nDeep Learning with Python  introduces the ﬁ  eld of deep learn-\\ning using the Python language and the powerful Keras library. Written by Keras creator and \\nGoogle AI researcher François \\nChollet, this book builds your understanding through intuitive explanations and practical examples. You’ll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you ﬁ  nish, you’ll have the knowledge and hands-on skills \\nto apply deep learning in your own projects. \\nWhat’s Inside\\n● Deep learning from ﬁ  rst principles\\n● Setting up your own deep-learning environment\\n● Image-classiﬁ  cation models\\n● Deep learning for text and sequences\\n● Neural style transfer, text generation, and image generation\\nReaders need intermediate Python skills. No previous experi-\\nence with Keras, TensorFlow, or machine learning is required.\\nFrançois Chollet  is an AI researcher on the Google Brain Team \\nand author of the Keras deep-learning library.\\nTo download their free eBook in PDF, ePub, and Kindle formats, \\nowners of this book should visit \\nwww.manning.com/books/deep-learning-with-python\\n$49.99 / Can $65.99  [INCLUDING eBOOK]\\nDeep Learning with PythonPYTHON/MACHINE LEARNING\\nMANNING“The clearest explanation \\nof deep learning I have come \\nacross ... it was a joy to read.” \\n—Richard Tobias, Cephasonics\\n“An excellent hands-on \\nintroductory title, with \\n  great depth and breadth.”—David Blumenthal-Barby\\nBabbel\\n“Bridges the gap between \\n the hype and a functioning  \\ndeep-learning system.”—Peter Rabinovitch, Akamai \\n“The best resource for \\nbecoming a master of \\n Keras and deep learning.” \\n—Claudio Rodriguez\\nCox Media GroupSEE  INSERT', metadata={'source': '/content/drive/MyDrive/RAG_DATA/deeplearningwithpython.pdf', 'page': 385}), Document(page_content='', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 0}), Document(page_content='', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 1}), Document(page_content='AN\\tIMPRINT\\tOF\\tPENGUIN\\tRANDOM\\tHOUSE\\tLLC\\n375\\tHudson\\tStreet\\nNew\\tYork,\\tNew\\tYork\\t10014\\nCopyright\\t©\\t2018\\tby\\tJames\\tClear\\nPenguin\\tsupports\\tcopyright.\\tCopyright\\tfuels\\tcreativity,\\tencourages\\tdiverse\\tvoices,\\tpromotes\\tfree\\tspeech,\\tand\\tcreates\\ta\\tvibrant\\tculture.\\tThank\\tyou\\tfor\\tbuying\\tan\\tauthorized\\tedition\\tof\\tthis\\tbook\\tand\\tfor\\ncomplying\\twith\\tcopyright\\tlaws\\tby\\tnot\\treproducing,\\tscanning,\\tor\\tdistributing\\tany\\tpart\\tof\\tit\\tin\\tany\\tform\\twithout\\tpermission.\\tYou\\tare\\tsupporting\\twriters\\tand\\tallowing\\tPenguin\\tto\\tcontinue\\tto\\tpublish\\tbooks\\nfor\\tevery\\treader.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 2}), Document(page_content='Ebook\\tISBN\\t9780735211308\\nWhile\\tthe\\tauthor\\thas\\tmade\\tevery\\teffort\\tto\\tprovide\\taccurate\\tInternet\\taddresses\\tat\\tthe\\ttime\\tof\\tpublication,\\tneither\\tthe\\tpublisher\\tnor\\tthe\\tauthor\\tassumes\\tany\\tresponsibility\\tfor\\terrors,\\tor\\tfor\\tchanges\\tthat\\toccur\\nafter\\tpublication.\\tFurther,\\tthe\\tpublisher\\tdoes\\tnot\\thave\\tany\\tcontrol\\tover\\tand\\tdoes\\tnot\\tassume\\tany\\tresponsibility\\tfor\\tauthor\\tor\\tthird-party\\twebsites\\tor\\ttheir\\tcontent.\\nVersion_1', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 3}), Document(page_content='a·tom·ic\\nəˈ\\ntämik\\n1.\\t\\nan\\textremely\\tsmall\\tamount\\tof\\ta\\tthing;\\tthe\\tsingle\\tirreducible\\tunit\\tof\\ta\\tlarger\\tsystem.\\n2.\\t\\nthe\\tsource\\tof\\timmense\\tenergy\\tor\\tpower.\\nhab·it\\nˈ\\nhab\\nə\\nt\\n1.\\t\\na\\troutine\\tor\\tpractice\\tperformed\\tregularly;\\tan\\tautomatic\\tresponse\\tto\\ta\\tspecific\\tsituation.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 4}), Document(page_content='Contents\\nTitle\\tPage\\nCopyright\\nEpigraph\\nIntroduction:\\tMy\\tStory\\nThe\\tFundamentals\\t\\nWhy\\tTiny\\tChanges\\tMake\\ta\\tBig\\tDifference\\n1\\tThe\\tSurprising\\tPower\\tof\\tAtomic\\tHabits\\n2\\tHow\\tYour\\tHabits\\tShape\\tYour\\tIdentity\\t(and\\tVice\\tVersa)\\n3\\tHow\\tto\\tBuild\\tBetter\\tHabits\\tin\\t4\\tSimple\\tSteps\\nThe\\t1st\\tLaw\\t\\nMake\\tIt\\tObvious\\n4\\tThe\\tMan\\tWho\\tDidn’t\\tLook\\tRight\\n5\\tThe\\tBest\\tWay\\tto\\tStart\\ta\\tNew\\tHabit\\n6\\tMotivation\\tIs\\tOverrated;\\tEnvironment\\tOften\\tMatters\\tMore\\n7\\tThe\\tSecret\\tto\\tSelf-Control\\nThe\\t2nd\\tLaw\\t\\nMake\\tIt\\tAttractive\\n8\\tHow\\tto\\tMake\\ta\\tHabit\\tIrresistible\\n9\\tThe\\tRole\\tof\\tFamily\\tand\\tFriends\\tin\\tShaping\\tYour\\tHabits\\n10\\tHow\\tto\\tFind\\tand\\tFix\\tthe\\tCauses\\tof\\tYour\\tBad\\tHabits\\nThe\\t3rd\\tLaw\\t\\nMake\\tIt\\tEasy\\n11\\tWalk\\tSlowly,\\tbut\\tNever\\tBackward\\n12\\tThe\\tLaw\\tof\\tLeast\\tEffort\\n13\\tHow\\tto\\tStop\\tProcrastinating\\tby\\tUsing\\tthe\\tTwo-Minute\\tRule\\n14\\tHow\\tto\\tMake\\tGood\\tHabits\\tInevitable\\tand\\tBad\\tHabits\\tImpossible', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 5}), Document(page_content='The\\t4th\\tLaw\\t\\nMake\\tIt\\tSatisfying\\n15\\tThe\\tCardinal\\tRule\\tof\\tBehavior\\tChange\\n16\\tHow\\tto\\tStick\\twith\\tGood\\tHabits\\tEvery\\tDay\\n17\\tHow\\tan\\tAccountability\\tPartner\\tCan\\tChange\\tEverything\\nAdvanced\\tTactics\\t\\nHow\\tto\\tGo\\tfrom\\tBeing\\tMerely\\tGood\\tto\\tBeing\\tTruly\\tGreat\\n18\\tThe\\tTruth\\tAbout\\tTalent\\t(When\\tGenes\\tMatter\\tand\\tWhen\\tThey\\tDon’t)\\n19\\tThe\\tGoldilocks\\tRule:\\tHow\\tto\\tStay\\tMotivated\\tin\\tLife\\tand\\tWork\\n20\\tThe\\tDownside\\tof\\tCreating\\tGood\\tHabits\\nConclusion:\\tThe\\tSecret\\tto\\tResults\\tThat\\tLast\\nAppendix\\nWhat\\tShould\\tYou\\tRead\\tNext?\\nLittle\\tLessons\\tfrom\\tthe\\tFour\\tLaws\\nHow\\tto\\tApply\\tThese\\tIdeas\\tto\\tBusiness\\nHow\\tto\\tApply\\tThese\\tIdeas\\tto\\tParenting\\nAcknowledgments\\nNotes\\nIndex\\nAbout\\tthe\\tAuthor', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 6}), Document(page_content='Introduction\\nMy\\tStory\\nO\\nN\\tTHE\\tFINAL\\t\\nday\\tof\\tmy\\tsophomore\\tyear\\tof\\thigh\\tschool,\\tI\\twas\\thit\\tin\\tthe\\tface\\twith\\ta\\nbaseball\\tbat.\\tAs\\tmy\\tclassmate\\ttook\\ta\\tfull\\tswing,\\tthe\\tbat\\tslipped\\tout\\tof\\this\\thands\\nand\\tcame\\tflying\\ttoward\\tme\\tbefore\\tstriking\\tme\\tdirectly\\tbetween\\tthe\\teyes.\\tI\\thave\\nno\\tmemory\\tof\\tthe\\tmoment\\tof\\timpact.\\nThe\\tbat\\tsmashed\\tinto\\tmy\\tface\\twith\\tsuch\\tforce\\tthat\\tit\\tcrushed\\tmy\\tnose\\tinto\\ta\\ndistorted\\tU-shape.\\tThe\\tcollision\\tsent\\tthe\\tsoft\\ttissue\\tof\\tmy\\tbrain\\tslamming\\tinto\\nthe\\tinside\\tof\\tmy\\tskull.\\tImmediately,\\ta\\twave\\tof\\tswelling\\tsurged\\tthroughout\\tmy\\nhead.\\tIn\\ta\\tfraction\\tof\\ta\\tsecond,\\tI\\thad\\ta\\tbroken\\tnose,\\tmultiple\\tskull\\tfractures,\\tand\\ntwo\\tshattered\\teye\\tsockets.\\nWhen\\tI\\topened\\tmy\\teyes,\\tI\\tsaw\\tpeople\\tstaring\\tat\\tme\\tand\\trunning\\tover\\tto\\thelp.\\nI\\tlooked\\tdown\\tand\\tnoticed\\tspots\\tof\\tred\\ton\\tmy\\tclothes.\\tOne\\tof\\tmy\\tclassmates\\ntook\\tthe\\tshirt\\toff\\this\\tback\\tand\\thanded\\tit\\tto\\tme.\\tI\\tused\\tit\\tto\\tplug\\tthe\\tstream\\tof\\nblood\\trushing\\tfrom\\tmy\\tbroken\\tnose.\\tShocked\\tand\\tconfused,\\tI\\twas\\tunaware\\tof\\nhow\\tseriously\\tI\\thad\\tbeen\\tinjured.\\nMy\\tteacher\\tlooped\\this\\tarm\\taround\\tmy\\tshoulder\\tand\\twe\\tbegan\\tthe\\tlong\\twalk\\tto\\nthe\\tnurse’s\\toffice:\\tacross\\tthe\\tfield,\\tdown\\tthe\\thill,\\tand\\tback\\t\\ninto\\tschool.\\tRandom\\nhands\\ttouched\\tmy\\tsides,\\tholding\\tme\\tupright.\\tWe\\ttook\\tour\\ttime\\tand\\twalked\\nslowly.\\tNobody\\trealized\\tthat\\tevery\\tminute\\tmattered.\\nWhen\\twe\\tarrived\\tat\\tthe\\tnurse’s\\toffice,\\tshe\\tasked\\tme\\ta\\tseries\\tof\\tquestions.\\n“What\\tyear\\tis\\tit?”\\n“1998,”\\tI\\tanswered.\\tIt\\twas\\tactually\\t2002.\\n“Who\\tis\\tthe\\tpresident\\tof\\tthe\\tUnited\\tStates?”\\n“Bill\\tClinton,”\\tI\\tsaid.\\tThe\\tcorrect\\tanswer\\twas\\tGeorge\\tW.\\tBush.\\n“What\\tis\\tyour\\tmom’s\\tname?”\\n“Uh.\\tUm.”\\tI\\tstalled.\\tTen\\tseconds\\tpassed.\\n“Patti,”\\tI\\tsaid\\tcasually,\\tignoring\\tthe\\tfact\\tthat\\tit\\thad\\ttaken\\tme\\tten\\tseconds\\tto\\nremember\\tmy\\town\\tmother’s\\tname.\\nThat\\tis\\tthe\\tlast\\tquestion\\tI\\tremember.\\tMy\\tbody\\twas\\tunable\\tto\\thandle\\tthe\\trapid\\nswelling\\tin\\tmy\\tbrain\\tand\\tI\\tlost\\tconsciousness\\tbefore\\tthe\\tambulance\\tarrived.\\nMinutes\\tlater,\\tI\\twas\\tcarried\\tout\\tof\\tschool\\tand\\ttaken\\tto\\tthe\\tlocal\\thospital.\\nShortly\\tafter\\tarriving,\\tmy\\tbody\\tbegan\\tshutting\\tdown.\\tI\\tstruggled\\twith\\tbasic\\nfunctions\\tlike\\tswallowing\\tand\\tbreathing.\\tI\\thad\\tmy\\tfirst\\tseizure\\tof\\tthe\\tday.\\tThen\\tI', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 7}), Document(page_content='stopped\\tbreathing\\tentirely.\\tAs\\tthe\\tdoctors\\thurried\\tto\\tsupply\\tme\\twith\\toxygen,\\nthey\\talso\\tdecided\\tthe\\tlocal\\thospital\\twas\\tunequipped\\tto\\thandle\\tthe\\tsituation\\tand\\nordered\\ta\\thelicopter\\tto\\tfly\\tme\\tto\\ta\\tlarger\\thospital\\tin\\tCincinnati.\\nI\\twas\\trolled\\tout\\tof\\tthe\\temergency\\troom\\tdoors\\tand\\ttoward\\tthe\\thelipad\\tacross\\nthe\\tstreet.\\tThe\\tstretcher\\trattled\\ton\\ta\\tbumpy\\tsidewalk\\tas\\tone\\tnurse\\tpushed\\tme\\nalong\\twhile\\tanother\\tpumped\\teach\\tbreath\\tinto\\tme\\tby\\thand.\\tMy\\tmother,\\twho\\thad\\narrived\\tat\\tthe\\thospital\\ta\\tfew\\tmoments\\tbefore,\\tclimbed\\tinto\\tthe\\thelicopter\\tbeside\\nme.\\tI\\tremained\\tunconscious\\tand\\tunable\\tto\\tbreathe\\ton\\tmy\\town\\tas\\tshe\\theld\\tmy\\nhand\\tduring\\tthe\\tflight.\\nWhile\\tmy\\tmother\\trode\\twith\\tme\\tin\\tthe\\thelicopter,\\tmy\\tfather\\twent\\thome\\tto\\ncheck\\ton\\tmy\\tbrother\\tand\\tsister\\tand\\tbreak\\tthe\\tnews\\tto\\tthem.\\tHe\\tchoked\\tback\\ntears\\tas\\the\\texplained\\tto\\tmy\\tsister\\tthat\\the\\twould\\tmiss\\ther\\teighth-grade\\tgraduation\\nceremony\\tthat\\tnight.\\tAfter\\tpassing\\tmy\\tsiblings\\toff\\tto\\tfamily\\tand\\tfriends,\\the\\ndrove\\tto\\tCincinnati\\tto\\tmeet\\tmy\\tmother.\\nWhen\\tmy\\tmom\\tand\\tI\\tlanded\\ton\\tthe\\troof\\tof\\tthe\\thospital,\\ta\\tteam\\tof\\tnearly\\ntwenty\\tdoctors\\tand\\tnurses\\tsprinted\\tonto\\tthe\\thelipad\\tand\\twheeled\\tme\\tinto\\tthe\\ntrauma\\tunit.\\tBy\\tthis\\ttime,\\tthe\\tswelling\\tin\\tmy\\tbrain\\thad\\tbecome\\tso\\tsevere\\tthat\\tI\\nwas\\thaving\\trepeated\\tpost-traumatic\\tseizures.\\tMy\\tbroken\\tbones\\tneeded\\tto\\tbe\\nfixed,\\tbut\\tI\\twas\\tin\\tno\\tcondition\\tto\\tundergo\\tsurgery.\\tAfter\\tyet\\tanother\\tseizure—\\nmy\\tthird\\tof\\tthe\\tday—I\\twas\\tput\\tinto\\ta\\tmedically\\tinduced\\tcoma\\tand\\tplaced\\ton\\ta\\nventilator.\\nMy\\tparents\\twere\\tno\\tstrangers\\tto\\tthis\\thospital.\\tTen\\tyears\\tearlier,\\tthey\\thad\\nentered\\tthe\\tsame\\tbuilding\\ton\\tthe\\tground\\tfloor\\tafter\\tmy\\tsister\\twas\\tdiagnosed\\twith\\nleukemia\\tat\\tage\\tthree.\\tI\\twas\\tfive\\tat\\tthe\\ttime.\\tMy\\tbrother\\twas\\tjust\\tsix\\tmonths\\told.\\nAfter\\ttwo\\tand\\ta\\thalf\\tyears\\tof\\tchemotherapy\\ttreatments,\\tspinal\\ttaps,\\tand\\tbone\\nmarrow\\tbiopsies,\\tmy\\tlittle\\tsister\\tfinally\\twalked\\tout\\tof\\tthe\\thospital\\thappy,\\nhealthy,\\tand\\tcancer\\tfree.\\tAnd\\tnow,\\tafter\\tten\\tyears\\tof\\tnormal\\tlife,\\tmy\\tparents\\nfound\\tthemselves\\tback\\tin\\tthe\\tsame\\tplace\\twith\\ta\\tdifferent\\tchild.\\nWhile\\tI\\tslipped\\tinto\\ta\\tcoma,\\tthe\\thospital\\tsent\\ta\\tpriest\\tand\\ta\\tsocial\\tworker\\tto\\ncomfort\\tmy\\tparents.\\tIt\\twas\\tthe\\tsame\\tpriest\\twho\\thad\\tmet\\twith\\tthem\\ta\\tdecade\\nearlier\\ton\\tthe\\tevening\\tthey\\tfound\\tout\\tmy\\tsister\\thad\\tcancer.\\nAs\\tday\\tfaded\\tinto\\tnight,\\ta\\tseries\\tof\\tmachines\\tkept\\tme\\talive.\\tMy\\tparents\\tslept\\nrestlessly\\ton\\ta\\thospital\\tmattress—one\\tmoment\\tthey\\twould\\tcollapse\\tfrom\\tfatigue,\\nthe\\tnext\\tthey\\twould\\tbe\\twide\\tawake\\twith\\tworry.\\tMy\\tmother\\twould\\ttell\\tme\\tlater,\\n“It\\twas\\tone\\tof\\tthe\\tworst\\tnights\\tI’ve\\tever\\thad.”\\nMY\\tRECOVERY', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 8}), Document(page_content='Mercifully,\\tby\\tthe\\tnext\\tmorning\\tmy\\tbreathing\\thad\\trebounded\\tto\\tthe\\tpoint\\twhere\\nthe\\tdoctors\\tfelt\\tcomfortable\\treleasing\\tme\\tfrom\\tthe\\tcoma.\\tWhen\\tI\\tfinally\\nregained\\tconsciousness,\\tI\\tdiscovered\\tthat\\tI\\thad\\tlost\\tmy\\tability\\tto\\tsmell.\\tAs\\ta\\ttest,\\na\\tnurse\\tasked\\tme\\tto\\tblow\\tmy\\tnose\\tand\\tsniff\\tan\\tapple\\tjuice\\tbox.\\tMy\\tsense\\tof\\nsmell\\treturned,\\tbut—to\\teveryone’s\\tsurprise—the\\tact\\tof\\tblowing\\tmy\\tnose\\tforced\\nair\\tthrough\\tthe\\tfractures\\tin\\tmy\\teye\\tsocket\\tand\\tpushed\\tmy\\tleft\\teye\\toutward.\\tMy\\neyeball\\tbulged\\tout\\tof\\tthe\\tsocket,\\theld\\tprecariously\\tin\\tplace\\tby\\tmy\\teyelid\\tand\\tthe\\noptic\\tnerve\\tattaching\\tmy\\teye\\tto\\tmy\\tbrain.\\nThe\\tophthalmologist\\tsaid\\tmy\\teye\\twould\\tgradually\\tslide\\tback\\tinto\\tplace\\tas\\tthe\\nair\\tseeped\\tout,\\tbut\\tit\\twas\\thard\\tto\\ttell\\thow\\tlong\\tthis\\twould\\ttake.\\tI\\twas\\tscheduled\\nfor\\tsurgery\\tone\\tweek\\tlater,\\twhich\\twould\\tallow\\tme\\tsome\\tadditional\\ttime\\tto\\theal.\\nI\\tlooked\\tlike\\tI\\thad\\tbeen\\ton\\tthe\\twrong\\tend\\tof\\ta\\tboxing\\tmatch,\\tbut\\tI\\twas\\tcleared\\nto\\tleave\\tthe\\thospital.\\tI\\treturned\\thome\\twith\\ta\\tbroken\\tnose,\\thalf\\ta\\tdozen\\tfacial\\nfractures,\\tand\\ta\\tbulging\\tleft\\teye.\\nThe\\tfollowing\\tmonths\\twere\\thard.\\tIt\\tfelt\\tlike\\teverything\\tin\\tmy\\tlife\\twas\\ton\\npause.\\tI\\thad\\tdouble\\tvision\\tfor\\tweeks;\\tI\\tliterally\\tcouldn’t\\tsee\\tstraight.\\tIt\\ttook\\nmore\\tthan\\ta\\tmonth,\\tbut\\tmy\\teyeball\\tdid\\teventually\\treturn\\tto\\tits\\tnormal\\tlocation.\\nBetween\\tthe\\tseizures\\tand\\tmy\\tvision\\tproblems,\\tit\\twas\\teight\\tmonths\\tbefore\\tI\\tcould\\ndrive\\ta\\tcar\\tagain.\\tAt\\tphysical\\ttherapy,\\tI\\tpracticed\\tbasic\\tmotor\\tpatterns\\tlike\\nwalking\\tin\\ta\\tstraight\\tline.\\tI\\twas\\tdetermined\\tnot\\tto\\tlet\\tmy\\tinjury\\tget\\tme\\tdown,\\tbut\\nthere\\twere\\tmore\\tthan\\ta\\tfew\\tmoments\\twhen\\tI\\tfelt\\tdepressed\\tand\\toverwhelmed.\\nI\\tbecame\\tpainfully\\taware\\tof\\thow\\tfar\\tI\\thad\\tto\\tgo\\twhen\\tI\\treturned\\tto\\tthe\\nbaseball\\tfield\\tone\\tyear\\tlater.\\tBaseball\\thad\\talways\\tbeen\\ta\\tmajor\\tpart\\tof\\tmy\\tlife.\\nMy\\tdad\\thad\\tplayed\\tminor\\tleague\\tbaseball\\tfor\\tthe\\tSt.\\tLouis\\tCardinals,\\tand\\tI\\thad\\ta\\ndream\\tof\\tplaying\\tprofessionally,\\ttoo.\\tAfter\\t\\nmonths\\tof\\trehabilitation,\\twhat\\tI\\nwanted\\tmore\\tthan\\tanything\\twas\\tto\\tget\\tback\\ton\\tthe\\tfield.\\nBut\\tmy\\treturn\\tto\\tbaseball\\twas\\tnot\\tsmooth.\\tWhen\\tthe\\tseason\\trolled\\taround,\\tI\\nwas\\tthe\\tonly\\tjunior\\tto\\tbe\\tcut\\tfrom\\tthe\\tvarsity\\tbaseball\\tteam.\\tI\\twas\\tsent\\tdown\\tto\\nplay\\twith\\tthe\\tsophomores\\ton\\tjunior\\tvarsity.\\tI\\thad\\tbeen\\tplaying\\tsince\\tage\\tfour,\\nand\\tfor\\tsomeone\\twho\\thad\\tspent\\tso\\tmuch\\ttime\\tand\\teffort\\ton\\tthe\\tsport,\\tgetting\\tcut\\nwas\\thumiliating.\\tI\\tvividly\\tremember\\tthe\\tday\\tit\\thappened.\\tI\\tsat\\tin\\tmy\\tcar\\tand\\ncried\\tas\\tI\\tflipped\\tthrough\\tthe\\tradio,\\tdesperately\\tsearching\\tfor\\ta\\tsong\\tthat\\twould\\nmake\\tme\\tfeel\\tbetter.\\nAfter\\ta\\tyear\\tof\\tself-doubt,\\tI\\tmanaged\\tto\\tmake\\tthe\\tvarsity\\tteam\\tas\\ta\\tsenior,\\tbut\\nI\\trarely\\tmade\\tit\\ton\\tthe\\tfield.\\tIn\\ttotal,\\tI\\tplayed\\televen\\tinnings\\tof\\thigh\\tschool\\nvarsity\\tbaseball,\\tbarely\\tmore\\tthan\\ta\\tsingle\\tgame.\\nDespite\\tmy\\tlackluster\\thigh\\tschool\\tcareer,\\tI\\tstill\\tbelieved\\tI\\tcould\\tbecome\\ta\\ngreat\\tplayer.\\tAnd\\tI\\tknew\\tthat\\tif\\tthings\\twere\\tgoing\\tto\\timprove,\\tI\\twas\\tthe\\tone\\nresponsible\\tfor\\tmaking\\tit\\thappen.\\tThe\\tturning\\tpoint\\tcame\\ttwo\\tyears\\tafter\\tmy', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 9}), Document(page_content='injury,\\twhen\\tI\\tbegan\\tcollege\\tat\\tDenison\\tUniversity.\\tIt\\twas\\ta\\tnew\\tbeginning,\\tand\\nit\\twas\\tthe\\tplace\\twhere\\tI\\twould\\tdiscover\\tthe\\tsurprising\\tpower\\tof\\tsmall\\thabits\\tfor\\nthe\\tfirst\\ttime.\\nHOW\\tI\\tLEARNED\\tABOUT\\tHABITS\\nAttending\\tDenison\\twas\\tone\\tof\\tthe\\tbest\\tdecisions\\tof\\tmy\\tlife.\\tI\\tearned\\ta\\tspot\\ton\\nthe\\tbaseball\\tteam\\tand,\\talthough\\tI\\twas\\tat\\tthe\\tbottom\\tof\\tthe\\troster\\tas\\ta\\tfreshman,\\tI\\nwas\\tthrilled.\\tDespite\\tthe\\tchaos\\tof\\tmy\\thigh\\tschool\\tyears,\\tI\\thad\\tmanaged\\tto\\nbecome\\ta\\tcollege\\tathlete.\\nI\\twasn’t\\tgoing\\tto\\tbe\\tstarting\\ton\\tthe\\tbaseball\\tteam\\tanytime\\tsoon,\\tso\\tI\\tfocused\\non\\tgetting\\tmy\\tlife\\tin\\torder.\\tWhile\\tmy\\tpeers\\tstayed\\tup\\tlate\\tand\\tplayed\\tvideo\\ngames,\\tI\\tbuilt\\tgood\\tsleep\\thabits\\tand\\twent\\tto\\tbed\\tearly\\teach\\tnight.\\tIn\\tthe\\tmessy\\nworld\\tof\\ta\\tcollege\\tdorm,\\tI\\tmade\\ta\\tpoint\\tto\\t\\nkeep\\tmy\\troom\\tneat\\tand\\ttidy.\\tThese\\nimprovements\\twere\\tminor,\\tbut\\tthey\\tgave\\tme\\ta\\tsense\\tof\\tcontrol\\tover\\tmy\\tlife.\\tI\\nstarted\\tto\\tfeel\\tconfident\\tagain.\\tAnd\\tthis\\tgrowing\\tbelief\\tin\\tmyself\\trippled\\tinto\\tthe\\nclassroom\\tas\\tI\\timproved\\tmy\\tstudy\\thabits\\tand\\tmanaged\\tto\\tearn\\tstraight\\tA’s\\nduring\\tmy\\tfirst\\tyear.\\nA\\thabit\\tis\\ta\\troutine\\tor\\tbehavior\\tthat\\tis\\tperformed\\tregularly—and,\\tin\\tmany\\ncases,\\tautomatically.\\tAs\\teach\\tsemester\\tpassed,\\tI\\taccumulated\\tsmall\\tbut\\nconsistent\\thabits\\tthat\\tultimately\\tled\\tto\\tresults\\tthat\\twere\\tunimaginable\\tto\\tme\\nwhen\\tI\\tstarted.\\tFor\\texample,\\tfor\\tthe\\tfirst\\ttime\\tin\\tmy\\tlife,\\tI\\tmade\\tit\\ta\\thabit\\tto\\tlift\\nweights\\tmultiple\\ttimes\\tper\\tweek,\\tand\\tin\\tthe\\tyears\\tthat\\tfollowed,\\tmy\\tsix-foot-\\nfour-inch\\tframe\\tbulked\\tup\\tfrom\\ta\\tfeatherweight\\t170\\tto\\ta\\tlean\\t200\\tpounds.\\nWhen\\tmy\\tsophomore\\tseason\\tarrived,\\tI\\tearned\\ta\\tstarting\\trole\\ton\\tthe\\tpitching\\nstaff.\\tBy\\tmy\\tjunior\\tyear,\\tI\\twas\\tvoted\\tteam\\tcaptain\\tand\\tat\\tthe\\tend\\tof\\tthe\\tseason,\\tI\\nwas\\tselected\\tfor\\tthe\\tall-conference\\tteam.\\tBut\\tit\\twas\\tnot\\tuntil\\tmy\\tsenior\\tseason\\nthat\\tmy\\tsleep\\thabits,\\tstudy\\thabits,\\tand\\tstrength-training\\thabits\\treally\\tbegan\\tto\\npay\\toff.\\nSix\\tyears\\tafter\\tI\\thad\\tbeen\\thit\\tin\\tthe\\tface\\twith\\ta\\tbaseball\\tbat,\\tflown\\tto\\tthe\\nhospital,\\tand\\tplaced\\tinto\\ta\\tcoma,\\tI\\twas\\tselected\\tas\\tthe\\ttop\\tmale\\tathlete\\tat\\nDenison\\tUniversity\\tand\\tnamed\\tto\\tthe\\tESPN\\tAcademic\\tAll-America\\tTeam—an\\nhonor\\tgiven\\tto\\tjust\\tthirty-three\\tplayers\\tacross\\tthe\\tcountry.\\tBy\\tthe\\ttime\\tI\\ngraduated,\\tI\\twas\\tlisted\\tin\\tthe\\tschool\\trecord\\tbooks\\tin\\teight\\tdifferent\\tcategories.\\nThat\\tsame\\tyear,\\tI\\twas\\tawarded\\tthe\\tuniversity’s\\thighest\\tacademic\\thonor,\\tthe\\nPresident’s\\tMedal.\\nI\\thope\\tyou’ll\\tforgive\\tme\\tif\\tthis\\tsounds\\tboastful.\\tTo\\tbe\\thonest,\\tthere\\twas\\nnothing\\tlegendary\\tor\\thistoric\\tabout\\tmy\\tathletic\\tcareer.\\tI\\tnever\\tended\\tup\\tplaying', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 10}), Document(page_content='professionally.\\tHowever,\\tlooking\\tback\\ton\\tthose\\tyears,\\tI\\tbelieve\\tI\\taccomplished\\nsomething\\tjust\\tas\\trare:\\tI\\tfulfilled\\tmy\\tpotential.\\tAnd\\tI\\tbelieve\\tthe\\tconcepts\\tin\\tthis\\nbook\\tcan\\thelp\\tyou\\tfulfill\\tyour\\tpotential\\tas\\twell.\\nWe\\tall\\tface\\tchallenges\\tin\\tlife.\\tThis\\tinjury\\twas\\tone\\tof\\tmine,\\tand\\tthe\\t\\nexperience\\ntaught\\tme\\ta\\tcritical\\tlesson:\\tchanges\\tthat\\tseem\\tsmall\\tand\\tunimportant\\tat\\tfirst\\twill\\ncompound\\tinto\\tremarkable\\tresults\\tif\\tyou’re\\twilling\\tto\\tstick\\twith\\tthem\\tfor\\tyears.\\nWe\\tall\\tdeal\\twith\\tsetbacks\\tbut\\tin\\tthe\\tlong\\trun,\\tthe\\tquality\\tof\\tour\\tlives\\toften\\ndepends\\ton\\tthe\\tquality\\tof\\tour\\thabits.\\tWith\\tthe\\tsame\\thabits,\\tyou’ll\\tend\\tup\\twith\\nthe\\tsame\\tresults.\\tBut\\twith\\tbetter\\thabits,\\tanything\\tis\\tpossible.\\nMaybe\\tthere\\tare\\tpeople\\twho\\tcan\\tachieve\\tincredible\\tsuccess\\tovernight.\\tI\\tdon’t\\nknow\\tany\\tof\\tthem,\\tand\\tI’m\\tcertainly\\tnot\\tone\\tof\\tthem.\\tThere\\twasn’t\\tone\\tdefining\\nmoment\\ton\\tmy\\tjourney\\tfrom\\tmedically\\tinduced\\tcoma\\tto\\tAcademic\\tAll-\\nAmerican;\\tthere\\twere\\tmany.\\tIt\\twas\\ta\\tgradual\\tevolution,\\ta\\tlong\\tseries\\tof\\tsmall\\nwins\\tand\\ttiny\\tbreakthroughs.\\tThe\\tonly\\tway\\tI\\tmade\\tprogress—the\\tonly\\tchoice\\tI\\nhad—was\\tto\\tstart\\tsmall.\\tAnd\\tI\\temployed\\tthis\\tsame\\tstrategy\\ta\\tfew\\tyears\\tlater\\nwhen\\tI\\tstarted\\tmy\\town\\tbusiness\\tand\\tbegan\\tworking\\ton\\tthis\\tbook.\\nHOW\\tAND\\tWHY\\tI\\tWROTE\\tTHIS\\tBOOK\\nIn\\tNovember\\t2012,\\tI\\tbegan\\tpublishing\\tarticles\\tat\\tjamesclear.com.\\tFor\\tyears,\\tI\\nhad\\tbeen\\tkeeping\\tnotes\\tabout\\tmy\\tpersonal\\texperiments\\twith\\thabits\\tand\\tI\\twas\\nfinally\\tready\\tto\\tshare\\tsome\\tof\\tthem\\tpublicly.\\tI\\tbegan\\tby\\tpublishing\\ta\\tnew\\tarticle\\nevery\\tMonday\\tand\\tThursday.\\tWithin\\ta\\tfew\\tmonths,\\tthis\\tsimple\\twriting\\thabit\\tled\\nto\\tmy\\tfirst\\tone\\tthousand\\temail\\tsubscribers,\\tand\\tby\\tthe\\tend\\tof\\t2013\\tthat\\tnumber\\nhad\\tgrown\\tto\\tmore\\tthan\\tthirty\\tthousand\\tpeople.\\nIn\\t2014,\\tmy\\temail\\tlist\\texpanded\\tto\\tover\\tone\\thundred\\tthousand\\tsubscribers,\\nwhich\\tmade\\tit\\tone\\tof\\tthe\\tfastest-growing\\tnewsletters\\ton\\tthe\\tinternet.\\tI\\thad\\tfelt\\nlike\\tan\\timpostor\\twhen\\tI\\tbegan\\twriting\\ttwo\\tyears\\tearlier,\\tbut\\tnow\\tI\\twas\\nbecoming\\tknown\\tas\\tan\\texpert\\ton\\thabits—a\\tnew\\tlabel\\tthat\\texcited\\tme\\tbut\\talso\\nfelt\\tuncomfortable.\\tI\\thad\\tnever\\tconsidered\\tmyself\\ta\\tmaster\\tof\\tthe\\ttopic,\\tbut\\nrather\\tsomeone\\twho\\twas\\texperimenting\\talongside\\tmy\\treaders.\\nIn\\t2015,\\tI\\treached\\ttwo\\thundred\\tthousand\\temail\\tsubscribers\\tand\\tsigned\\ta\\tbook\\ndeal\\twith\\tPenguin\\tRandom\\tHouse\\tto\\tbegin\\twriting\\tthe\\tbook\\tyou\\tare\\treading\\nnow.\\tAs\\tmy\\taudience\\tgrew,\\tso\\tdid\\tmy\\tbusiness\\topportunities.\\tI\\twas\\tincreasingly\\nasked\\tto\\tspeak\\tat\\ttop\\tcompanies\\tabout\\tthe\\tscience\\tof\\thabit\\tformation,\\tbehavior\\nchange,\\tand\\tcontinuous\\timprovement.\\tI\\tfound\\tmyself\\tdelivering\\tkeynote\\nspeeches\\tat\\tconferences\\tin\\tthe\\tUnited\\tStates\\tand\\tEurope.\\nIn\\t2016,\\tmy\\tarticles\\tbegan\\tto\\tappear\\tregularly\\tin\\tmajor\\tpublications\\tlike\\t\\nTime\\n,', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 11}), Document(page_content='Entrepreneur\\n,\\tand\\t\\nForbes\\n.\\tIncredibly,\\tmy\\twriting\\twas\\tread\\tby\\tover\\teight\\tmillion\\npeople\\tthat\\tyear.\\tCoaches\\tin\\tthe\\tNFL,\\tNBA,\\tand\\tMLB\\tbegan\\treading\\tmy\\twork\\nand\\tsharing\\tit\\twith\\ttheir\\tteams.\\nAt\\tthe\\tstart\\tof\\t2017,\\tI\\tlaunched\\tthe\\tHabits\\tAcademy,\\twhich\\tbecame\\tthe\\npremier\\ttraining\\tplatform\\tfor\\torganizations\\tand\\tindividuals\\tinterested\\tin\\tbuilding\\nbetter\\thabits\\tin\\tlife\\tand\\twork.\\n*\\n\\tFortune\\t500\\tcompanies\\tand\\tgrowing\\tstart-ups\\nbegan\\tto\\tenroll\\ttheir\\tleaders\\tand\\ttrain\\ttheir\\tstaff.\\tIn\\ttotal,\\tover\\tten\\tthousand\\nleaders,\\tmanagers,\\tcoaches,\\tand\\tteachers\\thave\\tgraduated\\tfrom\\tthe\\tHabits\\nAcademy,\\tand\\tmy\\twork\\twith\\tthem\\thas\\ttaught\\tme\\tan\\tincredible\\tamount\\tabout\\nwhat\\tit\\ttakes\\tto\\tmake\\thabits\\twork\\tin\\tthe\\treal\\tworld.\\nAs\\tI\\tput\\tthe\\tfinishing\\ttouches\\ton\\tthis\\tbook\\tin\\t2018,\\tjamesclear.com\\tis\\nreceiving\\tmillions\\tof\\tvisitors\\tper\\tmonth\\tand\\tnearly\\tfive\\thundred\\tthousand\\tpeople\\nsubscribe\\tto\\tmy\\tweekly\\temail\\tnewsletter—a\\tnumber\\tthat\\tis\\tso\\tfar\\tbeyond\\tmy\\nexpectations\\twhen\\tI\\tbegan\\tthat\\tI’m\\tnot\\teven\\tsure\\twhat\\tto\\tthink\\tof\\tit.\\nHOW\\tTHIS\\tBOOK\\tWILL\\tBENEFIT\\tYOU\\nThe\\tentrepreneur\\tand\\tinvestor\\tNaval\\tRavikant\\thas\\tsaid,\\t“To\\twrite\\ta\\tgreat\\tbook,\\nyou\\tmust\\tfirst\\tbecome\\tthe\\tbook.”\\tI\\toriginally\\tlearned\\tabout\\t\\nthe\\tideas\\tmentioned\\nhere\\tbecause\\tI\\thad\\tto\\tlive\\tthem.\\tI\\thad\\tto\\trely\\ton\\tsmall\\thabits\\tto\\trebound\\tfrom\\tmy\\ninjury,\\tto\\tget\\tstronger\\tin\\tthe\\tgym,\\tto\\tperform\\tat\\ta\\thigh\\tlevel\\ton\\tthe\\tfield,\\tto\\nbecome\\ta\\twriter,\\tto\\tbuild\\ta\\tsuccessful\\tbusiness,\\tand\\tsimply\\tto\\tdevelop\\tinto\\ta\\nresponsible\\tadult.\\tSmall\\thabits\\thelped\\tme\\tfulfill\\tmy\\tpotential,\\tand\\tsince\\tyou\\npicked\\tup\\tthis\\tbook,\\tI’m\\tguessing\\tyou’d\\tlike\\tto\\tfulfill\\tyours\\tas\\twell.\\nIn\\tthe\\tpages\\tthat\\tfollow,\\tI\\twill\\tshare\\ta\\tstep-by-step\\tplan\\tfor\\tbuilding\\tbetter\\nhabits—not\\tfor\\tdays\\tor\\tweeks,\\tbut\\tfor\\ta\\tlifetime.\\tWhile\\tscience\\tsupports\\neverything\\tI’ve\\twritten,\\tthis\\tbook\\tis\\tnot\\tan\\tacademic\\tresearch\\tpaper;\\tit’s\\tan\\noperating\\tmanual.\\tYou’ll\\tfind\\twisdom\\tand\\tpractical\\tadvice\\tfront\\tand\\tcenter\\tas\\tI\\nexplain\\tthe\\tscience\\tof\\thow\\tto\\tcreate\\tand\\tchange\\tyour\\thabits\\tin\\ta\\tway\\tthat\\tis\\teasy\\nto\\tunderstand\\tand\\tapply.\\nThe\\tfields\\tI\\tdraw\\ton—biology,\\tneuroscience,\\tphilosophy,\\tpsychology,\\tand\\nmore—have\\tbeen\\taround\\tfor\\tmany\\tyears.\\tWhat\\tI\\toffer\\tyou\\tis\\ta\\tsynthesis\\tof\\tthe\\nbest\\tideas\\tsmart\\tpeople\\tfigured\\tout\\ta\\tlong\\ttime\\tago\\tas\\twell\\tas\\tthe\\tmost\\ncompelling\\tdiscoveries\\tscientists\\thave\\tmade\\trecently.\\tMy\\tcontribution,\\tI\\thope,\\tis\\nto\\tfind\\tthe\\tideas\\tthat\\tmatter\\tmost\\tand\\tconnect\\tthem\\tin\\ta\\tway\\tthat\\tis\\thighly\\nactionable.\\tAnything\\twise\\tin\\tthese\\tpages\\tyou\\tshould\\tcredit\\tto\\tthe\\tmany\\texperts\\nwho\\tpreceded\\tme.\\tAnything\\tfoolish,\\tassume\\tit\\tis\\tmy\\terror.\\nThe\\tbackbone\\tof\\tthis\\tbook\\tis\\tmy\\tfour-step\\tmodel\\tof\\thabits—cue,\\tcraving,', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 12}), Document(page_content='response,\\tand\\treward—and\\tthe\\tfour\\tlaws\\tof\\tbehavior\\tchange\\tthat\\tevolve\\tout\\tof\\nthese\\tsteps.\\tReaders\\twith\\ta\\tpsychology\\tbackground\\tmay\\trecognize\\tsome\\tof\\tthese\\nterms\\tfrom\\toperant\\tconditioning,\\twhich\\twas\\tfirst\\tproposed\\tas\\t“\\nstimulus,\\nresponse,\\treward”\\tby\\tB.\\tF.\\tSkinner\\tin\\tthe\\t1930s\\tand\\thas\\tbeen\\tpopularized\\tmore\\nrecently\\tas\\t“\\ncue,\\troutine,\\treward”\\tin\\t\\nThe\\tPower\\tof\\tHabit\\n\\tby\\tCharles\\tDuhigg.\\nBehavioral\\tscientists\\tlike\\tSkinner\\trealized\\tthat\\tif\\tyou\\toffered\\tthe\\tright\\treward\\nor\\tpunishment,\\tyou\\tcould\\tget\\tpeople\\tto\\tact\\tin\\ta\\tcertain\\tway.\\tBut\\twhile\\tSkinner’s\\nmodel\\tdid\\tan\\texcellent\\tjob\\tof\\texplaining\\thow\\texternal\\tstimuli\\tinfluenced\\tour\\nhabits,\\tit\\tlacked\\ta\\tgood\\texplanation\\t\\nfor\\thow\\tour\\tthoughts,\\tfeelings,\\tand\\tbeliefs\\nimpact\\tour\\tbehavior.\\tInternal\\tstates—our\\tmoods\\tand\\temotions—matter,\\ttoo.\\tIn\\nrecent\\tdecades,\\tscientists\\thave\\tbegun\\tto\\tdetermine\\tthe\\tconnection\\tbetween\\tour\\nthoughts,\\tfeelings,\\tand\\tbehavior.\\tThis\\tresearch\\twill\\talso\\tbe\\tcovered\\tin\\tthese\\npages.\\nIn\\ttotal,\\tthe\\tframework\\tI\\toffer\\tis\\tan\\tintegrated\\tmodel\\tof\\tthe\\tcognitive\\tand\\nbehavioral\\tsciences.\\tI\\tbelieve\\tit\\tis\\tone\\tof\\tthe\\tfirst\\tmodels\\tof\\thuman\\tbehavior\\tto\\naccurately\\taccount\\tfor\\tboth\\tthe\\tinfluence\\tof\\texternal\\tstimuli\\tand\\tinternal\\nemotions\\ton\\tour\\thabits.\\tWhile\\tsome\\tof\\tthe\\tlanguage\\tmay\\tbe\\tfamiliar,\\tI\\tam\\nconfident\\tthat\\tthe\\tdetails—and\\tthe\\tapplications\\tof\\tthe\\tFour\\tLaws\\tof\\tBehavior\\nChange—will\\toffer\\ta\\tnew\\tway\\tto\\tthink\\tabout\\tyour\\thabits.\\nHuman\\tbehavior\\tis\\talways\\tchanging:\\tsituation\\tto\\tsituation,\\tmoment\\tto\\nmoment,\\tsecond\\tto\\tsecond.\\tBut\\tthis\\tbook\\tis\\tabout\\twhat\\t\\ndoesn’t\\n\\tchange.\\tIt’s\\nabout\\tthe\\tfundamentals\\tof\\thuman\\tbehavior.\\tThe\\tlasting\\tprinciples\\tyou\\tcan\\trely\\non\\tyear\\tafter\\tyear.\\tThe\\tideas\\tyou\\tcan\\tbuild\\ta\\tbusiness\\taround,\\tbuild\\ta\\tfamily\\naround,\\tbuild\\ta\\tlife\\taround.\\nThere\\tis\\tno\\tone\\tright\\tway\\tto\\tcreate\\tbetter\\thabits,\\tbut\\tthis\\tbook\\tdescribes\\tthe\\nbest\\tway\\tI\\tknow—an\\tapproach\\tthat\\twill\\tbe\\teffective\\tregardless\\tof\\twhere\\tyou\\nstart\\tor\\twhat\\tyou’re\\ttrying\\tto\\tchange.\\tThe\\tstrategies\\tI\\tcover\\twill\\tbe\\trelevant\\tto\\nanyone\\tlooking\\tfor\\ta\\tstep-by-step\\tsystem\\tfor\\timprovement,\\twhether\\tyour\\tgoals\\ncenter\\ton\\thealth,\\tmoney,\\tproductivity,\\trelationships,\\tor\\tall\\tof\\tthe\\tabove.\\tAs\\tlong\\nas\\thuman\\tbehavior\\tis\\tinvolved,\\tthis\\tbook\\twill\\tbe\\tyour\\tguide.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 13}), Document(page_content='THE\\t\\nFUNDAMENTALS\\nWhy\\tTiny\\tChanges\\tMake\\ta\\tBig\\tDifference', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 14}), Document(page_content='1\\nThe\\tSurprising\\tPower\\tof\\tAtomic\\tHabits\\nT\\nHE\\tFATE\\tOF\\t\\nBritish\\tCycling\\tchanged\\tone\\tday\\tin\\t2003.\\tThe\\torganization,\\twhich\\twas\\nthe\\tgoverning\\tbody\\tfor\\tprofessional\\tcycling\\tin\\tGreat\\tBritain,\\thad\\trecently\\thired\\nDave\\tBrailsford\\tas\\tits\\tnew\\tperformance\\tdirector.\\tAt\\tthe\\ttime,\\tprofessional\\ncyclists\\tin\\tGreat\\tBritain\\thad\\tendured\\tnearly\\tone\\thundred\\tyears\\tof\\tmediocrity.\\nSince\\t1908,\\tBritish\\triders\\thad\\twon\\t\\njust\\ta\\tsingle\\tgold\\tmedal\\tat\\tthe\\tOlympic\\nGames,\\tand\\tthey\\thad\\tfared\\teven\\tworse\\tin\\tcycling’s\\tbiggest\\trace,\\t\\nthe\\tTour\\tde\\nFrance.\\tIn\\t110\\tyears,\\tno\\tBritish\\tcyclist\\thad\\tever\\twon\\tthe\\tevent.\\nIn\\tfact,\\tthe\\tperformance\\tof\\tBritish\\triders\\thad\\tbeen\\tso\\tunderwhelming\\tthat\\t\\none\\nof\\tthe\\ttop\\tbike\\tmanufacturers\\tin\\tEurope\\trefused\\tto\\tsell\\tbikes\\tto\\tthe\\tteam\\tbecause\\nthey\\twere\\tafraid\\tthat\\tit\\twould\\thurt\\tsales\\tif\\tother\\tprofessionals\\tsaw\\tthe\\tBrits\\tusing\\ntheir\\tgear.\\nBrailsford\\thad\\tbeen\\thired\\tto\\tput\\tBritish\\tCycling\\ton\\ta\\tnew\\ttrajectory.\\tWhat\\nmade\\thim\\tdifferent\\tfrom\\tprevious\\tcoaches\\twas\\this\\trelentless\\tcommitment\\tto\\ta\\nstrategy\\tthat\\the\\treferred\\tto\\tas\\t“the\\taggregation\\tof\\tmarginal\\tgains,”\\twhich\\twas\\tthe\\nphilosophy\\tof\\tsearching\\tfor\\ta\\ttiny\\tmargin\\tof\\timprovement\\tin\\teverything\\tyou\\tdo.\\nBrailsford\\tsaid,\\t“\\nThe\\twhole\\tprinciple\\tcame\\tfrom\\tthe\\tidea\\tthat\\tif\\tyou\\tbroke\\tdown\\neverything\\tyou\\t\\ncould\\tthink\\tof\\tthat\\tgoes\\tinto\\triding\\ta\\tbike,\\tand\\tthen\\timprove\\tit\\tby\\n1\\tpercent,\\tyou\\twill\\tget\\ta\\tsignificant\\tincrease\\twhen\\tyou\\tput\\tthem\\tall\\ttogether.”\\nBrailsford\\tand\\this\\tcoaches\\tbegan\\tby\\tmaking\\tsmall\\tadjustments\\tyou\\tmight\\nexpect\\tfrom\\ta\\tprofessional\\tcycling\\tteam.\\tThey\\tredesigned\\tthe\\tbike\\tseats\\tto\\tmake\\nthem\\tmore\\tcomfortable\\tand\\trubbed\\talcohol\\ton\\tthe\\ttires\\tfor\\ta\\tbetter\\tgrip.\\tThey\\nasked\\triders\\tto\\twear\\telectrically\\theated\\tovershorts\\tto\\tmaintain\\tideal\\tmuscle\\ntemperature\\twhile\\triding\\tand\\tused\\tbiofeedback\\tsensors\\tto\\tmonitor\\thow\\teach\\nathlete\\tresponded\\tto\\ta\\tparticular\\tworkout.\\tThe\\tteam\\ttested\\tvarious\\tfabrics\\tin\\ta\\nwind\\ttunnel\\tand\\thad\\ttheir\\toutdoor\\triders\\tswitch\\tto\\tindoor\\tracing\\tsuits,\\twhich\\nproved\\tto\\tbe\\tlighter\\tand\\tmore\\taerodynamic.\\nBut\\tthey\\tdidn’t\\tstop\\tthere.\\tBrailsford\\tand\\this\\tteam\\tcontinued\\tto\\tfind\\t1\\tpercent', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 15}), Document(page_content='improvements\\tin\\toverlooked\\tand\\tunexpected\\tareas.\\tThey\\ttested\\tdifferent\\ttypes\\nof\\tmassage\\tgels\\tto\\tsee\\twhich\\tone\\tled\\tto\\tthe\\tfastest\\tmuscle\\trecovery.\\tThey\\thired\\ta\\nsurgeon\\tto\\tteach\\teach\\trider\\tthe\\tbest\\tway\\tto\\twash\\ttheir\\thands\\tto\\treduce\\tthe\\nchances\\tof\\tcatching\\ta\\tcold.\\tThey\\tdetermined\\tthe\\ttype\\tof\\tpillow\\tand\\tmattress\\tthat\\nled\\tto\\tthe\\tbest\\tnight’s\\tsleep\\tfor\\teach\\trider.\\t\\nThey\\teven\\tpainted\\tthe\\tinside\\tof\\tthe\\nteam\\ttruck\\twhite,\\twhich\\thelped\\tthem\\tspot\\tlittle\\tbits\\tof\\tdust\\tthat\\twould\\tnormally\\nslip\\tby\\tunnoticed\\tbut\\tcould\\tdegrade\\tthe\\tperformance\\tof\\tthe\\tfinely\\ttuned\\tbikes.\\nAs\\tthese\\tand\\thundreds\\tof\\tother\\tsmall\\timprovements\\taccumulated,\\tthe\\tresults\\ncame\\tfaster\\tthan\\tanyone\\tcould\\thave\\timagined.\\nJust\\tfive\\tyears\\tafter\\tBrailsford\\ttook\\tover,\\tthe\\tBritish\\tCycling\\tteam\\tdominated\\nthe\\troad\\tand\\ttrack\\tcycling\\tevents\\tat\\tthe\\t2008\\tOlympic\\tGames\\tin\\tBeijing,\\twhere\\nthey\\twon\\tan\\tastounding\\t60\\tpercent\\tof\\tthe\\tgold\\tmedals\\tavailable.\\tFour\\tyears\\nlater,\\twhen\\tthe\\tOlympic\\tGames\\tcame\\tto\\tLondon,\\t\\nthe\\tBrits\\traised\\tthe\\tbar\\tas\\tthey\\nset\\tnine\\tOlympic\\trecords\\tand\\tseven\\tworld\\trecords.\\nThat\\tsame\\tyear,\\t\\nBradley\\tWiggins\\tbecame\\tthe\\tfirst\\tBritish\\tcyclist\\tto\\twin\\tthe\\nTour\\tde\\tFrance.\\tThe\\tnext\\tyear,\\this\\tteammate\\t\\nChris\\tFroome\\twon\\tthe\\trace,\\tand\\the\\nwould\\tgo\\ton\\tto\\twin\\tagain\\tin\\t2015,\\t2016,\\tand\\t2017,\\tgiving\\tthe\\tBritish\\tteam\\tfive\\nTour\\tde\\tFrance\\tvictories\\tin\\tsix\\tyears.\\nDuring\\tthe\\tten-year\\tspan\\tfrom\\t2007\\tto\\t2017,\\tBritish\\tcyclists\\twon\\t178\\tworld\\nchampionships\\tand\\tsixty-six\\tOlympic\\tor\\tParalympic\\tgold\\tmedals\\tand\\tcaptured\\nfive\\tTour\\tde\\tFrance\\tvictories\\tin\\twhat\\tis\\twidely\\tregarded\\tas\\tthe\\tmost\\tsuccessful\\nrun\\tin\\tcycling\\thistory.\\n*\\nHow\\tdoes\\tthis\\thappen?\\tHow\\tdoes\\ta\\tteam\\tof\\tpreviously\\tordinary\\tathletes\\ntransform\\tinto\\tworld\\tchampions\\twith\\ttiny\\tchanges\\tthat,\\tat\\tfirst\\tglance,\\twould\\nseem\\tto\\tmake\\ta\\tmodest\\tdifference\\tat\\tbest?\\tWhy\\tdo\\tsmall\\timprovements\\naccumulate\\tinto\\tsuch\\tremarkable\\tresults,\\tand\\thow\\tcan\\tyou\\treplicate\\tthis\\napproach\\tin\\tyour\\town\\tlife?\\nWHY\\tSMALL\\tHABITS\\tMAKE\\tA\\tBIG\\tDIFFERENCE\\nIt\\tis\\tso\\teasy\\tto\\toverestimate\\tthe\\timportance\\tof\\tone\\tdefining\\tmoment\\tand\\nunderestimate\\tthe\\tvalue\\tof\\tmaking\\tsmall\\timprovements\\ton\\ta\\tdaily\\tbasis.\\tToo\\noften,\\twe\\tconvince\\tourselves\\tthat\\tmassive\\tsuccess\\trequires\\tmassive\\taction.\\nWhether\\tit\\tis\\tlosing\\tweight,\\tbuilding\\ta\\tbusiness,\\twriting\\ta\\tbook,\\twinning\\ta\\nchampionship,\\tor\\tachieving\\tany\\tother\\tgoal,\\twe\\tput\\tpressure\\ton\\tourselves\\tto\\nmake\\tsome\\tearth-shattering\\timprovement\\tthat\\teveryone\\twill\\ttalk\\tabout.\\nMeanwhile,\\timproving\\tby\\t1\\tpercent\\tisn’t\\tparticularly\\tnotable—sometimes\\tit\\nisn’t\\teven\\t\\nnoticeable\\n—but\\tit\\tcan\\tbe\\tfar\\tmore\\tmeaningful,\\tespecially\\tin\\tthe\\tlong', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 16}), Document(page_content='run.\\tThe\\tdifference\\ta\\ttiny\\timprovement\\tcan\\tmake\\tover\\ttime\\tis\\tastounding.\\nHere’s\\thow\\tthe\\tmath\\tworks\\tout:\\tif\\tyou\\tcan\\tget\\t1\\tpercent\\tbetter\\teach\\tday\\tfor\\tone\\nyear,\\t\\nyou’ll\\tend\\tup\\tthirty-seven\\ttimes\\tbetter\\tby\\tthe\\ttime\\tyou’re\\tdone.\\nConversely,\\tif\\tyou\\tget\\t1\\tpercent\\tworse\\teach\\tday\\tfor\\tone\\tyear,\\tyou’ll\\tdecline\\nnearly\\tdown\\tto\\tzero.\\tWhat\\tstarts\\tas\\ta\\tsmall\\twin\\tor\\ta\\tminor\\tsetback\\taccumulates\\ninto\\tsomething\\tmuch\\tmore.\\n1%\\tBETTER\\tEVERY\\tDAY\\n1%\\tworse\\tevery\\tday\\tfor\\tone\\tyear.\\t0.99\\n365\\n\\t=\\t00.03\\n1%\\tbetter\\tevery\\tday\\tfor\\tone\\tyear.\\t1.01\\n365\\n\\t=\\t37.78\\nFIGURE\\t1:\\tThe\\teffects\\tof\\tsmall\\thabits\\tcompound\\tover\\ttime.\\tFor\\texample,\\tif\\tyou\\tcan\\tget\\tjust\\t1\\tpercent\\tbetter\\teach\\tday,\\tyou’ll\\tend\\tup\\twith\\tresults\\tthat\\tare\\tnearly\\t37\\ttimes\\tbetter\\tafter\\tone\\nyear.\\nHabits\\tare\\tthe\\tcompound\\tinterest\\tof\\tselfimprovement.\\tThe\\tsame\\tway\\tthat\\nmoney\\tmultiplies\\tthrough\\tcompound\\tinterest,\\tthe\\teffects\\tof\\tyour\\thabits\\tmultiply\\nas\\tyou\\trepeat\\tthem.\\tThey\\tseem\\tto\\tmake\\tlittle\\tdifference\\ton\\tany\\tgiven\\tday\\tand\\tyet\\nthe\\timpact\\tthey\\tdeliver\\tover\\tthe\\tmonths\\tand\\tyears\\tcan\\tbe\\tenormous.\\tIt\\tis\\tonly\\nwhen\\tlooking\\tback\\ttwo,\\tfive,\\tor\\tperhaps\\tten\\tyears\\tlater\\tthat\\tthe\\tvalue\\tof\\tgood\\nhabits\\tand\\tthe\\tcost\\tof\\tbad\\tones\\tbecomes\\tstrikingly\\tapparent.\\nThis\\tcan\\tbe\\ta\\tdifficult\\tconcept\\tto\\tappreciate\\tin\\tdaily\\tlife.\\tWe\\toften\\t\\ndismiss\\nsmall\\tchanges\\tbecause\\tthey\\tdon’t\\tseem\\tto\\tmatter\\tvery\\tmuch\\tin\\tthe\\tmoment.\\tIf', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 17}), Document(page_content='you\\tsave\\ta\\tlittle\\tmoney\\tnow,\\tyou’re\\tstill\\tnot\\ta\\tmillionaire.\\tIf\\tyou\\tgo\\tto\\tthe\\tgym\\nthree\\tdays\\tin\\ta\\trow,\\tyou’re\\tstill\\tout\\tof\\tshape.\\tIf\\tyou\\tstudy\\tMandarin\\tfor\\tan\\thour\\ntonight,\\tyou\\tstill\\thaven’t\\tlearned\\tthe\\tlanguage.\\tWe\\tmake\\ta\\tfew\\tchanges,\\tbut\\tthe\\nresults\\tnever\\tseem\\tto\\tcome\\tquickly\\tand\\tso\\twe\\tslide\\tback\\tinto\\tour\\tprevious\\nroutines.\\nUnfortunately,\\tthe\\tslow\\tpace\\tof\\ttransformation\\talso\\tmakes\\tit\\teasy\\tto\\tlet\\ta\\tbad\\nhabit\\tslide.\\tIf\\tyou\\teat\\tan\\tunhealthy\\tmeal\\ttoday,\\tthe\\tscale\\tdoesn’t\\tmove\\tmuch.\\tIf\\nyou\\twork\\tlate\\ttonight\\tand\\tignore\\tyour\\tfamily,\\tthey\\twill\\tforgive\\tyou.\\tIf\\tyou\\nprocrastinate\\tand\\tput\\tyour\\tproject\\toff\\tuntil\\ttomorrow,\\tthere\\twill\\tusually\\tbe\\ttime\\nto\\tfinish\\tit\\tlater.\\tA\\tsingle\\tdecision\\tis\\teasy\\tto\\tdismiss.\\nBut\\twhen\\twe\\trepeat\\t1\\tpercent\\terrors,\\tday\\tafter\\tday,\\tby\\treplicating\\tpoor\\ndecisions,\\tduplicating\\ttiny\\tmistakes,\\tand\\trationalizing\\tlittle\\texcuses,\\tour\\tsmall\\nchoices\\tcompound\\tinto\\ttoxic\\tresults.\\tIt’s\\tthe\\taccumulation\\tof\\tmany\\tmissteps—a\\n1\\tpercent\\tdecline\\there\\tand\\tthere—that\\teventually\\tleads\\tto\\ta\\tproblem.\\nThe\\timpact\\tcreated\\tby\\ta\\tchange\\tin\\tyour\\thabits\\tis\\tsimilar\\tto\\tthe\\teffect\\tof\\nshifting\\tthe\\troute\\tof\\tan\\tairplane\\tby\\tjust\\ta\\tfew\\tdegrees.\\tImagine\\tyou\\tare\\tflying\\nfrom\\tLos\\tAngeles\\tto\\tNew\\tYork\\tCity.\\tIf\\ta\\tpilot\\tleaving\\tfrom\\tLAX\\tadjusts\\tthe\\nheading\\tjust\\t3.5\\tdegrees\\tsouth,\\tyou\\twill\\tland\\tin\\tWashington,\\tD.C.,\\tinstead\\tof\\nNew\\tYork.\\tSuch\\ta\\tsmall\\tchange\\tis\\tbarely\\tnoticeable\\tat\\ttakeoff—the\\tnose\\tof\\tthe\\nairplane\\tmoves\\tjust\\ta\\tfew\\tfeet—but\\twhen\\tmagnified\\tacross\\tthe\\tentire\\tUnited\\nStates,\\tyou\\tend\\tup\\thundreds\\tof\\tmiles\\tapart.\\n*\\nSimilarly,\\ta\\tslight\\tchange\\tin\\tyour\\tdaily\\thabits\\tcan\\tguide\\tyour\\tlife\\tto\\ta\\tvery\\ndifferent\\tdestination.\\tMaking\\ta\\tchoice\\tthat\\tis\\t1\\tpercent\\tbetter\\tor\\t1\\tpercent\\tworse\\nseems\\tinsignificant\\tin\\tthe\\tmoment,\\tbut\\tover\\tthe\\tspan\\t\\nof\\tmoments\\tthat\\tmake\\tup\\ta\\nlifetime\\tthese\\tchoices\\tdetermine\\tthe\\tdifference\\tbetween\\twho\\tyou\\tare\\tand\\twho\\nyou\\tcould\\tbe.\\tSuccess\\tis\\tthe\\tproduct\\tof\\tdaily\\thabits—not\\tonce-in-a-lifetime\\ntransformations.\\nThat\\tsaid,\\tit\\tdoesn’t\\tmatter\\thow\\tsuccessful\\tor\\tunsuccessful\\tyou\\tare\\tright\\tnow.\\nWhat\\tmatters\\tis\\twhether\\tyour\\thabits\\tare\\tputting\\tyou\\ton\\tthe\\tpath\\ttoward\\tsuccess.\\nYou\\tshould\\tbe\\tfar\\tmore\\tconcerned\\twith\\tyour\\tcurrent\\ttrajectory\\tthan\\twith\\tyour\\ncurrent\\tresults.\\tIf\\tyou’re\\ta\\tmillionaire\\tbut\\tyou\\tspend\\tmore\\tthan\\tyou\\tearn\\teach\\nmonth,\\tthen\\tyou’re\\ton\\ta\\tbad\\ttrajectory.\\tIf\\tyour\\tspending\\thabits\\tdon’t\\tchange,\\tit’s\\nnot\\tgoing\\tto\\tend\\twell.\\tConversely,\\tif\\tyou’re\\tbroke,\\tbut\\tyou\\tsave\\ta\\tlittle\\tbit\\tevery\\nmonth,\\tthen\\tyou’re\\ton\\tthe\\tpath\\ttoward\\tfinancial\\tfreedom—even\\tif\\tyou’re\\nmoving\\tslower\\tthan\\tyou’d\\tlike.\\nYour\\toutcomes\\tare\\ta\\tlagging\\tmeasure\\tof\\tyour\\thabits.\\tYour\\tnet\\tworth\\tis\\ta\\nlagging\\tmeasure\\tof\\tyour\\tfinancial\\thabits.\\tYour\\tweight\\tis\\ta\\tlagging\\tmeasure\\tof\\nyour\\teating\\thabits.\\tYour\\tknowledge\\tis\\ta\\tlagging\\tmeasure\\tof\\tyour\\tlearning\\thabits.\\nYour\\tclutter\\tis\\ta\\tlagging\\tmeasure\\tof\\tyour\\tcleaning\\thabits.\\tYou\\tget\\twhat\\tyou', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 18}), Document(page_content='repeat.\\nIf\\tyou\\twant\\tto\\tpredict\\twhere\\tyou’ll\\tend\\tup\\tin\\tlife,\\tall\\tyou\\thave\\tto\\tdo\\tis\\tfollow\\nthe\\tcurve\\tof\\ttiny\\tgains\\tor\\ttiny\\tlosses,\\tand\\tsee\\thow\\tyour\\tdaily\\tchoices\\twill\\ncompound\\tten\\tor\\ttwenty\\tyears\\tdown\\tthe\\tline.\\tAre\\tyou\\tspending\\tless\\tthan\\tyou\\nearn\\teach\\tmonth?\\tAre\\tyou\\tmaking\\tit\\tinto\\tthe\\tgym\\teach\\tweek?\\tAre\\tyou\\treading\\nbooks\\tand\\tlearning\\tsomething\\tnew\\teach\\tday?\\tTiny\\tbattles\\tlike\\tthese\\tare\\tthe\\tones\\nthat\\twill\\tdefine\\tyour\\tfuture\\tself.\\nTime\\tmagnifies\\tthe\\tmargin\\tbetween\\tsuccess\\tand\\tfailure.\\tIt\\twill\\tmultiply\\nwhatever\\tyou\\tfeed\\tit.\\tGood\\thabits\\tmake\\ttime\\tyour\\tally.\\tBad\\thabits\\tmake\\ttime\\nyour\\tenemy.\\nHabits\\tare\\ta\\tdouble-edged\\tsword.\\tBad\\thabits\\tcan\\tcut\\tyou\\tdown\\tjust\\tas\\teasily\\nas\\tgood\\thabits\\tcan\\tbuild\\tyou\\tup,\\twhich\\tis\\twhy\\tunderstanding\\tthe\\tdetails\\tis\\ncrucial.\\tYou\\tneed\\tto\\tknow\\thow\\thabits\\twork\\tand\\thow\\tto\\tdesign\\tthem\\tto\\tyour\\nliking,\\tso\\tyou\\tcan\\tavoid\\tthe\\tdangerous\\thalf\\tof\\tthe\\tblade.\\nYOUR\\tHABITS\\tCAN\\tCOMPOUND\\tFOR\\tYOU\\tOR\\tAGAINST\\tYOU\\nPositive\\tCompounding\\nProductivity\\tcompounds.\\t\\nAccomplishing\\tone\\textra\\ttask\\tis\\ta\\tsmall\\tfeat\\ton\\tany\\tgiven\\tday,\\tbut\\tit\\tcounts\\tfor\\ta\\tlot\\tover\\tan\\tentire\\tcareer.\\tThe\\teffect\\tof\\tautomating\\tan\\told\\ttask\\tor\\tmastering\\ta\\tnew\\nskill\\tcan\\tbe\\teven\\tgreater.\\tThe\\tmore\\ttasks\\tyou\\tcan\\thandle\\twithout\\tthinking,\\tthe\\tmore\\tyour\\tbrain\\tis\\tfree\\tto\\tfocus\\ton\\tother\\tareas.\\nKnowledge\\tcompounds.\\t\\nLearning\\tone\\tnew\\tidea\\twon’t\\tmake\\tyou\\ta\\tgenius,\\tbut\\ta\\tcommitment\\tto\\tlifelong\\tlearning\\tcan\\tbe\\ttransformative.\\tFurthermore,\\teach\\tbook\\tyou\\tread\\tnot\\tonly\\tteaches\\nyou\\tsomething\\tnew\\tbut\\talso\\topens\\tup\\tdifferent\\tways\\tof\\tthinking\\tabout\\told\\tideas.\\tAs\\tWarren\\tBuffett\\tsays,\\t“That’s\\thow\\tknowledge\\tworks.\\tIt\\tbuilds\\tup,\\tlike\\tcompound\\tinterest.”\\nRelationships\\tcompound.\\t\\nPeople\\treflect\\tyour\\tbehavior\\tback\\tto\\tyou.\\tThe\\tmore\\tyou\\thelp\\tothers,\\tthe\\tmore\\tothers\\twant\\tto\\thelp\\tyou.\\tBeing\\ta\\tlittle\\tbit\\tnicer\\tin\\teach\\tinteraction\\tcan\\tresult\\tin\\ta\\nnetwork\\tof\\tbroad\\tand\\tstrong\\tconnections\\tover\\ttime.\\nNegative\\tCompounding\\nStress\\tcompounds.\\n\\tThe\\tfrustration\\tof\\ta\\ttraffic\\tjam.\\tThe\\tweight\\tof\\tparenting\\tresponsibilities.\\tThe\\tworry\\tof\\tmaking\\tends\\tmeet.\\tThe\\tstrain\\tof\\tslightly\\thigh\\tblood\\tpressure.\\tBy\\tthemselves,\\tthese\\ncommon\\tcauses\\tof\\tstress\\tare\\tmanageable.\\tBut\\twhen\\tthey\\tpersist\\tfor\\tyears,\\tlittle\\tstresses\\tcompound\\tinto\\tserious\\thealth\\tissues.\\nNegative\\tthoughts\\tcompound.\\t\\nThe\\tmore\\tyou\\tthink\\tof\\tyourself\\tas\\tworthless,\\tstupid,\\tor\\tugly,\\tthe\\tmore\\tyou\\tcondition\\tyourself\\tto\\tinterpret\\tlife\\tthat\\tway.\\tYou\\tget\\ttrapped\\tin\\ta\\tthought\\tloop.\\tThe\\nsame\\tis\\ttrue\\tfor\\thow\\tyou\\tthink\\tabout\\tothers.\\tOnce\\tyou\\tfall\\tinto\\tthe\\thabit\\tof\\tseeing\\tpeople\\tas\\tangry,\\tunjust,\\tor\\tselfish,\\tyou\\tsee\\tthose\\tkind\\tof\\tpeople\\teverywhere.\\nOutrage\\tcompounds.\\t\\nRiots,\\tprotests,\\tand\\tmass\\tmovements\\tare\\trarely\\tthe\\tresult\\tof\\ta\\tsingle\\tevent.\\tInstead,\\ta\\tlong\\tseries\\tof\\tmicroaggressions\\tand\\tdaily\\taggravations\\tslowly\\tmultiply\\tuntil\\tone\\nevent\\ttips\\tthe\\tscales\\tand\\toutrage\\tspreads\\tlike\\twildfire.\\nWHAT\\tPROGRESS\\tIS\\tREALLY\\tLIKE\\nImagine\\tthat\\tyou\\thave\\tan\\tice\\tcube\\tsitting\\ton\\tthe\\ttable\\tin\\tfront\\tof\\tyou.\\tThe\\troom\\nis\\tcold\\tand\\tyou\\tcan\\tsee\\tyour\\tbreath.\\tIt\\tis\\tcurrently\\ttwenty-five\\tdegrees.\\tEver\\tso\\nslowly,\\tthe\\troom\\tbegins\\tto\\theat\\tup.\\nTwenty-six\\tdegrees.\\nTwenty-seven.\\nTwenty-eight.\\nThe\\tice\\tcube\\tis\\tstill\\tsitting\\ton\\tthe\\ttable\\tin\\tfront\\tof\\tyou.\\nTwenty-nine\\tdegrees.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 19}), Document(page_content='Thirty.\\nThirty-one.\\nStill,\\tnothing\\thas\\thappened.\\nThen,\\tthirty-two\\tdegrees.\\tThe\\tice\\tbegins\\tto\\tmelt.\\tA\\tone-degree\\tshift,\\nseemingly\\tno\\tdifferent\\tfrom\\tthe\\ttemperature\\tincreases\\tbefore\\tit,\\thas\\tunlocked\\ta\\nhuge\\tchange.\\nBreakthrough\\tmoments\\tare\\toften\\tthe\\tresult\\tof\\tmany\\tprevious\\tactions,\\twhich\\nbuild\\tup\\tthe\\tpotential\\trequired\\tto\\tunleash\\ta\\tmajor\\tchange.\\tThis\\tpattern\\tshows\\tup\\neverywhere.\\t\\nCancer\\tspends\\t80\\tpercent\\tof\\tits\\tlife\\tundetectable,\\tthen\\ttakes\\tover\\nthe\\tbody\\tin\\tmonths.\\tBamboo\\tcan\\tbarely\\tbe\\tseen\\tfor\\tthe\\tfirst\\tfive\\tyears\\tas\\tit\\nbuilds\\textensive\\troot\\tsystems\\tunderground\\tbefore\\texploding\\tninety\\tfeet\\tinto\\tthe\\nair\\twithin\\tsix\\tweeks.\\nSimilarly,\\thabits\\toften\\tappear\\tto\\tmake\\tno\\tdifference\\tuntil\\tyou\\tcross\\ta\\tcritical\\nthreshold\\tand\\tunlock\\ta\\tnew\\tlevel\\tof\\tperformance.\\tIn\\tthe\\tearly\\tand\\tmiddle\\tstages\\nof\\tany\\tquest,\\tthere\\tis\\toften\\ta\\tValley\\tof\\tDisappointment.\\tYou\\texpect\\tto\\tmake\\nprogress\\tin\\ta\\tlinear\\tfashion\\tand\\tit’s\\tfrustrating\\thow\\tineffective\\tchanges\\tcan\\tseem\\nduring\\tthe\\tfirst\\tdays,\\tweeks,\\tand\\teven\\tmonths.\\tIt\\tdoesn’t\\tfeel\\tlike\\tyou\\tare\\tgoing\\nanywhere.\\tIt’s\\ta\\thallmark\\tof\\tany\\tcompounding\\tprocess:\\tthe\\tmost\\tpowerful\\noutcomes\\tare\\tdelayed.\\nThis\\tis\\tone\\tof\\tthe\\tcore\\treasons\\twhy\\tit\\tis\\tso\\thard\\tto\\tbuild\\thabits\\tthat\\t\\nlast.\\nPeople\\tmake\\ta\\tfew\\tsmall\\tchanges,\\tfail\\tto\\tsee\\ta\\ttangible\\tresult,\\tand\\tdecide\\tto\\tstop.\\nYou\\tthink,\\t“I’ve\\tbeen\\trunning\\tevery\\tday\\tfor\\ta\\tmonth,\\tso\\twhy\\tcan’t\\tI\\tsee\\tany\\nchange\\tin\\tmy\\tbody?”\\tOnce\\tthis\\tkind\\tof\\tthinking\\ttakes\\tover,\\tit’s\\teasy\\tto\\tlet\\tgood\\nhabits\\tfall\\tby\\tthe\\twayside.\\tBut\\tin\\torder\\tto\\tmake\\ta\\tmeaningful\\tdifference,\\thabits\\nneed\\tto\\tpersist\\tlong\\tenough\\tto\\tbreak\\tthrough\\tthis\\tplateau—what\\tI\\tcall\\tthe\\nPlateau\\tof\\tLatent\\tPotential\\n.\\nIf\\tyou\\tfind\\tyourself\\tstruggling\\tto\\tbuild\\ta\\tgood\\thabit\\tor\\tbreak\\ta\\tbad\\tone,\\tit\\tis\\nnot\\tbecause\\tyou\\thave\\tlost\\tyour\\tability\\tto\\timprove.\\tIt\\tis\\toften\\tbecause\\tyou\\thave\\nnot\\tyet\\tcrossed\\tthe\\tPlateau\\tof\\tLatent\\tPotential.\\tComplaining\\tabout\\tnot\\tachieving\\nsuccess\\tdespite\\tworking\\thard\\tis\\tlike\\tcomplaining\\tabout\\tan\\tice\\tcube\\tnot\\tmelting\\nwhen\\tyou\\theated\\tit\\tfrom\\ttwenty-five\\tto\\tthirty-one\\tdegrees.\\tYour\\twork\\twas\\tnot\\nwasted;\\tit\\tis\\tjust\\tbeing\\tstored.\\tAll\\tthe\\taction\\thappens\\tat\\tthirty-two\\tdegrees.\\nWhen\\tyou\\tfinally\\tbreak\\tthrough\\tthe\\tPlateau\\tof\\tLatent\\tPotential,\\tpeople\\twill\\ncall\\tit\\tan\\tovernight\\tsuccess.\\tThe\\toutside\\tworld\\tonly\\tsees\\tthe\\tmost\\tdramatic\\tevent\\nrather\\tthan\\tall\\tthat\\tpreceded\\tit.\\tBut\\tyou\\tknow\\tthat\\tit’s\\tthe\\twork\\tyou\\tdid\\tlong\\tago\\n—when\\tit\\tseemed\\tthat\\tyou\\tweren’t\\tmaking\\tany\\tprogress—that\\tmakes\\tthe\\tjump\\ntoday\\tpossible.\\nIt\\tis\\tthe\\thuman\\tequivalent\\tof\\tgeological\\tpressure.\\tTwo\\ttectonic\\tplates\\tcan\\ngrind\\tagainst\\tone\\tanother\\tfor\\tmillions\\tof\\tyears,\\tthe\\ttension\\tslowly\\tbuilding\\tall', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 20}), Document(page_content='the\\twhile.\\tThen,\\tone\\tday,\\tthey\\trub\\teach\\tother\\tonce\\tagain,\\tin\\tthe\\tsame\\tfashion\\nthey\\thave\\tfor\\tages,\\tbut\\tthis\\ttime\\tthe\\ttension\\tis\\ttoo\\tgreat.\\tAn\\tearthquake\\terupts.\\nChange\\tcan\\ttake\\tyears—before\\tit\\thappens\\tall\\tat\\tonce.\\nMastery\\trequires\\tpatience.\\t\\nThe\\tSan\\tAntonio\\tSpurs,\\tone\\tof\\tthe\\tmost\\tsuccessful\\nteams\\tin\\tNBA\\thistory,\\thave\\ta\\tquote\\tfrom\\tsocial\\treformer\\tJacob\\tRiis\\thanging\\tin\\ntheir\\tlocker\\troom:\\t“When\\tnothing\\tseems\\tto\\thelp,\\tI\\tgo\\tand\\tlook\\tat\\ta\\tstonecutter\\nhammering\\taway\\tat\\this\\trock,\\tperhaps\\ta\\thundred\\ttimes\\twithout\\tas\\tmuch\\tas\\ta\\ncrack\\tshowing\\tin\\tit.\\tYet\\tat\\tthe\\thundred\\tand\\tfirst\\tblow\\tit\\twill\\tsplit\\tin\\ttwo,\\tand\\tI\\nknow\\tit\\twas\\tnot\\tthat\\tlast\\tblow\\tthat\\tdid\\tit—but\\tall\\tthat\\thad\\tgone\\tbefore.”\\nTHE\\tPLATEAU\\tOF\\tLATENT\\tPOTENTIAL\\nFIGURE\\t2:\\tWe\\toften\\texpect\\tprogress\\tto\\tbe\\tlinear.\\tAt\\tthe\\tvery\\tleast,\\twe\\thope\\tit\\twill\\tcome\\tquickly.\\tIn\\treality,\\tthe\\tresults\\tof\\tour\\tefforts\\tare\\toften\\tdelayed.\\tIt\\tis\\tnot\\tuntil\\tmonths\\tor\\tyears\\tlater\\nthat\\twe\\trealize\\tthe\\ttrue\\tvalue\\tof\\tthe\\tprevious\\twork\\twe\\thave\\tdone.\\tThis\\tcan\\tresult\\tin\\ta\\t“valley\\tof\\tdisappointment”\\twhere\\tpeople\\tfeel\\tdiscouraged\\tafter\\tputting\\tin\\tweeks\\tor\\tmonths\\tof\\thard\\twork\\nwithout\\texperiencing\\tany\\tresults.\\tHowever,\\tthis\\twork\\twas\\tnot\\twasted.\\tIt\\twas\\tsimply\\tbeing\\tstored.\\tIt\\tis\\tnot\\tuntil\\tmuch\\tlater\\tthat\\tthe\\tfull\\tvalue\\tof\\tprevious\\tefforts\\tis\\trevealed.\\nAll\\tbig\\tthings\\tcome\\tfrom\\tsmall\\tbeginnings.\\t\\nThe\\tseed\\tof\\tevery\\thabit\\tis\\ta\\nsingle,\\ttiny\\tdecision.\\tBut\\tas\\tthat\\tdecision\\tis\\trepeated,\\ta\\thabit\\tsprouts\\tand\\tgrows\\nstronger.\\tRoots\\tentrench\\tthemselves\\tand\\tbranches\\tgrow.\\tThe\\ttask\\tof\\tbreaking\\ta\\nbad\\thabit\\tis\\tlike\\tuprooting\\ta\\tpowerful\\toak\\twithin\\t\\nus.\\tAnd\\tthe\\ttask\\tof\\tbuilding\\ta\\ngood\\thabit\\tis\\tlike\\tcultivating\\ta\\tdelicate\\tflower\\tone\\tday\\tat\\ta\\ttime.\\nBut\\twhat\\tdetermines\\twhether\\twe\\tstick\\twith\\ta\\thabit\\tlong\\tenough\\tto\\tsurvive\\tthe\\nPlateau\\tof\\tLatent\\tPotential\\tand\\tbreak\\tthrough\\tto\\tthe\\tother\\tside?\\tWhat\\tis\\tit\\tthat', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 21}), Document(page_content='causes\\tsome\\tpeople\\tto\\tslide\\tinto\\tunwanted\\thabits\\tand\\tenables\\tothers\\tto\\tenjoy\\tthe\\ncompounding\\teffects\\tof\\tgood\\tones?\\nFORGET\\tABOUT\\tGOALS,\\tFOCUS\\tON\\tSYSTEMS\\tINSTEAD\\nPrevailing\\twisdom\\tclaims\\tthat\\tthe\\tbest\\tway\\tto\\tachieve\\twhat\\twe\\twant\\tin\\tlife—\\ngetting\\tinto\\tbetter\\tshape,\\tbuilding\\ta\\tsuccessful\\tbusiness,\\trelaxing\\tmore\\tand\\nworrying\\tless,\\tspending\\tmore\\ttime\\twith\\tfriends\\tand\\tfamily—is\\tto\\tset\\tspecific,\\nactionable\\tgoals.\\nFor\\tmany\\tyears,\\tthis\\twas\\thow\\tI\\tapproached\\tmy\\thabits,\\ttoo.\\tEach\\tone\\twas\\ta\\ngoal\\tto\\tbe\\treached.\\tI\\tset\\tgoals\\tfor\\tthe\\tgrades\\tI\\twanted\\tto\\tget\\tin\\tschool,\\tfor\\tthe\\nweights\\tI\\twanted\\tto\\tlift\\tin\\tthe\\tgym,\\tfor\\tthe\\tprofits\\tI\\twanted\\tto\\tearn\\tin\\tbusiness.\\tI\\nsucceeded\\tat\\ta\\tfew,\\tbut\\tI\\tfailed\\tat\\ta\\tlot\\tof\\tthem.\\tEventually,\\tI\\tbegan\\tto\\trealize\\nthat\\tmy\\tresults\\thad\\tvery\\tlittle\\tto\\tdo\\twith\\tthe\\tgoals\\tI\\tset\\tand\\tnearly\\teverything\\tto\\ndo\\twith\\tthe\\tsystems\\tI\\tfollowed.\\nWhat’s\\tthe\\tdifference\\tbetween\\tsystems\\tand\\tgoals?\\tIt’s\\ta\\tdistinction\\tI\\tfirst\\nlearned\\tfrom\\tScott\\tAdams,\\tthe\\tcartoonist\\tbehind\\tthe\\t\\nDilbert\\n\\tcomic.\\tGoals\\tare\\nabout\\tthe\\tresults\\tyou\\twant\\tto\\tachieve.\\tSystems\\tare\\tabout\\tthe\\tprocesses\\tthat\\tlead\\nto\\tthose\\tresults.\\nIf\\tyou’re\\ta\\tcoach,\\tyour\\tgoal\\tmight\\tbe\\tto\\twin\\ta\\tchampionship.\\tYour\\nsystem\\tis\\tthe\\tway\\tyou\\trecruit\\tplayers,\\tmanage\\tyour\\tassistant\\tcoaches,\\nand\\tconduct\\tpractice.\\nIf\\tyou’re\\tan\\tentrepreneur,\\tyour\\tgoal\\tmight\\tbe\\tto\\tbuild\\ta\\tmillion-dollar\\nbusiness.\\tYour\\tsystem\\tis\\thow\\tyou\\ttest\\tproduct\\tideas,\\thire\\temployees,\\nand\\trun\\tmarketing\\tcampaigns.\\nIf\\tyou’re\\ta\\tmusician,\\tyour\\tgoal\\tmight\\tbe\\tto\\tplay\\ta\\tnew\\tpiece.\\tYour\\nsystem\\tis\\thow\\toften\\tyou\\tpractice,\\thow\\tyou\\tbreak\\tdown\\tand\\ttackle\\ndifficult\\tmeasures,\\tand\\tyour\\tmethod\\tfor\\treceiving\\tfeedback\\tfrom\\tyour\\ninstructor.\\nNow\\tfor\\tthe\\tinteresting\\tquestion:\\tIf\\tyou\\tcompletely\\tignored\\tyour\\tgoals\\tand\\nfocused\\tonly\\ton\\tyour\\tsystem,\\twould\\tyou\\tstill\\tsucceed?\\tFor\\texample,\\tif\\tyou\\twere\\na\\tbasketball\\tcoach\\tand\\tyou\\tignored\\tyour\\tgoal\\tto\\twin\\ta\\tchampionship\\tand\\nfocused\\tonly\\ton\\twhat\\tyour\\tteam\\tdoes\\tat\\tpractice\\teach\\tday,\\twould\\tyou\\tstill\\tget\\nresults?\\nI\\tthink\\tyou\\twould.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 22}), Document(page_content='The\\tgoal\\tin\\tany\\tsport\\tis\\tto\\tfinish\\twith\\tthe\\tbest\\tscore,\\tbut\\tit\\twould\\tbe\\tridiculous\\nto\\tspend\\tthe\\twhole\\tgame\\tstaring\\tat\\tthe\\tscoreboard.\\tThe\\tonly\\tway\\tto\\tactually\\twin\\nis\\tto\\tget\\tbetter\\teach\\tday.\\tIn\\tthe\\twords\\tof\\tthree-time\\tSuper\\tBowl\\twinner\\tBill\\nWalsh,\\t“The\\tscore\\ttakes\\tcare\\tof\\titself.”\\tThe\\tsame\\tis\\ttrue\\tfor\\tother\\tareas\\tof\\tlife.\\tIf\\nyou\\twant\\tbetter\\tresults,\\tthen\\tforget\\tabout\\tsetting\\tgoals.\\tFocus\\ton\\tyour\\tsystem\\ninstead.\\nWhat\\tdo\\tI\\tmean\\tby\\tthis?\\tAre\\tgoals\\tcompletely\\tuseless?\\tOf\\tcourse\\tnot.\\tGoals\\nare\\tgood\\tfor\\tsetting\\ta\\tdirection,\\tbut\\tsystems\\tare\\tbest\\tfor\\tmaking\\tprogress.\\tA\\nhandful\\tof\\tproblems\\tarise\\twhen\\tyou\\tspend\\ttoo\\tmuch\\ttime\\tthinking\\tabout\\tyour\\ngoals\\tand\\tnot\\tenough\\ttime\\tdesigning\\tyour\\tsystems.\\nProblem\\t#1:\\tWinners\\tand\\tlosers\\thave\\tthe\\tsame\\tgoals.\\nGoal\\tsetting\\tsuffers\\tfrom\\ta\\tserious\\tcase\\tof\\tsurvivorship\\tbias.\\tWe\\tconcentrate\\ton\\nthe\\tpeople\\twho\\tend\\tup\\twinning—the\\tsurvivors—and\\t\\nmistakenly\\tassume\\tthat\\nambitious\\tgoals\\tled\\tto\\ttheir\\tsuccess\\twhile\\toverlooking\\tall\\tof\\tthe\\tpeople\\twho\\thad\\nthe\\tsame\\tobjective\\tbut\\tdidn’t\\tsucceed.\\nEvery\\tOlympian\\twants\\tto\\twin\\ta\\tgold\\tmedal.\\tEvery\\tcandidate\\twants\\tto\\tget\\tthe\\njob.\\tAnd\\tif\\tsuccessful\\tand\\tunsuccessful\\tpeople\\tshare\\tthe\\tsame\\tgoals,\\tthen\\t\\nthe\\ngoal\\tcannot\\tbe\\twhat\\tdifferentiates\\tthe\\twinners\\tfrom\\tthe\\tlosers.\\tIt\\twasn’t\\tthe\\t\\ngoal\\nof\\twinning\\tthe\\tTour\\tde\\tFrance\\tthat\\tpropelled\\tthe\\tBritish\\tcyclists\\tto\\tthe\\ttop\\tof\\tthe\\nsport.\\tPresumably,\\tthey\\thad\\twanted\\tto\\twin\\tthe\\trace\\tevery\\tyear\\tbefore—just\\tlike\\nevery\\tother\\tprofessional\\tteam.\\tThe\\tgoal\\thad\\talways\\tbeen\\tthere.\\tIt\\twas\\tonly\\twhen\\nthey\\timplemented\\ta\\t\\nsystem\\n\\tof\\tcontinuous\\tsmall\\timprovements\\tthat\\tthey\\tachieved\\na\\tdifferent\\toutcome.\\nProblem\\t#2:\\tAchieving\\ta\\tgoal\\tis\\tonly\\ta\\tmomentary\\tchange.\\nImagine\\tyou\\thave\\ta\\tmessy\\troom\\tand\\tyou\\tset\\ta\\tgoal\\tto\\tclean\\tit.\\tIf\\tyou\\tsummon\\nthe\\tenergy\\tto\\ttidy\\tup,\\tthen\\tyou\\twill\\thave\\ta\\tclean\\troom—for\\tnow.\\tBut\\tif\\tyou\\nmaintain\\tthe\\tsame\\tsloppy,\\tpack-rat\\thabits\\tthat\\tled\\tto\\ta\\tmessy\\troom\\tin\\tthe\\tfirst\\nplace,\\tsoon\\tyou’ll\\tbe\\tlooking\\tat\\ta\\tnew\\tpile\\tof\\tclutter\\tand\\thoping\\tfor\\tanother\\tburst\\nof\\tmotivation.\\tYou’re\\tleft\\tchasing\\tthe\\tsame\\toutcome\\tbecause\\tyou\\tnever\\tchanged\\nthe\\tsystem\\tbehind\\tit.\\tYou\\ttreated\\ta\\tsymptom\\twithout\\taddressing\\tthe\\tcause.\\nAchieving\\ta\\tgoal\\tonly\\tchanges\\tyour\\tlife\\t\\nfor\\tthe\\tmoment\\n.\\tThat’s\\tthe\\ncounterintuitive\\tthing\\tabout\\timprovement.\\tWe\\tthink\\twe\\tneed\\tto\\tchange\\tour\\nresults,\\tbut\\tthe\\tresults\\tare\\tnot\\tthe\\tproblem.\\tWhat\\twe\\treally\\tneed\\tto\\tchange\\tare\\nthe\\tsystems\\tthat\\tcause\\tthose\\tresults.\\tWhen\\tyou\\tsolve\\tproblems\\tat\\tthe\\tresults', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 23}), Document(page_content='level,\\tyou\\tonly\\tsolve\\tthem\\ttemporarily.\\tIn\\torder\\tto\\timprove\\tfor\\tgood,\\tyou\\tneed\\nto\\tsolve\\tproblems\\tat\\tthe\\tsystems\\tlevel.\\tFix\\tthe\\tinputs\\tand\\tthe\\toutputs\\twill\\tfix\\nthemselves.\\nProblem\\t#3:\\tGoals\\trestrict\\tyour\\thappiness.\\nThe\\timplicit\\tassumption\\tbehind\\tany\\tgoal\\tis\\tthis:\\t“Once\\tI\\treach\\tmy\\tgoal,\\tthen\\tI’ll\\nbe\\thappy.”\\tThe\\tproblem\\twith\\ta\\tgoals-first\\tmentality\\tis\\tthat\\tyou’re\\tcontinually\\nputting\\thappiness\\toff\\tuntil\\tthe\\tnext\\tmilestone.\\tI’ve\\tslipped\\tinto\\tthis\\ttrap\\tso\\tmany\\ntimes\\tI’ve\\tlost\\tcount.\\tFor\\tyears,\\thappiness\\twas\\talways\\tsomething\\tfor\\tmy\\tfuture\\nself\\tto\\tenjoy.\\tI\\tpromised\\tmyself\\tthat\\tonce\\tI\\tgained\\ttwenty\\tpounds\\tof\\tmuscle\\tor\\nafter\\tmy\\tbusiness\\twas\\tfeatured\\tin\\tthe\\t\\nNew\\tYork\\tTimes\\n,\\tthen\\tI\\tcould\\tfinally\\trelax.\\nFurthermore,\\tgoals\\tcreate\\tan\\t“either-or”\\tconflict:\\teither\\tyou\\tachieve\\tyour\\tgoal\\nand\\tare\\tsuccessful\\tor\\tyou\\tfail\\tand\\tyou\\tare\\ta\\tdisappointment.\\tYou\\tmentally\\tbox\\nyourself\\tinto\\ta\\tnarrow\\tversion\\tof\\thappiness.\\tThis\\tis\\tmisguided.\\tIt\\tis\\tunlikely\\tthat\\nyour\\tactual\\tpath\\tthrough\\tlife\\twill\\tmatch\\tthe\\texact\\tjourney\\tyou\\thad\\tin\\tmind\\twhen\\nyou\\tset\\tout.\\tIt\\tmakes\\tno\\tsense\\tto\\trestrict\\tyour\\tsatisfaction\\tto\\tone\\tscenario\\twhen\\nthere\\tare\\tmany\\tpaths\\tto\\tsuccess.\\nA\\tsystems-first\\tmentality\\tprovides\\tthe\\tantidote.\\tWhen\\tyou\\tfall\\tin\\tlove\\twith\\tthe\\nprocess\\trather\\tthan\\tthe\\tproduct,\\tyou\\tdon’t\\thave\\tto\\twait\\tto\\tgive\\tyourself\\npermission\\tto\\tbe\\thappy.\\tYou\\tcan\\tbe\\tsatisfied\\tanytime\\tyour\\tsystem\\tis\\trunning.\\nAnd\\ta\\tsystem\\tcan\\tbe\\tsuccessful\\tin\\tmany\\tdifferent\\tforms,\\tnot\\tjust\\tthe\\tone\\tyou\\nfirst\\tenvision.\\nProblem\\t#4:\\tGoals\\tare\\tat\\todds\\twith\\tlong-term\\tprogress.\\nFinally,\\ta\\tgoal-oriented\\tmind-set\\tcan\\tcreate\\ta\\t“yo-yo”\\teffect.\\tMany\\trunners\\twork\\nhard\\tfor\\tmonths,\\tbut\\tas\\tsoon\\tas\\tthey\\tcross\\tthe\\tfinish\\tline,\\tthey\\tstop\\ttraining.\\tThe\\nrace\\tis\\tno\\tlonger\\tthere\\tto\\tmotivate\\tthem.\\tWhen\\tall\\tof\\tyour\\thard\\twork\\tis\\tfocused\\non\\ta\\tparticular\\tgoal,\\twhat\\tis\\tleft\\tto\\tpush\\tyou\\tforward\\tafter\\tyou\\tachieve\\tit?\\tThis\\tis\\nwhy\\tmany\\tpeople\\tfind\\tthemselves\\treverting\\tto\\ttheir\\told\\thabits\\tafter\\naccomplishing\\ta\\tgoal.\\nThe\\tpurpose\\tof\\tsetting\\tgoals\\tis\\tto\\twin\\tthe\\tgame.\\tThe\\tpurpose\\tof\\tbuilding\\nsystems\\tis\\tto\\tcontinue\\tplaying\\tthe\\tgame.\\tTrue\\tlong-term\\tthinking\\tis\\tgoal-less\\nthinking.\\tIt’s\\tnot\\tabout\\tany\\tsingle\\taccomplishment.\\tIt\\tis\\tabout\\tthe\\tcycle\\tof\\nendless\\trefinement\\tand\\tcontinuous\\timprovement.\\tUltimately,\\tit\\tis\\tyour\\ncommitment\\tto\\tthe\\t\\nprocess\\n\\tthat\\twill\\tdetermine\\tyour\\t\\nprogress\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 24}), Document(page_content='A\\tSYSTEM\\tOF\\tATOMIC\\tHABITS\\nIf\\tyou’re\\thaving\\ttrouble\\tchanging\\tyour\\thabits,\\tthe\\tproblem\\tisn’t\\tyou.\\tThe\\nproblem\\tis\\tyour\\tsystem.\\tBad\\thabits\\trepeat\\tthemselves\\tagain\\tand\\tagain\\tnot\\nbecause\\tyou\\tdon’t\\twant\\tto\\tchange,\\tbut\\tbecause\\tyou\\thave\\tthe\\twrong\\tsystem\\tfor\\nchange.\\nYou\\tdo\\tnot\\trise\\tto\\tthe\\tlevel\\tof\\tyour\\tgoals.\\t\\nYou\\tfall\\tto\\tthe\\tlevel\\tof\\tyour\\nsystems.\\nFocusing\\ton\\tthe\\toverall\\tsystem,\\trather\\tthan\\ta\\tsingle\\tgoal,\\tis\\tone\\tof\\tthe\\tcore\\nthemes\\tof\\tthis\\tbook.\\tIt\\tis\\talso\\tone\\tof\\tthe\\tdeeper\\tmeanings\\tbehind\\tthe\\tword\\natomic\\n.\\tBy\\tnow,\\tyou’ve\\tprobably\\trealized\\tthat\\tan\\tatomic\\thabit\\trefers\\tto\\ta\\ttiny\\nchange,\\ta\\tmarginal\\tgain,\\ta\\t1\\tpercent\\timprovement.\\tBut\\tatomic\\thabits\\tare\\tnot\\tjust\\nany\\told\\thabits,\\thowever\\tsmall.\\tThey\\tare\\tlittle\\thabits\\tthat\\tare\\tpart\\tof\\ta\\tlarger\\nsystem.\\tJust\\tas\\tatoms\\tare\\tthe\\tbuilding\\tblocks\\tof\\tmolecules,\\tatomic\\thabits\\tare\\tthe\\nbuilding\\tblocks\\tof\\tremarkable\\tresults.\\nHabits\\tare\\tlike\\tthe\\tatoms\\tof\\tour\\tlives.\\tEach\\tone\\tis\\ta\\tfundamental\\tunit\\tthat\\ncontributes\\tto\\tyour\\toverall\\timprovement.\\tAt\\tfirst,\\tthese\\ttiny\\troutines\\tseem\\ninsignificant,\\tbut\\tsoon\\tthey\\tbuild\\ton\\teach\\tother\\tand\\tfuel\\tbigger\\twins\\tthat\\nmultiply\\tto\\ta\\tdegree\\tthat\\tfar\\toutweighs\\tthe\\tcost\\tof\\ttheir\\tinitial\\tinvestment.\\tThey\\nare\\tboth\\tsmall\\tand\\tmighty.\\tThis\\tis\\tthe\\tmeaning\\tof\\tthe\\tphrase\\t\\natomic\\thabits\\n—a\\nregular\\tpractice\\tor\\troutine\\tthat\\tis\\tnot\\tonly\\tsmall\\tand\\teasy\\tto\\tdo,\\tbut\\talso\\tthe\\nsource\\tof\\tincredible\\tpower;\\ta\\tcomponent\\tof\\tthe\\tsystem\\tof\\tcompound\\tgrowth.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 25}), Document(page_content='Chapter\\tSummary\\nHabits\\tare\\tthe\\tcompound\\tinterest\\tof\\tselfimprovement.\\tGetting\\t1\\npercent\\tbetter\\tevery\\tday\\tcounts\\tfor\\ta\\tlot\\tin\\tthe\\tlong-run.\\nHabits\\tare\\ta\\tdouble-edged\\tsword.\\tThey\\tcan\\twork\\tfor\\tyou\\tor\\tagainst\\nyou,\\twhich\\tis\\twhy\\tunderstanding\\tthe\\tdetails\\tis\\tessential.\\nSmall\\tchanges\\toften\\tappear\\tto\\tmake\\tno\\tdifference\\tuntil\\tyou\\tcross\\ta\\ncritical\\tthreshold.\\tThe\\tmost\\tpowerful\\toutcomes\\tof\\tany\\tcompounding\\nprocess\\tare\\tdelayed.\\tYou\\tneed\\tto\\tbe\\tpatient.\\nAn\\tatomic\\thabit\\tis\\ta\\tlittle\\thabit\\tthat\\tis\\tpart\\tof\\ta\\tlarger\\tsystem.\\tJust\\tas\\natoms\\tare\\tthe\\tbuilding\\tblocks\\tof\\tmolecules,\\tatomic\\thabits\\tare\\tthe\\nbuilding\\tblocks\\tof\\tremarkable\\tresults.\\nIf\\tyou\\twant\\tbetter\\tresults,\\tthen\\tforget\\tabout\\tsetting\\tgoals.\\tFocus\\ton\\nyour\\tsystem\\tinstead.\\nYou\\tdo\\tnot\\trise\\tto\\tthe\\tlevel\\tof\\tyour\\tgoals.\\tYou\\tfall\\tto\\tthe\\tlevel\\tof\\tyour\\nsystems.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 26}), Document(page_content='2\\nHow\\tYour\\tHabits\\tShape\\tYour\\tIdentity\\t(and\\tVice\\nVersa)\\nW\\nHY\\tIS\\tIT\\t\\nso\\teasy\\tto\\trepeat\\tbad\\thabits\\tand\\tso\\thard\\tto\\tform\\tgood\\tones?\\tFew\\tthings\\ncan\\thave\\ta\\tmore\\tpowerful\\timpact\\ton\\tyour\\tlife\\tthan\\timproving\\tyour\\tdaily\\thabits.\\nAnd\\tyet\\tit\\tis\\tlikely\\tthat\\tthis\\ttime\\tnext\\tyear\\tyou’ll\\tbe\\tdoing\\tthe\\tsame\\tthing\\trather\\nthan\\tsomething\\tbetter.\\nIt\\toften\\tfeels\\tdifficult\\tto\\tkeep\\tgood\\thabits\\tgoing\\tfor\\tmore\\tthan\\ta\\tfew\\tdays,\\neven\\twith\\tsincere\\teffort\\tand\\tthe\\toccasional\\tburst\\tof\\tmotivation.\\tHabits\\tlike\\nexercise,\\tmeditation,\\tjournaling,\\tand\\tcooking\\tare\\treasonable\\tfor\\ta\\tday\\tor\\ttwo\\tand\\nthen\\tbecome\\ta\\thassle.\\nHowever,\\tonce\\tyour\\thabits\\tare\\testablished,\\tthey\\tseem\\tto\\tstick\\taround\\tforever\\n—especially\\tthe\\tunwanted\\tones.\\tDespite\\tour\\tbest\\tintentions,\\tunhealthy\\thabits\\nlike\\teating\\tjunk\\tfood,\\twatching\\ttoo\\tmuch\\ttelevision,\\tprocrastinating,\\tand\\nsmoking\\tcan\\tfeel\\timpossible\\tto\\tbreak.\\nChanging\\tour\\thabits\\tis\\tchallenging\\tfor\\ttwo\\treasons:\\t(1)\\twe\\ttry\\tto\\tchange\\tthe\\nwrong\\tthing\\tand\\t(2)\\twe\\ttry\\tto\\tchange\\tour\\thabits\\tin\\tthe\\twrong\\tway.\\tIn\\tthis\\nchapter,\\tI’ll\\taddress\\tthe\\tfirst\\tpoint.\\tIn\\tthe\\tchapters\\tthat\\tfollow,\\tI’ll\\tanswer\\tthe\\nsecond.\\nOur\\tfirst\\tmistake\\tis\\tthat\\twe\\ttry\\tto\\tchange\\tthe\\twrong\\tthing.\\tTo\\t\\nunderstand\\twhat\\nI\\tmean,\\tconsider\\tthat\\tthere\\tare\\tthree\\tlevels\\tat\\twhich\\tchange\\tcan\\toccur.\\t\\nYou\\tcan\\nimagine\\tthem\\tlike\\tthe\\tlayers\\tof\\tan\\tonion.\\nTHREE\\tLAYERS\\tOF\\tBEHAVIOR\\tCHANGE', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 27}), Document(page_content='FIGURE\\t3:\\tThere\\tare\\tthree\\tlayers\\tof\\tbehavior\\tchange:\\ta\\tchange\\tin\\tyour\\toutcomes,\\ta\\tchange\\tin\\tyour\\tprocesses,\\tor\\ta\\tchange\\tin\\tyour\\tidentity.\\nThe\\tfirst\\tlayer\\tis\\tchanging\\tyour\\toutcomes.\\n\\tThis\\tlevel\\tis\\tconcerned\\twith\\nchanging\\tyour\\tresults:\\tlosing\\tweight,\\tpublishing\\ta\\tbook,\\twinning\\ta\\nchampionship.\\tMost\\tof\\tthe\\tgoals\\tyou\\tset\\tare\\tassociated\\twith\\tthis\\tlevel\\tof\\tchange.\\nThe\\tsecond\\tlayer\\tis\\tchanging\\tyour\\tprocess.\\n\\tThis\\tlevel\\tis\\tconcerned\\twith\\nchanging\\tyour\\thabits\\tand\\tsystems:\\timplementing\\ta\\tnew\\troutine\\tat\\tthe\\tgym,\\ndecluttering\\tyour\\tdesk\\tfor\\tbetter\\tworkflow,\\tdeveloping\\ta\\tmeditation\\tpractice.\\nMost\\tof\\tthe\\thabits\\tyou\\tbuild\\tare\\tassociated\\twith\\tthis\\tlevel.\\nThe\\tthird\\tand\\tdeepest\\tlayer\\tis\\tchanging\\tyour\\tidentity.\\n\\tThis\\tlevel\\tis\\nconcerned\\twith\\tchanging\\tyour\\tbeliefs:\\tyour\\tworldview,\\tyour\\tself-image,\\tyour\\njudgments\\tabout\\tyourself\\tand\\tothers.\\tMost\\tof\\tthe\\tbeliefs,\\tassumptions,\\tand\\nbiases\\tyou\\thold\\tare\\tassociated\\twith\\tthis\\tlevel.\\nOutcomes\\tare\\tabout\\twhat\\tyou\\tget.\\tProcesses\\tare\\tabout\\twhat\\tyou\\tdo.\\t\\nIdentity\\tis\\nabout\\twhat\\tyou\\tbelieve.\\tWhen\\tit\\tcomes\\tto\\tbuilding\\thabits\\tthat\\tlast—when\\tit\\ncomes\\tto\\tbuilding\\ta\\tsystem\\tof\\t1\\tpercent\\timprovements—the\\tproblem\\tis\\tnot\\tthat\\none\\tlevel\\tis\\t“better”\\tor\\t“worse”\\tthan\\tanother.\\tAll\\tlevels\\tof\\tchange\\tare\\tuseful\\tin\\ntheir\\town\\tway.\\tThe\\tproblem\\tis\\tthe\\t\\ndirection\\n\\tof\\tchange.\\nMany\\tpeople\\tbegin\\tthe\\tprocess\\tof\\tchanging\\ttheir\\thabits\\tby\\tfocusing\\ton\\t\\nwhat\\nthey\\twant\\tto\\tachieve.\\tThis\\tleads\\tus\\tto\\toutcome-based\\thabits.\\tThe\\talternative\\tis\\tto\\nbuild\\tidentity-based\\thabits.\\tWith\\tthis\\tapproach,\\twe\\tstart\\tby\\tfocusing\\ton\\t\\nwho\\n\\twe\\nwish\\tto\\tbecome.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 28}), Document(page_content='OUTCOME-BASED\\tHABITS\\nIDENTITY-BASED\\tHABITS', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 29}), Document(page_content='FIGURE\\t4:\\tWith\\toutcome-based\\thabits,\\tthe\\tfocus\\tis\\ton\\twhat\\tyou\\twant\\tto\\tachieve.\\tWith\\tidentity-based\\thabits,\\tthe\\tfocus\\tis\\ton\\twho\\tyou\\twish\\tto\\tbecome.\\nImagine\\ttwo\\tpeople\\tresisting\\ta\\tcigarette.\\tWhen\\toffered\\ta\\tsmoke,\\tthe\\tfirst\\nperson\\tsays,\\t“No\\tthanks.\\tI’m\\ttrying\\tto\\tquit.”\\tIt\\tsounds\\tlike\\ta\\treasonable\\nresponse,\\tbut\\tthis\\tperson\\tstill\\tbelieves\\tthey\\tare\\ta\\tsmoker\\twho\\tis\\ttrying\\tto\\tbe\\nsomething\\telse.\\tThey\\tare\\thoping\\ttheir\\tbehavior\\twill\\tchange\\twhile\\tcarrying\\naround\\tthe\\tsame\\tbeliefs.\\nThe\\tsecond\\tperson\\tdeclines\\tby\\tsaying,\\t“No\\tthanks.\\tI’m\\tnot\\ta\\tsmoker.”\\tIt’s\\ta\\nsmall\\tdifference,\\tbut\\tthis\\tstatement\\tsignals\\ta\\tshift\\tin\\tidentity.\\tSmoking\\twas\\tpart\\nof\\ttheir\\tformer\\tlife,\\tnot\\ttheir\\tcurrent\\tone.\\tThey\\tno\\tlonger\\tidentify\\tas\\tsomeone\\nwho\\tsmokes.\\nMost\\tpeople\\tdon’t\\teven\\tconsider\\tidentity\\tchange\\twhen\\tthey\\tset\\tout\\tto\\nimprove.\\tThey\\tjust\\tthink,\\t“I\\twant\\tto\\tbe\\tskinny\\t(outcome)\\tand\\tif\\tI\\tstick\\tto\\tthis\\ndiet,\\tthen\\tI’ll\\tbe\\tskinny\\t(process).”\\tThey\\tset\\tgoals\\tand\\tdetermine\\tthe\\tactions\\tthey', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 30}), Document(page_content='should\\ttake\\tto\\tachieve\\tthose\\tgoals\\twithout\\tconsidering\\tthe\\tbeliefs\\tthat\\tdrive\\ttheir\\nactions.\\tThey\\tnever\\tshift\\tthe\\tway\\tthey\\tlook\\tat\\tthemselves,\\tand\\tthey\\tdon’t\\trealize\\nthat\\ttheir\\told\\tidentity\\tcan\\tsabotage\\ttheir\\tnew\\tplans\\tfor\\tchange.\\nBehind\\tevery\\tsystem\\tof\\tactions\\tare\\ta\\tsystem\\tof\\tbeliefs.\\tThe\\tsystem\\tof\\ta\\ndemocracy\\tis\\tfounded\\ton\\tbeliefs\\tlike\\tfreedom,\\tmajority\\trule,\\tand\\tsocial\\tequality.\\nThe\\tsystem\\tof\\ta\\tdictatorship\\thas\\ta\\tvery\\tdifferent\\tset\\tof\\tbeliefs\\tlike\\tabsolute\\nauthority\\tand\\tstrict\\tobedience.\\tYou\\tcan\\timagine\\tmany\\tways\\tto\\ttry\\tto\\tget\\tmore\\npeople\\tto\\tvote\\tin\\ta\\tdemocracy,\\tbut\\tsuch\\tbehavior\\tchange\\twould\\tnever\\tget\\toff\\tthe\\nground\\tin\\ta\\tdictatorship.\\tThat’s\\tnot\\tthe\\tidentity\\tof\\tthe\\tsystem.\\tVoting\\tis\\ta\\nbehavior\\tthat\\tis\\timpossible\\tunder\\ta\\tcertain\\tset\\tof\\tbeliefs.\\nA\\tsimilar\\tpattern\\texists\\twhether\\twe\\tare\\tdiscussing\\tindividuals,\\torganizations,\\nor\\tsocieties.\\tThere\\tare\\ta\\tset\\tof\\tbeliefs\\tand\\tassumptions\\tthat\\tshape\\tthe\\tsystem,\\tan\\nidentity\\tbehind\\tthe\\thabits.\\nBehavior\\tthat\\tis\\tincongruent\\twith\\tthe\\tself\\twill\\tnot\\tlast.\\tYou\\tmay\\twant\\tmore\\nmoney,\\tbut\\tif\\tyour\\tidentity\\tis\\tsomeone\\twho\\tconsumes\\trather\\tthan\\tcreates,\\tthen\\nyou’ll\\tcontinue\\tto\\tbe\\tpulled\\ttoward\\tspending\\trather\\tthan\\tearning.\\tYou\\tmay\\twant\\nbetter\\thealth,\\tbut\\tif\\tyou\\tcontinue\\tto\\t\\nprioritize\\tcomfort\\tover\\taccomplishment,\\nyou’ll\\tbe\\tdrawn\\tto\\trelaxing\\trather\\tthan\\ttraining.\\tIt’s\\thard\\tto\\tchange\\tyour\\thabits\\tif\\nyou\\tnever\\tchange\\tthe\\tunderlying\\tbeliefs\\tthat\\tled\\tto\\tyour\\tpast\\tbehavior.\\tYou\\thave\\na\\tnew\\tgoal\\tand\\ta\\tnew\\tplan,\\tbut\\tyou\\thaven’t\\tchanged\\t\\nwho\\n\\tyou\\tare.\\nThe\\tstory\\tof\\tBrian\\tClark,\\tan\\tentrepreneur\\tfrom\\tBoulder,\\tColorado,\\tprovides\\ta\\ngood\\texample.\\t“For\\tas\\tlong\\tas\\tI\\tcan\\tremember,\\tI’ve\\tchewed\\tmy\\tfingernails,”\\nClark\\ttold\\tme.\\t“It\\tstarted\\tas\\ta\\tnervous\\thabit\\twhen\\tI\\twas\\tyoung,\\tand\\tthen\\nmorphed\\tinto\\tan\\tundesirable\\tgrooming\\tritual.\\tOne\\tday,\\t\\nI\\tresolved\\tto\\tstop\\nchewing\\tmy\\tnails\\tuntil\\tthey\\tgrew\\tout\\ta\\tbit.\\tThrough\\tmindful\\twillpower\\talone,\\tI\\nmanaged\\tto\\tdo\\tit.”\\nThen,\\tClark\\tdid\\tsomething\\tsurprising.\\n“I\\tasked\\tmy\\twife\\tto\\tschedule\\tmy\\tfirst-ever\\tmanicure,”\\the\\tsaid.\\t“My\\tthought\\nwas\\tthat\\tif\\tI\\tstarted\\tpaying\\tto\\tmaintain\\tmy\\tnails,\\tI\\twouldn’t\\tchew\\tthem.\\tAnd\\tit\\nworked,\\tbut\\tnot\\tfor\\tthe\\tmonetary\\treason.\\tWhat\\thappened\\twas\\tthe\\tmanicure\\tmade\\nmy\\tfingers\\tlook\\treally\\tnice\\tfor\\tthe\\tfirst\\ttime.\\tThe\\tmanicurist\\teven\\tsaid\\tthat—\\nother\\tthan\\tthe\\tchewing—I\\thad\\treally\\thealthy,\\tattractive\\tnails.\\tSuddenly,\\tI\\twas\\nproud\\tof\\tmy\\tfingernails.\\tAnd\\teven\\tthough\\tthat’s\\tsomething\\tI\\thad\\tnever\\taspired\\nto,\\tit\\tmade\\tall\\tthe\\tdifference.\\tI’ve\\tnever\\tchewed\\tmy\\tnails\\tsince;\\tnot\\teven\\ta\\tsingle\\nclose\\tcall.\\tAnd\\tit’s\\tbecause\\tI\\tnow\\ttake\\tpride\\tin\\tproperly\\tcaring\\tfor\\tthem.”\\nThe\\tultimate\\tform\\tof\\tintrinsic\\tmotivation\\tis\\twhen\\ta\\thabit\\tbecomes\\tpart\\tof\\tyour\\nidentity.\\tIt’s\\tone\\tthing\\tto\\tsay\\tI’m\\tthe\\ttype\\tof\\tperson\\twho\\t\\nwants\\n\\tthis.\\tIt’s\\nsomething\\tvery\\tdifferent\\tto\\tsay\\tI’m\\tthe\\ttype\\tof\\tperson\\twho\\t\\nis\\n\\tthis.\\nThe\\tmore\\tpride\\tyou\\thave\\tin\\ta\\tparticular\\taspect\\tof\\tyour\\tidentity,\\tthe\\tmore', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 31}), Document(page_content='motivated\\tyou\\twill\\tbe\\tto\\tmaintain\\tthe\\thabits\\tassociated\\twith\\tit.\\tIf\\tyou’re\\tproud\\nof\\thow\\tyour\\thair\\tlooks,\\tyou’ll\\tdevelop\\tall\\tsorts\\tof\\thabits\\tto\\tcare\\tfor\\tand\\tmaintain\\nit.\\tIf\\tyou’re\\tproud\\tof\\tthe\\tsize\\tof\\tyour\\tbiceps,\\tyou’ll\\tmake\\tsure\\tyou\\tnever\\tskip\\tan\\nupper-body\\tworkout.\\tIf\\tyou’re\\tproud\\tof\\tthe\\tscarves\\tyou\\tknit,\\tyou’ll\\tbe\\tmore\\nlikely\\tto\\tspend\\thours\\t\\nknitting\\teach\\tweek.\\tOnce\\tyour\\tpride\\tgets\\tinvolved,\\tyou’ll\\nfight\\ttooth\\tand\\tnail\\tto\\tmaintain\\tyour\\thabits.\\nTrue\\tbehavior\\tchange\\tis\\tidentity\\tchange.\\tYou\\tmight\\tstart\\ta\\thabit\\tbecause\\tof\\nmotivation,\\tbut\\tthe\\tonly\\treason\\tyou’ll\\tstick\\twith\\tone\\tis\\tthat\\tit\\tbecomes\\tpart\\tof\\nyour\\tidentity.\\tAnyone\\tcan\\tconvince\\tthemselves\\tto\\tvisit\\tthe\\tgym\\tor\\teat\\thealthy\\nonce\\tor\\ttwice,\\tbut\\tif\\tyou\\tdon’t\\tshift\\tthe\\tbelief\\tbehind\\tthe\\tbehavior,\\tthen\\tit\\tis\\thard\\nto\\tstick\\twith\\tlong-term\\tchanges.\\tImprovements\\tare\\tonly\\ttemporary\\tuntil\\tthey\\nbecome\\tpart\\tof\\twho\\tyou\\tare.\\nThe\\tgoal\\tis\\tnot\\tto\\tread\\ta\\tbook,\\tthe\\tgoal\\tis\\tto\\t\\nbecome\\n\\ta\\treader.\\nThe\\tgoal\\tis\\tnot\\tto\\trun\\ta\\tmarathon,\\tthe\\tgoal\\tis\\tto\\t\\nbecome\\n\\ta\\trunner.\\nThe\\tgoal\\tis\\tnot\\tto\\tlearn\\tan\\tinstrument,\\tthe\\tgoal\\tis\\tto\\t\\nbecome\\n\\ta\\nmusician.\\nYour\\tbehaviors\\tare\\tusually\\ta\\treflection\\tof\\tyour\\tidentity.\\tWhat\\tyou\\tdo\\tis\\tan\\nindication\\tof\\tthe\\ttype\\tof\\tperson\\tyou\\tbelieve\\tthat\\tyou\\tare—either\\tconsciously\\tor\\nnonconsciously.\\n*\\n\\t\\nResearch\\thas\\tshown\\tthat\\tonce\\ta\\tperson\\tbelieves\\tin\\ta\\tparticular\\naspect\\tof\\ttheir\\tidentity,\\tthey\\tare\\tmore\\tlikely\\tto\\tact\\tin\\talignment\\twith\\tthat\\tbelief.\\nFor\\texample,\\tpeople\\twho\\tidentified\\tas\\t“being\\ta\\tvoter”\\twere\\tmore\\tlikely\\tto\\tvote\\nthan\\tthose\\twho\\tsimply\\tclaimed\\t“voting”\\twas\\tan\\taction\\tthey\\twanted\\tto\\tperform.\\nSimilarly,\\tthe\\tperson\\twho\\tincorporates\\texercise\\tinto\\ttheir\\tidentity\\tdoesn’t\\thave\\nto\\tconvince\\tthemselves\\tto\\ttrain.\\tDoing\\tthe\\tright\\tthing\\tis\\teasy.\\tAfter\\tall,\\twhen\\nyour\\tbehavior\\tand\\tyour\\tidentity\\tare\\tfully\\taligned,\\tyou\\t\\nare\\tno\\tlonger\\tpursuing\\nbehavior\\tchange.\\tYou\\tare\\tsimply\\tacting\\tlike\\tthe\\ttype\\tof\\tperson\\tyou\\talready\\nbelieve\\tyourself\\tto\\tbe.\\nLike\\tall\\taspects\\tof\\thabit\\tformation,\\tthis,\\ttoo,\\tis\\ta\\tdouble-edged\\tsword.\\tWhen\\nworking\\tfor\\tyou,\\tidentity\\tchange\\tcan\\tbe\\ta\\tpowerful\\tforce\\tfor\\tselfimprovement.\\nWhen\\tworking\\tagainst\\tyou,\\tthough,\\tidentity\\tchange\\tcan\\tbe\\ta\\tcurse.\\tOnce\\tyou\\nhave\\tadopted\\tan\\tidentity,\\tit\\tcan\\tbe\\teasy\\tto\\tlet\\tyour\\tallegiance\\tto\\tit\\timpact\\tyour\\nability\\tto\\tchange.\\tMany\\tpeople\\twalk\\tthrough\\tlife\\tin\\ta\\tcognitive\\tslumber,\\tblindly\\nfollowing\\tthe\\tnorms\\tattached\\tto\\ttheir\\tidentity.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 32}), Document(page_content='“I’m\\tterrible\\twith\\tdirections.”\\n“I’m\\tnot\\ta\\tmorning\\tperson.”\\n“I’m\\tbad\\tat\\tremembering\\tpeople’s\\tnames.”\\n“I’m\\talways\\tlate.”\\n“I’m\\tnot\\tgood\\twith\\ttechnology.”\\n“I’m\\thorrible\\tat\\tmath.”\\n.\\t.\\t.\\tand\\ta\\tthousand\\tother\\tvariations.\\nWhen\\tyou\\thave\\trepeated\\ta\\tstory\\tto\\tyourself\\tfor\\tyears,\\tit\\tis\\teasy\\tto\\tslide\\tinto\\nthese\\tmental\\tgrooves\\tand\\taccept\\tthem\\tas\\ta\\tfact.\\tIn\\ttime,\\tyou\\tbegin\\tto\\tresist\\ncertain\\tactions\\tbecause\\t“that’s\\tnot\\twho\\tI\\tam.”\\t\\nThere\\tis\\tinternal\\tpressure\\tto\\nmaintain\\tyour\\tself-image\\tand\\tbehave\\tin\\ta\\tway\\tthat\\tis\\tconsistent\\twith\\tyour\\nbeliefs.\\tYou\\tfind\\twhatever\\tway\\tyou\\tcan\\tto\\tavoid\\tcontradicting\\tyourself.\\nThe\\tmore\\tdeeply\\ta\\tthought\\tor\\taction\\tis\\ttied\\tto\\tyour\\tidentity,\\tthe\\tmore\\tdifficult\\nit\\tis\\tto\\tchange\\tit.\\tIt\\tcan\\tfeel\\tcomfortable\\tto\\tbelieve\\twhat\\tyour\\tculture\\tbelieves\\n(group\\tidentity)\\tor\\tto\\tdo\\twhat\\tupholds\\tyour\\tself-image\\t(personal\\tidentity),\\teven\\nif\\tit’s\\twrong.\\tThe\\tbiggest\\tbarrier\\tto\\tpositive\\tchange\\tat\\tany\\tlevel—individual,\\nteam,\\tsociety—is\\tidentity\\tconflict.\\tGood\\thabits\\tcan\\tmake\\trational\\tsense,\\tbut\\tif\\nthey\\tconflict\\twith\\tyour\\tidentity,\\tyou\\twill\\tfail\\tto\\tput\\tthem\\tinto\\taction.\\nOn\\tany\\tgiven\\tday,\\tyou\\tmay\\tstruggle\\twith\\tyour\\thabits\\tbecause\\tyou’re\\ttoo\\tbusy\\nor\\ttoo\\ttired\\tor\\ttoo\\toverwhelmed\\tor\\thundreds\\tof\\tother\\treasons.\\tOver\\tthe\\tlong\\trun,\\nhowever,\\tthe\\treal\\treason\\tyou\\tfail\\tto\\tstick\\twith\\thabits\\tis\\tthat\\tyour\\tself-image\\tgets\\nin\\tthe\\tway.\\tThis\\tis\\twhy\\tyou\\tcan’t\\tget\\ttoo\\tattached\\tto\\tone\\tversion\\tof\\tyour\\nidentity.\\tProgress\\trequires\\tunlearning.\\tBecoming\\tthe\\tbest\\tversion\\tof\\tyourself\\nrequires\\tyou\\tto\\tcontinuously\\tedit\\tyour\\tbeliefs,\\tand\\tto\\tupgrade\\tand\\texpand\\tyour\\nidentity.\\nThis\\tbrings\\tus\\tto\\tan\\timportant\\tquestion:\\tIf\\tyour\\tbeliefs\\tand\\tworldview\\tplay\\nsuch\\tan\\timportant\\trole\\tin\\tyour\\tbehavior,\\twhere\\tdo\\tthey\\tcome\\tfrom\\tin\\tthe\\tfirst\\nplace?\\tHow,\\texactly,\\tis\\tyour\\tidentity\\tformed?\\tAnd\\thow\\tcan\\tyou\\temphasize\\tnew\\naspects\\tof\\tyour\\tidentity\\tthat\\tserve\\tyou\\tand\\tgradually\\terase\\tthe\\tpieces\\tthat\\thinder\\nyou?\\nTHE\\tTWO-STEP\\tPROCESS\\tTO\\tCHANGING\\tYOUR\\tIDENTITY\\nYour\\tidentity\\temerges\\tout\\tof\\tyour\\thabits.\\tYou\\tare\\tnot\\tborn\\twith\\tpreset\\tbeliefs.\\nEvery\\tbelief,\\tincluding\\tthose\\tabout\\tyourself,\\tis\\tlearned\\tand\\tconditioned\\tthrough\\nexperience.\\n*', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 33}), Document(page_content='More\\tprecisely,\\tyour\\thabits\\tare\\thow\\tyou\\t\\nembody\\n\\tyour\\tidentity.\\tWhen\\tyou\\nmake\\tyour\\tbed\\teach\\tday,\\tyou\\tembody\\tthe\\tidentity\\tof\\tan\\torganized\\tperson.\\tWhen\\nyou\\twrite\\teach\\tday,\\tyou\\tembody\\tthe\\tidentity\\tof\\ta\\tcreative\\tperson.\\tWhen\\tyou\\ntrain\\teach\\tday,\\tyou\\tembody\\tthe\\tidentity\\tof\\tan\\tathletic\\tperson.\\nThe\\tmore\\tyou\\trepeat\\ta\\tbehavior,\\tthe\\tmore\\tyou\\treinforce\\tthe\\tidentity\\nassociated\\twith\\tthat\\tbehavior.\\tIn\\tfact,\\tthe\\tword\\t\\nidentity\\n\\twas\\toriginally\\tderived\\nfrom\\tthe\\tLatin\\twords\\t\\nessentitas\\n,\\twhich\\tmeans\\t\\nbeing,\\n\\tand\\t\\nidentidem\\n,\\twhich\\nmeans\\t\\nrepeatedly\\n.\\t\\nYour\\tidentity\\tis\\tliterally\\tyour\\t“repeated\\tbeingness.”\\nWhatever\\tyour\\tidentity\\tis\\tright\\tnow,\\tyou\\tonly\\tbelieve\\tit\\tbecause\\tyou\\thave\\nproof\\tof\\tit.\\tIf\\tyou\\tgo\\tto\\tchurch\\tevery\\tSunday\\tfor\\ttwenty\\tyears,\\tyou\\thave\\nevidence\\tthat\\tyou\\tare\\treligious.\\tIf\\tyou\\tstudy\\tbiology\\tfor\\tone\\thour\\tevery\\tnight,\\nyou\\thave\\tevidence\\tthat\\tyou\\tare\\tstudious.\\tIf\\tyou\\tgo\\tto\\tthe\\tgym\\teven\\twhen\\tit’s\\nsnowing,\\tyou\\thave\\tevidence\\tthat\\tyou\\tare\\tcommitted\\tto\\tfitness.\\tThe\\tmore\\nevidence\\tyou\\thave\\tfor\\ta\\tbelief,\\tthe\\tmore\\tstrongly\\tyou\\twill\\tbelieve\\tit.\\nFor\\tmost\\tof\\tmy\\tearly\\tlife,\\tI\\tdidn’t\\tconsider\\tmyself\\ta\\twriter.\\tIf\\tyou\\twere\\tto\\task\\nany\\tof\\tmy\\thigh\\tschool\\tteachers\\tor\\tcollege\\tprofessors,\\tthey\\twould\\ttell\\tyou\\tI\\twas\\nan\\taverage\\twriter\\tat\\tbest:\\tcertainly\\tnot\\ta\\tstandout.\\tWhen\\tI\\tbegan\\tmy\\twriting\\ncareer,\\tI\\tpublished\\ta\\tnew\\tarticle\\tevery\\tMonday\\tand\\tThursday\\tfor\\tthe\\tfirst\\tfew\\nyears.\\tAs\\tthe\\tevidence\\tgrew,\\tso\\tdid\\tmy\\tidentity\\tas\\ta\\twriter.\\tI\\tdidn’t\\tstart\\tout\\tas\\ta\\nwriter.\\tI\\t\\nbecame\\n\\tone\\tthrough\\tmy\\thabits.\\nOf\\tcourse,\\tyour\\thabits\\tare\\tnot\\tthe\\t\\nonly\\n\\tactions\\tthat\\tinfluence\\tyour\\tidentity,\\tbut\\nby\\tvirtue\\tof\\ttheir\\tfrequency\\tthey\\tare\\tusually\\tthe\\tmost\\timportant\\tones.\\tEach\\nexperience\\tin\\tlife\\tmodifies\\tyour\\tself-image,\\tbut\\tit’s\\tunlikely\\tyou\\twould\\tconsider\\nyourself\\ta\\tsoccer\\tplayer\\tbecause\\tyou\\tkicked\\ta\\tball\\tonce\\tor\\tan\\tartist\\tbecause\\tyou\\nscribbled\\ta\\tpicture.\\tAs\\tyou\\trepeat\\tthese\\tactions,\\thowever,\\tthe\\tevidence\\naccumulates\\tand\\tyour\\tself-image\\tbegins\\tto\\tchange.\\tThe\\teffect\\tof\\tone-off\\nexperiences\\ttends\\tto\\tfade\\taway\\twhile\\tthe\\teffect\\tof\\thabits\\tgets\\treinforced\\twith\\ntime,\\twhich\\tmeans\\tyour\\thabits\\tcontribute\\tmost\\tof\\tthe\\tevidence\\tthat\\tshapes\\tyour\\nidentity.\\tIn\\tthis\\tway,\\tthe\\tprocess\\tof\\tbuilding\\thabits\\tis\\tactually\\tthe\\tprocess\\tof\\nbecoming\\tyourself.\\nThis\\tis\\ta\\tgradual\\tevolution.\\tWe\\tdo\\tnot\\tchange\\tby\\tsnapping\\tour\\t\\nfingers\\tand\\ndeciding\\tto\\tbe\\tsomeone\\tentirely\\tnew.\\t\\nWe\\tchange\\tbit\\tby\\tbit,\\tday\\tby\\tday,\\thabit\\tby\\nhabit.\\tWe\\tare\\tcontinually\\tundergoing\\tmicroevolutions\\tof\\tthe\\tself.\\nEach\\thabit\\tis\\tlike\\ta\\tsuggestion:\\t“Hey,\\tmaybe\\t\\nthis\\n\\tis\\twho\\tI\\tam.”\\tIf\\tyou\\tfinish\\ta\\nbook,\\tthen\\tperhaps\\tyou\\tare\\tthe\\ttype\\tof\\tperson\\twho\\tlikes\\treading.\\tIf\\tyou\\tgo\\tto\\tthe\\ngym,\\tthen\\tperhaps\\tyou\\tare\\tthe\\ttype\\tof\\tperson\\twho\\tlikes\\texercise.\\tIf\\tyou\\tpractice\\nplaying\\tthe\\tguitar,\\tperhaps\\tyou\\tare\\tthe\\ttype\\tof\\tperson\\twho\\tlikes\\tmusic.\\nEvery\\taction\\tyou\\ttake\\tis\\ta\\tvote\\tfor\\tthe\\ttype\\tof\\tperson\\tyou\\twish\\tto\\tbecome.\\tNo\\nsingle\\tinstance\\twill\\ttransform\\tyour\\tbeliefs,\\tbut\\tas\\tthe\\tvotes\\tbuild\\tup,\\tso\\tdoes\\tthe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 34}), Document(page_content='evidence\\tof\\tyour\\tnew\\tidentity.\\tThis\\tis\\tone\\treason\\twhy\\tmeaningful\\tchange\\tdoes\\nnot\\trequire\\tradical\\tchange.\\tSmall\\thabits\\tcan\\tmake\\ta\\tmeaningful\\tdifference\\tby\\nproviding\\tevidence\\tof\\ta\\tnew\\tidentity.\\tAnd\\tif\\ta\\tchange\\tis\\tmeaningful,\\tit\\tactually\\nis\\tbig.\\tThat’s\\tthe\\tparadox\\tof\\tmaking\\tsmall\\timprovements.\\nPutting\\tthis\\tall\\ttogether,\\tyou\\tcan\\tsee\\tthat\\thabits\\tare\\tthe\\tpath\\tto\\tchanging\\tyour\\nidentity.\\tThe\\tmost\\tpractical\\tway\\tto\\tchange\\t\\nwho\\n\\tyou\\tare\\tis\\tto\\tchange\\t\\nwhat\\n\\tyou\\ndo.\\nEach\\ttime\\tyou\\twrite\\ta\\tpage,\\tyou\\tare\\ta\\twriter.\\nEach\\ttime\\tyou\\tpractice\\tthe\\tviolin,\\tyou\\tare\\ta\\tmusician.\\nEach\\ttime\\tyou\\tstart\\ta\\tworkout,\\tyou\\tare\\tan\\tathlete.\\nEach\\ttime\\tyou\\tencourage\\tyour\\temployees,\\tyou\\tare\\ta\\tleader.\\nEach\\thabit\\tnot\\tonly\\tgets\\tresults\\tbut\\talso\\tteaches\\tyou\\tsomething\\tfar\\tmore\\nimportant:\\tto\\ttrust\\tyourself.\\tYou\\tstart\\tto\\tbelieve\\tyou\\tcan\\tactually\\taccomplish\\nthese\\tthings.\\tWhen\\tthe\\tvotes\\tmount\\tup\\tand\\tthe\\tevidence\\tbegins\\tto\\tchange,\\tthe\\nstory\\tyou\\ttell\\tyourself\\tbegins\\tto\\tchange\\tas\\twell.\\nOf\\tcourse,\\tit\\tworks\\tthe\\topposite\\tway,\\ttoo.\\tEvery\\ttime\\tyou\\tchoose\\tto\\tperform\\ta\\nbad\\thabit,\\tit’s\\ta\\tvote\\tfor\\tthat\\tidentity.\\tThe\\tgood\\tnews\\tis\\tthat\\t\\nyou\\tdon’t\\tneed\\tto\\tbe\\nperfect.\\tIn\\tany\\telection,\\tthere\\tare\\tgoing\\tto\\tbe\\tvotes\\tfor\\tboth\\tsides.\\tYou\\tdon’t\\nneed\\ta\\tunanimous\\tvote\\tto\\twin\\tan\\telection;\\tyou\\tjust\\tneed\\ta\\tmajority.\\tIt\\tdoesn’t\\nmatter\\tif\\tyou\\tcast\\ta\\tfew\\tvotes\\tfor\\ta\\tbad\\tbehavior\\tor\\tan\\tunproductive\\thabit.\\tYour\\ngoal\\tis\\tsimply\\tto\\twin\\tthe\\tmajority\\tof\\tthe\\ttime.\\nNew\\tidentities\\trequire\\tnew\\tevidence.\\tIf\\tyou\\tkeep\\tcasting\\tthe\\tsame\\tvotes\\nyou’ve\\talways\\tcast,\\tyou’re\\tgoing\\tto\\tget\\tthe\\tsame\\tresults\\tyou’ve\\talways\\thad.\\tIf\\nnothing\\tchanges,\\tnothing\\tis\\tgoing\\tto\\tchange.\\nIt\\tis\\ta\\tsimple\\ttwo-step\\tprocess:\\n1.\\t\\nDecide\\tthe\\ttype\\tof\\tperson\\tyou\\twant\\tto\\tbe.\\n2.\\t\\nProve\\tit\\tto\\tyourself\\twith\\tsmall\\twins.\\nFirst,\\tdecide\\twho\\tyou\\twant\\tto\\tbe.\\tThis\\tholds\\tat\\tany\\tlevel—as\\tan\\tindividual,\\tas\\na\\tteam,\\tas\\ta\\tcommunity,\\tas\\ta\\tnation.\\tWhat\\tdo\\tyou\\twant\\tto\\tstand\\tfor?\\tWhat\\tare\\nyour\\tprinciples\\tand\\tvalues?\\tWho\\tdo\\tyou\\twish\\tto\\tbecome?\\nThese\\tare\\tbig\\tquestions,\\tand\\tmany\\tpeople\\taren’t\\tsure\\twhere\\tto\\tbegin—but\\nthey\\tdo\\tknow\\twhat\\tkind\\tof\\tresults\\tthey\\twant:\\tto\\tget\\tsix-pack\\tabs\\tor\\tto\\tfeel\\tless', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 35}), Document(page_content='anxious\\tor\\tto\\tdouble\\ttheir\\tsalary.\\tThat’s\\tfine.\\tStart\\tthere\\tand\\twork\\tbackward\\nfrom\\tthe\\tresults\\tyou\\twant\\tto\\tthe\\ttype\\tof\\tperson\\twho\\tcould\\tget\\tthose\\tresults.\\tAsk\\nyourself,\\t“Who\\tis\\tthe\\ttype\\tof\\tperson\\tthat\\tcould\\tget\\tthe\\toutcome\\tI\\twant?”\\tWho\\tis\\nthe\\ttype\\tof\\tperson\\tthat\\tcould\\tlose\\tforty\\tpounds?\\tWho\\tis\\tthe\\ttype\\tof\\tperson\\tthat\\ncould\\tlearn\\ta\\tnew\\tlanguage?\\tWho\\tis\\tthe\\ttype\\tof\\tperson\\tthat\\tcould\\trun\\ta\\nsuccessful\\tstart-up?\\nFor\\texample,\\t“Who\\tis\\tthe\\ttype\\tof\\tperson\\twho\\tcould\\twrite\\ta\\tbook?”\\tIt’s\\nprobably\\tsomeone\\twho\\tis\\tconsistent\\tand\\treliable.\\tNow\\tyour\\tfocus\\tshifts\\tfrom\\nwriting\\ta\\tbook\\t(outcome-based)\\tto\\tbeing\\tthe\\ttype\\tof\\tperson\\twho\\tis\\tconsistent\\nand\\treliable\\t(identity-based).\\nThis\\tprocess\\tcan\\tlead\\tto\\tbeliefs\\tlike:\\n“I’m\\tthe\\tkind\\tof\\tteacher\\twho\\tstands\\tup\\tfor\\ther\\tstudents.”\\n“I’m\\tthe\\tkind\\tof\\tdoctor\\twho\\tgives\\teach\\tpatient\\tthe\\ttime\\tand\\tempathy\\nthey\\tneed.”\\n“I’m\\tthe\\tkind\\tof\\tmanager\\twho\\tadvocates\\tfor\\ther\\temployees.”\\nOnce\\tyou\\thave\\ta\\thandle\\ton\\tthe\\ttype\\tof\\tperson\\tyou\\twant\\tto\\tbe,\\tyou\\tcan\\tbegin\\ntaking\\tsmall\\tsteps\\tto\\treinforce\\tyour\\tdesired\\tidentity.\\tI\\thave\\ta\\tfriend\\twho\\tlost\\nover\\t100\\tpounds\\tby\\tasking\\therself,\\t“What\\twould\\ta\\thealthy\\tperson\\tdo?”\\tAll\\tday\\nlong,\\tshe\\twould\\tuse\\tthis\\tquestion\\tas\\ta\\tguide.\\tWould\\ta\\thealthy\\tperson\\twalk\\tor\\ntake\\ta\\tcab?\\tWould\\ta\\thealthy\\tperson\\torder\\ta\\tburrito\\tor\\ta\\tsalad?\\tShe\\tfigured\\tif\\tshe\\nacted\\tlike\\ta\\thealthy\\tperson\\tlong\\tenough,\\teventually\\tshe\\twould\\tbecome\\tthat\\nperson.\\tShe\\twas\\tright.\\nThe\\tconcept\\tof\\tidentity-based\\thabits\\tis\\tour\\tfirst\\tintroduction\\tto\\tanother\\tkey\\ntheme\\tin\\tthis\\tbook:\\tfeedback\\tloops.\\tYour\\thabits\\tshape\\tyour\\tidentity,\\tand\\tyour\\nidentity\\tshapes\\tyour\\thabits.\\tIt’s\\ta\\ttwo-way\\tstreet.\\tThe\\tformation\\tof\\tall\\thabits\\tis\\ta\\nfeedback\\tloop\\t(a\\tconcept\\twe\\twill\\texplore\\tin\\tdepth\\tin\\tthe\\tnext\\tchapter),\\tbut\\tit’s\\nimportant\\tto\\tlet\\tyour\\tvalues,\\tprinciples,\\tand\\tidentity\\tdrive\\tthe\\tloop\\trather\\tthan\\nyour\\tresults.\\tThe\\tfocus\\tshould\\talways\\tbe\\ton\\tbecoming\\tthat\\ttype\\tof\\tperson,\\tnot\\ngetting\\ta\\tparticular\\toutcome.\\nTHE\\tREAL\\tREASON\\tHABITS\\tMATTER\\nIdentity\\tchange\\tis\\tthe\\tNorth\\tStar\\tof\\thabit\\tchange.\\tThe\\tremainder\\tof\\tthis\\tbook\\nwill\\tprovide\\tyou\\twith\\tstep-by-step\\tinstructions\\ton\\thow\\tto\\tbuild\\tbetter\\thabits\\tin\\nyourself,\\tyour\\tfamily,\\tyour\\tteam,\\tyour\\tcompany,\\tand\\tanywhere\\telse\\tyou\\twish.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 36}), Document(page_content='But\\tthe\\ttrue\\tquestion\\tis:\\t“Are\\tyou\\tbecoming\\tthe\\ttype\\tof\\tperson\\tyou\\twant\\tto\\nbecome?”\\tThe\\tfirst\\tstep\\tis\\tnot\\t\\nwhat\\n\\tor\\t\\nhow\\n,\\tbut\\t\\nwho\\n.\\tYou\\tneed\\tto\\tknow\\twho\\tyou\\nwant\\tto\\tbe.\\tOtherwise,\\tyour\\tquest\\tfor\\tchange\\tis\\tlike\\ta\\tboat\\twithout\\ta\\trudder.\\tAnd\\nthat’s\\twhy\\twe\\tare\\tstarting\\there.\\nYou\\thave\\tthe\\tpower\\tto\\tchange\\tyour\\tbeliefs\\tabout\\tyourself.\\tYour\\tidentity\\tis\\tnot\\nset\\tin\\tstone.\\tYou\\thave\\ta\\tchoice\\tin\\tevery\\tmoment.\\tYou\\tcan\\tchoose\\tthe\\tidentity\\nyou\\twant\\tto\\treinforce\\ttoday\\twith\\tthe\\thabits\\tyou\\tchoose\\ttoday.\\tAnd\\tthis\\tbrings\\tus\\nto\\tthe\\tdeeper\\tpurpose\\tof\\tthis\\tbook\\tand\\tthe\\treal\\treason\\thabits\\tmatter.\\nBuilding\\tbetter\\thabits\\tisn’t\\tabout\\tlittering\\tyour\\tday\\twith\\tlife\\thacks.\\tIt’s\\tnot\\nabout\\tflossing\\tone\\ttooth\\teach\\tnight\\tor\\ttaking\\ta\\tcold\\tshower\\teach\\tmorning\\tor\\nwearing\\tthe\\tsame\\toutfit\\teach\\tday.\\tIt’s\\tnot\\tabout\\tachieving\\texternal\\tmeasures\\tof\\nsuccess\\tlike\\tearning\\tmore\\tmoney,\\tlosing\\tweight,\\tor\\treducing\\tstress.\\tHabits\\tcan\\nhelp\\tyou\\tachieve\\tall\\tof\\tthese\\tthings,\\tbut\\tfundamentally\\tthey\\tare\\tnot\\tabout\\t\\nhaving\\nsomething.\\tThey\\tare\\tabout\\t\\nbecoming\\n\\tsomeone.\\nUltimately,\\tyour\\thabits\\tmatter\\tbecause\\tthey\\thelp\\tyou\\tbecome\\tthe\\ttype\\tof\\nperson\\tyou\\twish\\tto\\tbe.\\tThey\\tare\\tthe\\tchannel\\tthrough\\twhich\\tyou\\tdevelop\\tyour\\ndeepest\\tbeliefs\\tabout\\tyourself.\\tQuite\\tliterally,\\tyou\\tbecome\\tyour\\thabits.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 37}), Document(page_content='Chapter\\tSummary\\nThere\\tare\\tthree\\tlevels\\tof\\tchange:\\toutcome\\tchange,\\tprocess\\tchange,\\tand\\nidentity\\tchange.\\nThe\\tmost\\teffective\\tway\\tto\\tchange\\tyour\\thabits\\tis\\tto\\tfocus\\tnot\\ton\\twhat\\nyou\\twant\\tto\\tachieve,\\tbut\\ton\\twho\\tyou\\twish\\tto\\tbecome.\\nYour\\tidentity\\temerges\\tout\\tof\\tyour\\thabits.\\tEvery\\taction\\tis\\ta\\tvote\\tfor\\tthe\\ntype\\tof\\tperson\\tyou\\twish\\tto\\tbecome.\\nBecoming\\tthe\\tbest\\tversion\\tof\\tyourself\\trequires\\tyou\\tto\\tcontinuously\\nedit\\tyour\\tbeliefs,\\tand\\tto\\tupgrade\\tand\\texpand\\tyour\\tidentity.\\nThe\\treal\\treason\\thabits\\tmatter\\tis\\tnot\\tbecause\\tthey\\tcan\\tget\\tyou\\tbetter\\nresults\\t(although\\tthey\\tcan\\tdo\\tthat),\\tbut\\tbecause\\tthey\\tcan\\tchange\\tyour\\nbeliefs\\tabout\\tyourself.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 38}), Document(page_content='3\\nHow\\tto\\tBuild\\tBetter\\tHabits\\tin\\t4\\tSimple\\tSteps\\nI\\nN\\t1898\\n,\\t\\nA\\t\\npsychologist\\tnamed\\t\\nEdward\\tThorndike\\tconducted\\tan\\texperiment\\tthat\\nwould\\tlay\\tthe\\tfoundation\\tfor\\tour\\tunderstanding\\tof\\thow\\thabits\\tform\\tand\\tthe\\trules\\nthat\\tguide\\tour\\tbehavior.\\tThorndike\\twas\\tinterested\\tin\\tstudying\\tthe\\tbehavior\\tof\\nanimals,\\tand\\the\\tstarted\\tby\\tworking\\twith\\tcats.\\nHe\\twould\\tplace\\teach\\tcat\\tinside\\ta\\tdevice\\tknown\\tas\\ta\\tpuzzle\\tbox.\\tThe\\tbox\\twas\\ndesigned\\tso\\tthat\\tthe\\tcat\\tcould\\tescape\\tthrough\\ta\\tdoor\\t“\\nby\\tsome\\tsimple\\tact,\\tsuch\\nas\\tpulling\\tat\\ta\\tloop\\tof\\tcord,\\tpressing\\ta\\tlever,\\tor\\tstepping\\ton\\ta\\tplatform.”\\tFor\\nexample,\\tone\\tbox\\tcontained\\ta\\tlever\\tthat,\\twhen\\tpressed,\\twould\\topen\\ta\\tdoor\\ton\\nthe\\tside\\tof\\tthe\\tbox.\\tOnce\\tthe\\tdoor\\thad\\tbeen\\topened,\\tthe\\tcat\\tcould\\tdart\\tout\\tand\\nrun\\tover\\tto\\ta\\tbowl\\tof\\tfood.\\nMost\\tcats\\twanted\\tto\\tescape\\tas\\tsoon\\tas\\tthey\\twere\\tplaced\\tinside\\tthe\\tbox.\\tThey\\nwould\\tpoke\\ttheir\\tnose\\tinto\\tthe\\tcorners,\\tstick\\ttheir\\tpaws\\tthrough\\topenings,\\tand\\nclaw\\tat\\tloose\\tobjects.\\tAfter\\ta\\tfew\\tminutes\\tof\\texploration,\\tthe\\tcats\\twould\\thappen\\nto\\tpress\\tthe\\tmagical\\tlever,\\tthe\\tdoor\\twould\\topen,\\tand\\tthey\\twould\\tescape.\\nThorndike\\ttracked\\tthe\\tbehavior\\tof\\teach\\tcat\\tacross\\tmany\\ttrials.\\tIn\\t\\nthe\\nbeginning,\\tthe\\tanimals\\tmoved\\taround\\tthe\\tbox\\tat\\trandom.\\tBut\\tas\\tsoon\\tas\\tthe\\nlever\\thad\\tbeen\\tpressed\\tand\\tthe\\tdoor\\topened,\\tthe\\tprocess\\tof\\tlearning\\tbegan.\\nGradually,\\teach\\tcat\\tlearned\\tto\\tassociate\\tthe\\taction\\tof\\tpressing\\tthe\\tlever\\twith\\tthe\\nreward\\tof\\tescaping\\tthe\\tbox\\tand\\tgetting\\tto\\tthe\\tfood.\\nAfter\\ttwenty\\tto\\tthirty\\ttrials,\\tthis\\tbehavior\\tbecame\\tso\\tautomatic\\tand\\thabitual\\nthat\\tthe\\tcat\\tcould\\tescape\\twithin\\ta\\tfew\\tseconds.\\tFor\\texample,\\tThorndike\\tnoted,\\n“Cat\\t12\\ttook\\tthe\\tfollowing\\ttimes\\tto\\tperform\\tthe\\tact.\\t160\\tseconds,\\t30\\tseconds,\\t90\\nseconds,\\t60,\\t15,\\t28,\\t20,\\t30,\\t22,\\t11,\\t15,\\t20,\\t12,\\t10,\\t14,\\t10,\\t8,\\t8,\\t5,\\t10,\\t8,\\t6,\\t6,\\t7.”\\nDuring\\tthe\\tfirst\\tthree\\ttrials,\\tthe\\tcat\\tescaped\\tin\\tan\\taverage\\tof\\t1.5\\tminutes.\\nDuring\\tthe\\tlast\\tthree\\ttrials,\\tit\\tescaped\\tin\\tan\\taverage\\tof\\t6.3\\tseconds.\\tWith\\npractice,\\teach\\tcat\\tmade\\tfewer\\terrors\\tand\\ttheir\\tactions\\tbecame\\tquicker\\tand\\tmore\\nautomatic.\\tRather\\tthan\\trepeat\\tthe\\tsame\\tmistakes,\\tthe\\tcat\\tbegan\\tto\\tcut\\tstraight\\tto', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 39}), Document(page_content='the\\tsolution.\\nFrom\\this\\tstudies,\\tThorndike\\tdescribed\\tthe\\tlearning\\tprocess\\tby\\tstating,\\n“\\nbehaviors\\tfollowed\\tby\\tsatisfying\\tconsequences\\ttend\\tto\\tbe\\trepeated\\tand\\tthose\\nthat\\tproduce\\tunpleasant\\tconsequences\\tare\\tless\\tlikely\\tto\\tbe\\trepeated.”\\tHis\\twork\\nprovides\\tthe\\tperfect\\tstarting\\tpoint\\tfor\\tdiscussing\\thow\\thabits\\tform\\tin\\tour\\town\\nlives.\\tIt\\talso\\tprovides\\tanswers\\tto\\tsome\\tfundamental\\tquestions\\tlike:\\tWhat\\tare\\nhabits?\\tAnd\\twhy\\tdoes\\tthe\\tbrain\\tbother\\tbuilding\\tthem\\tat\\tall?\\nWHY\\tYOUR\\tBRAIN\\tBUILDS\\tHABITS\\nA\\thabit\\tis\\ta\\tbehavior\\tthat\\thas\\tbeen\\trepeated\\tenough\\ttimes\\tto\\tbecome\\tautomatic.\\nThe\\tprocess\\tof\\thabit\\tformation\\tbegins\\twith\\ttrial\\tand\\terror.\\tWhenever\\tyou\\nencounter\\ta\\tnew\\tsituation\\tin\\tlife,\\tyour\\tbrain\\thas\\tto\\tmake\\ta\\tdecision.\\t\\nHow\\tdo\\tI\\nrespond\\tto\\tthis?\\n\\tThe\\tfirst\\ttime\\tyou\\tcome\\tacross\\ta\\tproblem,\\tyou’re\\tnot\\tsure\\thow\\nto\\tsolve\\tit.\\tLike\\tThorndike’s\\tcat,\\tyou’re\\tjust\\ttrying\\tthings\\tout\\tto\\tsee\\twhat\\tworks.\\nNeurological\\tactivity\\tin\\tthe\\tbrain\\tis\\thigh\\tduring\\tthis\\tperiod.\\tYou\\tare\\tcarefully\\nanalyzing\\tthe\\tsituation\\tand\\tmaking\\tconscious\\tdecisions\\tabout\\thow\\tto\\tact.\\tYou’re\\ntaking\\tin\\ttons\\tof\\tnew\\tinformation\\tand\\ttrying\\tto\\tmake\\tsense\\tof\\tit\\tall.\\tThe\\tbrain\\tis\\nbusy\\tlearning\\tthe\\tmost\\teffective\\tcourse\\tof\\taction.\\nOccasionally,\\tlike\\ta\\tcat\\tpressing\\ton\\ta\\tlever,\\tyou\\tstumble\\tacross\\ta\\tsolution.\\nYou’re\\tfeeling\\tanxious,\\tand\\tyou\\tdiscover\\tthat\\tgoing\\tfor\\ta\\trun\\tcalms\\tyou\\tdown.\\nYou’re\\tmentally\\texhausted\\tfrom\\ta\\tlong\\tday\\tof\\twork,\\tand\\tyou\\tlearn\\tthat\\tplaying\\nvideo\\tgames\\trelaxes\\tyou.\\tYou’re\\texploring,\\texploring,\\texploring,\\tand\\tthen—\\nBAM—a\\treward.\\nAfter\\tyou\\tstumble\\tupon\\tan\\tunexpected\\treward,\\tyou\\talter\\tyour\\tstrategy\\tfor\\tnext\\ntime.\\tYour\\tbrain\\timmediately\\tbegins\\tto\\tcatalog\\tthe\\tevents\\tthat\\tpreceded\\tthe\\nreward.\\t\\nWait\\ta\\tminute—that\\tfelt\\tgood.\\tWhat\\tdid\\tI\\tdo\\tright\\tbefore\\tthat?\\nThis\\tis\\tthe\\tfeedback\\tloop\\tbehind\\tall\\thuman\\tbehavior:\\ttry,\\tfail,\\tlearn,\\ttry\\ndifferently.\\tWith\\tpractice,\\tthe\\tuseless\\tmovements\\tfade\\taway\\tand\\tthe\\tuseful\\nactions\\tget\\treinforced.\\tThat’s\\ta\\thabit\\tforming.\\nWhenever\\tyou\\tface\\ta\\tproblem\\trepeatedly,\\tyour\\tbrain\\tbegins\\tto\\tautomate\\tthe\\nprocess\\tof\\tsolving\\tit.\\tYour\\thabits\\tare\\tjust\\ta\\tseries\\tof\\tautomatic\\tsolutions\\tthat\\nsolve\\tthe\\tproblems\\tand\\tstresses\\tyou\\tface\\tregularly.\\tAs\\tbehavioral\\tscientist\\tJason\\nHreha\\twrites,\\t“\\nHabits\\tare,\\tsimply,\\treliable\\tsolutions\\tto\\trecurring\\tproblems\\tin\\tour\\nenvironment.”\\nAs\\thabits\\tare\\tcreated,\\tthe\\tlevel\\tof\\tactivity\\tin\\tthe\\tbrain\\t\\ndecreases\\n.\\tYou\\tlearn\\tto\\nlock\\tin\\ton\\tthe\\tcues\\tthat\\tpredict\\tsuccess\\tand\\ttune\\tout\\teverything\\telse.\\tWhen\\ta\\nsimilar\\tsituation\\tarises\\tin\\tthe\\tfuture,\\tyou\\tknow\\texactly\\twhat\\tto\\tlook\\tfor.\\tThere\\tis', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 40}), Document(page_content='no\\tlonger\\ta\\tneed\\tto\\tanalyze\\tevery\\tangle\\tof\\ta\\tsituation.\\tYour\\tbrain\\tskips\\tthe\\nprocess\\tof\\ttrial\\tand\\terror\\tand\\tcreates\\ta\\tmental\\trule:\\tif\\tthis,\\tthen\\tthat.\\tThese\\ncognitive\\tscripts\\tcan\\tbe\\tfollowed\\tautomatically\\twhenever\\tthe\\tsituation\\tis\\nappropriate.\\tNow,\\twhenever\\tyou\\tfeel\\tstressed,\\tyou\\tget\\tthe\\titch\\tto\\trun.\\tAs\\tsoon\\tas\\nyou\\twalk\\tin\\tthe\\tdoor\\tfrom\\twork,\\tyou\\tgrab\\tthe\\tvideo\\tgame\\tcontroller.\\tA\\t\\nchoice\\nthat\\tonce\\trequired\\teffort\\tis\\tnow\\tautomatic.\\tA\\thabit\\thas\\tbeen\\tcreated.\\nHabits\\tare\\tmental\\tshortcuts\\tlearned\\tfrom\\texperience.\\tIn\\ta\\tsense,\\ta\\thabit\\tis\\tjust\\na\\tmemory\\tof\\tthe\\tsteps\\tyou\\tpreviously\\tfollowed\\tto\\tsolve\\ta\\tproblem\\tin\\tthe\\tpast.\\nWhenever\\tthe\\tconditions\\tare\\tright,\\tyou\\tcan\\tdraw\\ton\\tthis\\tmemory\\tand\\nautomatically\\tapply\\tthe\\tsame\\tsolution.\\tThe\\tprimary\\treason\\t\\nthe\\tbrain\\tremembers\\nthe\\tpast\\tis\\tto\\tbetter\\tpredict\\twhat\\twill\\twork\\tin\\tthe\\tfuture.\\nHabit\\tformation\\tis\\tincredibly\\tuseful\\tbecause\\t\\nthe\\tconscious\\tmind\\tis\\tthe\\nbottleneck\\tof\\tthe\\tbrain.\\tIt\\tcan\\tonly\\tpay\\tattention\\tto\\tone\\tproblem\\tat\\ta\\ttime.\\tAs\\ta\\nresult,\\tyour\\tbrain\\tis\\talways\\tworking\\tto\\tpreserve\\tyour\\tconscious\\tattention\\tfor\\nwhatever\\ttask\\tis\\tmost\\tessential.\\tWhenever\\tpossible,\\t\\nthe\\tconscious\\tmind\\tlikes\\tto\\npawn\\toff\\ttasks\\tto\\tthe\\tnonconscious\\tmind\\tto\\tdo\\tautomatically.\\tThis\\tis\\tprecisely\\nwhat\\thappens\\twhen\\ta\\thabit\\tis\\tformed.\\t\\nHabits\\treduce\\tcognitive\\tload\\tand\\tfree\\tup\\nmental\\tcapacity,\\tso\\tyou\\tcan\\tallocate\\tyour\\tattention\\tto\\tother\\ttasks.\\nDespite\\ttheir\\tefficiency,\\tsome\\tpeople\\tstill\\twonder\\tabout\\tthe\\tbenefits\\tof\\thabits.\\nThe\\targument\\tgoes\\tlike\\tthis:\\t“Will\\thabits\\tmake\\tmy\\tlife\\tdull?\\tI\\tdon’t\\twant\\tto\\npigeonhole\\tmyself\\tinto\\ta\\tlifestyle\\tI\\tdon’t\\tenjoy.\\tDoesn’t\\tso\\tmuch\\troutine\\ttake\\naway\\tthe\\tvibrancy\\tand\\tspontaneity\\tof\\tlife?”\\tHardly.\\tSuch\\tquestions\\tset\\tup\\ta\\tfalse\\ndichotomy.\\tThey\\tmake\\tyou\\tthink\\tthat\\tyou\\thave\\tto\\tchoose\\tbetween\\tbuilding\\nhabits\\tand\\tattaining\\tfreedom.\\tIn\\treality,\\tthe\\ttwo\\tcomplement\\teach\\tother.\\nHabits\\tdo\\tnot\\trestrict\\tfreedom.\\tThey\\tcreate\\tit.\\tIn\\tfact,\\tthe\\tpeople\\twho\\tdon’t\\nhave\\ttheir\\thabits\\thandled\\tare\\toften\\tthe\\tones\\twith\\tthe\\t\\nleast\\n\\tamount\\tof\\tfreedom.\\nWithout\\tgood\\tfinancial\\thabits,\\tyou\\twill\\talways\\tbe\\tstruggling\\tfor\\tthe\\tnext\\tdollar.\\nWithout\\tgood\\thealth\\thabits,\\tyou\\twill\\talways\\tseem\\tto\\tbe\\tshort\\ton\\tenergy.\\tWithout\\ngood\\tlearning\\thabits,\\tyou\\twill\\talways\\tfeel\\tlike\\tyou’re\\tbehind\\tthe\\tcurve.\\tIf\\tyou’re\\nalways\\tbeing\\tforced\\tto\\tmake\\tdecisions\\tabout\\tsimple\\ttasks—when\\tshould\\tI\\twork\\nout,\\twhere\\tdo\\t\\nI\\tgo\\tto\\twrite,\\twhen\\tdo\\tI\\tpay\\tthe\\tbills—then\\tyou\\thave\\tless\\ttime\\tfor\\nfreedom.\\tIt’s\\tonly\\tby\\tmaking\\tthe\\tfundamentals\\tof\\tlife\\teasier\\tthat\\tyou\\tcan\\tcreate\\nthe\\tmental\\tspace\\tneeded\\tfor\\tfree\\tthinking\\tand\\tcreativity.\\nConversely,\\twhen\\tyou\\thave\\tyour\\thabits\\tdialed\\tin\\tand\\tthe\\tbasics\\tof\\tlife\\tare\\nhandled\\tand\\tdone,\\tyour\\tmind\\tis\\tfree\\tto\\tfocus\\ton\\tnew\\tchallenges\\tand\\tmaster\\tthe\\nnext\\tset\\tof\\tproblems.\\tBuilding\\thabits\\tin\\tthe\\tpresent\\tallows\\tyou\\tto\\tdo\\tmore\\tof\\nwhat\\tyou\\twant\\tin\\tthe\\tfuture.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 41}), Document(page_content='THE\\tSCIENCE\\tOF\\tHOW\\tHABITS\\tWORK\\nThe\\tprocess\\tof\\tbuilding\\ta\\thabit\\tcan\\tbe\\tdivided\\tinto\\tfour\\tsimple\\tsteps:\\tcue,\\ncraving,\\tresponse,\\tand\\treward.\\n*\\n\\tBreaking\\tit\\tdown\\tinto\\tthese\\tfundamental\\tparts\\ncan\\thelp\\tus\\tunderstand\\twhat\\ta\\thabit\\tis,\\thow\\tit\\tworks,\\tand\\thow\\tto\\timprove\\tit.\\nFIGURE\\t5:\\tAll\\thabits\\tproceed\\tthrough\\tfour\\tstages\\tin\\tthe\\tsame\\torder:\\tcue,\\tcraving,\\tresponse,\\tand\\treward.\\nThis\\tfour-step\\tpattern\\tis\\tthe\\tbackbone\\tof\\tevery\\thabit,\\tand\\tyour\\tbrain\\truns\\nthrough\\tthese\\tsteps\\tin\\tthe\\tsame\\torder\\teach\\ttime.\\nFirst,\\tthere\\tis\\tthe\\tcue.\\tThe\\tcue\\ttriggers\\tyour\\tbrain\\tto\\tinitiate\\ta\\t\\nbehavior.\\tIt\\tis\\ta\\nbit\\tof\\tinformation\\tthat\\tpredicts\\ta\\treward.\\tOur\\tprehistoric\\tancestors\\twere\\tpaying\\nattention\\tto\\tcues\\tthat\\tsignaled\\tthe\\tlocation\\tof\\tprimary\\trewards\\tlike\\tfood,\\twater,\\nand\\tsex.\\tToday,\\twe\\tspend\\tmost\\tof\\tour\\ttime\\tlearning\\tcues\\tthat\\tpredict\\tsecondary\\nrewards\\tlike\\tmoney\\tand\\tfame,\\tpower\\tand\\tstatus,\\tpraise\\tand\\tapproval,\\tlove\\tand\\nfriendship,\\tor\\ta\\tsense\\tof\\tpersonal\\tsatisfaction.\\t(Of\\tcourse,\\tthese\\tpursuits\\talso\\nindirectly\\timprove\\tour\\todds\\tof\\tsurvival\\tand\\treproduction,\\twhich\\tis\\tthe\\tdeeper\\nmotive\\tbehind\\teverything\\twe\\tdo.)\\nYour\\tmind\\tis\\tcontinuously\\tanalyzing\\tyour\\tinternal\\tand\\texternal\\tenvironment\\nfor\\thints\\tof\\twhere\\trewards\\tare\\tlocated.\\tBecause\\tthe\\tcue\\tis\\tthe\\tfirst\\tindication\\tthat\\nwe’re\\tclose\\tto\\ta\\treward,\\tit\\tnaturally\\tleads\\tto\\ta\\tcraving.\\nCravings\\tare\\tthe\\tsecond\\tstep,\\tand\\tthey\\tare\\tthe\\tmotivational\\tforce\\tbehind\\tevery\\nhabit.\\tWithout\\tsome\\tlevel\\tof\\tmotivation\\tor\\tdesire—without\\tcraving\\ta\\tchange—\\nwe\\thave\\tno\\treason\\tto\\tact.\\tWhat\\tyou\\tcrave\\tis\\tnot\\tthe\\thabit\\titself\\tbut\\tthe\\tchange\\tin\\nstate\\tit\\tdelivers.\\tYou\\tdo\\tnot\\tcrave\\tsmoking\\ta\\tcigarette,\\tyou\\tcrave\\tthe\\tfeeling\\tof\\nrelief\\tit\\tprovides.\\tYou\\tare\\tnot\\tmotivated\\tby\\tbrushing\\tyour\\tteeth\\tbut\\trather\\tby\\tthe\\nfeeling\\tof\\ta\\tclean\\tmouth.\\tYou\\tdo\\tnot\\twant\\tto\\tturn\\ton\\tthe\\ttelevision,\\tyou\\twant\\tto\\nbe\\tentertained.\\tEvery\\tcraving\\tis\\tlinked\\tto\\ta\\tdesire\\tto\\tchange\\tyour\\tinternal\\tstate.\\nThis\\tis\\tan\\timportant\\tpoint\\tthat\\twe\\twill\\tdiscuss\\tin\\tdetail\\tlater.\\nCravings\\tdiffer\\tfrom\\tperson\\tto\\tperson.\\tIn\\ttheory,\\tany\\tpiece\\tof\\tinformation\\ncould\\ttrigger\\ta\\tcraving,\\tbut\\tin\\tpractice,\\tpeople\\tare\\tnot\\tmotivated\\tby\\tthe\\tsame\\ncues.\\tFor\\ta\\tgambler,\\tthe\\tsound\\tof\\tslot\\tmachines\\tcan\\tbe\\ta\\tpotent\\ttrigger\\tthat', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 42}), Document(page_content='sparks\\tan\\tintense\\twave\\tof\\tdesire.\\tFor\\tsomeone\\twho\\trarely\\tgambles,\\tthe\\tjingles\\nand\\tchimes\\tof\\tthe\\tcasino\\tare\\tjust\\tbackground\\tnoise.\\tCues\\tare\\tmeaningless\\tuntil\\nthey\\tare\\tinterpreted.\\tThe\\tthoughts,\\tfeelings,\\tand\\temotions\\tof\\tthe\\tobserver\\tare\\nwhat\\ttransform\\ta\\tcue\\tinto\\ta\\tcraving.\\nThe\\tthird\\tstep\\tis\\tthe\\tresponse.\\tThe\\tresponse\\tis\\tthe\\tactual\\thabit\\tyou\\tperform,\\nwhich\\tcan\\ttake\\tthe\\tform\\tof\\ta\\tthought\\tor\\tan\\taction.\\tWhether\\t\\na\\tresponse\\toccurs\\ndepends\\ton\\thow\\tmotivated\\tyou\\tare\\tand\\thow\\tmuch\\tfriction\\tis\\tassociated\\twith\\tthe\\nbehavior.\\tIf\\ta\\tparticular\\taction\\trequires\\tmore\\tphysical\\tor\\tmental\\teffort\\tthan\\tyou\\nare\\twilling\\tto\\texpend,\\tthen\\tyou\\twon’t\\tdo\\tit.\\tYour\\tresponse\\talso\\tdepends\\ton\\tyour\\nability.\\tIt\\tsounds\\tsimple,\\tbut\\ta\\thabit\\tcan\\toccur\\tonly\\tif\\tyou\\tare\\tcapable\\tof\\tdoing\\nit.\\tIf\\tyou\\twant\\tto\\tdunk\\ta\\tbasketball\\tbut\\tcan’t\\tjump\\thigh\\tenough\\tto\\treach\\tthe\\nhoop,\\twell,\\tyou’re\\tout\\tof\\tluck.\\nFinally,\\tthe\\tresponse\\tdelivers\\ta\\treward.\\tRewards\\tare\\tthe\\tend\\tgoal\\tof\\tevery\\nhabit.\\tThe\\tcue\\tis\\tabout\\tnoticing\\tthe\\treward.\\tThe\\tcraving\\tis\\tabout\\twanting\\tthe\\nreward.\\tThe\\tresponse\\tis\\tabout\\tobtaining\\tthe\\treward.\\tWe\\tchase\\trewards\\tbecause\\nthey\\tserve\\ttwo\\tpurposes:\\t(1)\\tthey\\tsatisfy\\tus\\tand\\t(2)\\tthey\\tteach\\tus.\\nThe\\tfirst\\tpurpose\\tof\\trewards\\tis\\tto\\t\\nsatisfy\\tyour\\tcraving\\n.\\tYes,\\trewards\\tprovide\\nbenefits\\ton\\ttheir\\town.\\tFood\\tand\\twater\\tdeliver\\tthe\\tenergy\\tyou\\tneed\\tto\\tsurvive.\\nGetting\\ta\\tpromotion\\tbrings\\tmore\\tmoney\\tand\\trespect.\\tGetting\\tin\\tshape\\timproves\\nyour\\thealth\\tand\\tyour\\tdating\\tprospects.\\tBut\\tthe\\tmore\\timmediate\\tbenefit\\tis\\tthat\\nrewards\\tsatisfy\\tyour\\tcraving\\tto\\teat\\tor\\tto\\tgain\\tstatus\\tor\\tto\\twin\\tapproval.\\tAt\\tleast\\nfor\\ta\\tmoment,\\trewards\\tdeliver\\tcontentment\\tand\\trelief\\tfrom\\tcraving.\\nSecond,\\trewards\\tteach\\tus\\twhich\\tactions\\tare\\tworth\\tremembering\\tin\\tthe\\tfuture.\\nYour\\tbrain\\tis\\ta\\treward\\tdetector.\\tAs\\tyou\\tgo\\tabout\\tyour\\tlife,\\tyour\\tsensory\\tnervous\\nsystem\\tis\\tcontinuously\\tmonitoring\\twhich\\tactions\\tsatisfy\\tyour\\tdesires\\tand\\tdeliver\\npleasure.\\t\\nFeelings\\tof\\tpleasure\\tand\\tdisappointment\\tare\\tpart\\tof\\tthe\\tfeedback\\nmechanism\\tthat\\thelps\\tyour\\tbrain\\tdistinguish\\tuseful\\tactions\\tfrom\\tuseless\\tones.\\nRewards\\tclose\\tthe\\tfeedback\\tloop\\tand\\tcomplete\\tthe\\thabit\\tcycle.\\nIf\\ta\\tbehavior\\tis\\tinsufficient\\tin\\tany\\tof\\tthe\\tfour\\tstages,\\tit\\twill\\tnot\\tbecome\\ta\\nhabit.\\tEliminate\\tthe\\tcue\\tand\\tyour\\thabit\\twill\\tnever\\tstart.\\tReduce\\tthe\\tcraving\\tand\\nyou\\twon’t\\texperience\\tenough\\tmotivation\\tto\\tact.\\tMake\\tthe\\tbehavior\\tdifficult\\tand\\nyou\\twon’t\\tbe\\table\\tto\\tdo\\tit.\\tAnd\\tif\\tthe\\treward\\tfails\\tto\\tsatisfy\\tyour\\tdesire,\\tthen\\nyou’ll\\thave\\tno\\treason\\tto\\tdo\\tit\\tagain\\tin\\t\\nthe\\tfuture.\\tWithout\\tthe\\tfirst\\tthree\\tsteps,\\ta\\nbehavior\\twill\\tnot\\toccur.\\tWithout\\tall\\tfour,\\ta\\tbehavior\\twill\\tnot\\tbe\\trepeated.\\nTHE\\tHABIT\\tLOOP', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 43}), Document(page_content='FIGURE\\t6:\\tThe\\tfour\\tstages\\tof\\thabit\\tare\\tbest\\tdescribed\\tas\\ta\\tfeedback\\tloop.\\tThey\\tform\\tan\\tendless\\tcycle\\tthat\\tis\\trunning\\tevery\\tmoment\\tyou\\tare\\talive.\\tThis\\t“habit\\tloop”\\tis\\tcontinually\\tscanning\\nthe\\tenvironment,\\tpredicting\\twhat\\twill\\thappen\\tnext,\\ttrying\\tout\\tdifferent\\tresponses,\\tand\\tlearning\\tfrom\\tthe\\tresults.\\n*\\nIn\\tsummary,\\tthe\\tcue\\ttriggers\\ta\\tcraving,\\twhich\\tmotivates\\ta\\tresponse,\\twhich\\nprovides\\ta\\treward,\\twhich\\tsatisfies\\tthe\\tcraving\\tand,\\tultimately,\\tbecomes\\nassociated\\twith\\tthe\\tcue.\\tTogether,\\tthese\\tfour\\tsteps\\tform\\ta\\tneurological\\tfeedback\\nloop—cue,\\tcraving,\\tresponse,\\treward;\\t\\ncue,\\tcraving,\\tresponse,\\treward—that\\nultimately\\tallows\\tyou\\tto\\tcreate\\tautomatic\\thabits.\\tThis\\tcycle\\tis\\tknown\\tas\\tthe\\thabit\\nloop.\\nThis\\tfour-step\\tprocess\\tis\\tnot\\tsomething\\tthat\\thappens\\toccasionally,\\tbut\\trather\\tit\\nis\\tan\\tendless\\tfeedback\\tloop\\tthat\\tis\\trunning\\tand\\tactive\\tduring\\tevery\\tmoment\\tyou\\nare\\talive—even\\tnow.\\tThe\\tbrain\\tis\\tcontinually\\tscanning\\tthe\\tenvironment,\\npredicting\\twhat\\twill\\thappen\\tnext,\\ttrying\\tout\\tdifferent\\tresponses,\\tand\\tlearning\\nfrom\\tthe\\tresults.\\tThe\\tentire\\tprocess\\tis\\tcompleted\\tin\\ta\\tsplit\\tsecond,\\tand\\twe\\tuse\\tit\\nagain\\tand\\tagain\\twithout\\trealizing\\teverything\\tthat\\thas\\tbeen\\tpacked\\tinto\\tthe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 44}), Document(page_content='previous\\tmoment.\\nWe\\tcan\\tsplit\\tthese\\tfour\\tsteps\\tinto\\ttwo\\tphases:\\tthe\\tproblem\\tphase\\tand\\tthe\\nsolution\\tphase.\\tThe\\tproblem\\tphase\\tincludes\\tthe\\tcue\\tand\\tthe\\tcraving,\\tand\\tit\\tis\\nwhen\\tyou\\trealize\\tthat\\tsomething\\tneeds\\tto\\tchange.\\tThe\\tsolution\\tphase\\tincludes\\nthe\\tresponse\\tand\\tthe\\treward,\\tand\\tit\\tis\\twhen\\tyou\\ttake\\taction\\tand\\tachieve\\tthe\\nchange\\tyou\\tdesire.\\nProblem\\tphase\\n1.\\tCue\\n2.\\tCraving\\nSolution\\tphase\\n3.\\tResponse\\n4.\\tReward\\nAll\\tbehavior\\tis\\tdriven\\tby\\tthe\\tdesire\\tto\\tsolve\\ta\\tproblem.\\tSometimes\\tthe\\nproblem\\tis\\tthat\\tyou\\tnotice\\tsomething\\tgood\\tand\\tyou\\twant\\tto\\tobtain\\tit.\\tSometimes\\nthe\\tproblem\\tis\\tthat\\tyou\\tare\\texperiencing\\tpain\\tand\\tyou\\twant\\tto\\trelieve\\tit.\\tEither\\nway,\\tthe\\tpurpose\\tof\\tevery\\thabit\\tis\\tto\\tsolve\\tthe\\tproblems\\tyou\\tface.\\nIn\\tthe\\ttable\\ton\\tthe\\tfollowing\\tpage,\\tyou\\tcan\\tsee\\ta\\tfew\\texamples\\tof\\twhat\\tthis\\nlooks\\tlike\\tin\\treal\\tlife.\\nImagine\\twalking\\tinto\\ta\\tdark\\troom\\tand\\tflipping\\ton\\tthe\\tlight\\tswitch.\\tYou\\thave\\nperformed\\tthis\\tsimple\\thabit\\tso\\tmany\\ttimes\\tthat\\tit\\toccurs\\twithout\\tthinking.\\tYou\\nproceed\\tthrough\\tall\\tfour\\tstages\\tin\\tthe\\tfraction\\tof\\ta\\tsecond.\\tThe\\turge\\tto\\tact\\tstrikes\\nyou\\twithout\\tthinking.\\nProblem\\tphase\\n1.\\tCue:\\n\\tYour\\tphone\\tbuzzes\\twith\\ta\\tnew\\ttext\\tmessage.\\n2.\\tCraving:\\n\\tYou\\twant\\tto\\tlearn\\tthe\\tcontents\\tof\\tthe\\tmessage.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tgrab\\tyour\\tphone\\tand\\tread\\tthe\\ttext.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\tread\\tthe\\tmessage.\\tGrabbing\\tyour\\tphone\\tbecomes\\tassociated\\twith\\tyour\\tphone\\tbuzzing.\\nProblem\\tphase\\n1.\\tCue:\\n\\tYou\\tare\\tanswering\\temails.\\n2.\\tCraving:\\n\\tYou\\tbegin\\tto\\tfeel\\tstressed\\tand\\toverwhelmed\\tby\\twork.\\tYou\\twant\\tto\\tfeel\\tin\\tcontrol.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tbite\\tyour\\tnails.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\treduce\\tstress.\\tBiting\\tyour\\tnails\\tbecomes\\tassociated\\twith\\tanswering\\temail.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 45}), Document(page_content='Problem\\tphase\\n1.\\tCue:\\n\\tYou\\twake\\tup.\\n2.\\tCraving:\\n\\tYou\\twant\\tto\\tfeel\\talert.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tdrink\\ta\\tcup\\tof\\tcoffee.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\tfeel\\talert.\\tDrinking\\tcoffee\\tbecomes\\tassociated\\twith\\twaking\\tup.\\nProblem\\tphase\\n1.\\tCue:\\n\\tYou\\tsmell\\ta\\tdoughnut\\tshop\\tas\\tyou\\twalk\\tdown\\tthe\\tstreet\\tnear\\tyour\\toffice.\\n2.\\tCraving:\\n\\tYou\\tbegin\\tto\\tcrave\\ta\\tdoughnut.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tbuy\\ta\\tdoughnut\\tand\\teat\\tit.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\teat\\ta\\tdoughnut.\\tBuying\\ta\\tdoughnut\\tbecomes\\tassociated\\twith\\twalking\\tdown\\tthe\\tstreet\\tnear\\tyour\\toffice.\\nProblem\\tphase\\n1.\\tCue:\\n\\tYou\\thit\\ta\\tstumbling\\tblock\\ton\\ta\\tproject\\tat\\twork.\\n2.\\tCraving:\\n\\tYou\\tfeel\\tstuck\\tand\\twant\\tto\\trelieve\\tyour\\tfrustration.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tpull\\tout\\tyour\\tphone\\tand\\tcheck\\tsocial\\tmedia.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\tfeel\\trelieved.\\tChecking\\tsocial\\tmedia\\tbecomes\\tassociated\\twith\\tfeeling\\tstalled\\tat\\twork.\\nProblem\\tphase\\n1.\\tCue:\\n\\tYou\\twalk\\tinto\\ta\\tdark\\troom.\\n2.\\tCraving:\\n\\tYou\\twant\\tto\\tbe\\table\\tto\\tsee.\\nSolution\\tphase\\n3.\\tResponse:\\n\\tYou\\tflip\\tthe\\tlight\\tswitch.\\n4.\\tReward:\\n\\tYou\\tsatisfy\\tyour\\tcraving\\tto\\tsee.\\tTurning\\ton\\tthe\\tlight\\tswitch\\tbecomes\\tassociated\\twith\\tbeing\\tin\\ta\\tdark\\troom.\\nBy\\tthe\\ttime\\twe\\tbecome\\tadults,\\twe\\trarely\\tnotice\\tthe\\thabits\\tthat\\tare\\trunning\\tour\\nlives.\\tMost\\tof\\tus\\tnever\\tgive\\ta\\tsecond\\tthought\\tto\\tthe\\tfact\\tthat\\twe\\ttie\\tthe\\tsame\\nshoe\\tfirst\\teach\\tmorning,\\tor\\tunplug\\tthe\\ttoaster\\tafter\\teach\\tuse,\\tor\\talways\\tchange\\ninto\\tcomfortable\\tclothes\\tafter\\tgetting\\thome\\tfrom\\twork.\\tAfter\\tdecades\\tof\\tmental\\nprogramming,\\twe\\tautomatically\\tslip\\tinto\\tthese\\tpatterns\\tof\\tthinking\\tand\\tacting.\\nTHE\\tFOUR\\tLAWS\\tOF\\tBEHAVIOR\\tCHANGE', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 46}), Document(page_content='In\\tthe\\tfollowing\\tchapters,\\twe\\twill\\tsee\\ttime\\tand\\tagain\\thow\\tthe\\tfour\\tstages\\tof\\tcue,\\ncraving,\\tresponse,\\tand\\treward\\tinfluence\\tnearly\\teverything\\twe\\tdo\\teach\\tday.\\tBut\\nbefore\\twe\\tdo\\tthat,\\twe\\tneed\\tto\\ttransform\\tthese\\tfour\\tsteps\\tinto\\ta\\tpractical\\nframework\\tthat\\twe\\tcan\\tuse\\tto\\tdesign\\tgood\\thabits\\tand\\teliminate\\tbad\\tones.\\nI\\trefer\\tto\\tthis\\tframework\\tas\\tthe\\t\\nFour\\tLaws\\tof\\tBehavior\\tChange\\n,\\tand\\tit\\nprovides\\ta\\tsimple\\tset\\tof\\trules\\tfor\\tcreating\\tgood\\thabits\\tand\\tbreaking\\tbad\\t\\nones.\\nYou\\tcan\\tthink\\tof\\teach\\tlaw\\tas\\ta\\tlever\\tthat\\tinfluences\\thuman\\tbehavior.\\tWhen\\tthe\\nlevers\\tare\\tin\\tthe\\tright\\tpositions,\\tcreating\\tgood\\thabits\\tis\\teffortless.\\tWhen\\tthey\\tare\\nin\\tthe\\twrong\\tpositions,\\tit\\tis\\tnearly\\timpossible.\\nHow\\tto\\tCreate\\ta\\tGood\\tHabit\\nThe\\t1st\\tlaw\\t(Cue):\\n\\tMake\\tit\\tobvious.\\nThe\\t2nd\\tlaw\\t(Craving):\\n\\tMake\\tit\\tattractive.\\nThe\\t3rd\\tlaw\\t(Response):\\n\\tMake\\tit\\teasy.\\nThe\\t4th\\tlaw\\t(Reward):\\n\\tMake\\tit\\tsatisfying.\\nWe\\tcan\\tinvert\\tthese\\tlaws\\tto\\tlearn\\thow\\tto\\tbreak\\ta\\tbad\\thabit.\\nHow\\tto\\tBreak\\ta\\tBad\\tHabit\\nInversion\\tof\\tthe\\t1st\\tlaw\\t(Cue):\\n\\tMake\\tit\\tinvisible.\\nInversion\\tof\\tthe\\t2nd\\tlaw\\t(Craving):\\n\\tMake\\tit\\tunattractive.\\nInversion\\tof\\tthe\\t3rd\\tlaw\\t(Response):\\n\\tMake\\tit\\tdifficult.\\nInversion\\tof\\tthe\\t4th\\tlaw\\t(Reward):\\n\\tMake\\tit\\tunsatisfying.\\nIt\\twould\\tbe\\tirresponsible\\tfor\\tme\\tto\\tclaim\\tthat\\tthese\\tfour\\tlaws\\tare\\tan\\nexhaustive\\tframework\\tfor\\tchanging\\t\\nany\\n\\thuman\\tbehavior,\\tbut\\tI\\tthink\\tthey’re\\nclose.\\tAs\\tyou\\twill\\tsoon\\tsee,\\tthe\\tFour\\tLaws\\tof\\tBehavior\\tChange\\tapply\\tto\\tnearly\\nevery\\tfield,\\tfrom\\tsports\\tto\\tpolitics,\\tart\\tto\\tmedicine,\\tcomedy\\tto\\tmanagement.\\nThese\\tlaws\\tcan\\tbe\\tused\\tno\\tmatter\\twhat\\tchallenge\\tyou\\tare\\tfacing.\\tThere\\tis\\tno\\nneed\\tfor\\tcompletely\\tdifferent\\tstrategies\\tfor\\teach\\thabit.\\nWhenever\\tyou\\twant\\tto\\tchange\\tyour\\tbehavior,\\tyou\\tcan\\tsimply\\task\\tyourself:\\n1.\\t\\nHow\\tcan\\tI\\tmake\\tit\\tobvious?\\n2.\\t\\nHow\\tcan\\tI\\tmake\\tit\\tattractive?\\n3.\\t\\nHow\\tcan\\tI\\tmake\\tit\\teasy?\\n4.\\t\\nHow\\tcan\\tI\\tmake\\tit\\tsatisfying?\\nIf\\tyou\\thave\\tever\\twondered,\\t“Why\\tdon’t\\tI\\tdo\\twhat\\tI\\tsay\\tI’m\\tgoing\\tto\\tdo?\\tWhy\\ndon’t\\tI\\tlose\\tthe\\tweight\\tor\\tstop\\tsmoking\\tor\\tsave\\tfor\\tretirement\\tor\\tstart\\tthat\\tside\\nbusiness?\\tWhy\\tdo\\tI\\tsay\\tsomething\\tis\\timportant\\tbut\\tnever\\tseem\\tto\\tmake\\ttime\\tfor\\nit?”\\tThe\\tanswers\\tto\\tthose\\tquestions\\tcan\\tbe\\tfound\\tsomewhere\\tin\\tthese\\tfour\\tlaws.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 47}), Document(page_content='The\\tkey\\tto\\tcreating\\tgood\\thabits\\tand\\tbreaking\\tbad\\tones\\tis\\tto\\tunderstand\\tthese\\nfundamental\\tlaws\\tand\\thow\\tto\\talter\\tthem\\tto\\tyour\\tspecifications.\\tEvery\\tgoal\\tis\\ndoomed\\tto\\tfail\\tif\\tit\\tgoes\\tagainst\\tthe\\tgrain\\tof\\thuman\\tnature.\\nYour\\thabits\\tare\\tshaped\\tby\\tthe\\tsystems\\tin\\tyour\\tlife.\\tIn\\tthe\\tchapters\\tthat\\tfollow,\\nwe\\twill\\tdiscuss\\tthese\\tlaws\\tone\\tby\\tone\\tand\\tshow\\thow\\tyou\\tcan\\tuse\\tthem\\tto\\tcreate\\na\\tsystem\\tin\\twhich\\tgood\\thabits\\temerge\\tnaturally\\tand\\tbad\\thabits\\twither\\taway.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 48}), Document(page_content='Chapter\\tSummary\\nA\\thabit\\tis\\ta\\tbehavior\\tthat\\thas\\tbeen\\trepeated\\tenough\\ttimes\\tto\\tbecome\\nautomatic.\\nThe\\tultimate\\tpurpose\\tof\\thabits\\tis\\tto\\tsolve\\tthe\\tproblems\\tof\\tlife\\twith\\tas\\nlittle\\tenergy\\tand\\teffort\\tas\\tpossible.\\nAny\\thabit\\tcan\\tbe\\tbroken\\tdown\\tinto\\ta\\tfeedback\\tloop\\tthat\\tinvolves\\tfour\\nsteps:\\tcue,\\tcraving,\\tresponse,\\tand\\treward.\\nThe\\tFour\\tLaws\\tof\\tBehavior\\tChange\\tare\\ta\\tsimple\\tset\\tof\\trules\\twe\\tcan\\nuse\\tto\\tbuild\\tbetter\\thabits.\\tThey\\tare\\t(1)\\tmake\\tit\\tobvious,\\t(2)\\tmake\\tit\\nattractive,\\t(3)\\tmake\\tit\\teasy,\\tand\\t(4)\\tmake\\tit\\tsatisfying.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 49}), Document(page_content='THE\\t1ST\\tLAW\\nMake\\tIt\\tObvious', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 50}), Document(page_content='4\\nThe\\tMan\\tWho\\tDidn’t\\tLook\\tRight\\nT\\nH\\nE\\tPSYCHOLOGIST\\t\\nG\\nARY\\t\\nKlein\\tonce\\ttold\\tme\\ta\\tstory\\tabout\\ta\\twoman\\twho\\tattended\\ta\\nfamily\\tgathering.\\tShe\\thad\\tspent\\tyears\\tworking\\tas\\ta\\tparamedic\\tand,\\tupon\\tarriving\\nat\\tthe\\tevent,\\ttook\\tone\\tlook\\tat\\ther\\tfather-in-law\\tand\\tgot\\tvery\\tconcerned.\\n“I\\tdon’t\\tlike\\tthe\\tway\\tyou\\tlook,”\\tshe\\tsaid.\\nHer\\tfather-in-law,\\twho\\twas\\tfeeling\\tperfectly\\tfine,\\tjokingly\\treplied,\\t“Well,\\tI\\ndon’t\\tlike\\tyour\\tlooks,\\teither.”\\n“No,”\\tshe\\tinsisted.\\t“You\\tneed\\tto\\tgo\\tto\\tthe\\thospital\\tnow.”\\nA\\tfew\\thours\\tlater,\\tthe\\tman\\twas\\tundergoing\\tlifesaving\\tsurgery\\tafter\\tan\\nexamination\\thad\\trevealed\\tthat\\the\\thad\\ta\\tblockage\\tto\\ta\\tmajor\\tartery\\tand\\twas\\tat\\nimmediate\\trisk\\tof\\ta\\theart\\tattack.\\tWithout\\this\\tdaughter-in-law’s\\tintuition,\\the\\ncould\\thave\\tdied.\\nWhat\\tdid\\tthe\\tparamedic\\tsee?\\tHow\\tdid\\tshe\\tpredict\\this\\timpending\\theart\\tattack?\\nWhen\\tmajor\\tarteries\\tare\\tobstructed,\\tthe\\tbody\\tfocuses\\ton\\tsending\\tblood\\tto\\ncritical\\torgans\\tand\\taway\\tfrom\\tperipheral\\tlocations\\tnear\\tthe\\tsurface\\tof\\tthe\\tskin.\\nThe\\tresult\\tis\\ta\\tchange\\tin\\tthe\\tpattern\\tof\\tdistribution\\tof\\tblood\\tin\\tthe\\tface.\\tAfter\\nmany\\tyears\\tof\\tworking\\twith\\tpeople\\twith\\t\\nheart\\tfailure,\\tthe\\twoman\\thad\\nunknowingly\\tdeveloped\\tthe\\tability\\tto\\trecognize\\tthis\\tpattern\\ton\\tsight.\\tShe\\ncouldn’t\\texplain\\twhat\\tit\\twas\\tthat\\tshe\\tnoticed\\tin\\ther\\tfather-in-law’s\\tface,\\tbut\\tshe\\nknew\\tsomething\\twas\\twrong.\\nSimilar\\tstories\\texist\\tin\\tother\\tfields.\\tFor\\texample,\\t\\nmilitary\\tanalysts\\tcan\\tidentify\\nwhich\\tblip\\ton\\ta\\tradar\\tscreen\\tis\\tan\\tenemy\\tmissile\\tand\\twhich\\tone\\tis\\ta\\tplane\\tfrom\\ntheir\\town\\tfleet\\teven\\tthough\\tthey\\tare\\ttraveling\\tat\\tthe\\tsame\\tspeed,\\tflying\\tat\\tthe\\nsame\\taltitude,\\tand\\tlook\\tidentical\\ton\\tradar\\tin\\tnearly\\tevery\\trespect.\\tDuring\\tthe\\nGulf\\tWar,\\tLieutenant\\tCommander\\tMichael\\tRiley\\tsaved\\tan\\tentire\\tbattleship\\nwhen\\the\\tordered\\ta\\tmissile\\tshot\\tdown—despite\\tthe\\tfact\\tthat\\tit\\tlooked\\texactly\\tlike\\nthe\\tbattleship’s\\town\\tplanes\\ton\\tradar.\\tHe\\tmade\\tthe\\tright\\tcall,\\tbut\\teven\\this\\nsuperior\\tofficers\\tcouldn’t\\texplain\\thow\\the\\tdid\\tit.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 51}), Document(page_content='Museum\\tcurators\\thave\\tbeen\\tknown\\tto\\tdiscern\\tthe\\tdifference\\tbetween\\tan\\nauthentic\\tpiece\\tof\\tart\\tand\\tan\\texpertly\\tproduced\\tcounterfeit\\teven\\tthough\\tthey\\ncan’t\\ttell\\tyou\\tprecisely\\twhich\\tdetails\\ttipped\\tthem\\toff.\\t\\nExperienced\\tradiologists\\ncan\\tlook\\tat\\ta\\tbrain\\tscan\\tand\\tpredict\\tthe\\tarea\\twhere\\ta\\tstroke\\twill\\tdevelop\\tbefore\\nany\\tobvious\\tsigns\\tare\\tvisible\\tto\\tthe\\tuntrained\\teye.\\tI’ve\\teven\\theard\\tof\\nhairdressers\\tnoticing\\twhether\\ta\\tclient\\tis\\tpregnant\\tbased\\tonly\\ton\\tthe\\tfeel\\tof\\ther\\nhair.\\nThe\\thuman\\tbrain\\tis\\ta\\tprediction\\tmachine.\\tIt\\tis\\tcontinuously\\ttaking\\tin\\tyour\\nsurroundings\\tand\\tanalyzing\\tthe\\tinformation\\tit\\tcomes\\tacross.\\tWhenever\\tyou\\nexperience\\tsomething\\trepeatedly—like\\ta\\tparamedic\\tseeing\\tthe\\tface\\tof\\ta\\theart\\nattack\\tpatient\\tor\\ta\\tmilitary\\tanalyst\\tseeing\\ta\\tmissile\\ton\\ta\\tradar\\tscreen—your\\tbrain\\nbegins\\tnoticing\\twhat\\tis\\timportant,\\tsorting\\tthrough\\tthe\\tdetails\\tand\\thighlighting\\nthe\\trelevant\\tcues,\\tand\\tcataloging\\tthat\\tinformation\\tfor\\tfuture\\tuse.\\nWith\\tenough\\tpractice,\\tyou\\tcan\\tpick\\tup\\ton\\tthe\\tcues\\tthat\\tpredict\\tcertain\\noutcomes\\twithout\\tconsciously\\tthinking\\tabout\\tit.\\tAutomatically,\\tyour\\tbrain\\nencodes\\tthe\\tlessons\\tlearned\\tthrough\\texperience.\\tWe\\tcan’t\\t\\nalways\\texplain\\twhat\\tit\\nis\\twe\\tare\\tlearning,\\tbut\\tlearning\\tis\\thappening\\tall\\talong\\tthe\\tway,\\tand\\tyour\\tability\\nto\\tnotice\\tthe\\trelevant\\tcues\\tin\\ta\\tgiven\\tsituation\\tis\\tthe\\tfoundation\\tfor\\tevery\\thabit\\nyou\\thave.\\nWe\\tunderestimate\\thow\\tmuch\\tour\\tbrains\\tand\\tbodies\\tcan\\tdo\\twithout\\tthinking.\\nYou\\tdo\\tnot\\ttell\\tyour\\thair\\tto\\tgrow,\\tyour\\theart\\tto\\tpump,\\tyour\\tlungs\\tto\\tbreathe,\\tor\\nyour\\tstomach\\tto\\tdigest.\\tAnd\\tyet\\tyour\\tbody\\thandles\\tall\\tthis\\tand\\tmore\\ton\\nautopilot.\\tYou\\tare\\tmuch\\tmore\\tthan\\tyour\\tconscious\\tself.\\nConsider\\thunger.\\tHow\\tdo\\tyou\\tknow\\twhen\\tyou’re\\thungry?\\tYou\\tdon’t\\nnecessarily\\thave\\tto\\tsee\\ta\\tcookie\\ton\\tthe\\tcounter\\tto\\trealize\\tthat\\tit\\tis\\ttime\\tto\\teat.\\nAppetite\\tand\\thunger\\tare\\tgoverned\\tnonconsciously.\\tYour\\tbody\\thas\\ta\\tvariety\\tof\\nfeedback\\tloops\\tthat\\tgradually\\talert\\tyou\\twhen\\tit\\tis\\ttime\\tto\\teat\\tagain\\tand\\tthat\\ttrack\\nwhat\\tis\\tgoing\\ton\\taround\\tyou\\tand\\twithin\\tyou.\\tCravings\\tcan\\tarise\\tthanks\\tto\\nhormones\\tand\\tchemicals\\tcirculating\\tthrough\\tyour\\tbody.\\tSuddenly,\\tyou’re\\nhungry\\teven\\tthough\\tyou’re\\tnot\\tquite\\tsure\\twhat\\ttipped\\tyou\\toff.\\nThis\\tis\\tone\\tof\\tthe\\tmost\\tsurprising\\tinsights\\tabout\\tour\\thabits:\\tyou\\tdon’t\\tneed\\tto\\nbe\\taware\\tof\\tthe\\tcue\\tfor\\ta\\thabit\\tto\\tbegin.\\tYou\\tcan\\tnotice\\tan\\topportunity\\tand\\ttake\\naction\\twithout\\tdedicating\\tconscious\\tattention\\tto\\tit.\\tThis\\tis\\twhat\\tmakes\\thabits\\nuseful.\\nIt’s\\talso\\twhat\\tmakes\\tthem\\tdangerous.\\tAs\\thabits\\tform,\\tyour\\tactions\\tcome\\nunder\\tthe\\tdirection\\tof\\tyour\\tautomatic\\tand\\tnonconscious\\tmind.\\tYou\\tfall\\tinto\\told\\npatterns\\tbefore\\tyou\\trealize\\twhat’s\\thappening.\\tUnless\\tsomeone\\tpoints\\tit\\tout,\\tyou\\nmay\\tnot\\tnotice\\tthat\\tyou\\tcover\\tyour\\tmouth\\twith\\tyour\\thand\\twhenever\\tyou\\tlaugh,\\nthat\\tyou\\tapologize\\tbefore\\tasking\\ta\\tquestion,\\tor\\tthat\\tyou\\thave\\ta\\thabit\\tof\\tfinishing', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 52}), Document(page_content='other\\tpeople’s\\tsentences.\\tAnd\\tthe\\tmore\\tyou\\trepeat\\tthese\\tpatterns,\\tthe\\tless\\tlikely\\nyou\\tbecome\\tto\\tquestion\\twhat\\tyou’re\\tdoing\\tand\\twhy\\tyou’re\\tdoing\\tit.\\nI\\tonce\\theard\\tof\\ta\\tretail\\tclerk\\twho\\twas\\tinstructed\\tto\\tcut\\tup\\tempty\\tgift\\tcards\\nafter\\tcustomers\\thad\\tused\\tup\\tthe\\tbalance\\ton\\tthe\\tcard.\\tOne\\tday,\\t\\nthe\\tclerk\\tcashed\\nout\\ta\\tfew\\tcustomers\\tin\\ta\\trow\\twho\\tpurchased\\twith\\tgift\\tcards.\\tWhen\\tthe\\tnext\\nperson\\twalked\\tup,\\t\\nthe\\tclerk\\tswiped\\tthe\\tcustomer’s\\tactual\\tcredit\\tcard,\\tpicked\\tup\\nthe\\tscissors,\\tand\\tthen\\tcut\\tit\\tin\\thalf—entirely\\ton\\tautopilot—before\\tlooking\\tup\\tat\\nthe\\tstunned\\tcustomer\\tand\\trealizing\\twhat\\thad\\tjust\\thappened.\\nAnother\\twoman\\tI\\tcame\\tacross\\tin\\tmy\\tresearch\\twas\\ta\\tformer\\tpreschool\\tteacher\\nwho\\thad\\tswitched\\tto\\ta\\tcorporate\\tjob.\\tEven\\tthough\\tshe\\twas\\tnow\\tworking\\twith\\nadults,\\ther\\told\\thabits\\twould\\tkick\\tin\\tand\\t\\nshe\\tkept\\tasking\\tcoworkers\\tif\\tthey\\thad\\nwashed\\ttheir\\thands\\tafter\\tgoing\\tto\\tthe\\tbathroom.\\tI\\talso\\tfound\\tthe\\t\\nstory\\tof\\ta\\tman\\nwho\\thad\\tspent\\tyears\\tworking\\tas\\ta\\tlifeguard\\tand\\twould\\toccasionally\\tyell\\t“Walk!”\\nwhenever\\the\\tsaw\\ta\\tchild\\trunning.\\nOver\\ttime,\\tthe\\tcues\\tthat\\tspark\\tour\\thabits\\tbecome\\tso\\tcommon\\tthat\\tthey\\tare\\nessentially\\tinvisible:\\tthe\\ttreats\\ton\\tthe\\tkitchen\\tcounter,\\tthe\\tremote\\tcontrol\\tnext\\tto\\nthe\\tcouch,\\tthe\\tphone\\tin\\tour\\tpocket.\\tOur\\tresponses\\tto\\tthese\\tcues\\tare\\tso\\tdeeply\\nencoded\\tthat\\tit\\tmay\\tfeel\\tlike\\tthe\\turge\\tto\\tact\\tcomes\\tfrom\\tnowhere.\\tFor\\tthis\\nreason,\\twe\\tmust\\tbegin\\tthe\\tprocess\\tof\\tbehavior\\tchange\\twith\\tawareness.\\nBefore\\twe\\tcan\\teffectively\\tbuild\\tnew\\thabits,\\twe\\tneed\\tto\\tget\\ta\\thandle\\ton\\tour\\ncurrent\\tones.\\tThis\\tcan\\tbe\\tmore\\tchallenging\\tthan\\tit\\tsounds\\tbecause\\tonce\\ta\\thabit\\tis\\nfirmly\\trooted\\tin\\tyour\\tlife,\\tit\\tis\\tmostly\\tnonconscious\\tand\\tautomatic.\\tIf\\ta\\thabit\\nremains\\tmindless,\\tyou\\tcan’t\\texpect\\tto\\timprove\\tit.\\tAs\\tthe\\tpsychologist\\tCarl\\tJung\\nsaid,\\t“\\nUntil\\tyou\\tmake\\tthe\\tunconscious\\tconscious,\\tit\\twill\\tdirect\\tyour\\tlife\\tand\\tyou\\nwill\\tcall\\tit\\tfate.”\\nTHE\\tHABITS\\tSCORECARD\\nThe\\tJapanese\\trailway\\tsystem\\tis\\tregarded\\tas\\tone\\tof\\tthe\\tbest\\tin\\tthe\\tworld.\\tIf\\tyou\\never\\tfind\\tyourself\\triding\\ta\\ttrain\\tin\\tTokyo,\\tyou’ll\\tnotice\\tthat\\tthe\\tconductors\\thave\\na\\tpeculiar\\thabit.\\nAs\\teach\\toperator\\truns\\tthe\\ttrain,\\tthey\\tproceed\\tthrough\\ta\\tritual\\tof\\tpointing\\tat\\ndifferent\\tobjects\\tand\\tcalling\\tout\\tcommands.\\tWhen\\tthe\\ttrain\\tapproaches\\ta\\tsignal,\\nthe\\toperator\\twill\\tpoint\\tat\\tit\\tand\\tsay,\\t“Signal\\tis\\tgreen.”\\tAs\\tthe\\ttrain\\tpulls\\tinto\\tand\\nout\\tof\\teach\\tstation,\\tthe\\toperator\\twill\\tpoint\\tat\\tthe\\tspeedometer\\tand\\tcall\\tout\\tthe\\nexact\\tspeed.\\tWhen\\tit’s\\ttime\\tto\\tleave,\\tthe\\toperator\\twill\\tpoint\\tat\\tthe\\ttimetable\\tand\\nstate\\tthe\\ttime.\\tOut\\ton\\tthe\\tplatform,\\tother\\temployees\\tare\\tperforming\\tsimilar\\nactions.\\tBefore\\teach\\ttrain\\tdeparts,\\tstaff\\tmembers\\twill\\tpoint\\talong\\tthe\\tedge\\tof\\tthe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 53}), Document(page_content='platform\\tand\\tdeclare,\\t“All\\tclear!”\\tEvery\\tdetail\\tis\\tidentified,\\tpointed\\tat,\\tand\\nnamed\\taloud.\\n*\\nThis\\tprocess,\\tknown\\tas\\t\\nPointing-and-Calling\\n,\\tis\\ta\\tsafety\\tsystem\\tdesigned\\tto\\nreduce\\tmistakes.\\tIt\\tseems\\tsilly,\\tbut\\tit\\tworks\\tincredibly\\twell.\\t\\nPointing-and-\\nCalling\\treduces\\terrors\\tby\\tup\\tto\\t85\\tpercent\\tand\\tcuts\\taccidents\\tby\\t30\\tpercent.\\t\\nThe\\nMTA\\tsubway\\tsystem\\tin\\tNew\\tYork\\tCity\\tadopted\\ta\\tmodified\\tversion\\tthat\\tis\\n“point-only,”\\tand\\t“within\\ttwo\\tyears\\tof\\timplementation,\\tincidents\\tof\\tincorrectly\\nberthed\\tsubways\\tfell\\t57\\tpercent.”\\nPointing-and-Calling\\tis\\tso\\teffective\\tbecause\\tit\\traises\\tthe\\tlevel\\tof\\tawareness\\nfrom\\ta\\tnonconscious\\thabit\\tto\\ta\\tmore\\tconscious\\tlevel.\\tBecause\\tthe\\ttrain\\toperators\\nmust\\tuse\\ttheir\\teyes,\\thands,\\tmouth,\\tand\\tears,\\tthey\\tare\\tmore\\tlikely\\tto\\tnotice\\nproblems\\tbefore\\tsomething\\tgoes\\twrong.\\nMy\\twife\\tdoes\\tsomething\\tsimilar.\\tWhenever\\twe\\tare\\tpreparing\\tto\\twalk\\tout\\tthe\\ndoor\\tfor\\ta\\ttrip,\\tshe\\tverbally\\tcalls\\tout\\tthe\\tmost\\tessential\\t\\nitems\\tin\\ther\\tpacking\\tlist.\\n“I’ve\\tgot\\tmy\\tkeys.\\tI’ve\\tgot\\tmy\\twallet.\\tI’ve\\tgot\\tmy\\tglasses.\\tI’ve\\tgot\\tmy\\nhusband.”\\nThe\\tmore\\tautomatic\\ta\\tbehavior\\tbecomes,\\tthe\\tless\\tlikely\\twe\\tare\\tto\\tconsciously\\nthink\\tabout\\tit.\\tAnd\\twhen\\twe’ve\\tdone\\tsomething\\ta\\tthousand\\ttimes\\tbefore,\\twe\\nbegin\\tto\\toverlook\\tthings.\\tWe\\tassume\\tthat\\tthe\\tnext\\ttime\\twill\\tbe\\tjust\\tlike\\tthe\\tlast.\\nWe’re\\tso\\tused\\tto\\tdoing\\twhat\\twe’ve\\talways\\tdone\\tthat\\twe\\tdon’t\\tstop\\tto\\tquestion\\nwhether\\tit’s\\tthe\\tright\\tthing\\tto\\tdo\\tat\\tall.\\tMany\\tof\\tour\\tfailures\\tin\\tperformance\\tare\\nlargely\\tattributable\\tto\\ta\\tlack\\tof\\tself-awareness.\\nOne\\tof\\tour\\tgreatest\\tchallenges\\tin\\tchanging\\thabits\\tis\\tmaintaining\\tawareness\\tof\\nwhat\\twe\\tare\\tactually\\tdoing.\\tThis\\thelps\\texplain\\twhy\\tthe\\tconsequences\\tof\\tbad\\nhabits\\tcan\\tsneak\\tup\\ton\\tus.\\tWe\\tneed\\ta\\t“point-and-call”\\tsystem\\tfor\\tour\\tpersonal\\nlives.\\tThat’s\\tthe\\torigin\\tof\\tthe\\tHabits\\tScorecard,\\twhich\\tis\\ta\\tsimple\\texercise\\tyou\\ncan\\tuse\\tto\\tbecome\\tmore\\taware\\tof\\tyour\\tbehavior.\\tTo\\tcreate\\tyour\\town,\\tmake\\ta\\tlist\\nof\\tyour\\tdaily\\thabits.\\nHere’s\\ta\\tsample\\tof\\twhere\\tyour\\tlist\\tmight\\tstart:\\nWake\\tup\\nTurn\\toff\\talarm\\nCheck\\tmy\\tphone\\nGo\\tto\\tthe\\tbathroom\\nWeigh\\tmyself\\nTake\\ta\\tshower\\nBrush\\tmy\\tteeth\\nFloss\\tmy\\tteeth', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 54}), Document(page_content='Put\\ton\\tdeodorant\\nHang\\tup\\ttowel\\tto\\tdry\\nGet\\tdressed\\nMake\\ta\\tcup\\tof\\ttea\\n.\\t.\\t.\\tand\\tso\\ton.\\nOnce\\tyou\\thave\\ta\\tfull\\tlist,\\tlook\\tat\\teach\\tbehavior,\\tand\\task\\tyourself,\\t“Is\\tthis\\ta\\ngood\\thabit,\\ta\\tbad\\thabit,\\tor\\ta\\tneutral\\thabit?”\\tIf\\tit\\tis\\ta\\tgood\\thabit,\\twrite\\t“+”\\tnext\\tto\\nit.\\tIf\\tit\\tis\\ta\\tbad\\thabit,\\twrite\\t“–”.\\tIf\\tit\\tis\\ta\\tneutral\\thabit,\\twrite\\t“=”.\\nFor\\texample,\\tthe\\tlist\\tabove\\tmight\\tlook\\tlike\\tthis:\\nWake\\tup\\t=\\nTurn\\toff\\talarm\\t=\\nCheck\\tmy\\tphone\\t–\\nGo\\tto\\tthe\\tbathroom\\t=\\nWeigh\\tmyself\\t+\\nTake\\ta\\tshower\\t+\\nBrush\\tmy\\tteeth\\t+\\nFloss\\tmy\\tteeth\\t+\\nPut\\ton\\tdeodorant\\t+\\nHang\\tup\\ttowel\\tto\\tdry\\t=\\nGet\\tdressed\\t=\\nMake\\ta\\tcup\\tof\\ttea\\t+\\nThe\\tmarks\\tyou\\tgive\\tto\\ta\\tparticular\\thabit\\twill\\tdepend\\ton\\tyour\\tsituation\\tand\\nyour\\tgoals.\\tFor\\tsomeone\\twho\\tis\\ttrying\\tto\\tlose\\tweight,\\teating\\ta\\tbagel\\twith\\tpeanut\\nbutter\\tevery\\tmorning\\tmight\\tbe\\ta\\tbad\\thabit.\\tFor\\tsomeone\\twho\\tis\\ttrying\\tto\\tbulk\\tup\\nand\\tadd\\tmuscle,\\tthe\\tsame\\tbehavior\\tmight\\tbe\\ta\\tgood\\thabit.\\tIt\\tall\\tdepends\\ton\\twhat\\nyou’re\\tworking\\ttoward.\\n*\\nScoring\\tyour\\thabits\\tcan\\tbe\\ta\\tbit\\tmore\\tcomplex\\tfor\\tanother\\treason\\tas\\twell.\\tThe\\nlabels\\t“good\\thabit”\\tand\\t“bad\\thabit”\\tare\\tslightly\\tinaccurate.\\tThere\\tare\\tno\\tgood\\nhabits\\tor\\tbad\\thabits.\\tThere\\tare\\tonly\\teffective\\thabits.\\tThat\\tis,\\teffective\\tat\\tsolving\\nproblems.\\tAll\\thabits\\tserve\\tyou\\tin\\tsome\\tway—even\\tthe\\tbad\\tones—which\\tis\\twhy\\nyou\\trepeat\\tthem.\\tFor\\tthis\\texercise,\\tcategorize\\tyour\\thabits\\tby\\thow\\tthey\\twill\\nbenefit\\tyou\\tin\\tthe\\tlong\\trun.\\tGenerally\\tspeaking,\\tgood\\thabits\\twill\\thave\\tnet\\npositive\\toutcomes.\\tBad\\thabits\\thave\\tnet\\tnegative\\toutcomes.\\tSmoking\\ta\\tcigarette', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 55}), Document(page_content='may\\treduce\\tstress\\tright\\tnow\\t(that’s\\thow\\tit’s\\tserving\\tyou),\\tbut\\tit’s\\tnot\\ta\\thealthy\\nlong-term\\tbehavior.\\nIf\\tyou’re\\tstill\\thaving\\ttrouble\\tdetermining\\thow\\tto\\trate\\ta\\tparticular\\thabit,\\there\\tis\\na\\tquestion\\tI\\tlike\\tto\\tuse:\\t“Does\\tthis\\tbehavior\\thelp\\tme\\tbecome\\tthe\\ttype\\tof\\tperson\\tI\\nwish\\tto\\tbe?\\tDoes\\tthis\\thabit\\tcast\\ta\\tvote\\tfor\\tor\\tagainst\\tmy\\tdesired\\tidentity?”\\nHabits\\tthat\\treinforce\\tyour\\tdesired\\tidentity\\tare\\tusually\\tgood.\\tHabits\\tthat\\tconflict\\nwith\\tyour\\tdesired\\tidentity\\tare\\tusually\\tbad.\\nAs\\tyou\\tcreate\\tyour\\tHabits\\tScorecard,\\tthere\\tis\\tno\\tneed\\tto\\tchange\\tanything\\tat\\nfirst.\\tThe\\tgoal\\tis\\tto\\tsimply\\tnotice\\twhat\\tis\\tactually\\tgoing\\ton.\\tObserve\\tyour\\nthoughts\\tand\\tactions\\twithout\\tjudgment\\tor\\tinternal\\t\\ncriticism.\\tDon’t\\tblame\\nyourself\\tfor\\tyour\\tfaults.\\tDon’t\\tpraise\\tyourself\\tfor\\tyour\\tsuccesses.\\nIf\\tyou\\teat\\ta\\tchocolate\\tbar\\tevery\\tmorning,\\tacknowledge\\tit,\\talmost\\tas\\tif\\tyou\\nwere\\twatching\\tsomeone\\telse.\\t\\nOh,\\thow\\tinteresting\\tthat\\tthey\\twould\\tdo\\tsuch\\ta\\nthing.\\n\\tIf\\tyou\\tbinge-eat,\\tsimply\\tnotice\\tthat\\tyou\\tare\\teating\\tmore\\tcalories\\tthan\\tyou\\nshould.\\tIf\\tyou\\twaste\\ttime\\tonline,\\tnotice\\tthat\\tyou\\tare\\tspending\\tyour\\tlife\\tin\\ta\\tway\\nthat\\tyou\\tdo\\tnot\\twant\\tto.\\nThe\\tfirst\\tstep\\tto\\tchanging\\tbad\\thabits\\tis\\tto\\tbe\\ton\\tthe\\tlookout\\tfor\\tthem.\\tIf\\tyou\\nfeel\\tlike\\tyou\\tneed\\textra\\thelp,\\tthen\\tyou\\tcan\\ttry\\tPointing-and-Calling\\tin\\tyour\\town\\nlife.\\tSay\\tout\\tloud\\tthe\\taction\\tthat\\tyou\\tare\\tthinking\\tof\\ttaking\\tand\\twhat\\tthe\\toutcome\\nwill\\tbe.\\tIf\\tyou\\twant\\tto\\tcut\\tback\\ton\\tyour\\tjunk\\tfood\\thabit\\tbut\\tnotice\\tyourself\\ngrabbing\\tanother\\tcookie,\\tsay\\tout\\tloud,\\t“I’m\\tabout\\tto\\teat\\tthis\\tcookie,\\tbut\\tI\\tdon’t\\nneed\\tit.\\tEating\\tit\\twill\\tcause\\tme\\tto\\tgain\\tweight\\tand\\thurt\\tmy\\thealth.”\\nHearing\\tyour\\tbad\\thabits\\tspoken\\taloud\\tmakes\\tthe\\tconsequences\\tseem\\tmore\\nreal.\\tIt\\tadds\\tweight\\tto\\tthe\\taction\\trather\\tthan\\tletting\\tyourself\\tmindlessly\\tslip\\tinto\\nan\\told\\troutine.\\tThis\\tapproach\\tis\\tuseful\\teven\\tif\\tyou’re\\tsimply\\ttrying\\tto\\tremember\\na\\ttask\\ton\\tyour\\tto-do\\tlist.\\tJust\\tsaying\\tout\\tloud,\\t“Tomorrow,\\tI\\tneed\\tto\\tgo\\tto\\tthe\\npost\\toffice\\tafter\\tlunch,”\\tincreases\\tthe\\todds\\tthat\\tyou’ll\\tactually\\tdo\\tit.\\tYou’re\\ngetting\\tyourself\\tto\\tacknowledge\\tthe\\tneed\\tfor\\taction—and\\tthat\\tcan\\tmake\\tall\\tthe\\ndifference.\\nThe\\tprocess\\tof\\tbehavior\\tchange\\talways\\tstarts\\twith\\tawareness.\\tStrategies\\tlike\\nPointing-and-Calling\\tand\\tthe\\tHabits\\tScorecard\\tare\\tfocused\\ton\\tgetting\\tyou\\tto\\nrecognize\\tyour\\thabits\\tand\\tacknowledge\\tthe\\tcues\\tthat\\ttrigger\\tthem,\\twhich\\tmakes\\nit\\tpossible\\tto\\trespond\\tin\\ta\\tway\\tthat\\tbenefits\\tyou.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 56}), Document(page_content='Chapter\\tSummary\\nWith\\tenough\\tpractice,\\tyour\\tbrain\\twill\\tpick\\tup\\ton\\tthe\\tcues\\tthat\\tpredict\\ncertain\\toutcomes\\twithout\\tconsciously\\tthinking\\tabout\\tit.\\nOnce\\tour\\thabits\\tbecome\\tautomatic,\\twe\\tstop\\tpaying\\tattention\\tto\\twhat\\nwe\\tare\\tdoing.\\nThe\\tprocess\\tof\\tbehavior\\tchange\\talways\\tstarts\\twith\\tawareness.\\tYou\\nneed\\tto\\tbe\\taware\\tof\\tyour\\thabits\\tbefore\\tyou\\tcan\\tchange\\tthem.\\nPointing-and-Calling\\traises\\tyour\\tlevel\\tof\\tawareness\\tfrom\\ta\\nnonconscious\\thabit\\tto\\ta\\tmore\\tconscious\\tlevel\\tby\\tverbalizing\\tyour\\nactions.\\nThe\\tHabits\\tScorecard\\tis\\ta\\tsimple\\texercise\\tyou\\tcan\\tuse\\tto\\tbecome\\tmore\\naware\\tof\\tyour\\tbehavior.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 57}), Document(page_content='5\\nThe\\tBest\\tWay\\tto\\tStart\\ta\\tNew\\tHabit\\nI\\nN\\t2001\\n,\\t\\nRESEARCHERS\\t\\nin\\tGreat\\tBritain\\tbegan\\tworking\\twith\\t248\\tpeople\\tto\\tbuild\\tbetter\\nexercise\\thabits\\tover\\tthe\\tcourse\\tof\\ttwo\\tweeks.\\tThe\\tsubjects\\twere\\tdivided\\tinto\\nthree\\tgroups.\\nThe\\tfirst\\tgroup\\twas\\tthe\\tcontrol\\tgroup.\\tThey\\twere\\tsimply\\tasked\\tto\\ttrack\\thow\\noften\\tthey\\texercised.\\nThe\\tsecond\\tgroup\\twas\\tthe\\t“motivation”\\tgroup.\\tThey\\twere\\tasked\\tnot\\tonly\\tto\\ntrack\\ttheir\\tworkouts\\tbut\\talso\\tto\\tread\\tsome\\tmaterial\\ton\\tthe\\tbenefits\\tof\\texercise.\\nThe\\tresearchers\\talso\\texplained\\tto\\tthe\\tgroup\\thow\\texercise\\tcould\\treduce\\tthe\\trisk\\nof\\tcoronary\\theart\\tdisease\\tand\\timprove\\theart\\thealth.\\nFinally,\\tthere\\twas\\tthe\\tthird\\tgroup.\\tThese\\tsubjects\\treceived\\tthe\\tsame\\npresentation\\tas\\tthe\\tsecond\\tgroup,\\twhich\\tensured\\tthat\\tthey\\thad\\tequal\\tlevels\\tof\\nmotivation.\\tHowever,\\tthey\\twere\\talso\\tasked\\tto\\tformulate\\ta\\tplan\\tfor\\twhen\\tand\\nwhere\\tthey\\twould\\texercise\\tover\\tthe\\tfollowing\\tweek.\\tSpecifically,\\teach\\tmember\\nof\\tthe\\tthird\\tgroup\\tcompleted\\tthe\\tfollowing\\tsentence:\\t“During\\tthe\\tnext\\tweek,\\tI\\nwill\\tpartake\\tin\\tat\\tleast\\t20\\tminutes\\tof\\tvigorous\\texercise\\ton\\t[DAY]\\tat\\t[TIME]\\tin\\n[PLACE].”\\nIn\\tthe\\tfirst\\tand\\tsecond\\tgroups,\\t35\\tto\\t38\\tpercent\\tof\\tpeople\\texercised\\t\\nat\\tleast\\nonce\\tper\\tweek.\\t(Interestingly,\\tthe\\tmotivational\\tpresentation\\tgiven\\tto\\tthe\\tsecond\\ngroup\\tseemed\\tto\\thave\\tno\\tmeaningful\\timpact\\ton\\tbehavior.)\\tBut\\t91\\tpercent\\tof\\tthe\\nthird\\tgroup\\texercised\\tat\\tleast\\tonce\\tper\\tweek—more\\tthan\\tdouble\\tthe\\tnormal\\trate.\\nThe\\tsentence\\tthey\\tfilled\\tout\\tis\\twhat\\tresearchers\\trefer\\tto\\tas\\tan\\t\\nimplementation\\nintention\\n,\\twhich\\tis\\ta\\tplan\\tyou\\tmake\\tbeforehand\\tabout\\twhen\\tand\\twhere\\tto\\tact.\\nThat\\tis,\\thow\\tyou\\t\\nintend\\n\\tto\\t\\nimplement\\n\\ta\\tparticular\\thabit.\\nThe\\tcues\\tthat\\tcan\\ttrigger\\ta\\thabit\\tcome\\tin\\ta\\twide\\trange\\tof\\tforms—the\\tfeel\\tof\\nyour\\tphone\\tbuzzing\\tin\\tyour\\tpocket,\\tthe\\tsmell\\tof\\tchocolate\\tchip\\tcookies,\\tthe\\nsound\\tof\\tambulance\\tsirens—but\\tthe\\ttwo\\tmost\\tcommon\\tcues\\tare\\ttime\\tand\\nlocation.\\tImplementation\\tintentions\\tleverage\\tboth\\tof\\tthese\\tcues.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 58}), Document(page_content='Broadly\\tspeaking,\\tthe\\tformat\\tfor\\tcreating\\tan\\timplementation\\tintention\\tis:\\n“When\\tsituation\\tX\\tarises,\\tI\\twill\\tperform\\tresponse\\tY.”\\nHundreds\\tof\\tstudies\\thave\\tshown\\tthat\\t\\nimplementation\\tintentions\\tare\\teffective\\nfor\\tsticking\\tto\\tour\\tgoals,\\twhether\\tit’s\\t\\nwriting\\tdown\\tthe\\texact\\ttime\\tand\\tdate\\tof\\nwhen\\tyou\\twill\\tget\\ta\\tflu\\tshot\\tor\\t\\nrecording\\tthe\\ttime\\tof\\tyour\\tcolonoscopy\\nappointment.\\tThey\\tincrease\\tthe\\todds\\tthat\\tpeople\\twill\\tstick\\twith\\thabits\\tlike\\nrecycling,\\tstudying,\\tgoing\\tto\\tsleep\\tearly,\\tand\\tstopping\\tsmoking.\\nResearchers\\thave\\teven\\tfound\\tthat\\t\\nvoter\\tturnout\\tincreases\\twhen\\tpeople\\tare\\nforced\\tto\\tcreate\\timplementation\\tintentions\\tby\\tanswering\\tquestions\\tlike:\\t“What\\nroute\\tare\\tyou\\ttaking\\tto\\tthe\\tpolling\\tstation?\\tAt\\twhat\\ttime\\tare\\tyou\\tplanning\\tto\\tgo?\\nWhat\\tbus\\twill\\tget\\tyou\\tthere?”\\t\\nOther\\tsuccessful\\tgovernment\\tprograms\\thave\\nprompted\\tcitizens\\tto\\tmake\\ta\\tclear\\tplan\\tto\\tsend\\ttaxes\\tin\\ton\\ttime\\tor\\tprovided\\ndirections\\ton\\twhen\\tand\\twhere\\tto\\tpay\\tlate\\ttraffic\\tbills.\\nThe\\tpunch\\tline\\tis\\tclear:\\t\\npeople\\twho\\tmake\\ta\\tspecific\\tplan\\tfor\\twhen\\t\\nand\\twhere\\nthey\\twill\\tperform\\ta\\tnew\\thabit\\tare\\tmore\\tlikely\\tto\\tfollow\\tthrough.\\tToo\\tmany\\npeople\\ttry\\tto\\tchange\\ttheir\\thabits\\twithout\\tthese\\tbasic\\tdetails\\tfigured\\tout.\\tWe\\ttell\\nourselves,\\t“I’m\\tgoing\\tto\\teat\\thealthier”\\tor\\t“I’m\\tgoing\\tto\\twrite\\tmore,”\\tbut\\twe\\nnever\\tsay\\twhen\\tand\\twhere\\tthese\\thabits\\tare\\tgoing\\tto\\thappen.\\tWe\\tleave\\tit\\tup\\tto\\nchance\\tand\\thope\\tthat\\twe\\twill\\t“just\\tremember\\tto\\tdo\\tit”\\tor\\tfeel\\tmotivated\\tat\\tthe\\nright\\ttime.\\tAn\\timplementation\\tintention\\tsweeps\\taway\\tfoggy\\tnotions\\tlike\\t“I\\twant\\nto\\twork\\tout\\tmore”\\tor\\t“I\\twant\\tto\\tbe\\tmore\\tproductive”\\tor\\t“I\\tshould\\tvote”\\tand\\ntransforms\\tthem\\tinto\\ta\\tconcrete\\tplan\\tof\\taction.\\nMany\\tpeople\\tthink\\tthey\\tlack\\tmotivation\\twhen\\twhat\\tthey\\treally\\tlack\\tis\\tclarity.\\nIt\\tis\\tnot\\talways\\tobvious\\twhen\\tand\\twhere\\tto\\ttake\\taction.\\tSome\\tpeople\\tspend\\ttheir\\nentire\\tlives\\twaiting\\tfor\\tthe\\ttime\\tto\\tbe\\tright\\tto\\tmake\\tan\\timprovement.\\nOnce\\tan\\timplementation\\tintention\\thas\\tbeen\\tset,\\tyou\\tdon’t\\thave\\tto\\twait\\tfor\\ninspiration\\tto\\tstrike.\\t\\nDo\\tI\\twrite\\ta\\tchapter\\ttoday\\tor\\tnot?\\tDo\\tI\\tmeditate\\tthis\\nmorning\\tor\\tat\\tlunch?\\n\\tWhen\\tthe\\tmoment\\tof\\taction\\toccurs,\\tthere\\tis\\tno\\tneed\\tto\\nmake\\ta\\tdecision.\\tSimply\\tfollow\\tyour\\tpredetermined\\tplan.\\nThe\\tsimple\\tway\\tto\\tapply\\tthis\\tstrategy\\tto\\tyour\\thabits\\tis\\tto\\tfill\\tout\\tthis\\nsentence:\\nI\\twill\\t[BEHAVIOR]\\tat\\t[TIME]\\tin\\t[LOCATION].\\nMeditation.\\tI\\twill\\tmeditate\\tfor\\tone\\tminute\\tat\\t7\\ta.m.\\tin\\tmy\\tkitchen.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 59}), Document(page_content='Studying.\\tI\\twill\\tstudy\\tSpanish\\tfor\\ttwenty\\tminutes\\tat\\t6\\tp.m.\\tin\\tmy\\nbedroom.\\nExercise.\\tI\\twill\\texercise\\tfor\\tone\\thour\\tat\\t5\\tp.m.\\tin\\tmy\\tlocal\\tgym.\\nMarriage.\\tI\\twill\\tmake\\tmy\\tpartner\\ta\\tcup\\tof\\ttea\\tat\\t8\\ta.m.\\tin\\tthe\\tkitchen.\\nIf\\tyou\\taren’t\\tsure\\twhen\\tto\\tstart\\tyour\\thabit,\\ttry\\tthe\\tfirst\\tday\\tof\\tthe\\tweek,\\nmonth,\\tor\\tyear.\\tPeople\\tare\\tmore\\tlikely\\tto\\ttake\\taction\\tat\\tthose\\t\\ntimes\\tbecause\\t\\nhope\\nis\\tusually\\thigher.\\tIf\\twe\\thave\\thope,\\twe\\thave\\ta\\treason\\tto\\ttake\\taction.\\tA\\tfresh\\tstart\\nfeels\\tmotivating.\\nThere\\tis\\tanother\\tbenefit\\tto\\timplementation\\tintentions.\\tBeing\\tspecific\\tabout\\nwhat\\tyou\\twant\\tand\\thow\\tyou\\twill\\tachieve\\tit\\thelps\\tyou\\tsay\\tno\\tto\\tthings\\tthat\\tderail\\nprogress,\\tdistract\\tyour\\tattention,\\tand\\tpull\\tyou\\toff\\tcourse.\\tWe\\toften\\tsay\\tyes\\tto\\nlittle\\trequests\\tbecause\\twe\\tare\\tnot\\tclear\\tenough\\tabout\\twhat\\twe\\tneed\\tto\\tbe\\tdoing\\ninstead.\\tWhen\\tyour\\tdreams\\tare\\tvague,\\tit’s\\teasy\\tto\\trationalize\\tlittle\\texceptions\\tall\\nday\\tlong\\tand\\tnever\\tget\\taround\\tto\\tthe\\tspecific\\tthings\\tyou\\tneed\\tto\\tdo\\tto\\tsucceed.\\nGive\\tyour\\thabits\\ta\\ttime\\tand\\ta\\tspace\\tto\\tlive\\tin\\tthe\\tworld.\\tThe\\tgoal\\tis\\tto\\tmake\\nthe\\ttime\\tand\\tlocation\\tso\\tobvious\\tthat,\\twith\\tenough\\trepetition,\\tyou\\tget\\tan\\turge\\tto\\ndo\\tthe\\tright\\tthing\\tat\\tthe\\tright\\ttime,\\teven\\tif\\tyou\\tcan’t\\tsay\\twhy.\\tAs\\tthe\\t\\nwriter\\nJason\\tZweig\\tnoted,\\t“Obviously\\tyou’re\\tnever\\tgoing\\tto\\tjust\\twork\\tout\\twithout\\nconscious\\tthought.\\tBut\\tlike\\ta\\tdog\\tsalivating\\tat\\ta\\tbell,\\tmaybe\\tyou\\tstart\\tto\\tget\\nantsy\\taround\\tthe\\ttime\\tof\\tday\\tyou\\tnormally\\twork\\tout.”\\nThere\\tare\\t\\nmany\\tways\\tto\\tuse\\timplementation\\tintentions\\tin\\tyour\\tlife\\tand\\twork.\\nMy\\tfavorite\\tapproach\\tis\\tone\\tI\\tlearned\\tfrom\\tStanford\\tprofessor\\tBJ\\tFogg\\tand\\tit\\tis\\na\\tstrategy\\tI\\trefer\\tto\\tas\\t\\nhabit\\tstacking\\n.\\nHABIT\\tSTACKING:\\tA\\tSIMPLE\\tPLAN\\tTO\\tOVERHAUL\\tYOUR\\tHABITS\\nThe\\tFrench\\tphilosopher\\tDenis\\tDiderot\\tlived\\tnearly\\this\\tentire\\tlife\\tin\\tpoverty,\\tbut\\nthat\\tall\\tchanged\\tone\\tday\\tin\\t1765.\\nDiderot’s\\tdaughter\\twas\\tabout\\tto\\tbe\\tmarried\\tand\\the\\tcould\\tnot\\tafford\\tto\\tpay\\tfor\\nthe\\twedding.\\tDespite\\this\\tlack\\tof\\twealth,\\tDiderot\\twas\\twell\\tknown\\tfor\\this\\trole\\tas\\nthe\\tco-founder\\tand\\twriter\\tof\\t\\nEncyclopédie\\n,\\tone\\tof\\tthe\\tmost\\tcomprehensive\\nencyclopedias\\tof\\tthe\\ttime.\\tWhen\\tCatherine\\tthe\\tGreat,\\tthe\\tEmpress\\tof\\tRussia,\\nheard\\tof\\tDiderot’s\\tfinancial\\ttroubles,\\ther\\theart\\twent\\tout\\tto\\thim.\\tShe\\twas\\ta\\tbook\\nlover\\tand\\tgreatly\\tenjoyed\\this\\tencyclopedia.\\tShe\\toffered\\tto\\tbuy\\tDiderot’s\\npersonal\\tlibrary\\tfor\\t\\n£1,000—more\\tthan\\t$150,000\\ttoday.\\n*\\n\\tSuddenly,\\tDiderot\\thad\\nmoney\\tto\\tspare.\\tWith\\this\\tnew\\twealth,\\the\\tnot\\tonly\\tpaid\\tfor\\tthe\\twedding\\tbut\\talso', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 60}), Document(page_content='acquired\\ta\\tscarlet\\trobe\\tfor\\thimself.\\nDiderot’s\\tscarlet\\trobe\\twas\\tbeautiful.\\tSo\\tbeautiful,\\tin\\tfact,\\tthat\\the\\timmediately\\nnoticed\\thow\\tout\\tof\\tplace\\tit\\tseemed\\twhen\\tsurrounded\\tby\\this\\tmore\\tcommon\\npossessions.\\tHe\\twrote\\tthat\\tthere\\twas\\t“\\nno\\tmore\\tcoordination,\\tno\\tmore\\tunity,\\tno\\nmore\\tbeauty”\\tbetween\\this\\telegant\\trobe\\tand\\tthe\\trest\\tof\\this\\tstuff.\\nDiderot\\tsoon\\tfelt\\tthe\\turge\\tto\\tupgrade\\this\\tpossessions.\\tHe\\treplaced\\this\\trug\\twith\\none\\tfrom\\tDamascus.\\tHe\\tdecorated\\this\\thome\\twith\\texpensive\\tsculptures.\\tHe\\nbought\\ta\\tmirror\\tto\\tplace\\tabove\\tthe\\tmantel,\\tand\\ta\\tbetter\\tkitchen\\ttable.\\tHe\\ttossed\\naside\\this\\told\\tstraw\\tchair\\tfor\\ta\\tleather\\tone.\\tLike\\tfalling\\tdominoes,\\tone\\tpurchase\\nled\\tto\\tthe\\tnext.\\nDiderot’s\\tbehavior\\tis\\tnot\\tuncommon.\\tIn\\tfact,\\tthe\\ttendency\\tfor\\tone\\tpurchase\\tto\\nlead\\tto\\tanother\\tone\\thas\\ta\\tname:\\tthe\\tDiderot\\tEffect.\\t\\nThe\\tDiderot\\tEffect\\tstates\\tthat\\nobtaining\\ta\\tnew\\tpossession\\toften\\tcreates\\ta\\tspiral\\tof\\tconsumption\\tthat\\tleads\\tto\\nadditional\\tpurchases.\\nYou\\tcan\\tspot\\tthis\\tpattern\\teverywhere.\\tYou\\tbuy\\ta\\tdress\\tand\\thave\\tto\\tget\\tnew\\nshoes\\tand\\tearrings\\tto\\tmatch.\\tYou\\tbuy\\ta\\tcouch\\tand\\tsuddenly\\tquestion\\tthe\\tlayout\\nof\\tyour\\tentire\\tliving\\troom.\\tYou\\tbuy\\ta\\ttoy\\tfor\\tyour\\tchild\\tand\\tsoon\\tfind\\tyourself\\npurchasing\\tall\\tof\\tthe\\taccessories\\tthat\\tgo\\twith\\tit.\\tIt’s\\ta\\tchain\\treaction\\tof\\npurchases.\\nMany\\thuman\\tbehaviors\\tfollow\\tthis\\tcycle.\\tYou\\toften\\tdecide\\twhat\\tto\\tdo\\tnext\\nbased\\ton\\twhat\\tyou\\thave\\tjust\\tfinished\\tdoing.\\tGoing\\tto\\tthe\\tbathroom\\tleads\\tto\\nwashing\\tand\\tdrying\\tyour\\thands,\\twhich\\treminds\\tyou\\tthat\\tyou\\tneed\\tto\\tput\\tthe\\ndirty\\ttowels\\tin\\tthe\\tlaundry,\\tso\\tyou\\tadd\\tlaundry\\tdetergent\\tto\\tthe\\tshopping\\tlist,\\tand\\nso\\ton.\\tNo\\tbehavior\\thappens\\tin\\tisolation.\\tEach\\taction\\tbecomes\\ta\\tcue\\tthat\\ttriggers\\nthe\\tnext\\tbehavior.\\nWhy\\tis\\tthis\\timportant?\\nWhen\\tit\\tcomes\\tto\\tbuilding\\tnew\\thabits,\\tyou\\tcan\\tuse\\tthe\\tconnectedness\\tof\\nbehavior\\tto\\tyour\\tadvantage.\\tOne\\tof\\tthe\\tbest\\tways\\tto\\tbuild\\ta\\tnew\\thabit\\tis\\tto\\nidentify\\ta\\tcurrent\\thabit\\tyou\\talready\\tdo\\teach\\tday\\tand\\tthen\\tstack\\tyour\\tnew\\nbehavior\\ton\\ttop.\\tThis\\tis\\tcalled\\t\\nhabit\\tstacking\\n.\\nHabit\\tstacking\\tis\\ta\\tspecial\\tform\\tof\\tan\\timplementation\\tintention.\\tRather\\tthan\\npairing\\tyour\\tnew\\thabit\\twith\\ta\\tparticular\\ttime\\tand\\tlocation,\\tyou\\tpair\\tit\\twith\\ta\\ncurrent\\thabit.\\tThis\\tmethod,\\t\\nwhich\\twas\\tcreated\\tby\\tBJ\\tFogg\\tas\\tpart\\tof\\this\\tTiny\\nHabits\\tprogram,\\tcan\\tbe\\tused\\tto\\tdesign\\tan\\tobvious\\tcue\\tfor\\tnearly\\tany\\thabit.\\n*\\nThe\\thabit\\tstacking\\tformula\\tis:\\n“After\\t[CURRENT\\tHABIT],\\tI\\twill\\t[NEW\\tHABIT].”', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 61}), Document(page_content='For\\texample:\\nMeditation.\\tAfter\\tI\\tpour\\tmy\\tcup\\tof\\tcoffee\\teach\\tmorning,\\tI\\twill\\nmeditate\\tfor\\tone\\tminute.\\nExercise.\\tAfter\\tI\\ttake\\toff\\tmy\\twork\\tshoes,\\tI\\twill\\timmediately\\tchange\\ninto\\tmy\\tworkout\\tclothes.\\nGratitude.\\tAfter\\tI\\tsit\\tdown\\tto\\tdinner,\\tI\\twill\\tsay\\tone\\tthing\\tI’m\\tgrateful\\nfor\\tthat\\thappened\\ttoday.\\nMarriage.\\tAfter\\tI\\tget\\tinto\\tbed\\tat\\tnight,\\tI\\twill\\tgive\\tmy\\tpartner\\ta\\tkiss.\\nSafety.\\tAfter\\tI\\tput\\ton\\tmy\\trunning\\tshoes,\\tI\\twill\\ttext\\ta\\tfriend\\tor\\tfamily\\nmember\\twhere\\tI\\tam\\trunning\\tand\\thow\\tlong\\tit\\twill\\ttake.\\nThe\\tkey\\tis\\tto\\ttie\\tyour\\tdesired\\tbehavior\\tinto\\tsomething\\tyou\\talready\\tdo\\teach\\nday.\\tOnce\\tyou\\thave\\tmastered\\tthis\\tbasic\\tstructure,\\tyou\\tcan\\tbegin\\tto\\tcreate\\tlarger\\nstacks\\tby\\tchaining\\tsmall\\thabits\\ttogether.\\tThis\\tallows\\tyou\\tto\\t\\ntake\\tadvantage\\tof\\nthe\\tnatural\\tmomentum\\tthat\\tcomes\\tfrom\\tone\\tbehavior\\tleading\\tinto\\tthe\\tnext—a\\npositive\\tversion\\tof\\tthe\\tDiderot\\tEffect.\\nHABIT\\tSTACKING', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 62}), Document(page_content='FIGURE\\t7:\\tHabit\\tstacking\\tincreases\\tthe\\tlikelihood\\tthat\\tyou’ll\\tstick\\twith\\ta\\thabit\\tby\\tstacking\\tyour\\tnew\\tbehavior\\ton\\ttop\\tof\\tan\\told\\tone.\\tThis\\tprocess\\tcan\\tbe\\trepeated\\tto\\tchain\\tnumerous\\thabits\\ntogether,\\teach\\tone\\tacting\\tas\\tthe\\tcue\\tfor\\tthe\\tnext.\\nYour\\tmorning\\troutine\\thabit\\tstack\\tmight\\tlook\\tlike\\tthis:\\n1.\\t\\nAfter\\tI\\tpour\\tmy\\tmorning\\tcup\\tof\\tcoffee,\\tI\\twill\\tmeditate\\tfor\\tsixty\\nseconds.\\n2.\\t\\nAfter\\tI\\tmeditate\\tfor\\tsixty\\tseconds,\\tI\\twill\\twrite\\tmy\\tto-do\\tlist\\tfor\\tthe\\nday.\\n3.\\t\\nAfter\\tI\\twrite\\tmy\\tto-do\\tlist\\tfor\\tthe\\tday,\\tI\\twill\\timmediately\\tbegin\\tmy\\nfirst\\ttask.\\nOr,\\tconsider\\tthis\\thabit\\tstack\\tin\\tthe\\tevening:', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 63}), Document(page_content='1.\\t\\nAfter\\tI\\tfinish\\teating\\tdinner,\\tI\\twill\\tput\\tmy\\tplate\\tdirectly\\tinto\\tthe\\ndishwasher.\\n2.\\t\\nAfter\\tI\\tput\\tmy\\tdishes\\taway,\\tI\\twill\\timmediately\\twipe\\tdown\\tthe\\tcounter.\\n3.\\t\\nAfter\\tI\\twipe\\tdown\\tthe\\tcounter,\\tI\\twill\\tset\\tout\\tmy\\tcoffee\\tmug\\tfor\\ntomorrow\\tmorning.\\nYou\\tcan\\talso\\tinsert\\tnew\\tbehaviors\\tinto\\tthe\\tmiddle\\tof\\tyour\\tcurrent\\troutines.\\nFor\\texample,\\tyou\\tmay\\talready\\thave\\ta\\tmorning\\troutine\\tthat\\tlooks\\tlike\\tthis:\\tWake\\nup\\t>\\tMake\\tmy\\tbed\\t>\\tTake\\ta\\tshower.\\tLet’s\\tsay\\tyou\\twant\\tto\\tdevelop\\tthe\\thabit\\tof\\nreading\\tmore\\teach\\tnight.\\tYou\\tcan\\texpand\\tyour\\thabit\\tstack\\tand\\ttry\\tsomething\\nlike:\\tWake\\tup\\t>\\tMake\\tmy\\tbed\\t>\\t\\nPlace\\ta\\tbook\\ton\\tmy\\tpillow\\n\\t>\\tTake\\ta\\tshower.\\nNow,\\twhen\\tyou\\tclimb\\tinto\\tbed\\teach\\tnight,\\ta\\tbook\\twill\\tbe\\tsitting\\tthere\\twaiting\\nfor\\tyou\\tto\\tenjoy.\\nOverall,\\thabit\\tstacking\\tallows\\tyou\\tto\\tcreate\\ta\\tset\\tof\\tsimple\\trules\\tthat\\tguide\\nyour\\tfuture\\tbehavior.\\tIt’s\\tlike\\tyou\\talways\\thave\\ta\\tgame\\tplan\\tfor\\twhich\\taction\\nshould\\tcome\\tnext.\\tOnce\\tyou\\tget\\tcomfortable\\twith\\tthis\\tapproach,\\tyou\\tcan\\ndevelop\\tgeneral\\thabit\\tstacks\\tto\\tguide\\tyou\\twhenever\\tthe\\tsituation\\tis\\tappropriate:\\nExercise.\\tWhen\\tI\\tsee\\ta\\tset\\tof\\tstairs,\\tI\\twill\\ttake\\tthem\\tinstead\\tof\\tusing\\nthe\\televator.\\nSocial\\tskills.\\tWhen\\tI\\twalk\\tinto\\ta\\tparty,\\tI\\twill\\tintroduce\\tmyself\\tto\\nsomeone\\tI\\tdon’t\\tknow\\tyet.\\nFinances.\\tWhen\\tI\\twant\\tto\\tbuy\\tsomething\\tover\\t$100,\\tI\\twill\\twait\\ntwenty-four\\thours\\tbefore\\tpurchasing.\\nHealthy\\teating.\\tWhen\\tI\\tserve\\tmyself\\ta\\tmeal,\\tI\\twill\\talways\\tput\\tveggies\\non\\tmy\\tplate\\tfirst.\\nMinimalism.\\tWhen\\tI\\tbuy\\ta\\tnew\\titem,\\tI\\twill\\tgive\\tsomething\\taway.\\n(“One\\tin,\\tone\\tout.”)\\nMood.\\tWhen\\tthe\\tphone\\trings,\\tI\\twill\\ttake\\tone\\tdeep\\tbreath\\tand\\tsmile\\nbefore\\tanswering.\\nForgetfulness.\\tWhen\\tI\\tleave\\ta\\tpublic\\tplace,\\tI\\twill\\tcheck\\tthe\\ttable\\tand\\nchairs\\tto\\tmake\\tsure\\tI\\tdon’t\\tleave\\tanything\\tbehind.\\nNo\\tmatter\\thow\\tyou\\tuse\\tthis\\tstrategy,\\tthe\\tsecret\\tto\\tcreating\\ta\\tsuccessful\\thabit\\nstack\\tis\\tselecting\\tthe\\tright\\tcue\\tto\\tkick\\tthings\\toff.\\tUnlike\\tan\\timplementation\\nintention,\\twhich\\tspecifically\\tstates\\tthe\\ttime\\tand\\tlocation\\tfor\\ta\\tgiven\\tbehavior,', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 64}), Document(page_content='habit\\tstacking\\timplicitly\\thas\\tthe\\ttime\\tand\\tlocation\\tbuilt\\tinto\\tit.\\tWhen\\tand\\twhere\\nyou\\tchoose\\tto\\tinsert\\ta\\thabit\\tinto\\tyour\\tdaily\\troutine\\tcan\\tmake\\ta\\tbig\\tdifference.\\tIf\\nyou’re\\ttrying\\tto\\tadd\\tmeditation\\tinto\\tyour\\tmorning\\troutine\\tbut\\tmornings\\tare\\nchaotic\\tand\\tyour\\tkids\\tkeep\\trunning\\tinto\\tthe\\troom,\\tthen\\tthat\\tmay\\tbe\\tthe\\twrong\\nplace\\tand\\ttime.\\tConsider\\twhen\\tyou\\tare\\tmost\\tlikely\\tto\\tbe\\tsuccessful.\\tDon’t\\task\\nyourself\\tto\\tdo\\ta\\thabit\\twhen\\tyou’re\\tlikely\\tto\\tbe\\toccupied\\twith\\tsomething\\telse.\\nYour\\tcue\\tshould\\talso\\thave\\tthe\\tsame\\tfrequency\\tas\\tyour\\tdesired\\thabit.\\tIf\\tyou\\nwant\\tto\\tdo\\ta\\thabit\\tevery\\tday,\\tbut\\tyou\\tstack\\tit\\ton\\ttop\\tof\\ta\\thabit\\tthat\\tonly\\thappens\\non\\tMondays,\\tthat’s\\tnot\\ta\\tgood\\tchoice.\\nOne\\tway\\tto\\tfind\\tthe\\tright\\ttrigger\\tfor\\tyour\\thabit\\tstack\\tis\\tby\\tbrainstorming\\ta\\tlist\\nof\\tyour\\tcurrent\\thabits.\\tYou\\tcan\\tuse\\tyour\\tHabits\\tScorecard\\tfrom\\tthe\\tlast\\tchapter\\nas\\ta\\tstarting\\tpoint.\\tAlternatively,\\tyou\\tcan\\tcreate\\ta\\tlist\\twith\\ttwo\\tcolumns.\\tIn\\tthe\\nfirst\\tcolumn,\\twrite\\tdown\\tthe\\thabits\\tyou\\tdo\\teach\\tday\\twithout\\tfail.\\n*\\nFor\\texample:\\nGet\\tout\\tof\\tbed.\\nTake\\ta\\tshower.\\nBrush\\tyour\\tteeth.\\nGet\\tdressed.\\nBrew\\ta\\tcup\\tof\\tcoffee.\\nEat\\tbreakfast.\\nTake\\tthe\\tkids\\tto\\tschool.\\nStart\\tthe\\twork\\tday.\\nEat\\tlunch.\\nEnd\\tthe\\twork\\tday.\\nChange\\tout\\tof\\twork\\tclothes.\\nSit\\tdown\\tfor\\tdinner.\\nTurn\\toff\\tthe\\tlights.\\nGet\\tinto\\tbed.\\nYour\\tlist\\tcan\\tbe\\tmuch\\tlonger,\\tbut\\tyou\\tget\\tthe\\tidea.\\tIn\\tthe\\tsecond\\tcolumn,\\nwrite\\tdown\\tall\\tof\\tthe\\tthings\\tthat\\thappen\\tto\\tyou\\teach\\tday\\twithout\\tfail.\\tFor\\nexample:\\nThe\\tsun\\trises.\\nYou\\tget\\ta\\ttext\\tmessage.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 65}), Document(page_content='The\\tsong\\tyou\\tare\\tlistening\\tto\\tends.\\nThe\\tsun\\tsets.\\nArmed\\twith\\tthese\\ttwo\\tlists,\\tyou\\tcan\\tbegin\\tsearching\\tfor\\tthe\\tbest\\tplace\\tto\\tlayer\\nyour\\tnew\\thabit\\tinto\\tyour\\tlifestyle.\\nHabit\\tstacking\\tworks\\tbest\\twhen\\tthe\\tcue\\tis\\thighly\\tspecific\\tand\\timmediately\\nactionable.\\tMany\\tpeople\\tselect\\tcues\\tthat\\tare\\ttoo\\tvague.\\tI\\tmade\\tthis\\tmistake\\nmyself.\\tWhen\\tI\\twanted\\tto\\tstart\\ta\\tpush-up\\thabit,\\tmy\\thabit\\tstack\\twas\\t“When\\tI\\ttake\\na\\tbreak\\tfor\\tlunch,\\tI\\twill\\tdo\\tten\\tpush-ups.”\\tAt\\tfirst\\tglance,\\tthis\\tsounded\\nreasonable.\\tBut\\tsoon,\\tI\\trealized\\tthe\\ttrigger\\twas\\tunclear.\\tWould\\tI\\tdo\\tmy\\tpush-ups\\nbefore\\tI\\tate\\tlunch?\\tAfter\\tI\\tate\\tlunch?\\tWhere\\twould\\tI\\tdo\\tthem?\\tAfter\\ta\\tfew\\ninconsistent\\tdays,\\tI\\tchanged\\tmy\\thabit\\tstack\\tto:\\t“When\\tI\\tclose\\tmy\\tlaptop\\tfor\\nlunch,\\tI\\twill\\tdo\\tten\\tpush-ups\\tnext\\tto\\tmy\\tdesk.”\\tAmbiguity\\tgone.\\nHabits\\tlike\\t“read\\tmore”\\tor\\t“eat\\tbetter”\\tare\\tworthy\\tcauses,\\tbut\\tthese\\tgoals\\tdo\\nnot\\tprovide\\tinstruction\\ton\\thow\\tand\\twhen\\tto\\tact.\\tBe\\tspecific\\tand\\tclear:\\tAfter\\tI\\nclose\\tthe\\tdoor.\\tAfter\\tI\\tbrush\\tmy\\tteeth.\\tAfter\\tI\\tsit\\t\\ndown\\tat\\tthe\\ttable.\\tThe\\nspecificity\\tis\\timportant.\\tThe\\tmore\\ttightly\\tbound\\tyour\\tnew\\thabit\\tis\\tto\\ta\\tspecific\\ncue,\\tthe\\tbetter\\tthe\\todds\\tare\\tthat\\tyou\\twill\\tnotice\\twhen\\tthe\\ttime\\tcomes\\tto\\tact.\\nThe\\t1st\\tLaw\\tof\\tBehavior\\tChange\\tis\\tto\\t\\nmake\\tit\\tobvious.\\n\\tStrategies\\tlike\\nimplementation\\tintentions\\tand\\thabit\\tstacking\\tare\\tamong\\tthe\\tmost\\tpractical\\tways\\nto\\tcreate\\tobvious\\tcues\\tfor\\tyour\\thabits\\tand\\tdesign\\ta\\tclear\\tplan\\tfor\\twhen\\tand\\nwhere\\tto\\ttake\\taction.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 66}), Document(page_content='Chapter\\tSummary\\nThe\\t1st\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\tobvious\\n.\\nThe\\ttwo\\tmost\\tcommon\\tcues\\tare\\ttime\\tand\\tlocation.\\nCreating\\tan\\timplementation\\tintention\\tis\\ta\\tstrategy\\tyou\\tcan\\tuse\\tto\\tpair\\ta\\nnew\\thabit\\twith\\ta\\tspecific\\ttime\\tand\\tlocation.\\nThe\\timplementation\\tintention\\tformula\\tis:\\tI\\twill\\t[BEHAVIOR]\\tat\\n[TIME]\\tin\\t[LOCATION].\\nHabit\\tstacking\\tis\\ta\\tstrategy\\tyou\\tcan\\tuse\\tto\\tpair\\ta\\tnew\\thabit\\twith\\ta\\ncurrent\\thabit.\\nThe\\thabit\\tstacking\\tformula\\tis:\\tAfter\\t[CURRENT\\tHABIT],\\tI\\twill\\n[NEW\\tHABIT].', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 67}), Document(page_content='6\\nMotivation\\tIs\\tOverrated;\\tEnvironment\\tOften\\nMatters\\tMore\\nA\\nN\\nNE\\t\\nT\\nHORNDIKE\\n,\\t\\nA\\t\\nprimary\\tcare\\tphysician\\tat\\tMassachusetts\\tGeneral\\tHospital\\tin\\nBoston,\\thad\\ta\\tcrazy\\tidea.\\tShe\\tbelieved\\tshe\\tcould\\timprove\\tthe\\teating\\thabits\\tof\\nthousands\\tof\\thospital\\tstaff\\tand\\tvisitors\\twithout\\tchanging\\ttheir\\twillpower\\tor\\nmotivation\\tin\\tthe\\tslightest\\tway.\\tIn\\tfact,\\tshe\\tdidn’t\\tplan\\ton\\ttalking\\tto\\tthem\\tat\\tall.\\nThorndike\\tand\\ther\\tcolleagues\\tdesigned\\ta\\tsix-month\\tstudy\\tto\\talter\\tthe\\t“choice\\narchitecture”\\tof\\tthe\\thospital\\tcafeteria.\\tThey\\tstarted\\tby\\tchanging\\thow\\tdrinks\\twere\\narranged\\tin\\tthe\\troom.\\tOriginally,\\tthe\\trefrigerators\\tlocated\\tnext\\tto\\tthe\\tcash\\nregisters\\tin\\tthe\\tcafeteria\\twere\\tfilled\\twith\\tonly\\tsoda.\\tThe\\tresearchers\\tadded\\twater\\nas\\tan\\toption\\tto\\teach\\tone.\\tAdditionally,\\tthey\\tplaced\\tbaskets\\tof\\tbottled\\twater\\tnext\\nto\\tthe\\tfood\\tstations\\tthroughout\\tthe\\troom.\\tSoda\\twas\\tstill\\tin\\tthe\\tprimary\\nrefrigerators,\\tbut\\twater\\twas\\tnow\\tavailable\\tat\\t\\nall\\n\\tdrink\\tlocations.\\nOver\\tthe\\tnext\\tthree\\tmonths,\\tthe\\tnumber\\tof\\tsoda\\tsales\\tat\\tthe\\thospital\\tdropped\\nby\\t11.4\\tpercent.\\tMeanwhile,\\tsales\\tof\\tbottled\\twater\\tincreased\\tby\\t25.8\\tpercent.\\nThey\\tmade\\tsimilar\\tadjustments—and\\tsaw\\tsimilar\\tresults—with\\tthe\\tfood\\tin\\tthe\\ncafeteria.\\tNobody\\thad\\tsaid\\ta\\tword\\tto\\tanyone\\teating\\tthere.\\nBEFORE\\tAFTER', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 68}), Document(page_content='FIGURE\\t8:\\tHere\\tis\\ta\\trepresentation\\tof\\twhat\\tthe\\tcafeteria\\tlooked\\tlike\\tbefore\\tthe\\tenvironment\\tdesign\\tchanges\\twere\\tmade\\t(left)\\tand\\tafter\\t(right).\\tThe\\tshaded\\tboxes\\tindicate\\tareas\\twhere\\tbottled\\nwater\\twas\\tavailable\\tin\\teach\\tinstance.\\tBecause\\tthe\\tamount\\tof\\twater\\tin\\tthe\\tenvironment\\twas\\tincreased,\\tbehavior\\tshifted\\tnaturally\\tand\\twithout\\tadditional\\tmotivation.\\nPeople\\toften\\t\\nchoose\\tproducts\\tnot\\tbecause\\tof\\t\\nwhat\\n\\tthey\\tare,\\tbut\\tbecause\\tof\\nwhere\\n\\tthey\\tare.\\tIf\\tI\\twalk\\tinto\\tthe\\tkitchen\\tand\\tsee\\ta\\tplate\\tof\\tcookies\\ton\\tthe\\ncounter,\\tI’ll\\tpick\\tup\\thalf\\ta\\tdozen\\tand\\tstart\\teating,\\teven\\tif\\tI\\thadn’t\\tbeen\\tthinking\\nabout\\tthem\\tbeforehand\\tand\\tdidn’t\\tnecessarily\\tfeel\\thungry.\\tIf\\tthe\\tcommunal\\ttable\\nat\\tthe\\toffice\\tis\\talways\\tfilled\\twith\\tdoughnuts\\tand\\tbagels,\\tit’s\\tgoing\\tto\\tbe\\thard\\tnot\\nto\\tgrab\\tone\\tevery\\tnow\\tand\\tthen.\\tYour\\thabits\\tchange\\tdepending\\ton\\tthe\\troom\\tyou\\nare\\tin\\tand\\tthe\\tcues\\tin\\tfront\\tof\\tyou.\\nEnvironment\\tis\\tthe\\tinvisible\\thand\\tthat\\tshapes\\thuman\\tbehavior.\\t\\nDespite\\tour\\nunique\\tpersonalities,\\tcertain\\tbehaviors\\ttend\\tto\\tarise\\tagain\\tand\\tagain\\tunder\\ncertain\\tenvironmental\\tconditions.\\tIn\\tchurch,\\tpeople\\ttend\\tto\\ttalk\\tin\\twhispers.\\tOn\\na\\tdark\\tstreet,\\tpeople\\tact\\twary\\tand\\tguarded.\\tIn\\tthis\\tway,\\tthe\\tmost\\tcommon\\tform\\nof\\tchange\\tis\\tnot\\tinternal,\\tbut\\texternal:\\twe\\tare\\tchanged\\tby\\tthe\\tworld\\taround\\tus.\\nEvery\\thabit\\tis\\tcontext\\tdependent.\\nIn\\t1936,\\tpsychologist\\tKurt\\tLewin\\twrote\\ta\\tsimple\\tequation\\tthat\\tmakes\\ta\\npowerful\\tstatement:\\t\\nBehavior\\tis\\ta\\tfunction\\tof\\tthe\\tPerson\\tin\\ttheir\\tEnvironment,\\nor\\tB\\t=\\t\\nf\\n\\t(P,E).\\nIt\\tdidn’t\\ttake\\tlong\\tfor\\tLewin’s\\tEquation\\tto\\tbe\\ttested\\tin\\tbusiness.\\tIn\\t1952,\\tthe\\neconomist\\tHawkins\\tStern\\tdescribed\\ta\\tphenomenon\\the\\tcalled\\t\\nSuggestion\\tImpulse\\nBuying\\n,\\twhich\\t“is\\ttriggered\\twhen\\ta\\tshopper\\tsees\\ta\\tproduct\\tfor\\tthe\\tfirst\\ttime\\tand\\nvisualizes\\ta\\tneed\\tfor\\tit.”\\tIn\\tother\\twords,\\tcustomers\\twill\\toccasionally\\tbuy\\nproducts\\tnot\\tbecause\\tthey\\t\\nwant\\n\\tthem\\tbut\\tbecause\\tof\\thow\\tthey\\tare\\t\\npresented\\n\\tto', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 69}), Document(page_content='them.\\nFor\\texample,\\titems\\tat\\teye\\tlevel\\ttend\\tto\\tbe\\tpurchased\\tmore\\tthan\\tthose\\tdown\\nnear\\tthe\\tfloor.\\tFor\\tthis\\treason,\\tyou’ll\\tfind\\texpensive\\tbrand\\tnames\\tfeatured\\tin\\neasy-to-reach\\tlocations\\ton\\tstore\\tshelves\\tbecause\\tthey\\tdrive\\tthe\\tmost\\tprofit,\\twhile\\ncheaper\\talternatives\\tare\\ttucked\\taway\\tin\\tharder-to-reach\\tspots.\\tThe\\tsame\\tgoes\\tfor\\nend\\tcaps,\\twhich\\tare\\tthe\\tunits\\tat\\tthe\\tend\\tof\\taisles.\\tEnd\\tcaps\\tare\\tmoneymaking\\nmachines\\tfor\\tretailers\\tbecause\\tthey\\tare\\tobvious\\tlocations\\tthat\\tencounter\\ta\\tlot\\tof\\nfoot\\ttraffic.\\tFor\\texample,\\t\\n45\\tpercent\\tof\\tCoca-Cola\\tsales\\tcome\\tspecifically\\tfrom\\nend-of-the-aisle\\tracks.\\nThe\\tmore\\tobviously\\tavailable\\ta\\tproduct\\tor\\tservice\\tis,\\tthe\\tmore\\tlikely\\tyou\\tare\\nto\\ttry\\tit.\\t\\nPeople\\tdrink\\tBud\\tLight\\tbecause\\tit\\tis\\tin\\tevery\\tbar\\tand\\tvisit\\tStarbucks\\nbecause\\tit\\tis\\ton\\tevery\\tcorner.\\tWe\\tlike\\tto\\tthink\\tthat\\twe\\tare\\tin\\tcontrol.\\tIf\\twe\\nchoose\\twater\\tover\\tsoda,\\twe\\tassume\\tit\\tis\\tbecause\\twe\\twanted\\tto\\tdo\\tso.\\tThe\\ttruth,\\nhowever,\\tis\\tthat\\tmany\\tof\\tthe\\tactions\\twe\\ttake\\teach\\tday\\tare\\tshaped\\tnot\\tby\\npurposeful\\tdrive\\tand\\tchoice\\tbut\\tby\\tthe\\tmost\\tobvious\\toption.\\nEvery\\tliving\\tbeing\\thas\\tits\\town\\tmethods\\tfor\\tsensing\\tand\\tunderstanding\\tthe\\nworld.\\tEagles\\thave\\tremarkable\\tlong-distance\\tvision.\\tSnakes\\tcan\\tsmell\\tby\\n“tasting\\tthe\\tair”\\twith\\ttheir\\thighly\\tsensitive\\ttongues.\\tSharks\\tcan\\tdetect\\tsmall\\namounts\\tof\\telectricity\\tand\\tvibrations\\tin\\tthe\\twater\\tcaused\\tby\\tnearby\\tfish.\\tEven\\nbacteria\\thave\\tchemoreceptors—tiny\\tsensory\\tcells\\tthat\\tallow\\tthem\\tto\\tdetect\\ttoxic\\nchemicals\\tin\\ttheir\\tenvironment.\\nIn\\thumans,\\tperception\\tis\\tdirected\\tby\\tthe\\tsensory\\tnervous\\tsystem.\\tWe\\tperceive\\nthe\\tworld\\tthrough\\tsight,\\tsound,\\tsmell,\\ttouch,\\tand\\ttaste.\\tBut\\twe\\talso\\thave\\tother\\nways\\tof\\tsensing\\tstimuli.\\tSome\\tare\\tconscious,\\tbut\\tmany\\tare\\tnonconscious.\\tFor\\ninstance,\\tyou\\tcan\\t“notice”\\twhen\\tthe\\ttemperature\\tdrops\\tbefore\\ta\\tstorm,\\tor\\twhen\\nthe\\tpain\\tin\\tyour\\tgut\\trises\\tduring\\ta\\tstomachache,\\tor\\twhen\\tyou\\tfall\\toff\\tbalance\\nwhile\\twalking\\ton\\trocky\\tground.\\tReceptors\\tin\\tyour\\tbody\\tpick\\tup\\ton\\ta\\twide\\trange\\nof\\tinternal\\tstimuli,\\tsuch\\tas\\tthe\\tamount\\tof\\tsalt\\tin\\tyour\\tblood\\tor\\tthe\\tneed\\tto\\tdrink\\nwhen\\tthirsty.\\nThe\\tmost\\tpowerful\\tof\\tall\\thuman\\tsensory\\tabilities,\\thowever,\\tis\\tvision.\\t\\nThe\\nhuman\\tbody\\thas\\tabout\\televen\\tmillion\\tsensory\\treceptors.\\tApproximately\\tten\\nmillion\\tof\\tthose\\tare\\tdedicated\\tto\\tsight.\\tSome\\texperts\\testimate\\tthat\\t\\nhalf\\tof\\tthe\\nbrain’s\\tresources\\tare\\tused\\ton\\tvision.\\tGiven\\tthat\\twe\\tare\\tmore\\tdependent\\ton\\tvision\\nthan\\ton\\tany\\tother\\tsense,\\tit\\tshould\\tcome\\tas\\tno\\tsurprise\\tthat\\tvisual\\tcues\\tare\\tthe\\ngreatest\\tcatalyst\\tof\\tour\\tbehavior.\\tFor\\tthis\\treason,\\ta\\tsmall\\tchange\\tin\\twhat\\tyou\\t\\nsee\\ncan\\tlead\\tto\\ta\\tbig\\tshift\\tin\\twhat\\tyou\\t\\ndo\\n.\\tAs\\ta\\tresult,\\tyou\\tcan\\timagine\\thow\\nimportant\\tit\\tis\\tto\\tlive\\tand\\twork\\tin\\tenvironments\\tthat\\tare\\tfilled\\twith\\tproductive\\ncues\\tand\\tdevoid\\tof\\tunproductive\\tones.\\nThankfully,\\tthere\\tis\\tgood\\tnews\\tin\\tthis\\trespect.\\tYou\\tdon’t\\thave\\tto\\tbe\\tthe\\tvictim', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 70}), Document(page_content='of\\tyour\\tenvironment.\\tYou\\tcan\\talso\\tbe\\tthe\\tarchitect\\tof\\tit.\\nHOW\\tTO\\tDESIGN\\tYOUR\\tENVIRONMENT\\tFOR\\tSUCCESS\\nDuring\\tthe\\tenergy\\tcrisis\\tand\\toil\\tembargo\\tof\\tthe\\t1970s,\\tDutch\\tresearchers\\tbegan\\nto\\tpay\\tclose\\tattention\\tto\\tthe\\tcountry’s\\tenergy\\tusage.\\tIn\\tone\\tsuburb\\tnear\\nAmsterdam,\\tthey\\tfound\\tthat\\tsome\\thomeowners\\tused\\t30\\tpercent\\tless\\tenergy\\tthan\\ntheir\\tneighbors—despite\\tthe\\thomes\\tbeing\\tof\\tsimilar\\tsize\\tand\\tgetting\\telectricity\\nfor\\tthe\\tsame\\tprice.\\nIt\\tturned\\tout\\tthe\\thouses\\tin\\tthis\\tneighborhood\\twere\\tnearly\\tidentical\\texcept\\tfor\\none\\tfeature:\\tthe\\tlocation\\tof\\tthe\\telectrical\\tmeter.\\tSome\\thad\\tone\\tin\\tthe\\tbasement.\\nOthers\\thad\\tthe\\telectrical\\tmeter\\tupstairs\\tin\\tthe\\tmain\\thallway.\\tAs\\tyou\\tmay\\tguess,\\nthe\\thomes\\twith\\tthe\\tmeters\\tlocated\\tin\\tthe\\tmain\\thallway\\tused\\tless\\telectricity.\\nWhen\\ttheir\\tenergy\\tuse\\twas\\tobvious\\tand\\teasy\\tto\\ttrack,\\tpeople\\tchanged\\ttheir\\nbehavior.\\nEvery\\thabit\\tis\\tinitiated\\tby\\ta\\tcue,\\tand\\twe\\tare\\tmore\\tlikely\\tto\\tnotice\\tcues\\tthat\\nstand\\tout.\\tUnfortunately,\\tthe\\tenvironments\\twhere\\twe\\tlive\\tand\\twork\\toften\\tmake\\nit\\teasy\\t\\nnot\\n\\tto\\tdo\\tcertain\\tactions\\tbecause\\tthere\\tis\\tno\\tobvious\\tcue\\tto\\ttrigger\\tthe\\nbehavior.\\tIt’s\\teasy\\t\\nnot\\n\\tto\\tpractice\\tthe\\tguitar\\twhen\\tit’s\\ttucked\\taway\\tin\\tthe\\tcloset.\\nIt’s\\teasy\\t\\nnot\\n\\tto\\tread\\ta\\tbook\\twhen\\tthe\\tbookshelf\\tis\\tin\\tthe\\tcorner\\tof\\tthe\\tguest\\nroom.\\tIt’s\\teasy\\t\\nnot\\n\\tto\\ttake\\tyour\\tvitamins\\twhen\\tthey\\tare\\tout\\tof\\tsight\\tin\\tthe\\tpantry.\\nWhen\\tthe\\tcues\\tthat\\tspark\\ta\\thabit\\tare\\tsubtle\\tor\\thidden,\\tthey\\tare\\teasy\\tto\\tignore.\\nBy\\tcomparison,\\tcreating\\tobvious\\tvisual\\tcues\\tcan\\tdraw\\tyour\\tattention\\ttoward\\ta\\ndesired\\thabit.\\tIn\\tthe\\tearly\\t1990s,\\tthe\\tcleaning\\tstaff\\tat\\tSchiphol\\tAirport\\tin\\nAmsterdam\\tinstalled\\ta\\tsmall\\tsticker\\tthat\\tlooked\\tlike\\ta\\tfly\\tnear\\tthe\\tcenter\\tof\\teach\\nurinal.\\tApparently,\\twhen\\tmen\\tstepped\\tup\\tto\\tthe\\turinals,\\tthey\\taimed\\tfor\\twhat\\tthey\\nthought\\twas\\ta\\tbug.\\tThe\\tstickers\\timproved\\ttheir\\taim\\tand\\tsignificantly\\treduced\\n“spillage”\\taround\\tthe\\turinals.\\tFurther\\tanalysis\\tdetermined\\tthat\\t\\nthe\\tstickers\\tcut\\nbathroom\\tcleaning\\tcosts\\tby\\t8\\tpercent\\tper\\tyear.\\nI’ve\\texperienced\\tthe\\tpower\\tof\\tobvious\\tcues\\tin\\tmy\\town\\tlife.\\tI\\tused\\tto\\tbuy\\napples\\tfrom\\tthe\\tstore,\\tput\\tthem\\tin\\tthe\\tcrisper\\tin\\tthe\\tbottom\\tof\\tthe\\t\\nrefrigerator,\\nand\\tforget\\tall\\tabout\\tthem.\\tBy\\tthe\\ttime\\tI\\tremembered,\\tthe\\tapples\\twould\\thave\\ngone\\tbad.\\tI\\tnever\\tsaw\\tthem,\\tso\\tI\\tnever\\tate\\tthem.\\nEventually,\\tI\\ttook\\tmy\\town\\tadvice\\tand\\tredesigned\\tmy\\tenvironment.\\tI\\tbought\\ta\\nlarge\\tdisplay\\tbowl\\tand\\tplaced\\tit\\tin\\tthe\\tmiddle\\tof\\tthe\\tkitchen\\tcounter.\\tThe\\tnext\\ntime\\tI\\tbought\\tapples,\\tthat\\twas\\twhere\\tthey\\twent—out\\tin\\tthe\\topen\\twhere\\tI\\tcould\\nsee\\tthem.\\tAlmost\\tlike\\tmagic,\\tI\\tbegan\\teating\\ta\\tfew\\tapples\\teach\\tday\\tsimply\\nbecause\\tthey\\twere\\tobvious\\trather\\tthan\\tout\\tof\\tsight.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 71}), Document(page_content='Here\\tare\\ta\\tfew\\tways\\tyou\\tcan\\tredesign\\tyour\\tenvironment\\tand\\tmake\\tthe\\tcues\\nfor\\tyour\\tpreferred\\thabits\\tmore\\tobvious:\\nIf\\tyou\\twant\\tto\\tremember\\tto\\ttake\\tyour\\tmedication\\teach\\tnight,\\tput\\tyour\\npill\\tbottle\\tdirectly\\tnext\\tto\\tthe\\tfaucet\\ton\\tthe\\tbathroom\\tcounter.\\nIf\\tyou\\twant\\tto\\tpractice\\tguitar\\tmore\\tfrequently,\\tplace\\tyour\\tguitar\\tstand\\nin\\tthe\\tmiddle\\tof\\tthe\\tliving\\troom.\\nIf\\tyou\\twant\\tto\\tremember\\tto\\tsend\\tmore\\tthank-you\\tnotes,\\tkeep\\ta\\tstack\\tof\\nstationery\\ton\\tyour\\tdesk.\\nIf\\tyou\\twant\\tto\\tdrink\\tmore\\twater,\\tfill\\tup\\ta\\tfew\\twater\\tbottles\\teach\\nmorning\\tand\\tplace\\tthem\\tin\\tcommon\\tlocations\\taround\\tthe\\thouse.\\nIf\\tyou\\twant\\tto\\tmake\\ta\\thabit\\ta\\tbig\\tpart\\tof\\tyour\\tlife,\\tmake\\tthe\\tcue\\ta\\tbig\\tpart\\tof\\nyour\\tenvironment.\\tThe\\tmost\\tpersistent\\tbehaviors\\tusually\\thave\\tmultiple\\tcues.\\nConsider\\thow\\tmany\\tdifferent\\tways\\ta\\tsmoker\\tcould\\tbe\\tprompted\\tto\\tpull\\tout\\ta\\ncigarette:\\tdriving\\tin\\tthe\\tcar,\\tseeing\\ta\\tfriend\\tsmoke,\\tfeeling\\tstressed\\tat\\twork,\\tand\\nso\\ton.\\nThe\\tsame\\tstrategy\\tcan\\tbe\\temployed\\tfor\\tgood\\thabits.\\tBy\\tsprinkling\\ttriggers\\nthroughout\\tyour\\tsurroundings,\\tyou\\tincrease\\tthe\\todds\\tthat\\tyou’ll\\tthink\\tabout\\tyour\\nhabit\\tthroughout\\tthe\\tday.\\tMake\\tsure\\tthe\\tbest\\tchoice\\tis\\tthe\\tmost\\tobvious\\tone.\\nMaking\\ta\\tbetter\\tdecision\\tis\\teasy\\tand\\tnatural\\twhen\\tthe\\tcues\\tfor\\tgood\\thabits\\tare\\nright\\tin\\tfront\\tof\\tyou.\\nEnvironment\\tdesign\\tis\\tpowerful\\tnot\\tonly\\tbecause\\tit\\tinfluences\\thow\\twe\\tengage\\nwith\\tthe\\tworld\\tbut\\talso\\tbecause\\twe\\trarely\\tdo\\tit.\\tMost\\tpeople\\tlive\\tin\\ta\\tworld\\nothers\\thave\\tcreated\\tfor\\tthem.\\tBut\\tyou\\tcan\\talter\\tthe\\tspaces\\twhere\\tyou\\tlive\\tand\\nwork\\tto\\tincrease\\tyour\\texposure\\tto\\tpositive\\tcues\\tand\\treduce\\tyour\\texposure\\tto\\nnegative\\tones.\\tEnvironment\\tdesign\\tallows\\tyou\\tto\\ttake\\tback\\tcontrol\\tand\\tbecome\\nthe\\tarchitect\\tof\\tyour\\tlife.\\tBe\\tthe\\tdesigner\\tof\\tyour\\tworld\\tand\\tnot\\tmerely\\tthe\\nconsumer\\tof\\tit.\\nTHE\\tCONTEXT\\tIS\\tTHE\\tCUE\\nThe\\tcues\\tthat\\ttrigger\\ta\\thabit\\tcan\\tstart\\tout\\tvery\\tspecific,\\tbut\\tover\\ttime\\tyour\\thabits\\nbecome\\tassociated\\tnot\\twith\\ta\\tsingle\\ttrigger\\tbut\\twith\\tthe\\tentire\\t\\ncontext\\nsurrounding\\tthe\\tbehavior.\\nFor\\texample,\\tmany\\tpeople\\tdrink\\tmore\\tin\\tsocial\\tsituations\\tthan\\tthey\\twould\\never\\tdrink\\talone.\\tThe\\ttrigger\\tis\\trarely\\ta\\tsingle\\tcue,\\tbut\\trather\\tthe\\twhole\\tsituation:', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 72}), Document(page_content='watching\\tyour\\tfriends\\torder\\tdrinks,\\thearing\\tthe\\tmusic\\tat\\tthe\\tbar,\\tseeing\\tthe\\tbeers\\non\\ttap.\\nWe\\tmentally\\tassign\\tour\\thabits\\tto\\tthe\\tlocations\\tin\\twhich\\tthey\\toccur:\\tthe\\thome,\\nthe\\toffice,\\tthe\\tgym.\\tEach\\tlocation\\tdevelops\\ta\\tconnection\\tto\\tcertain\\thabits\\tand\\nroutines.\\tYou\\testablish\\ta\\tparticular\\trelationship\\twith\\tthe\\tobjects\\ton\\tyour\\tdesk,\\nthe\\titems\\ton\\tyour\\tkitchen\\tcounter,\\tthe\\tthings\\tin\\tyour\\tbedroom.\\nOur\\tbehavior\\tis\\tnot\\tdefined\\tby\\tthe\\tobjects\\tin\\tthe\\tenvironment\\tbut\\tby\\tour\\nrelationship\\tto\\tthem.\\tIn\\tfact,\\tthis\\tis\\ta\\tuseful\\tway\\tto\\tthink\\tabout\\tthe\\tinfluence\\tof\\nthe\\tenvironment\\ton\\tyour\\tbehavior.\\tStop\\tthinking\\tabout\\tyour\\tenvironment\\tas\\nfilled\\twith\\tobjects.\\tStart\\tthinking\\tabout\\tit\\tas\\tfilled\\twith\\trelationships.\\tThink\\tin\\nterms\\tof\\thow\\tyou\\tinteract\\twith\\tthe\\tspaces\\taround\\tyou.\\tFor\\tone\\tperson,\\ther\\tcouch\\nis\\tthe\\tplace\\twhere\\tshe\\treads\\tfor\\tan\\thour\\teach\\tnight.\\tFor\\tsomeone\\telse,\\tthe\\tcouch\\nis\\twhere\\the\\twatches\\ttelevision\\tand\\teats\\ta\\tbowl\\tof\\tice\\tcream\\tafter\\twork.\\tDifferent\\npeople\\tcan\\thave\\tdifferent\\tmemories—and\\tthus\\tdifferent\\thabits—associated\\twith\\nthe\\tsame\\tplace.\\nThe\\tgood\\tnews?\\tYou\\tcan\\ttrain\\tyourself\\tto\\tlink\\ta\\tparticular\\thabit\\twith\\ta\\nparticular\\tcontext.\\nIn\\tone\\tstudy,\\tscientists\\tinstructed\\tinsomniacs\\tto\\tget\\tinto\\tbed\\tonly\\twhen\\tthey\\nwere\\ttired.\\tIf\\tthey\\tcouldn’t\\tfall\\tasleep,\\tthey\\twere\\ttold\\tto\\tsit\\tin\\ta\\tdifferent\\troom\\nuntil\\tthey\\tbecame\\tsleepy.\\tOver\\ttime,\\tsubjects\\tbegan\\tto\\tassociate\\tthe\\tcontext\\tof\\ntheir\\tbed\\twith\\tthe\\taction\\tof\\t\\nsleeping,\\tand\\tit\\tbecame\\teasier\\tto\\tquickly\\tfall\\tasleep\\nwhen\\tthey\\tclimbed\\tin\\tbed.\\tTheir\\tbrains\\tlearned\\tthat\\tsleeping—not\\tbrowsing\\ton\\ntheir\\tphones,\\tnot\\twatching\\ttelevision,\\tnot\\tstaring\\tat\\tthe\\tclock—was\\tthe\\tonly\\naction\\tthat\\thappened\\tin\\tthat\\troom.\\nThe\\tpower\\tof\\tcontext\\talso\\treveals\\tan\\timportant\\tstrategy:\\t\\nhabits\\tcan\\tbe\\teasier\\nto\\tchange\\tin\\ta\\tnew\\tenvironment.\\tIt\\thelps\\tto\\tescape\\tthe\\tsubtle\\ttriggers\\tand\\tcues\\nthat\\tnudge\\tyou\\ttoward\\tyour\\tcurrent\\thabits.\\tGo\\tto\\ta\\tnew\\tplace—a\\tdifferent\\tcoffee\\nshop,\\ta\\tbench\\tin\\tthe\\tpark,\\ta\\tcorner\\tof\\tyour\\troom\\tyou\\tseldom\\tuse—and\\tcreate\\ta\\nnew\\troutine\\tthere.\\nIt\\tis\\teasier\\tto\\tassociate\\ta\\tnew\\thabit\\twith\\ta\\tnew\\tcontext\\tthan\\tto\\tbuild\\ta\\tnew\\nhabit\\tin\\tthe\\tface\\tof\\tcompeting\\tcues.\\tIt\\tcan\\tbe\\tdifficult\\tto\\tgo\\tto\\tbed\\tearly\\tif\\tyou\\nwatch\\ttelevision\\tin\\tyour\\tbedroom\\teach\\tnight.\\tIt\\tcan\\tbe\\thard\\tto\\tstudy\\tin\\tthe\\tliving\\nroom\\twithout\\tgetting\\tdistracted\\tif\\tthat’s\\twhere\\tyou\\talways\\tplay\\tvideo\\tgames.\\nBut\\t\\nwhen\\tyou\\tstep\\toutside\\tyour\\tnormal\\tenvironment,\\tyou\\tleave\\tyour\\tbehavioral\\nbiases\\tbehind.\\t\\nYou\\taren’t\\tbattling\\told\\tenvironmental\\tcues,\\twhich\\tallows\\tnew\\nhabits\\tto\\tform\\twithout\\tinterruption.\\nWant\\tto\\tthink\\tmore\\tcreatively?\\tMove\\tto\\ta\\tbigger\\troom,\\ta\\trooftop\\tpatio,\\tor\\ta\\nbuilding\\twith\\texpansive\\tarchitecture.\\tTake\\ta\\tbreak\\tfrom\\tthe\\tspace\\twhere\\tyou\\tdo\\nyour\\tdaily\\twork,\\twhich\\tis\\talso\\tlinked\\tto\\tyour\\tcurrent\\tthought\\tpatterns.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 73}), Document(page_content='Trying\\tto\\teat\\thealthier?\\tIt\\tis\\tlikely\\tthat\\tyou\\tshop\\ton\\tautopilot\\tat\\tyour\\tregular\\nsupermarket.\\tTry\\ta\\tnew\\tgrocery\\tstore.\\tYou\\tmay\\tfind\\tit\\teasier\\tto\\t\\navoid\\tunhealthy\\nfood\\twhen\\tyour\\tbrain\\tdoesn’t\\tautomatically\\tknow\\twhere\\tit\\tis\\tlocated\\tin\\tthe\\tstore.\\nWhen\\tyou\\tcan’t\\tmanage\\tto\\tget\\tto\\tan\\tentirely\\tnew\\tenvironment,\\tredefine\\tor\\nrearrange\\tyour\\tcurrent\\tone.\\tCreate\\ta\\tseparate\\tspace\\tfor\\twork,\\tstudy,\\texercise,\\nentertainment,\\tand\\tcooking.\\tThe\\tmantra\\tI\\tfind\\tuseful\\tis\\t“One\\tspace,\\tone\\tuse.”\\nWhen\\tI\\tstarted\\tmy\\tcareer\\tas\\tan\\tentrepreneur,\\tI\\twould\\toften\\twork\\tfrom\\tmy\\ncouch\\tor\\tat\\tthe\\tkitchen\\ttable.\\tIn\\tthe\\tevenings,\\tI\\tfound\\tit\\tvery\\tdifficult\\tto\\tstop\\nworking.\\tThere\\twas\\tno\\tclear\\tdivision\\tbetween\\tthe\\tend\\tof\\twork\\ttime\\tand\\tthe\\nbeginning\\tof\\tpersonal\\ttime.\\tWas\\tthe\\tkitchen\\ttable\\tmy\\toffice\\tor\\tthe\\tspace\\twhere\\tI\\nate\\tmeals?\\tWas\\tthe\\tcouch\\twhere\\tI\\trelaxed\\tor\\twhere\\tI\\tsent\\temails?\\tEverything\\nhappened\\tin\\tthe\\tsame\\tplace.\\nA\\tfew\\tyears\\tlater,\\tI\\tcould\\tfinally\\tafford\\tto\\tmove\\tto\\ta\\thome\\twith\\ta\\tseparate\\nroom\\tfor\\tmy\\toffice.\\tSuddenly,\\twork\\twas\\tsomething\\tthat\\thappened\\t“in\\there”\\tand\\npersonal\\tlife\\twas\\tsomething\\tthat\\thappened\\t“out\\tthere.”\\tIt\\twas\\teasier\\tfor\\tme\\tto\\nturn\\toff\\tthe\\tprofessional\\tside\\tof\\tmy\\tbrain\\twhen\\tthere\\twas\\ta\\tclear\\tdividing\\tline\\nbetween\\twork\\tlife\\tand\\thome\\tlife.\\tEach\\troom\\thad\\tone\\tprimary\\tuse.\\tThe\\tkitchen\\nwas\\tfor\\tcooking.\\tThe\\toffice\\twas\\tfor\\tworking.\\nWhenever\\tpossible,\\tavoid\\tmixing\\tthe\\tcontext\\tof\\tone\\thabit\\twith\\tanother.\\tWhen\\nyou\\tstart\\tmixing\\tcontexts,\\tyou’ll\\tstart\\tmixing\\thabits—and\\tthe\\teasier\\tones\\twill\\nusually\\twin\\tout.\\tThis\\tis\\tone\\treason\\twhy\\tthe\\tversatility\\tof\\tmodern\\ttechnology\\tis\\nboth\\ta\\tstrength\\tand\\ta\\tweakness.\\tYou\\tcan\\tuse\\tyour\\tphone\\tfor\\tall\\tsorts\\tof\\ttasks,\\nwhich\\tmakes\\tit\\ta\\tpowerful\\tdevice.\\tBut\\twhen\\tyou\\tcan\\tuse\\tyour\\tphone\\tto\\tdo\\nnearly\\tanything,\\tit\\tbecomes\\thard\\tto\\tassociate\\tit\\twith\\tone\\ttask.\\tYou\\twant\\tto\\tbe\\nproductive,\\tbut\\tyou’re\\talso\\tconditioned\\tto\\tbrowse\\tsocial\\tmedia,\\tcheck\\temail,\\tand\\nplay\\tvideo\\tgames\\twhenever\\tyou\\topen\\tyour\\tphone.\\tIt’s\\ta\\tmishmash\\tof\\tcues.\\nYou\\tmay\\tbe\\tthinking,\\t“You\\tdon’t\\tunderstand.\\tI\\tlive\\tin\\tNew\\tYork\\tCity.\\tMy\\napartment\\tis\\tthe\\tsize\\tof\\ta\\tsmartphone.\\tI\\tneed\\teach\\troom\\tto\\t\\nplay\\tmultiple\\troles.”\\nFair\\tenough.\\tIf\\tyour\\tspace\\tis\\tlimited,\\tdivide\\tyour\\troom\\tinto\\tactivity\\tzones:\\ta\\nchair\\tfor\\treading,\\ta\\tdesk\\tfor\\twriting,\\ta\\ttable\\tfor\\teating.\\tYou\\tcan\\tdo\\tthe\\tsame\\twith\\nyour\\tdigital\\tspaces.\\tI\\tknow\\ta\\twriter\\twho\\tuses\\this\\tcomputer\\tonly\\tfor\\twriting,\\this\\ntablet\\tonly\\tfor\\treading,\\tand\\this\\tphone\\tonly\\tfor\\tsocial\\tmedia\\tand\\ttexting.\\tEvery\\nhabit\\tshould\\thave\\ta\\thome.\\nIf\\tyou\\tcan\\tmanage\\tto\\tstick\\twith\\tthis\\tstrategy,\\teach\\tcontext\\twill\\tbecome\\nassociated\\twith\\ta\\tparticular\\thabit\\tand\\tmode\\tof\\tthought.\\tHabits\\tthrive\\tunder\\npredictable\\tcircumstances\\tlike\\tthese.\\tFocus\\tcomes\\tautomatically\\twhen\\tyou\\tare\\nsitting\\tat\\tyour\\twork\\tdesk.\\tRelaxation\\tis\\teasier\\twhen\\tyou\\tare\\tin\\ta\\tspace\\tdesigned\\nfor\\tthat\\tpurpose.\\tSleep\\tcomes\\tquickly\\twhen\\tit\\tis\\tthe\\tonly\\tthing\\tthat\\thappens\\tin\\nyour\\tbedroom.\\tIf\\tyou\\twant\\tbehaviors\\tthat\\tare\\tstable\\tand\\tpredictable,\\tyou\\tneed\\tan', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 74}), Document(page_content='environment\\tthat\\tis\\tstable\\tand\\tpredictable.\\nA\\tstable\\tenvironment\\twhere\\teverything\\thas\\ta\\tplace\\tand\\ta\\tpurpose\\tis\\tan\\nenvironment\\twhere\\thabits\\tcan\\teasily\\tform.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 75}), Document(page_content='Chapter\\tSummary\\nSmall\\tchanges\\tin\\tcontext\\tcan\\tlead\\tto\\tlarge\\tchanges\\tin\\tbehavior\\tover\\ntime.\\nEvery\\thabit\\tis\\tinitiated\\tby\\ta\\tcue.\\tWe\\tare\\tmore\\tlikely\\tto\\tnotice\\tcues\\tthat\\nstand\\tout.\\nMake\\tthe\\tcues\\tof\\tgood\\thabits\\tobvious\\tin\\tyour\\tenvironment.\\nGradually,\\tyour\\thabits\\tbecome\\tassociated\\tnot\\twith\\ta\\tsingle\\ttrigger\\tbut\\nwith\\tthe\\tentire\\tcontext\\tsurrounding\\tthe\\tbehavior.\\tThe\\tcontext\\tbecomes\\nthe\\tcue.\\nIt\\tis\\teasier\\tto\\tbuild\\tnew\\thabits\\tin\\ta\\tnew\\tenvironment\\tbecause\\tyou\\tare\\nnot\\tfighting\\tagainst\\told\\tcues.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 76}), Document(page_content='7\\nThe\\tSecret\\tto\\tSelf-Control\\nI\\nN\\t1971\\n,\\tas\\tthe\\tVietnam\\tWar\\twas\\theading\\tinto\\tits\\tsixteenth\\tyear,\\tcongressmen\\nRobert\\tSteele\\tfrom\\tConnecticut\\tand\\tMorgan\\tMurphy\\tfrom\\tIllinois\\tmade\\ta\\ndiscovery\\tthat\\tstunned\\tthe\\tAmerican\\tpublic.\\tWhile\\tvisiting\\tthe\\ttroops,\\tthey\\thad\\nlearned\\tthat\\tover\\t15\\tpercent\\tof\\tU.S.\\tsoldiers\\tstationed\\tthere\\twere\\theroin\\taddicts.\\nFollow-up\\tresearch\\trevealed\\tthat\\t35\\tpercent\\tof\\tservice\\tmembers\\tin\\tVietnam\\thad\\ntried\\theroin\\tand\\tas\\tmany\\tas\\t20\\tpercent\\twere\\taddicted—the\\tproblem\\twas\\teven\\nworse\\tthan\\tthey\\thad\\tinitially\\tthought.\\nThe\\tdiscovery\\tled\\tto\\ta\\tflurry\\tof\\tactivity\\tin\\tWashington,\\tincluding\\t\\nthe\\tcreation\\nof\\tthe\\tSpecial\\tAction\\tOffice\\tof\\tDrug\\tAbuse\\tPrevention\\tunder\\tPresident\\tNixon\\tto\\npromote\\tprevention\\tand\\trehabilitation\\tand\\tto\\ttrack\\taddicted\\tservice\\tmembers\\nwhen\\tthey\\treturned\\thome.\\nLee\\tRobins\\twas\\tone\\tof\\tthe\\tresearchers\\tin\\tcharge.\\tIn\\ta\\tfinding\\tthat\\tcompletely\\nupended\\tthe\\taccepted\\tbeliefs\\tabout\\taddiction,\\tRobins\\tfound\\tthat\\twhen\\tsoldiers\\nwho\\thad\\tbeen\\theroin\\tusers\\treturned\\thome,\\tonly\\t5\\tpercent\\tof\\tthem\\tbecame\\nreaddicted\\twithin\\ta\\tyear,\\tand\\tjust\\t12\\tpercent\\trelapsed\\twithin\\tthree\\tyears.\\tIn\\tother\\nwords,\\tapproximately\\t\\nnine\\tout\\tof\\t\\nten\\tsoldiers\\twho\\tused\\theroin\\tin\\tVietnam\\neliminated\\ttheir\\taddiction\\tnearly\\tovernight.\\nThis\\tfinding\\tcontradicted\\tthe\\tprevailing\\tview\\tat\\tthe\\ttime,\\twhich\\tconsidered\\nheroin\\taddiction\\tto\\tbe\\ta\\tpermanent\\tand\\tirreversible\\tcondition.\\tInstead,\\tRobins\\nrevealed\\tthat\\taddictions\\tcould\\tspontaneously\\tdissolve\\tif\\tthere\\twas\\ta\\tradical\\nchange\\tin\\tthe\\tenvironment.\\tIn\\tVietnam,\\tsoldiers\\tspent\\tall\\tday\\tsurrounded\\tby\\ncues\\ttriggering\\theroin\\tuse:\\tit\\twas\\teasy\\tto\\taccess,\\tthey\\twere\\tengulfed\\tby\\tthe\\nconstant\\tstress\\tof\\twar,\\tthey\\tbuilt\\tfriendships\\twith\\tfellow\\tsoldiers\\twho\\twere\\talso\\nheroin\\tusers,\\tand\\tthey\\twere\\tthousands\\tof\\tmiles\\tfrom\\thome.\\tOnce\\ta\\tsoldier\\nreturned\\tto\\tthe\\tUnited\\tStates,\\tthough,\\the\\tfound\\thimself\\tin\\tan\\tenvironment\\tdevoid\\nof\\tthose\\ttriggers.\\tWhen\\tthe\\tcontext\\tchanged,\\tso\\tdid\\tthe\\thabit.\\nCompare\\tthis\\tsituation\\tto\\tthat\\tof\\ta\\ttypical\\tdrug\\tuser.\\tSomeone\\tbecomes', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 77}), Document(page_content='addicted\\tat\\thome\\tor\\twith\\tfriends,\\tgoes\\tto\\ta\\tclinic\\tto\\tget\\tclean—which\\tis\\tdevoid\\nof\\tall\\tthe\\tenvironmental\\tstimuli\\tthat\\tprompt\\ttheir\\thabit—then\\treturns\\tto\\ttheir\\told\\nneighborhood\\twith\\tall\\tof\\ttheir\\tprevious\\tcues\\tthat\\tcaused\\tthem\\tto\\tget\\taddicted\\tin\\nthe\\tfirst\\tplace.\\tIt’s\\tno\\twonder\\tthat\\tusually\\tyou\\tsee\\tnumbers\\tthat\\tare\\tthe\\texact\\nopposite\\tof\\tthose\\tin\\tthe\\tVietnam\\tstudy.\\tTypically,\\t\\n90\\tpercent\\tof\\theroin\\tusers\\nbecome\\treaddicted\\tonce\\tthey\\treturn\\thome\\tfrom\\trehab.\\nThe\\tVietnam\\tstudies\\tran\\tcounter\\tto\\tmany\\tof\\tour\\tcultural\\tbeliefs\\tabout\\tbad\\nhabits\\tbecause\\tit\\tchallenged\\tthe\\tconventional\\tassociation\\tof\\tunhealthy\\tbehavior\\nas\\ta\\tmoral\\tweakness.\\tIf\\tyou’re\\toverweight,\\ta\\tsmoker,\\tor\\tan\\taddict,\\tyou’ve\\tbeen\\ntold\\tyour\\tentire\\tlife\\tthat\\tit\\tis\\tbecause\\tyou\\tlack\\tself-control—maybe\\teven\\tthat\\nyou’re\\ta\\tbad\\tperson.\\tThe\\tidea\\tthat\\ta\\tlittle\\tbit\\tof\\tdiscipline\\twould\\tsolve\\tall\\tour\\nproblems\\tis\\tdeeply\\tembedded\\tin\\tour\\tculture.\\nRecent\\tresearch,\\thowever,\\tshows\\tsomething\\tdifferent.\\tWhen\\tscientists\\nanalyze\\tpeople\\twho\\tappear\\tto\\thave\\ttremendous\\tself-control,\\tit\\tturns\\tout\\tthose\\nindividuals\\taren’t\\tall\\tthat\\tdifferent\\tfrom\\tthose\\twho\\tare\\tstruggling.\\tInstead,\\n“\\ndisciplined”\\tpeople\\tare\\tbetter\\tat\\tstructuring\\ttheir\\t\\nlives\\tin\\ta\\tway\\tthat\\t\\ndoes\\tnot\\nrequire\\n\\theroic\\twillpower\\tand\\tself-control.\\tIn\\tother\\twords,\\tthey\\tspend\\tless\\ttime\\tin\\ntempting\\tsituations.\\nThe\\tpeople\\twith\\tthe\\tbest\\tself-control\\tare\\ttypically\\tthe\\tones\\twho\\tneed\\tto\\tuse\\tit\\nthe\\tleast.\\t\\nIt’s\\teasier\\tto\\tpractice\\tself-restraint\\twhen\\tyou\\tdon’t\\thave\\tto\\tuse\\tit\\tvery\\noften.\\tSo,\\tyes,\\tperseverance,\\tgrit,\\tand\\twillpower\\tare\\tessential\\tto\\tsuccess,\\tbut\\tthe\\nway\\tto\\timprove\\tthese\\tqualities\\tis\\tnot\\tby\\twishing\\tyou\\twere\\ta\\tmore\\tdisciplined\\nperson,\\tbut\\tby\\tcreating\\ta\\tmore\\tdisciplined\\tenvironment.\\nThis\\tcounterintuitive\\tidea\\tmakes\\teven\\tmore\\tsense\\tonce\\tyou\\tunderstand\\twhat\\nhappens\\twhen\\ta\\thabit\\tis\\tformed\\tin\\tthe\\tbrain.\\t\\nA\\thabit\\tthat\\thas\\tbeen\\tencoded\\tin\\nthe\\tmind\\tis\\tready\\tto\\tbe\\tused\\twhenever\\tthe\\trelevant\\tsituation\\tarises.\\tWhen\\tPatty\\nOlwell,\\ta\\ttherapist\\tfrom\\tAustin,\\tTexas,\\tstarted\\tsmoking,\\tshe\\twould\\toften\\tlight\\tup\\nwhile\\triding\\thorses\\twith\\ta\\tfriend.\\tEventually,\\tshe\\tquit\\tsmoking\\tand\\tavoided\\tit\\nfor\\tyears.\\tShe\\thad\\talso\\tstopped\\triding.\\tDecades\\tlater,\\tshe\\thopped\\ton\\ta\\thorse\\nagain\\tand\\tfound\\therself\\tcraving\\ta\\tcigarette\\tfor\\tthe\\tfirst\\ttime\\tin\\tforever.\\t\\nThe\\tcues\\nwere\\tstill\\tinternalized;\\tshe\\tjust\\thadn’t\\tbeen\\texposed\\tto\\tthem\\tin\\ta\\tlong\\ttime.\\nOnce\\ta\\thabit\\thas\\tbeen\\tencoded,\\tthe\\turge\\tto\\tact\\tfollows\\twhenever\\tthe\\nenvironmental\\tcues\\treappear.\\tThis\\tis\\tone\\treason\\tbehavior\\tchange\\ttechniques\\tcan\\nbackfire.\\t\\nShaming\\tobese\\tpeople\\twith\\tweight-loss\\tpresentations\\tcan\\tmake\\tthem\\nfeel\\tstressed,\\tand\\tas\\ta\\tresult\\tmany\\tpeople\\treturn\\tto\\ttheir\\tfavorite\\tcoping\\tstrategy:\\novereating.\\t\\nShowing\\tpictures\\tof\\tblackened\\tlungs\\tto\\tsmokers\\tleads\\tto\\thigher\\nlevels\\tof\\tanxiety,\\twhich\\tdrives\\tmany\\tpeople\\tto\\treach\\tfor\\ta\\tcigarette.\\tIf\\tyou’re\\tnot\\ncareful\\tabout\\tcues,\\tyou\\tcan\\tcause\\tthe\\tvery\\tbehavior\\tyou\\twant\\tto\\tstop.\\nBad\\thabits\\tare\\tautocatalytic:\\tthe\\tprocess\\tfeeds\\titself.\\tThey\\tfoster\\tthe\\tfeelings', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 78}), Document(page_content='they\\ttry\\tto\\tnumb.\\tYou\\tfeel\\tbad,\\tso\\tyou\\teat\\tjunk\\tfood.\\tBecause\\tyou\\teat\\tjunk\\tfood,\\nyou\\tfeel\\tbad.\\tWatching\\ttelevision\\tmakes\\tyou\\tfeel\\tsluggish,\\tso\\tyou\\twatch\\tmore\\ntelevision\\tbecause\\tyou\\tdon’t\\thave\\tthe\\tenergy\\tto\\tdo\\tanything\\telse.\\tWorrying\\nabout\\tyour\\thealth\\tmakes\\tyou\\tfeel\\t\\nanxious,\\twhich\\tcauses\\tyou\\tto\\tsmoke\\tto\\tease\\nyour\\tanxiety,\\twhich\\tmakes\\tyour\\thealth\\teven\\tworse\\tand\\tsoon\\tyou’re\\tfeeling\\tmore\\nanxious.\\tIt’s\\ta\\tdownward\\tspiral,\\ta\\trunaway\\ttrain\\tof\\tbad\\thabits.\\nResearchers\\trefer\\tto\\tthis\\tphenomenon\\tas\\t“cue-induced\\twanting”:\\tan\\texternal\\ntrigger\\tcauses\\ta\\tcompulsive\\tcraving\\tto\\trepeat\\ta\\tbad\\thabit.\\tOnce\\tyou\\t\\nnotice\\nsomething,\\tyou\\tbegin\\tto\\t\\nwant\\n\\tit.\\tThis\\tprocess\\tis\\thappening\\tall\\tthe\\ttime—often\\nwithout\\tus\\trealizing\\tit.\\tScientists\\thave\\tfound\\tthat\\t\\nshowing\\taddicts\\ta\\tpicture\\tof\\ncocaine\\tfor\\tjust\\tthirty-three\\tmilliseconds\\tstimulates\\tthe\\treward\\tpathway\\tin\\tthe\\nbrain\\tand\\tsparks\\tdesire.\\tThis\\tspeed\\tis\\ttoo\\tfast\\tfor\\tthe\\tbrain\\tto\\tconsciously\\nregister—the\\taddicts\\tcouldn’t\\teven\\ttell\\tyou\\twhat\\tthey\\thad\\tseen—but\\tthey\\tcraved\\nthe\\tdrug\\tall\\tthe\\tsame.\\nHere’s\\tthe\\tpunch\\tline:\\tYou\\tcan\\tbreak\\ta\\thabit,\\tbut\\tyou’re\\tunlikely\\tto\\tforget\\tit.\\nOnce\\tthe\\tmental\\tgrooves\\tof\\thabit\\thave\\tbeen\\tcarved\\tinto\\tyour\\tbrain,\\tthey\\tare\\nnearly\\timpossible\\tto\\tremove\\tentirely—even\\tif\\tthey\\tgo\\tunused\\tfor\\tquite\\ta\\twhile.\\nAnd\\tthat\\tmeans\\tthat\\tsimply\\tresisting\\ttemptation\\tis\\tan\\tineffective\\tstrategy.\\tIt\\tis\\nhard\\tto\\tmaintain\\ta\\tZen\\tattitude\\tin\\ta\\tlife\\tfilled\\twith\\tinterruptions.\\tIt\\ttakes\\ttoo\\nmuch\\tenergy.\\tIn\\tthe\\tshort-run,\\tyou\\tcan\\tchoose\\tto\\toverpower\\ttemptation.\\tIn\\tthe\\nlong-run,\\twe\\tbecome\\ta\\tproduct\\tof\\tthe\\tenvironment\\tthat\\twe\\tlive\\tin.\\tTo\\tput\\tit\\nbluntly,\\tI\\thave\\tnever\\tseen\\tsomeone\\tconsistently\\tstick\\tto\\tpositive\\thabits\\tin\\ta\\nnegative\\tenvironment.\\nA\\tmore\\treliable\\tapproach\\tis\\tto\\tcut\\tbad\\thabits\\toff\\tat\\tthe\\tsource.\\tOne\\tof\\tthe\\nmost\\tpractical\\tways\\tto\\teliminate\\ta\\tbad\\thabit\\tis\\tto\\treduce\\texposure\\tto\\tthe\\tcue\\tthat\\ncauses\\tit.\\nIf\\tyou\\tcan’t\\tseem\\tto\\tget\\tany\\twork\\tdone,\\tleave\\tyour\\tphone\\tin\\tanother\\nroom\\tfor\\ta\\tfew\\thours.\\nIf\\tyou’re\\tcontinually\\tfeeling\\tlike\\tyou’re\\tnot\\tenough,\\tstop\\tfollowing\\nsocial\\tmedia\\taccounts\\tthat\\ttrigger\\tjealousy\\tand\\tenvy.\\nIf\\tyou’re\\twasting\\ttoo\\tmuch\\ttime\\twatching\\ttelevision,\\tmove\\tthe\\tTV\\tout\\nof\\tthe\\tbedroom.\\nIf\\tyou’re\\tspending\\ttoo\\tmuch\\tmoney\\ton\\telectronics,\\tquit\\treading\\nreviews\\tof\\tthe\\tlatest\\ttech\\tgear.\\nIf\\tyou’re\\tplaying\\ttoo\\tmany\\tvideo\\tgames,\\tunplug\\tthe\\tconsole\\tand\\tput\\tit\\nin\\ta\\tcloset\\tafter\\teach\\tuse.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 79}), Document(page_content='This\\tpractice\\tis\\tan\\tinversion\\tof\\tthe\\t1st\\tLaw\\tof\\tBehavior\\tChange.\\tRather\\tthan\\nmake\\tit\\tobvious\\n,\\tyou\\tcan\\t\\nmake\\tit\\tinvisible\\n.\\tI’m\\toften\\tsurprised\\tby\\thow\\teffective\\nsimple\\tchanges\\tlike\\tthese\\tcan\\tbe.\\tRemove\\ta\\tsingle\\tcue\\tand\\tthe\\tentire\\thabit\\toften\\nfades\\taway.\\nSelf-control\\tis\\ta\\tshort-term\\tstrategy,\\tnot\\ta\\tlong-term\\tone.\\tYou\\tmay\\tbe\\table\\tto\\nresist\\ttemptation\\tonce\\tor\\ttwice,\\tbut\\tit’s\\tunlikely\\tyou\\tcan\\tmuster\\tthe\\twillpower\\tto\\noverride\\tyour\\tdesires\\tevery\\ttime.\\tInstead\\tof\\tsummoning\\ta\\tnew\\tdose\\tof\\twillpower\\nwhenever\\tyou\\twant\\tto\\tdo\\tthe\\tright\\tthing,\\tyour\\tenergy\\twould\\tbe\\tbetter\\tspent\\noptimizing\\tyour\\tenvironment.\\tThis\\tis\\tthe\\tsecret\\tto\\tself-control.\\tMake\\tthe\\tcues\\tof\\nyour\\tgood\\thabits\\tobvious\\tand\\tthe\\tcues\\tof\\tyour\\tbad\\thabits\\tinvisible.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 80}), Document(page_content='Chapter\\tSummary\\nThe\\tinversion\\tof\\tthe\\t1st\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\tinvisible\\n.\\nOnce\\ta\\thabit\\tis\\tformed,\\tit\\tis\\tunlikely\\tto\\tbe\\tforgotten.\\nPeople\\twith\\thigh\\tself-control\\ttend\\tto\\tspend\\tless\\ttime\\tin\\ttempting\\nsituations.\\tIt’s\\teasier\\tto\\tavoid\\ttemptation\\tthan\\tresist\\tit.\\nOne\\tof\\tthe\\tmost\\tpractical\\tways\\tto\\teliminate\\ta\\tbad\\thabit\\tis\\tto\\treduce\\nexposure\\tto\\tthe\\tcue\\tthat\\tcauses\\tit.\\nSelf-control\\tis\\ta\\tshort-term\\tstrategy,\\tnot\\ta\\tlong-term\\tone.\\nHOW\\tTO\\tCREATE\\tA\\tGOOD\\tHABIT\\nThe\\t1st\\tLaw\\n:\\t\\nMake\\tIt\\tObvious\\n1.1:\\t\\nFill\\tout\\tthe\\tHabits\\tScorecard.\\tWrite\\tdown\\tyour\\tcurrent\\thabits\\tto\\tbecome\\taware\\tof\\tthem.\\n1.2:\\t\\nUse\\timplementation\\tintentions\\n:\\t\\n“I\\twill\\t[BEHAVIOR]\\tat\\t[TIME]\\tin\\t[LOCATION].”\\n1.3:\\t\\nUse\\thabit\\tstacking\\n:\\t\\n“After\\t[CURRENT\\tHABIT],\\tI\\twill\\t[NEW\\tHABIT].”\\n1.4:\\t\\nDesign\\tyour\\tenvironment.\\tMake\\tthe\\tcues\\tof\\tgood\\thabits\\tobvious\\tand\\tvisible.\\nThe\\t2nd\\tLaw\\n:\\t\\nMake\\tIt\\tAttractive\\nThe\\t3rd\\tLaw\\n:\\t\\nMake\\tIt\\tEasy\\nThe\\t4th\\tLaw\\n:\\t\\nMake\\tIt\\tSatisfying\\nHOW\\tTO\\tBREAK\\tA\\tBAD\\tHABIT\\nInversion\\tof\\tthe\\t1st\\tLaw\\n:\\t\\nMake\\tIt\\tInvisible\\n1.5:\\t\\nReduce\\texposure.\\tRemove\\tthe\\tcues\\tof\\tyour\\tbad\\thabits\\tfrom\\tyour\\tenvironment.\\nInversion\\tof\\tthe\\t2nd\\tLaw\\n:\\t\\nMake\\tIt\\tUnattractive\\nInversion\\tof\\tthe\\t3rd\\tLaw\\n:\\t\\nMake\\tIt\\tDifficult\\nInversion\\tof\\tthe\\t4th\\tLaw\\n:\\t\\nMake\\tIt\\tUnsatisfying\\nYou\\tcan\\tdownload\\ta\\tprintable\\tversion\\tof\\tthis\\thabits\\tcheat\\tsheet\\tat:\\t\\natomichabits.com/cheatsheet', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 81}), Document(page_content='THE\\t2ND\\tLAW\\nMake\\tIt\\tAttractive', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 82}), Document(page_content='8\\nHow\\tto\\tMake\\ta\\tHabit\\tIrresistible\\nI\\nN\\tTHE\\t1940S\\n,\\ta\\tDutch\\tscientist\\tnamed\\t\\nNiko\\tTinbergen\\tperformed\\ta\\tseries\\tof\\nexperiments\\tthat\\ttransformed\\tour\\tunderstanding\\tof\\twhat\\tmotivates\\tus.\\tTinbergen\\n—who\\teventually\\twon\\ta\\tNobel\\tPrize\\tfor\\this\\twork—was\\tinvestigating\\therring\\ngulls,\\tthe\\tgray\\tand\\twhite\\tbirds\\toften\\tseen\\tflying\\talong\\tthe\\tseashores\\tof\\tNorth\\nAmerica.\\nAdult\\therring\\tgulls\\thave\\ta\\tsmall\\tred\\tdot\\ton\\ttheir\\tbeak,\\tand\\tTinbergen\\tnoticed\\nthat\\tnewly\\thatched\\tchicks\\twould\\tpeck\\tthis\\tspot\\twhenever\\tthey\\twanted\\tfood.\\tTo\\nbegin\\tone\\texperiment,\\the\\tcreated\\ta\\tcollection\\tof\\tfake\\tcardboard\\tbeaks,\\tjust\\ta\\nhead\\twithout\\ta\\tbody.\\tWhen\\tthe\\tparents\\thad\\tflown\\taway,\\the\\twent\\tover\\tto\\tthe\\tnest\\nand\\toffered\\tthese\\tdummy\\tbeaks\\tto\\tthe\\tchicks.\\tThe\\tbeaks\\twere\\tobvious\\tfakes,\\nand\\the\\tassumed\\tthe\\tbaby\\tbirds\\twould\\treject\\tthem\\taltogether.\\nHowever,\\twhen\\tthe\\ttiny\\tgulls\\tsaw\\tthe\\tred\\tspot\\ton\\tthe\\tcardboard\\tbeak,\\tthey\\npecked\\taway\\tjust\\tas\\tif\\tit\\twere\\tattached\\tto\\ttheir\\town\\tmother.\\tThey\\thad\\ta\\tclear\\npreference\\tfor\\tthose\\tred\\tspots—as\\tif\\tthey\\thad\\tbeen\\tgenetically\\tprogrammed\\tat\\nbirth.\\tSoon\\tTinbergen\\tdiscovered\\tthat\\tthe\\tbigger\\tthe\\tred\\tspot,\\tthe\\tfaster\\tthe\\nchicks\\tpecked.\\tEventually,\\the\\tcreated\\ta\\tbeak\\twith\\tthree\\tlarge\\tred\\tdots\\ton\\tit.\\nWhen\\the\\tplaced\\tit\\tover\\tthe\\tnest,\\t\\nthe\\tbaby\\tbirds\\twent\\tcrazy\\twith\\tdelight.\\tThey\\npecked\\tat\\tthe\\tlittle\\tred\\tpatches\\tas\\tif\\tit\\twas\\tthe\\tgreatest\\tbeak\\tthey\\thad\\tever\\tseen.\\nTinbergen\\tand\\this\\tcolleagues\\tdiscovered\\tsimilar\\tbehavior\\tin\\tother\\tanimals.\\nFor\\texample,\\tthe\\tgreylag\\tgoose\\tis\\ta\\tground-nesting\\tbird.\\tOccasionally,\\tas\\tthe\\nmother\\tmoves\\taround\\ton\\tthe\\tnest,\\tone\\tof\\tthe\\teggs\\twill\\troll\\tout\\tand\\tsettle\\ton\\tthe\\ngrass\\tnearby.\\tWhenever\\tthis\\thappens,\\tthe\\tgoose\\twill\\twaddle\\tover\\tto\\tthe\\tegg\\tand\\nuse\\tits\\tbeak\\tand\\tneck\\tto\\tpull\\tit\\tback\\tinto\\tthe\\tnest.\\nTinbergen\\tdiscovered\\tthat\\t\\nthe\\tgoose\\twill\\tpull\\t\\nany\\n\\tnearby\\tround\\tobject,\\tsuch\\tas\\na\\tbilliard\\tball\\tor\\ta\\tlightbulb,\\tback\\tinto\\tthe\\tnest.\\tThe\\tbigger\\tthe\\tobject,\\tthe\\tgreater\\ntheir\\tresponse.\\tOne\\tgoose\\teven\\tmade\\ta\\ttremendous\\teffort\\tto\\troll\\ta\\tvolleyball\\nback\\tand\\tsit\\ton\\ttop.\\tLike\\tthe\\tbaby\\tgulls\\tautomatically\\tpecking\\tat\\tred\\tdots,\\tthe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 83}), Document(page_content='greylag\\tgoose\\twas\\tfollowing\\tan\\tinstinctive\\trule:\\t\\nWhen\\tI\\tsee\\ta\\tround\\tobject\\nnearby,\\tI\\tmust\\troll\\tit\\tback\\tinto\\tthe\\tnest.\\tThe\\tbigger\\tthe\\tround\\tobject,\\tthe\\tharder\\tI\\nshould\\ttry\\tto\\tget\\tit.\\nIt’s\\tlike\\tthe\\tbrain\\tof\\teach\\tanimal\\tis\\tpreloaded\\twith\\tcertain\\trules\\tfor\\tbehavior,\\nand\\twhen\\tit\\tcomes\\tacross\\tan\\texaggerated\\tversion\\tof\\tthat\\trule,\\tit\\tlights\\tup\\tlike\\ta\\nChristmas\\ttree.\\tScientists\\trefer\\tto\\tthese\\texaggerated\\tcues\\tas\\t\\nsupernormal\\tstimuli\\n.\\nA\\tsupernormal\\tstimulus\\tis\\ta\\theightened\\tversion\\tof\\treality—like\\ta\\tbeak\\twith\\nthree\\tred\\tdots\\tor\\tan\\tegg\\tthe\\tsize\\tof\\ta\\tvolleyball—and\\tit\\telicits\\ta\\tstronger\\nresponse\\tthan\\tusual.\\nHumans\\tare\\talso\\tprone\\tto\\tfall\\tfor\\texaggerated\\tversions\\tof\\treality.\\tJunk\\tfood,\\nfor\\texample,\\tdrives\\tour\\treward\\tsystems\\tinto\\ta\\tfrenzy.\\tAfter\\tspending\\thundreds\\nof\\tthousands\\tof\\tyears\\thunting\\tand\\tforaging\\tfor\\tfood\\tin\\tthe\\twild,\\tthe\\thuman\\tbrain\\nhas\\tevolved\\tto\\tplace\\ta\\thigh\\tvalue\\ton\\tsalt,\\tsugar,\\tand\\tfat.\\tSuch\\tfoods\\tare\\toften\\ncalorie-dense\\tand\\tthey\\twere\\tquite\\trare\\twhen\\tour\\tancient\\tancestors\\twere\\troaming\\nthe\\tsavannah.\\tWhen\\tyou\\tdon’t\\tknow\\twhere\\tyour\\tnext\\tmeal\\tis\\tcoming\\tfrom,\\neating\\tas\\tmuch\\tas\\tpossible\\tis\\tan\\texcellent\\tstrategy\\tfor\\tsurvival.\\nToday,\\thowever,\\twe\\tlive\\tin\\ta\\tcalorie-rich\\tenvironment.\\tFood\\tis\\t\\nabundant,\\tbut\\nyour\\tbrain\\tcontinues\\tto\\tcrave\\tit\\tlike\\tit\\tis\\tscarce.\\tPlacing\\ta\\thigh\\tvalue\\ton\\tsalt,\\nsugar,\\tand\\tfat\\tis\\tno\\tlonger\\tadvantageous\\tto\\tour\\thealth,\\tbut\\tthe\\tcraving\\tpersists\\nbecause\\tthe\\tbrain’s\\treward\\tcenters\\thave\\tnot\\tchanged\\tfor\\tapproximately\\tfifty\\nthousand\\tyears.\\t\\nThe\\tmodern\\tfood\\tindustry\\trelies\\ton\\tstretching\\tour\\tPaleolithic\\ninstincts\\tbeyond\\ttheir\\tevolutionary\\tpurpose.\\nA\\tprimary\\tgoal\\tof\\tfood\\tscience\\tis\\tto\\tcreate\\tproducts\\tthat\\tare\\tmore\\tattractive\\tto\\nconsumers.\\t\\nNearly\\tevery\\tfood\\tin\\ta\\tbag,\\tbox,\\tor\\tjar\\thas\\tbeen\\tenhanced\\tin\\tsome\\nway,\\tif\\tonly\\twith\\tadditional\\tflavoring.\\tCompanies\\tspend\\tmillions\\tof\\tdollars\\tto\\ndiscover\\tthe\\tmost\\tsatisfying\\tlevel\\tof\\tcrunch\\tin\\ta\\tpotato\\tchip\\tor\\tthe\\tperfect\\namount\\tof\\tfizz\\tin\\ta\\tsoda.\\tEntire\\tdepartments\\tare\\tdedicated\\tto\\toptimizing\\thow\\ta\\nproduct\\tfeels\\tin\\tyour\\tmouth—a\\tquality\\tknown\\tas\\t\\norosensation\\n.\\t\\nFrench\\tfries,\\tfor\\nexample,\\tare\\ta\\tpotent\\tcombination—golden\\tbrown\\tand\\tcrunchy\\ton\\tthe\\toutside,\\nlight\\tand\\tsmooth\\ton\\tthe\\tinside.\\nOther\\tprocessed\\tfoods\\tenhance\\t\\ndynamic\\tcontrast\\n,\\twhich\\trefers\\tto\\titems\\twith\\ta\\ncombination\\tof\\tsensations,\\tlike\\tcrunchy\\tand\\tcreamy.\\tImagine\\tthe\\tgooeyness\\tof\\nmelted\\tcheese\\ton\\ttop\\tof\\ta\\tcrispy\\tpizza\\tcrust,\\tor\\tthe\\tcrunch\\tof\\tan\\tOreo\\tcookie\\ncombined\\twith\\tits\\tsmooth\\tcenter.\\tWith\\tnatural,\\tunprocessed\\tfoods,\\tyou\\ttend\\tto\\nexperience\\tthe\\tsame\\tsensations\\tover\\tand\\tover—\\nhow’s\\tthat\\tseventeenth\\tbite\\tof\\nkale\\ttaste?\\n\\tAfter\\ta\\tfew\\tminutes,\\tyour\\tbrain\\tloses\\tinterest\\tand\\tyou\\tbegin\\tto\\tfeel\\nfull.\\tBut\\tfoods\\tthat\\tare\\thigh\\tin\\tdynamic\\tcontrast\\tkeep\\tthe\\texperience\\tnovel\\tand\\ninteresting,\\tencouraging\\tyou\\tto\\teat\\tmore.\\nUltimately,\\t\\nsuch\\tstrategies\\tenable\\tfood\\tscientists\\tto\\tfind\\tthe\\t“bliss\\tpoint”\\tfor', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 84}), Document(page_content='each\\tproduct—the\\tprecise\\tcombination\\tof\\tsalt,\\tsugar,\\tand\\tfat\\tthat\\texcites\\tyour\\nbrain\\tand\\tkeeps\\tyou\\tcoming\\tback\\tfor\\tmore.\\tThe\\tresult,\\tof\\tcourse,\\tis\\tthat\\tyou\\novereat\\tbecause\\thyperpalatable\\tfoods\\tare\\tmore\\tattractive\\tto\\tthe\\thuman\\tbrain.\\tAs\\nStephan\\tGuyenet,\\ta\\tneuroscientist\\twho\\tspecializes\\tin\\teating\\tbehavior\\tand\\nobesity,\\tsays,\\t“\\nWe’ve\\tgotten\\ttoo\\tgood\\tat\\tpushing\\tour\\town\\tbuttons.”\\nThe\\tmodern\\tfood\\tindustry,\\tand\\tthe\\tovereating\\thabits\\tit\\thas\\tspawned,\\tis\\tjust\\none\\texample\\tof\\tthe\\t2nd\\tLaw\\tof\\tBehavior\\tChange:\\t\\nMake\\tit\\tattractive.\\n\\tThe\\tmore\\nattractive\\tan\\topportunity\\tis,\\tthe\\tmore\\tlikely\\tit\\tis\\tto\\tbecome\\thabit-forming.\\nLook\\taround.\\tSociety\\tis\\tfilled\\twith\\thighly\\tengineered\\tversions\\tof\\treality\\tthat\\nare\\tmore\\tattractive\\tthan\\tthe\\tworld\\tour\\tancestors\\tevolved\\tin.\\tStores\\tfeature\\nmannequins\\twith\\texaggerated\\thips\\tand\\tbreasts\\tto\\tsell\\tclothes.\\tSocial\\tmedia\\ndelivers\\tmore\\t“likes”\\tand\\tpraise\\tin\\ta\\tfew\\tminutes\\tthan\\twe\\tcould\\tever\\tget\\tin\\tthe\\noffice\\tor\\tat\\thome.\\tOnline\\tporn\\tsplices\\ttogether\\tstimulating\\tscenes\\tat\\ta\\trate\\tthat\\nwould\\tbe\\timpossible\\tto\\treplicate\\tin\\treal\\tlife.\\tAdvertisements\\tare\\tcreated\\twith\\ta\\ncombination\\tof\\tideal\\tlighting,\\tprofessional\\tmakeup,\\tand\\tPhotoshopped\\tedits—\\neven\\tthe\\tmodel\\tdoesn’t\\tlook\\tlike\\tthe\\tperson\\tin\\tthe\\tfinal\\timage.\\tThese\\tare\\tthe\\nsupernormal\\tstimuli\\tof\\tour\\tmodern\\tworld.\\tThey\\texaggerate\\tfeatures\\tthat\\tare\\nnaturally\\tattractive\\tto\\tus,\\tand\\tour\\tinstincts\\tgo\\twild\\tas\\ta\\tresult,\\tdriving\\tus\\tinto\\nexcessive\\tshopping\\thabits,\\tsocial\\tmedia\\thabits,\\tporn\\thabits,\\teating\\thabits,\\tand\\nmany\\tothers.\\nIf\\thistory\\tserves\\tas\\ta\\tguide,\\tthe\\topportunities\\tof\\tthe\\tfuture\\twill\\tbe\\tmore\\nattractive\\tthan\\tthose\\tof\\ttoday.\\tThe\\ttrend\\tis\\tfor\\trewards\\tto\\tbecome\\tmore\\nconcentrated\\tand\\tstimuli\\tto\\tbecome\\tmore\\tenticing.\\tJunk\\tfood\\tis\\ta\\tmore\\nconcentrated\\tform\\tof\\tcalories\\tthan\\tnatural\\tfoods.\\tHard\\tliquor\\tis\\ta\\tmore\\nconcentrated\\tform\\tof\\talcohol\\tthan\\tbeer.\\tVideo\\tgames\\tare\\ta\\tmore\\tconcentrated\\nform\\tof\\tplay\\tthan\\tboard\\tgames.\\tCompared\\tto\\tnature,\\tthese\\tpleasure-packed\\nexperiences\\tare\\thard\\tto\\tresist.\\tWe\\thave\\tthe\\tbrains\\tof\\tour\\tancestors\\tbut\\ntemptations\\tthey\\tnever\\thad\\tto\\tface.\\nIf\\tyou\\twant\\tto\\tincrease\\tthe\\todds\\tthat\\ta\\tbehavior\\twill\\toccur,\\tthen\\tyou\\tneed\\tto\\nmake\\tit\\tattractive.\\tThroughout\\tour\\tdiscussion\\tof\\tthe\\t2nd\\tLaw,\\tour\\tgoal\\tis\\tto\\tlearn\\nhow\\tto\\tmake\\tour\\thabits\\tirresistible.\\tWhile\\tit\\tis\\tnot\\tpossible\\tto\\ttransform\\tevery\\nhabit\\tinto\\ta\\tsupernormal\\tstimulus,\\twe\\tcan\\tmake\\tany\\thabit\\tmore\\tenticing.\\tTo\\tdo\\nthis,\\twe\\tmust\\tstart\\tby\\tunderstanding\\twhat\\ta\\tcraving\\tis\\tand\\thow\\tit\\tworks.\\nWe\\tbegin\\tby\\texamining\\ta\\tbiological\\tsignature\\tthat\\tall\\thabits\\tshare—the\\ndopamine\\tspike.\\nTHE\\tDOPAMINE-DRIVEN\\tFEEDBACK\\tLOOP', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 85}), Document(page_content='Scientists\\tcan\\ttrack\\tthe\\tprecise\\tmoment\\ta\\tcraving\\toccurs\\tby\\tmeasuring\\ta\\nneurotransmitter\\tcalled\\tdopamine.\\n*\\n\\t\\nThe\\timportance\\tof\\tdopamine\\tbecame\\napparent\\tin\\t1954\\twhen\\tthe\\tneuroscientists\\tJames\\tOlds\\tand\\tPeter\\tMilner\\tran\\tan\\nexperiment\\tthat\\trevealed\\tthe\\t\\nneurological\\tprocesses\\tbehind\\tcraving\\tand\\tdesire.\\nBy\\timplanting\\telectrodes\\tin\\tthe\\tbrains\\tof\\trats,\\tthe\\tresearchers\\tblocked\\tthe\\trelease\\nof\\tdopamine.\\tTo\\tthe\\tsurprise\\tof\\tthe\\tscientists,\\tthe\\t\\nrats\\tlost\\tall\\twill\\tto\\tlive.\\tThey\\nwouldn’t\\teat.\\tThey\\twouldn’t\\thave\\tsex.\\tThey\\tdidn’t\\tcrave\\tanything.\\tWithin\\ta\\tfew\\ndays,\\tthe\\tanimals\\tdied\\tof\\tthirst.\\nIn\\tfollow-up\\tstudies,\\tother\\tscientists\\talso\\tinhibited\\tthe\\tdopamine-releasing\\nparts\\tof\\tthe\\tbrain,\\tbut\\tthis\\ttime,\\tthey\\tsquirted\\tlittle\\tdroplets\\tof\\tsugar\\tinto\\tthe\\nmouths\\tof\\tthe\\tdopamine-depleted\\trats.\\tTheir\\tlittle\\trat\\tfaces\\tlit\\tup\\twith\\npleasurable\\tgrins\\tfrom\\tthe\\ttasty\\tsubstance.\\tEven\\tthough\\tdopamine\\twas\\tblocked,\\nthey\\t\\nliked\\n\\tthe\\tsugar\\tjust\\tas\\tmuch\\tas\\tbefore;\\tthey\\tjust\\tdidn’t\\t\\nwant\\n\\tit\\tanymore.\\tThe\\nability\\tto\\texperience\\tpleasure\\tremained,\\tbut\\twithout\\tdopamine,\\tdesire\\tdied.\\tAnd\\nwithout\\tdesire,\\taction\\tstopped.\\nWhen\\tother\\tresearchers\\treversed\\tthis\\tprocess\\tand\\tflooded\\tthe\\treward\\tsystem\\nof\\tthe\\tbrain\\twith\\tdopamine,\\tanimals\\tperformed\\thabits\\tat\\tbreakneck\\tspeed.\\tIn\\tone\\nstudy,\\tmice\\treceived\\ta\\tpowerful\\thit\\tof\\tdopamine\\teach\\ttime\\tthey\\tpoked\\ttheir\\tnose\\nin\\ta\\tbox.\\tWithin\\tminutes,\\t\\nthe\\t\\nmice\\tdeveloped\\ta\\tcraving\\tso\\tstrong\\tthey\\tbegan\\npoking\\ttheir\\tnose\\tinto\\tthe\\tbox\\teight\\thundred\\ttimes\\tper\\thour.\\t(Humans\\tare\\tnot\\tso\\ndifferent:\\t\\nthe\\taverage\\tslot\\tmachine\\tplayer\\twill\\tspin\\tthe\\twheel\\tsix\\thundred\\ttimes\\nper\\thour.)\\nHabits\\tare\\ta\\t\\ndopamine-driven\\tfeedback\\tloop.\\tEvery\\tbehavior\\tthat\\tis\\thighly\\nhabit-forming—taking\\tdrugs,\\teating\\tjunk\\tfood,\\tplaying\\tvideo\\tgames,\\tbrowsing\\nsocial\\tmedia—is\\tassociated\\twith\\thigher\\tlevels\\tof\\tdopamine.\\tThe\\tsame\\tcan\\tbe\\nsaid\\tfor\\tour\\tmost\\tbasic\\thabitual\\tbehaviors\\tlike\\teating\\tfood,\\tdrinking\\twater,\\nhaving\\tsex,\\tand\\tinteracting\\tsocially.\\nFor\\tyears,\\tscientists\\tassumed\\tdopamine\\twas\\tall\\tabout\\tpleasure,\\tbut\\tnow\\twe\\nknow\\tit\\tplays\\ta\\tcentral\\trole\\tin\\tmany\\tneurological\\tprocesses,\\tincluding\\nmotivation,\\tlearning\\tand\\tmemory,\\tpunishment\\tand\\taversion,\\tand\\tvoluntary\\nmovement.\\nWhen\\tit\\tcomes\\tto\\thabits,\\tthe\\tkey\\ttakeaway\\tis\\tthis:\\t\\ndopamine\\tis\\treleased\\tnot\\nonly\\twhen\\tyou\\t\\nexperience\\n\\tpleasure,\\tbut\\talso\\twhen\\tyou\\n\\tanticipate\\n\\tit.\\tGambling\\naddicts\\thave\\ta\\tdopamine\\tspike\\tright\\t\\nbefore\\n\\tthey\\tplace\\ta\\tbet,\\tnot\\tafter\\tthey\\twin.\\nCocaine\\taddicts\\tget\\ta\\tsurge\\tof\\tdopamine\\twhen\\tthey\\t\\nsee\\n\\tthe\\tpowder,\\tnot\\tafter\\nthey\\ttake\\tit.\\tWhenever\\tyou\\tpredict\\tthat\\tan\\topportunity\\twill\\tbe\\trewarding,\\tyour\\nlevels\\tof\\tdopamine\\tspike\\tin\\tanticipation.\\tAnd\\t\\nwhenever\\tdopamine\\trises,\\tso\\tdoes\\nyour\\tmotivation\\tto\\tact.\\nIt\\tis\\tthe\\tanticipation\\tof\\ta\\treward—not\\tthe\\tfulfillment\\tof\\tit—that\\tgets\\tus\\tto\\ttake', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 86}), Document(page_content='action.\\nInterestingly,\\t\\nthe\\treward\\tsystem\\tthat\\tis\\tactivated\\tin\\tthe\\tbrain\\twhen\\tyou\\t\\nreceive\\na\\treward\\tis\\tthe\\tsame\\tsystem\\tthat\\tis\\tactivated\\twhen\\tyou\\t\\nanticipate\\n\\ta\\treward.\\tThis\\nis\\tone\\treason\\tthe\\tanticipation\\tof\\tan\\texperience\\tcan\\toften\\tfeel\\tbetter\\tthan\\tthe\\nattainment\\tof\\tit.\\tAs\\ta\\tchild,\\tthinking\\tabout\\tChristmas\\tmorning\\tcan\\tbe\\tbetter\\tthan\\nopening\\tthe\\tgifts.\\tAs\\tan\\tadult,\\tdaydreaming\\tabout\\tan\\tupcoming\\tvacation\\tcan\\tbe\\nmore\\tenjoyable\\tthan\\tactually\\tbeing\\ton\\tvacation.\\tScientists\\trefer\\tto\\tthis\\tas\\tthe\\ndifference\\tbetween\\t“wanting”\\tand\\t“liking.”\\nTHE\\tDOPAMINE\\tSPIKE', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 87}), Document(page_content='FIGURE\\t9:\\tBefore\\ta\\thabit\\tis\\tlearned\\t(A),\\tdopamine\\tis\\treleased\\twhen\\tthe\\treward\\tis\\texperienced\\tfor\\tthe\\tfirst\\ttime.\\tThe\\tnext\\ttime\\taround\\t(B),\\tdopamine\\trises\\t\\nbefore\\n\\ttaking\\taction,\\timmediately\\nafter\\ta\\tcue\\tis\\trecognized.\\tThis\\tspike\\tleads\\tto\\ta\\tfeeling\\tof\\tdesire\\tand\\ta\\tcraving\\tto\\ttake\\taction\\twhenever\\tthe\\tcue\\tis\\tspotted.\\tOnce\\ta\\thabit\\tis\\tlearned,\\tdopamine\\twill\\tnot\\trise\\twhen\\ta\\treward\\tis\\nexperienced\\tbecause\\tyou\\talready\\texpect\\tthe\\treward.\\tHowever,\\tif\\tyou\\tsee\\ta\\tcue\\tand\\texpect\\ta\\treward,\\tbut\\tdo\\tnot\\tget\\tone,\\tthen\\tdopamine\\twill\\tdrop\\tin\\tdisappointment\\t(C).\\tThe\\tsensitivity\\tof\\tthe\\ndopamine\\tresponse\\tcan\\tclearly\\tbe\\tseen\\twhen\\ta\\treward\\tis\\tprovided\\tlate\\t(D).\\tFirst,\\tthe\\tcue\\tis\\tidentified\\tand\\tdopamine\\trises\\tas\\ta\\tcraving\\tbuilds.\\tNext,\\ta\\tresponse\\tis\\ttaken\\tbut\\tthe\\treward\\tdoes\\tnot\\ncome\\tas\\tquickly\\tas\\texpected\\tand\\tdopamine\\tbegins\\tto\\tdrop.\\tFinally,\\twhen\\tthe\\treward\\tcomes\\ta\\tlittle\\tlater\\tthan\\tyou\\thad\\thoped,\\tdopamine\\tspikes\\tagain.\\tIt\\tis\\tas\\tif\\tthe\\tbrain\\tis\\tsaying,\\t“See!\\tI\\nknew\\tI\\twas\\tright.\\tDon’t\\tforget\\tto\\trepeat\\tthis\\taction\\tnext\\ttime.”\\nYour\\tbrain\\thas\\tfar\\tmore\\tneural\\tcircuitry\\tallocated\\tfor\\t\\nwanting\\n\\trewards\\tthan\\nfor\\t\\nliking\\n\\tthem.\\tThe\\twanting\\tcenters\\tin\\tthe\\tbrain\\tare\\tlarge:\\tthe\\tbrain\\tstem,\\tthe\\nnucleus\\taccumbens,\\tthe\\tventral\\ttegmental\\tarea,\\tthe\\tdorsal\\tstriatum,\\tthe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 88}), Document(page_content='amygdala,\\tand\\tportions\\tof\\tthe\\tprefrontal\\tcortex.\\tBy\\tcomparison,\\tthe\\tliking\\ncenters\\tof\\tthe\\tbrain\\tare\\tmuch\\tsmaller.\\tThey\\tare\\toften\\treferred\\tto\\tas\\t“hedonic\\thot\\nspots”\\tand\\tare\\tdistributed\\tlike\\ttiny\\tislands\\tthroughout\\tthe\\tbrain.\\tFor\\tinstance,\\nresearchers\\thave\\tfound\\tthat\\t\\n100\\tpercent\\tof\\tthe\\tnucleus\\taccumbens\\tis\\tactivated\\nduring\\twanting.\\tMeanwhile,\\tonly\\t10\\tpercent\\tof\\tthe\\tstructure\\tis\\tactivated\\tduring\\nliking.\\nThe\\tfact\\tthat\\tthe\\tbrain\\tallocates\\tso\\tmuch\\tprecious\\tspace\\tto\\tthe\\tregions\\nresponsible\\tfor\\tcraving\\tand\\tdesire\\tprovides\\tfurther\\tevidence\\tof\\tthe\\tcrucial\\trole\\nthese\\tprocesses\\tplay.\\tDesire\\tis\\tthe\\tengine\\tthat\\tdrives\\tbehavior.\\tEvery\\taction\\tis\\ntaken\\tbecause\\tof\\tthe\\tanticipation\\tthat\\tprecedes\\tit.\\tIt\\tis\\tthe\\tcraving\\tthat\\tleads\\tto\\nthe\\tresponse.\\nThese\\tinsights\\treveal\\tthe\\timportance\\tof\\tthe\\t2nd\\tLaw\\tof\\tBehavior\\tChange.\\tWe\\nneed\\tto\\tmake\\tour\\thabits\\tattractive\\tbecause\\tit\\tis\\tthe\\texpectation\\tof\\ta\\trewarding\\nexperience\\tthat\\tmotivates\\tus\\tto\\tact\\tin\\tthe\\tfirst\\tplace.\\tThis\\tis\\twhere\\ta\\tstrategy\\nknown\\tas\\ttemptation\\tbundling\\tcomes\\tinto\\tplay.\\nHOW\\tTO\\tUSE\\tTEMPTATION\\tBUNDLING\\tTO\\tMAKE\\tYOUR\\tHABITS\\nMORE\\tATTRACTIVE\\nRonan\\tByrne,\\tan\\telectrical\\tengineering\\tstudent\\tin\\tDublin,\\tIreland,\\tenjoyed\\nwatching\\tNetflix,\\tbut\\the\\talso\\tknew\\tthat\\the\\tshould\\texercise\\tmore\\toften\\tthan\\the\\ndid.\\tPutting\\this\\tengineering\\tskills\\tto\\tuse,\\t\\nByrne\\thacked\\this\\tstationary\\tbike\\tand\\nconnected\\tit\\tto\\this\\tlaptop\\tand\\ttelevision.\\tThen\\the\\twrote\\ta\\tcomputer\\tprogram\\tthat\\nwould\\tallow\\tNetflix\\tto\\trun\\t\\nonly\\n\\tif\\the\\twas\\tcycling\\tat\\ta\\tcertain\\tspeed.\\tIf\\the\\tslowed\\ndown\\tfor\\ttoo\\tlong,\\twhatever\\tshow\\the\\twas\\twatching\\twould\\tpause\\tuntil\\the\\tstarted\\npedaling\\tagain.\\tHe\\twas,\\tin\\tthe\\twords\\tof\\tone\\tfan,\\t“\\neliminating\\tobesity\\tone\\tNetflix\\nbinge\\tat\\ta\\ttime.”\\nHe\\twas\\talso\\temploying\\ttemptation\\tbundling\\tto\\tmake\\this\\texercise\\thabit\\tmore\\nattractive.\\tTemptation\\tbundling\\tworks\\tby\\tlinking\\tan\\taction\\tyou\\twant\\tto\\tdo\\twith\\nan\\taction\\tyou\\tneed\\tto\\tdo.\\tIn\\tByrne’s\\tcase,\\the\\tbundled\\twatching\\tNetflix\\t(the\\nthing\\the\\twanted\\tto\\tdo)\\twith\\triding\\this\\tstationary\\tbike\\t(the\\tthing\\the\\tneeded\\tto\\tdo).\\nBusinesses\\tare\\tmasters\\tat\\ttemptation\\tbundling.\\tFor\\tinstance,\\twhen\\tthe\\nAmerican\\tBroadcasting\\tCompany,\\tmore\\tcommonly\\tknown\\tas\\tABC,\\tlaunched\\tits\\nThursday-night\\ttelevision\\tlineup\\tfor\\tthe\\t2014–2015\\tseason,\\tthey\\tpromoted\\ntemptation\\tbundling\\ton\\ta\\tmassive\\tscale.\\nEvery\\tThursday,\\tthe\\tcompany\\twould\\tair\\tthree\\tshows\\tcreated\\tby\\tscreenwriter\\nShonda\\tRhimes—\\nGrey’s\\tAnatomy\\n,\\t\\nScandal\\n,\\tand\\t\\nHow\\tto\\tGet\\tAway\\twith\\tMurder\\n.\\nThey\\tbranded\\tit\\tas\\t“TGIT\\ton\\tABC”\\t(TGIT\\tstands\\tfor\\tThank\\tGod\\tIt’s\\tThursday).', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 89}), Document(page_content='In\\taddition\\tto\\tpromoting\\tthe\\tshows,\\tABC\\tencouraged\\tviewers\\tto\\tmake\\tpopcorn,\\ndrink\\tred\\twine,\\tand\\tenjoy\\tthe\\tevening.\\nAndrew\\tKubitz,\\thead\\tof\\tscheduling\\tfor\\tABC,\\tdescribed\\tthe\\tidea\\tbehind\\tthe\\ncampaign:\\t“\\nWe\\tsee\\tThursday\\tnight\\tas\\ta\\tviewership\\topportunity,\\twith\\teither\\ncouples\\tor\\twomen\\tby\\tthemselves\\twho\\twant\\tto\\tsit\\tdown\\tand\\tescape\\tand\\thave\\tfun\\nand\\tdrink\\ttheir\\tred\\twine\\tand\\thave\\tsome\\tpopcorn.”\\tThe\\tbrilliance\\tof\\tthis\\tstrategy\\nis\\tthat\\tABC\\twas\\tassociating\\tthe\\tthing\\tthey\\t\\nneeded\\n\\tviewers\\tto\\tdo\\t(watch\\ttheir\\nshows)\\twith\\tactivities\\ttheir\\tviewers\\talready\\n\\twanted\\n\\tto\\tdo\\t(relax,\\tdrink\\twine,\\tand\\neat\\tpopcorn).\\nOver\\ttime,\\tpeople\\tbegan\\tto\\tconnect\\twatching\\tABC\\twith\\tfeeling\\trelaxed\\tand\\nentertained.\\tIf\\tyou\\tdrink\\tred\\twine\\tand\\teat\\tpopcorn\\tat\\t8\\tp.m.\\tevery\\tThursday,\\nthen\\teventually\\t“8\\tp.m.\\ton\\tThursday”\\t\\nmeans\\n\\trelaxation\\tand\\tentertainment.\\tThe\\nreward\\tgets\\tassociated\\twith\\tthe\\tcue,\\tand\\tthe\\thabit\\tof\\tturning\\ton\\tthe\\ttelevision\\nbecomes\\tmore\\tattractive.\\nYou’re\\tmore\\tlikely\\tto\\tfind\\ta\\tbehavior\\tattractive\\tif\\tyou\\tget\\tto\\tdo\\tone\\tof\\tyour\\nfavorite\\tthings\\tat\\tthe\\tsame\\ttime.\\tPerhaps\\tyou\\twant\\tto\\thear\\tabout\\tthe\\tlatest\\ncelebrity\\tgossip,\\tbut\\tyou\\tneed\\tto\\tget\\tin\\tshape.\\tUsing\\ttemptation\\tbundling,\\tyou\\ncould\\tonly\\tread\\tthe\\ttabloids\\tand\\twatch\\t\\nreality\\tshows\\tat\\tthe\\tgym.\\tMaybe\\tyou\\nwant\\tto\\tget\\ta\\tpedicure,\\tbut\\tyou\\tneed\\tto\\tclean\\tout\\tyour\\temail\\tinbox.\\tSolution:\\nonly\\tget\\ta\\tpedicure\\twhile\\tprocessing\\toverdue\\twork\\temails.\\nTemptation\\tbundling\\tis\\tone\\tway\\tto\\tapply\\ta\\tpsychology\\ttheory\\tknown\\tas\\nPremack’s\\tPrinciple.\\tNamed\\tafter\\tthe\\twork\\tof\\tprofessor\\tDavid\\tPremack,\\tthe\\nprinciple\\tstates\\tthat\\t“\\nmore\\tprobable\\tbehaviors\\twill\\treinforce\\tless\\tprobable\\nbehaviors.”\\tIn\\tother\\twords,\\teven\\tif\\tyou\\tdon’t\\treally\\twant\\tto\\tprocess\\toverdue\\nwork\\temails,\\tyou’ll\\tbecome\\tconditioned\\tto\\tdo\\tit\\tif\\tit\\tmeans\\tyou\\tget\\tto\\tdo\\nsomething\\tyou\\treally\\twant\\tto\\tdo\\talong\\tthe\\tway.\\nYou\\tcan\\teven\\tcombine\\ttemptation\\tbundling\\twith\\tthe\\thabit\\tstacking\\tstrategy\\nwe\\tdiscussed\\tin\\tChapter\\t5\\tto\\tcreate\\ta\\tset\\tof\\trules\\tto\\tguide\\tyour\\tbehavior.\\nThe\\thabit\\tstacking\\t+\\ttemptation\\tbundling\\tformula\\tis:\\n1.\\t\\nAfter\\t[CURRENT\\tHABIT],\\tI\\twill\\t[HABIT\\tI\\tNEED].\\n2.\\t\\nAfter\\t[HABIT\\tI\\tNEED],\\tI\\twill\\t[HABIT\\tI\\tWANT].\\nIf\\tyou\\twant\\tto\\tread\\tthe\\tnews,\\tbut\\tyou\\tneed\\tto\\texpress\\tmore\\tgratitude:', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 90}), Document(page_content='1.\\t\\nAfter\\tI\\tget\\tmy\\tmorning\\tcoffee,\\tI\\twill\\tsay\\tone\\tthing\\tI’m\\tgrateful\\tfor\\nthat\\thappened\\tyesterday\\t(need).\\n2.\\t\\nAfter\\tI\\tsay\\tone\\tthing\\tI’m\\tgrateful\\tfor,\\tI\\twill\\tread\\tthe\\tnews\\t(want).\\nIf\\tyou\\twant\\tto\\twatch\\tsports,\\tbut\\tyou\\tneed\\tto\\tmake\\tsales\\tcalls:\\n1.\\t\\nAfter\\tI\\tget\\tback\\tfrom\\tmy\\tlunch\\tbreak,\\tI\\twill\\tcall\\tthree\\tpotential\\tclients\\n(need).\\n2.\\t\\nAfter\\tI\\tcall\\tthree\\tpotential\\tclients,\\tI\\twill\\tcheck\\tESPN\\t(want).\\nIf\\tyou\\twant\\tto\\tcheck\\tFacebook,\\tbut\\tyou\\tneed\\tto\\texercise\\tmore:\\n1.\\t\\nAfter\\tI\\tpull\\tout\\tmy\\tphone,\\tI\\twill\\tdo\\tten\\tburpees\\t(need).\\n2.\\t\\nAfter\\tI\\tdo\\tten\\tburpees,\\tI\\twill\\tcheck\\tFacebook\\t(want).\\nThe\\thope\\tis\\tthat\\teventually\\tyou’ll\\tlook\\tforward\\tto\\tcalling\\tthree\\tclients\\tor\\ndoing\\tten\\tburpees\\tbecause\\tit\\tmeans\\tyou\\tget\\tto\\tread\\tthe\\tlatest\\tsports\\tnews\\tor\\ncheck\\tFacebook.\\tDoing\\tthe\\tthing\\tyou\\tneed\\tto\\tdo\\tmeans\\tyou\\tget\\tto\\tdo\\tthe\\tthing\\nyou\\twant\\tto\\tdo.\\nWe\\tbegan\\tthis\\tchapter\\tby\\tdiscussing\\tsupernormal\\tstimuli,\\twhich\\tare\\nheightened\\tversions\\tof\\treality\\tthat\\tincrease\\tour\\tdesire\\tto\\ttake\\taction.\\tTemptation\\nbundling\\tis\\tone\\tway\\tto\\tcreate\\ta\\theightened\\tversion\\tof\\tany\\thabit\\tby\\tconnecting\\tit\\nwith\\tsomething\\tyou\\talready\\twant.\\tEngineering\\ta\\ttruly\\tirresistible\\thabit\\tis\\ta\\thard\\ntask,\\tbut\\tthis\\tsimple\\tstrategy\\tcan\\tbe\\temployed\\tto\\tmake\\tnearly\\tany\\thabit\\tmore\\nattractive\\tthan\\tit\\twould\\tbe\\totherwise.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 91}), Document(page_content='Chapter\\tSummary\\nThe\\t2nd\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\tattractive.\\nThe\\tmore\\tattractive\\tan\\topportunity\\tis,\\tthe\\tmore\\tlikely\\tit\\tis\\tto\\tbecome\\nhabit-forming.\\nHabits\\tare\\ta\\tdopamine-driven\\tfeedback\\tloop.\\tWhen\\tdopamine\\trises,\\tso\\ndoes\\tour\\tmotivation\\tto\\tact.\\nIt\\tis\\tthe\\tanticipation\\tof\\ta\\treward—not\\tthe\\tfulfillment\\tof\\tit—that\\tgets\\tus\\nto\\ttake\\taction.\\tThe\\tgreater\\tthe\\tanticipation,\\tthe\\tgreater\\tthe\\tdopamine\\nspike.\\nTemptation\\tbundling\\tis\\tone\\tway\\tto\\tmake\\tyour\\thabits\\tmore\\tattractive.\\nThe\\tstrategy\\tis\\tto\\tpair\\tan\\taction\\tyou\\t\\nwant\\n\\tto\\tdo\\twith\\tan\\taction\\tyou\\nneed\\n\\tto\\tdo.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 92}), Document(page_content='9\\nThe\\tRole\\tof\\tFamily\\tand\\tFriends\\tin\\tShaping\\tYour\\nHabits\\nI\\nN\\t1965\\n,\\ta\\tHungarian\\tman\\tnamed\\tLaszlo\\tPolgar\\twrote\\ta\\tseries\\tof\\tstrange\\tletters\\tto\\ta\\nwoman\\tnamed\\tKlara.\\nLaszlo\\twas\\ta\\tfirm\\tbeliever\\tin\\thard\\twork.\\tIn\\tfact,\\tit\\twas\\tall\\the\\tbelieved\\tin:\\the\\ncompletely\\trejected\\tthe\\tidea\\tof\\tinnate\\ttalent.\\tHe\\tclaimed\\tthat\\twith\\tdeliberate\\npractice\\tand\\tthe\\tdevelopment\\tof\\tgood\\thabits,\\ta\\tchild\\tcould\\tbecome\\ta\\tgenius\\tin\\nany\\tfield.\\tHis\\tmantra\\twas\\t“\\nA\\tgenius\\tis\\tnot\\tborn,\\tbut\\tis\\teducated\\tand\\ttrained.”\\nLaszlo\\tbelieved\\tin\\tthis\\tidea\\tso\\tstrongly\\tthat\\the\\twanted\\tto\\ttest\\tit\\twith\\this\\town\\nchildren—and\\the\\twas\\twriting\\tto\\tKlara\\tbecause\\the\\t“needed\\ta\\twife\\twilling\\tto\\njump\\ton\\tboard.”\\tKlara\\twas\\ta\\tteacher\\tand,\\talthough\\tshe\\tmay\\tnot\\thave\\tbeen\\tas\\nadamant\\tas\\tLaszlo,\\tshe\\talso\\tbelieved\\tthat\\twith\\tproper\\tinstruction,\\tanyone\\tcould\\nadvance\\ttheir\\tskills.\\nLaszlo\\tdecided\\tchess\\twould\\tbe\\ta\\tsuitable\\tfield\\tfor\\tthe\\texperiment,\\tand\\the\\tlaid\\nout\\ta\\tplan\\tto\\traise\\this\\tchildren\\tto\\tbecome\\tchess\\tprodigies.\\tThe\\tkids\\twould\\tbe\\nhome-schooled,\\ta\\trarity\\tin\\tHungary\\tat\\tthe\\ttime.\\tThe\\thouse\\twould\\tbe\\tfilled\\twith\\nchess\\tbooks\\tand\\tpictures\\tof\\tfamous\\tchess\\tplayers.\\tThe\\tchildren\\twould\\tplay\\nagainst\\teach\\tother\\tconstantly\\tand\\tcompete\\tin\\tthe\\tbest\\ttournaments\\tthey\\tcould\\nfind.\\tThe\\tfamily\\twould\\t\\nkeep\\ta\\tmeticulous\\tfile\\tsystem\\tof\\tthe\\ttournament\\thistory\\nof\\tevery\\tcompetitor\\tthe\\tchildren\\tfaced.\\tTheir\\tlives\\twould\\tbe\\tdedicated\\tto\\tchess.\\nLaszlo\\tsuccessfully\\tcourted\\tKlara,\\tand\\twithin\\ta\\tfew\\tyears,\\tthe\\tPolgars\\twere\\nparents\\tto\\tthree\\tyoung\\tgirls:\\tSusan,\\tSofia,\\tand\\tJudit.\\nSusan,\\tthe\\toldest,\\tbegan\\tplaying\\tchess\\twhen\\tshe\\twas\\tfour\\tyears\\told.\\tWithin\\nsix\\tmonths,\\tshe\\twas\\tdefeating\\tadults.\\nSofia,\\tthe\\tmiddle\\tchild,\\tdid\\teven\\tbetter.\\tBy\\tfourteen,\\tshe\\twas\\ta\\tworld\\nchampion,\\tand\\ta\\tfew\\tyears\\tlater,\\tshe\\tbecame\\ta\\tgrandmaster.\\nJudit,\\tthe\\tyoungest,\\twas\\tthe\\tbest\\tof\\tall.\\tBy\\tage\\tfive,\\tshe\\tcould\\tbeat\\ther\\tfather.\\nAt\\ttwelve,\\tshe\\twas\\tthe\\tyoungest\\tplayer\\tever\\tlisted\\tamong\\tthe\\ttop\\tone\\thundred', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 93}), Document(page_content='chess\\tplayers\\tin\\tthe\\tworld.\\tAt\\tfifteen\\tyears\\tand\\tfour\\tmonths\\told,\\tshe\\tbecame\\tthe\\nyoungest\\tgrandmaster\\tof\\tall\\ttime—younger\\tthan\\tBobby\\tFischer,\\tthe\\tprevious\\nrecord\\tholder.\\tFor\\ttwenty-seven\\tyears,\\tshe\\twas\\tthe\\tnumber-one-ranked\\tfemale\\nchess\\tplayer\\tin\\tthe\\tworld.\\nThe\\tchildhood\\tof\\tthe\\tPolgar\\tsisters\\twas\\tatypical,\\tto\\tsay\\tthe\\tleast.\\tAnd\\tyet,\\tif\\nyou\\task\\tthem\\tabout\\tit,\\tthey\\tclaim\\ttheir\\tlifestyle\\twas\\tattractive,\\teven\\tenjoyable.\\tIn\\ninterviews,\\tthe\\tsisters\\ttalk\\tabout\\ttheir\\tchildhood\\tas\\tentertaining\\trather\\tthan\\ngrueling.\\tThey\\tloved\\tplaying\\tchess.\\tThey\\tcouldn’t\\tget\\tenough\\tof\\tit.\\tOnce,\\tLaszlo\\nreportedly\\tfound\\tSofia\\tplaying\\tchess\\tin\\tthe\\tbathroom\\tin\\tthe\\tmiddle\\tof\\tthe\\tnight.\\nEncouraging\\ther\\tto\\tgo\\tback\\tto\\tsleep,\\the\\tsaid,\\t“Sofia,\\tleave\\tthe\\tpieces\\talone!”\\tTo\\nwhich\\tshe\\treplied,\\t“Daddy,\\t\\nthey\\n\\twon’t\\tleave\\t\\nme\\n\\talone!”\\nThe\\tPolgar\\tsisters\\tgrew\\tup\\tin\\ta\\tculture\\tthat\\tprioritized\\tchess\\tabove\\tall\\telse—\\npraised\\tthem\\tfor\\tit,\\trewarded\\tthem\\tfor\\tit.\\tIn\\ttheir\\tworld,\\tan\\tobsession\\twith\\tchess\\nwas\\tnormal.\\tAnd\\tas\\twe\\tare\\tabout\\tto\\tsee,\\twhatever\\thabits\\tare\\tnormal\\tin\\tyour\\nculture\\tare\\tamong\\tthe\\tmost\\tattractive\\tbehaviors\\tyou’ll\\tfind.\\nTHE\\tSEDUCTIVE\\tPULL\\tOF\\tSOCIAL\\tNORMS\\nHumans\\tare\\therd\\tanimals.\\tWe\\twant\\tto\\tfit\\tin,\\tto\\tbond\\twith\\tothers,\\tand\\tto\\tearn\\tthe\\nrespect\\tand\\tapproval\\tof\\tour\\tpeers.\\tSuch\\tinclinations\\tare\\tessential\\tto\\tour\\tsurvival.\\nFor\\tmost\\tof\\tour\\tevolutionary\\thistory,\\tour\\tancestors\\tlived\\tin\\ttribes.\\tBecoming\\nseparated\\tfrom\\tthe\\ttribe—or\\tworse,\\tbeing\\tcast\\tout—was\\ta\\tdeath\\tsentence.\\t“The\\nlone\\twolf\\tdies,\\tbut\\tthe\\tpack\\tsurvives.”\\n*\\nMeanwhile,\\tthose\\twho\\tcollaborated\\tand\\tbonded\\twith\\tothers\\tenjoyed\\tincreased\\nsafety,\\tmating\\topportunities,\\tand\\taccess\\tto\\tresources.\\tAs\\tCharles\\tDarwin\\tnoted,\\n“In\\tthe\\tlong\\thistory\\tof\\thumankind,\\tthose\\twho\\tlearned\\tto\\tcollaborate\\tand\\nimprovise\\tmost\\teffectively\\thave\\tprevailed.”\\tAs\\ta\\tresult,\\tone\\tof\\tthe\\tdeepest\\nhuman\\tdesires\\tis\\tto\\tbelong.\\tAnd\\tthis\\tancient\\tpreference\\texerts\\ta\\tpowerful\\ninfluence\\ton\\tour\\tmodern\\tbehavior.\\nWe\\tdon’t\\tchoose\\tour\\tearliest\\thabits,\\twe\\timitate\\tthem.\\tWe\\tfollow\\tthe\\tscript\\nhanded\\tdown\\tby\\tour\\tfriends\\tand\\tfamily,\\tour\\tchurch\\tor\\tschool,\\tour\\tlocal\\ncommunity\\tand\\tsociety\\tat\\tlarge.\\tEach\\tof\\tthese\\tcultures\\tand\\tgroups\\tcomes\\twith\\nits\\town\\tset\\tof\\texpectations\\tand\\tstandards—when\\tand\\twhether\\tto\\tget\\tmarried,\\nhow\\tmany\\tchildren\\tto\\thave,\\twhich\\tholidays\\tto\\tcelebrate,\\thow\\tmuch\\tmoney\\tto\\nspend\\ton\\tyour\\tchild’s\\tbirthday\\tparty.\\tIn\\tmany\\tways,\\tthese\\tsocial\\tnorms\\tare\\tthe\\ninvisible\\trules\\tthat\\tguide\\tyour\\tbehavior\\teach\\tday.\\tYou’re\\talways\\tkeeping\\tthem\\nin\\tmind,\\teven\\tif\\tthey\\tare\\tat\\tthe\\tnot\\ttop\\tof\\tyour\\tmind.\\tOften,\\tyou\\tfollow\\tthe\\thabits\\nof\\tyour\\tculture\\twithout\\tthinking,\\twithout\\tquestioning,\\tand\\tsometimes\\twithout', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 94}), Document(page_content='remembering.\\tAs\\tthe\\tFrench\\tphilosopher\\tMichel\\tde\\tMontaigne\\twrote,\\t“The\\ncustoms\\tand\\tpractices\\tof\\tlife\\tin\\tsociety\\tsweep\\tus\\talong.”\\nMost\\tof\\tthe\\ttime,\\tgoing\\talong\\twith\\tthe\\tgroup\\tdoes\\tnot\\tfeel\\tlike\\ta\\tburden.\\nEveryone\\twants\\tto\\tbelong.\\tIf\\tyou\\tgrow\\tup\\tin\\ta\\tfamily\\tthat\\t\\nrewards\\tyou\\tfor\\tyour\\nchess\\tskills,\\tplaying\\tchess\\twill\\tseem\\tlike\\ta\\tvery\\tattractive\\tthing\\tto\\tdo.\\tIf\\tyou\\nwork\\tin\\ta\\tjob\\twhere\\teveryone\\twears\\texpensive\\tsuits,\\tthen\\tyou’ll\\tbe\\tinclined\\tto\\nsplurge\\ton\\tone\\tas\\twell.\\tIf\\tall\\tof\\tyour\\tfriends\\tare\\tsharing\\tan\\tinside\\tjoke\\tor\\tusing\\ta\\nnew\\tphrase,\\tyou’ll\\twant\\tto\\tdo\\tit,\\ttoo,\\tso\\tthey\\tknow\\tthat\\tyou\\t“get\\tit.”\\tBehaviors\\nare\\tattractive\\twhen\\tthey\\thelp\\tus\\tfit\\tin.\\nWe\\timitate\\tthe\\thabits\\tof\\tthree\\tgroups\\tin\\tparticular:\\n1.\\t\\nThe\\tclose.\\n2.\\t\\nThe\\tmany.\\n3.\\t\\nThe\\tpowerful.\\nEach\\tgroup\\toffers\\tan\\topportunity\\tto\\tleverage\\tthe\\t2nd\\tLaw\\tof\\tBehavior\\tChange\\nand\\tmake\\tour\\thabits\\tmore\\tattractive.\\n1.\\tImitating\\tthe\\tClose\\nProximity\\thas\\ta\\tpowerful\\teffect\\ton\\tour\\tbehavior.\\tThis\\tis\\ttrue\\tof\\tthe\\tphysical\\nenvironment,\\tas\\twe\\tdiscussed\\tin\\tChapter\\t6,\\tbut\\tit\\tis\\talso\\ttrue\\tof\\tthe\\tsocial\\nenvironment.\\nWe\\tpick\\tup\\thabits\\tfrom\\tthe\\tpeople\\taround\\tus.\\tWe\\tcopy\\tthe\\tway\\tour\\tparents\\nhandle\\targuments,\\tthe\\tway\\tour\\tpeers\\tflirt\\twith\\tone\\tanother,\\tthe\\tway\\tour\\ncoworkers\\tget\\tresults.\\tWhen\\tyour\\tfriends\\tsmoke\\tpot,\\tyou\\tgive\\tit\\ta\\ttry,\\ttoo.\\tWhen\\nyour\\twife\\thas\\ta\\thabit\\tof\\tdouble-checking\\tthat\\tthe\\tdoor\\tis\\tlocked\\tbefore\\tgoing\\tto\\nbed,\\tyou\\tpick\\tit\\tup\\tas\\twell.\\nI\\tfind\\tthat\\tI\\toften\\timitate\\tthe\\tbehavior\\tof\\tthose\\taround\\tme\\twithout\\trealizing\\tit.\\nIn\\tconversation,\\tI’ll\\tautomatically\\tassume\\tthe\\tbody\\tposture\\tof\\tthe\\tother\\tperson.\\nIn\\tcollege,\\tI\\tbegan\\tto\\ttalk\\tlike\\tmy\\troommates.\\tWhen\\ttraveling\\tto\\tother\\tcountries,\\nI\\tunconsciously\\timitate\\tthe\\tlocal\\taccent\\tdespite\\treminding\\tmyself\\tto\\tstop.\\nAs\\ta\\tgeneral\\trule,\\tthe\\tcloser\\twe\\tare\\tto\\tsomeone,\\tthe\\tmore\\tlikely\\twe\\t\\nare\\tto\\nimitate\\tsome\\tof\\ttheir\\thabits.\\tOne\\tgroundbreaking\\tstudy\\ttracked\\ttwelve\\tthousand\\npeople\\tfor\\tthirty-two\\tyears\\tand\\tfound\\tthat\\t“\\na\\tperson’s\\tchances\\tof\\tbecoming\\nobese\\tincreased\\tby\\t57\\tpercent\\tif\\the\\tor\\tshe\\thad\\ta\\tfriend\\twho\\tbecame\\tobese.”\\tIt\\nworks\\tthe\\tother\\tway,\\ttoo.\\tAnother\\tstudy\\tfound\\tthat\\t\\nif\\tone\\tperson\\tin\\ta', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 95}), Document(page_content='relationship\\tlost\\tweight,\\tthe\\tother\\tpartner\\twould\\talso\\tslim\\tdown\\tabout\\tone\\tthird\\nof\\tthe\\ttime.\\tOur\\tfriends\\tand\\tfamily\\tprovide\\ta\\tsort\\tof\\tinvisible\\tpeer\\tpressure\\tthat\\npulls\\tus\\tin\\ttheir\\tdirection.\\nOf\\tcourse,\\tpeer\\tpressure\\tis\\tbad\\tonly\\tif\\tyou’re\\tsurrounded\\tby\\tbad\\tinfluences.\\nWhen\\tastronaut\\tMike\\tMassimino\\twas\\ta\\tgraduate\\tstudent\\tat\\tMIT,\\the\\ttook\\ta\\tsmall\\nrobotics\\tclass.\\t\\nOf\\tthe\\tten\\tpeople\\tin\\tthe\\tclass,\\t\\nfour\\n\\tbecame\\tastronauts.\\tIf\\tyour\\ngoal\\twas\\tto\\tmake\\tit\\tinto\\tspace,\\tthen\\tthat\\troom\\twas\\tabout\\tthe\\tbest\\tculture\\tyou\\ncould\\task\\tfor.\\tSimilarly,\\tone\\tstudy\\tfound\\tthat\\t\\nthe\\thigher\\tyour\\tbest\\tfriend’s\\tIQ\\tat\\nage\\televen\\tor\\ttwelve,\\tthe\\thigher\\tyour\\tIQ\\twould\\tbe\\tat\\tage\\tfifteen,\\teven\\tafter\\ncontrolling\\tfor\\tnatural\\tlevels\\tof\\tintelligence.\\tWe\\tsoak\\tup\\tthe\\tqualities\\tand\\npractices\\tof\\tthose\\taround\\tus.\\nOne\\tof\\tthe\\tmost\\teffective\\tthings\\tyou\\tcan\\tdo\\tto\\tbuild\\tbetter\\thabits\\tis\\tto\\tjoin\\ta\\nculture\\twhere\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior.\\tNew\\thabits\\tseem\\nachievable\\twhen\\tyou\\tsee\\tothers\\tdoing\\tthem\\tevery\\tday.\\tIf\\tyou\\tare\\tsurrounded\\tby\\nfit\\tpeople,\\tyou’re\\tmore\\tlikely\\tto\\tconsider\\tworking\\tout\\tto\\tbe\\ta\\tcommon\\thabit.\\tIf\\nyou’re\\tsurrounded\\tby\\tjazz\\tlovers,\\tyou’re\\tmore\\tlikely\\tto\\tbelieve\\tit’s\\treasonable\\tto\\nplay\\tjazz\\tevery\\tday.\\tYour\\tculture\\tsets\\tyour\\texpectation\\tfor\\twhat\\tis\\t“normal.”\\nSurround\\tyourself\\twith\\tpeople\\twho\\thave\\tthe\\thabits\\tyou\\twant\\tto\\thave\\tyourself.\\nYou’ll\\trise\\ttogether.\\nTo\\tmake\\tyour\\thabits\\teven\\tmore\\tattractive,\\tyou\\tcan\\ttake\\tthis\\tstrategy\\tone\\tstep\\nfurther.\\nJoin\\ta\\tculture\\twhere\\t(1)\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior\\tand\\t(2)\\nyou\\talready\\thave\\tsomething\\tin\\tcommon\\twith\\tthe\\tgroup.\\tSteve\\tKamb,\\tan\\nentrepreneur\\tin\\tNew\\tYork\\tCity,\\truns\\ta\\tcompany\\tcalled\\t\\nNerd\\tFitness,\\twhich\\n“helps\\tnerds,\\tmisfits,\\tand\\tmutants\\tlose\\tweight,\\tget\\tstrong,\\tand\\tget\\thealthy.”\\tHis\\nclients\\tinclude\\tvideo\\tgame\\tlovers,\\tmovie\\tfanatics,\\tand\\taverage\\tJoes\\twho\\twant\\tto\\nget\\tin\\tshape.\\tMany\\tpeople\\tfeel\\tout\\tof\\tplace\\tthe\\tfirst\\ttime\\tthey\\tgo\\tto\\tthe\\tgym\\tor\\ntry\\tto\\tchange\\ttheir\\tdiet,\\tbut\\tif\\tyou\\tare\\talready\\tsimilar\\tto\\tthe\\tother\\tmembers\\tof\\tthe\\ngroup\\tin\\tsome\\tway—say,\\tyour\\tmutual\\tlove\\tof\\t\\nStar\\tWars\\n—change\\tbecomes\\nmore\\tappealing\\tbecause\\tit\\tfeels\\tlike\\tsomething\\tpeople\\tlike\\tyou\\talready\\tdo.\\nNothing\\tsustains\\tmotivation\\tbetter\\tthan\\tbelonging\\tto\\tthe\\ttribe.\\tIt\\ttransforms\\ta\\npersonal\\tquest\\tinto\\ta\\tshared\\tone.\\tPreviously,\\tyou\\twere\\ton\\tyour\\town.\\tYour\\nidentity\\twas\\tsingular.\\t\\nYou\\tare\\ta\\treader.\\tYou\\tare\\ta\\tmusician.\\tYou\\tare\\tan\\tathlete.\\nWhen\\tyou\\tjoin\\ta\\tbook\\tclub\\tor\\ta\\tband\\tor\\ta\\tcycling\\tgroup,\\tyour\\tidentity\\tbecomes\\nlinked\\tto\\tthose\\taround\\tyou.\\tGrowth\\tand\\tchange\\tis\\tno\\tlonger\\tan\\tindividual\\npursuit.\\t\\nWe\\tare\\treaders.\\tWe\\tare\\tmusicians.\\tWe\\tare\\tcyclists.\\n\\tThe\\tshared\\tidentity\\nbegins\\tto\\treinforce\\tyour\\tpersonal\\tidentity.\\tThis\\tis\\twhy\\tremaining\\tpart\\tof\\ta\\tgroup\\nafter\\tachieving\\ta\\tgoal\\tis\\tcrucial\\tto\\tmaintaining\\tyour\\thabits.\\tIt’s\\tfriendship\\tand\\ncommunity\\tthat\\tembed\\ta\\tnew\\tidentity\\tand\\thelp\\tbehaviors\\tlast\\tover\\tthe\\tlong\\trun.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 96}), Document(page_content='2.\\tImitating\\tthe\\tMany\\nIn\\tthe\\t1950s,\\tpsychologist\\t\\nSolomon\\tAsch\\tconducted\\ta\\tseries\\tof\\texperiments\\tthat\\nare\\tnow\\ttaught\\tto\\tlegions\\tof\\tundergrads\\teach\\tyear.\\tTo\\tbegin\\teach\\texperiment,\\nthe\\tsubject\\tentered\\tthe\\troom\\twith\\ta\\tgroup\\tof\\tstrangers.\\tUnbeknownst\\tto\\tthem,\\nthe\\tother\\tparticipants\\twere\\tactors\\tplanted\\tby\\tthe\\tresearcher\\tand\\tinstructed\\tto\\ndeliver\\tscripted\\tanswers\\tto\\tcertain\\tquestions.\\nThe\\tgroup\\twould\\tbe\\tshown\\tone\\tcard\\twith\\ta\\tline\\ton\\tit\\tand\\tthen\\ta\\tsecond\\tcard\\nwith\\ta\\tseries\\tof\\tlines.\\tEach\\tperson\\twas\\tasked\\tto\\tselect\\tthe\\tline\\ton\\tthe\\tsecond\\tcard\\nthat\\twas\\tsimilar\\tin\\tlength\\tto\\tthe\\tline\\ton\\tthe\\tfirst\\tcard.\\tIt\\twas\\ta\\tvery\\tsimple\\ttask.\\nHere\\tis\\tan\\texample\\tof\\ttwo\\tcards\\tused\\tin\\tthe\\texperiment:\\nCONFORMING\\tTO\\tSOCIAL\\tNORMS\\nFIGURE\\t10:\\tThis\\tis\\ta\\trepresentation\\tof\\ttwo\\tcards\\tused\\tby\\tSolomon\\tAsch\\tin\\this\\tfamous\\tsocial\\tconformity\\texperiments.\\tThe\\tlength\\tof\\tthe\\tline\\ton\\tthe\\tfirst\\tcard\\t(left)\\tis\\tobviously\\tthe\\tsame\\tas\\nline\\tC,\\tbut\\twhen\\ta\\tgroup\\tof\\tactors\\tclaimed\\tit\\twas\\ta\\tdifferent\\tlength\\tthe\\tresearch\\tsubjects\\twould\\toften\\tchange\\ttheir\\tminds\\tand\\tgo\\twith\\tthe\\tcrowd\\trather\\tthan\\tbelieve\\ttheir\\town\\teyes.\\nThe\\texperiment\\talways\\tbegan\\tthe\\tsame.\\tFirst,\\tthere\\twould\\tbe\\tsome\\teasy\\ttrials', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 97}), Document(page_content='where\\teveryone\\tagreed\\ton\\tthe\\tcorrect\\tline.\\tAfter\\ta\\tfew\\trounds,\\tthe\\tparticipants\\nwere\\tshown\\ta\\ttest\\tthat\\twas\\tjust\\tas\\tobvious\\tas\\tthe\\tprevious\\tones,\\texcept\\tthe\\tactors\\nin\\tthe\\troom\\twould\\tselect\\tan\\tintentionally\\t\\nincorrect\\n\\tanswer.\\tFor\\texample,\\tthey\\nwould\\trespond\\t“A”\\tto\\tthe\\tcomparison\\tshown\\tin\\tFigure\\t10.\\tEveryone\\twould\\nagree\\tthat\\tthe\\tlines\\twere\\tthe\\tsame\\teven\\tthough\\tthey\\twere\\tclearly\\tdifferent.\\nThe\\tsubject,\\twho\\twas\\tunaware\\tof\\tthe\\truse,\\twould\\timmediately\\t\\nbecome\\nbewildered.\\tTheir\\teyes\\twould\\topen\\twide.\\tThey\\twould\\tlaugh\\tnervously\\tto\\nthemselves.\\tThey\\twould\\tdouble-check\\tthe\\treactions\\tof\\tother\\tparticipants.\\tTheir\\nagitation\\twould\\tgrow\\tas\\tone\\tperson\\tafter\\tanother\\tdelivered\\tthe\\tsame\\tincorrect\\nresponse.\\tSoon,\\tthe\\tsubject\\tbegan\\tto\\tdoubt\\ttheir\\town\\teyes.\\tEventually,\\tthey\\ndelivered\\tthe\\tanswer\\tthey\\tknew\\tin\\ttheir\\theart\\tto\\tbe\\tincorrect.\\nAsch\\tran\\tthis\\texperiment\\tmany\\ttimes\\tand\\tin\\tmany\\tdifferent\\tways.\\tWhat\\the\\ndiscovered\\twas\\tthat\\tas\\tthe\\tnumber\\tof\\tactors\\tincreased,\\tso\\tdid\\tthe\\tconformity\\tof\\nthe\\tsubject.\\tIf\\tit\\twas\\tjust\\tthe\\tsubject\\tand\\tone\\tactor,\\tthen\\tthere\\twas\\tno\\teffect\\ton\\nthe\\tperson’s\\tchoice.\\tThey\\tjust\\tassumed\\tthey\\twere\\tin\\tthe\\troom\\twith\\ta\\tdummy.\\nWhen\\ttwo\\tactors\\twere\\tin\\tthe\\troom\\twith\\tthe\\tsubject,\\tthere\\twas\\tstill\\tlittle\\timpact.\\nBut\\tas\\tthe\\tnumber\\tof\\tpeople\\tincreased\\tto\\tthree\\tactors\\tand\\tfour\\tand\\tall\\tthe\\tway\\tto\\neight,\\tthe\\tsubject\\tbecame\\tmore\\tlikely\\tto\\tsecond-guess\\tthemselves.\\t\\nBy\\tthe\\tend\\tof\\nthe\\texperiment,\\tnearly\\t75\\tpercent\\tof\\tthe\\tsubjects\\thad\\tagreed\\twith\\tthe\\tgroup\\nanswer\\teven\\tthough\\tit\\twas\\tobviously\\tincorrect.\\nWhenever\\twe\\tare\\tunsure\\thow\\tto\\tact,\\twe\\tlook\\tto\\tthe\\tgroup\\tto\\tguide\\tour\\nbehavior.\\tWe\\tare\\tconstantly\\tscanning\\tour\\tenvironment\\tand\\twondering,\\t“What\\tis\\neveryone\\telse\\tdoing?”\\tWe\\tcheck\\treviews\\ton\\tAmazon\\tor\\tYelp\\tor\\tTripAdvisor\\nbecause\\twe\\twant\\tto\\timitate\\tthe\\t“best”\\tbuying,\\teating,\\tand\\ttravel\\thabits.\\tIt’s\\nusually\\ta\\tsmart\\tstrategy.\\tThere\\tis\\tevidence\\tin\\tnumbers.\\nBut\\tthere\\tcan\\tbe\\ta\\tdownside.\\nThe\\tnormal\\tbehavior\\tof\\tthe\\ttribe\\toften\\toverpowers\\tthe\\tdesired\\tbehavior\\tof\\tthe\\nindividual.\\tFor\\texample,\\tone\\tstudy\\tfound\\tthat\\twhen\\t\\na\\tchimpanzee\\tlearns\\tan\\neffective\\tway\\tto\\tcrack\\tnuts\\topen\\tas\\ta\\tmember\\tof\\tone\\tgroup\\tand\\tthen\\tswitches\\tto\\na\\tnew\\tgroup\\tthat\\tuses\\ta\\tless\\teffective\\tstrategy,\\tit\\twill\\tavoid\\tusing\\tthe\\tsuperior\\nnut\\tcracking\\tmethod\\tjust\\tto\\tblend\\tin\\twith\\tthe\\trest\\tof\\tthe\\tchimps.\\nHumans\\tare\\tsimilar.\\tThere\\tis\\ttremendous\\tinternal\\tpressure\\tto\\tcomply\\twith\\tthe\\nnorms\\tof\\tthe\\tgroup.\\tThe\\treward\\tof\\tbeing\\taccepted\\tis\\toften\\t\\ngreater\\tthan\\tthe\\nreward\\tof\\twinning\\tan\\targument,\\tlooking\\tsmart,\\tor\\tfinding\\ttruth.\\tMost\\tdays,\\twe’d\\nrather\\tbe\\twrong\\twith\\tthe\\tcrowd\\tthan\\tbe\\tright\\tby\\tourselves.\\nThe\\thuman\\tmind\\tknows\\thow\\tto\\tget\\talong\\twith\\tothers.\\tIt\\t\\nwants\\n\\tto\\tget\\talong\\nwith\\tothers.\\tThis\\tis\\tour\\tnatural\\tmode.\\tYou\\tcan\\toverride\\tit—you\\tcan\\tchoose\\tto\\nignore\\tthe\\tgroup\\tor\\tto\\tstop\\tcaring\\twhat\\tother\\tpeople\\tthink—but\\tit\\ttakes\\twork.\\nRunning\\tagainst\\tthe\\tgrain\\tof\\tyour\\tculture\\trequires\\textra\\teffort.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 98}), Document(page_content='When\\tchanging\\tyour\\thabits\\tmeans\\tchallenging\\tthe\\ttribe,\\tchange\\tis\\nunattractive.\\tWhen\\tchanging\\tyour\\thabits\\tmeans\\tfitting\\tin\\twith\\tthe\\ttribe,\\tchange\\nis\\tvery\\tattractive.\\n3.\\tImitating\\tthe\\tPowerful\\nHumans\\teverywhere\\tpursue\\tpower,\\tprestige,\\tand\\tstatus.\\tWe\\twant\\tpins\\tand\\nmedallions\\ton\\tour\\tjackets.\\tWe\\twant\\tPresident\\tor\\tPartner\\tin\\tour\\ttitles.\\tWe\\twant\\tto\\nbe\\tacknowledged,\\trecognized,\\tand\\tpraised.\\tThis\\ttendency\\tcan\\tseem\\tvain,\\tbut\\noverall,\\tit’s\\ta\\tsmart\\tmove.\\tHistorically,\\ta\\tperson\\twith\\tgreater\\tpower\\tand\\tstatus\\nhas\\taccess\\tto\\tmore\\tresources,\\tworries\\tless\\tabout\\tsurvival,\\tand\\tproves\\tto\\tbe\\ta\\nmore\\tattractive\\tmate.\\nWe\\tare\\tdrawn\\tto\\tbehaviors\\tthat\\tearn\\tus\\trespect,\\tapproval,\\tadmiration,\\tand\\nstatus.\\tWe\\twant\\tto\\tbe\\tthe\\tone\\tin\\tthe\\tgym\\twho\\tcan\\tdo\\tmuscle-ups\\tor\\tthe\\tmusician\\nwho\\tcan\\tplay\\tthe\\thardest\\tchord\\tprogressions\\tor\\tthe\\tparent\\twith\\tthe\\tmost\\naccomplished\\tchildren\\tbecause\\tthese\\tthings\\tseparate\\tus\\tfrom\\tthe\\tcrowd.\\tOnce\\nwe\\tfit\\tin,\\twe\\tstart\\tlooking\\tfor\\tways\\tto\\tstand\\tout.\\nThis\\tis\\tone\\treason\\twe\\tcare\\tso\\tmuch\\tabout\\tthe\\thabits\\tof\\thighly\\teffective\\npeople.\\tWe\\ttry\\tto\\tcopy\\tthe\\tbehavior\\tof\\tsuccessful\\tpeople\\tbecause\\twe\\tdesire\\nsuccess\\tourselves.\\tMany\\tof\\tour\\tdaily\\thabits\\tare\\timitations\\tof\\tpeople\\twe\\tadmire.\\nYou\\treplicate\\tthe\\tmarketing\\tstrategies\\tof\\tthe\\tmost\\tsuccessful\\tfirms\\tin\\tyour\\nindustry.\\tYou\\tmake\\ta\\trecipe\\tfrom\\tyour\\t\\nfavorite\\tbaker.\\tYou\\tborrow\\tthe\\nstorytelling\\tstrategies\\tof\\tyour\\tfavorite\\twriter.\\tYou\\tmimic\\tthe\\tcommunication\\nstyle\\tof\\tyour\\tboss.\\tWe\\timitate\\tpeople\\twe\\tenvy.\\nHigh-status\\tpeople\\tenjoy\\tthe\\tapproval,\\trespect,\\tand\\tpraise\\tof\\tothers.\\tAnd\\tthat\\nmeans\\tif\\ta\\tbehavior\\tcan\\tget\\tus\\tapproval,\\trespect,\\tand\\tpraise,\\twe\\tfind\\tit\\tattractive.\\nWe\\tare\\talso\\tmotivated\\tto\\tavoid\\tbehaviors\\tthat\\twould\\tlower\\tour\\tstatus.\\tWe\\ntrim\\tour\\thedges\\tand\\tmow\\tour\\tlawn\\tbecause\\twe\\tdon’t\\twant\\tto\\tbe\\tthe\\tslob\\tof\\tthe\\nneighborhood.\\tWhen\\tour\\tmother\\tcomes\\tto\\tvisit,\\twe\\tclean\\tup\\tthe\\thouse\\tbecause\\nwe\\tdon’t\\twant\\tto\\tbe\\tjudged.\\tWe\\tare\\tcontinually\\twondering\\t“What\\twill\\tothers\\nthink\\tof\\tme?”\\tand\\taltering\\tour\\tbehavior\\tbased\\ton\\tthe\\tanswer.\\nThe\\tPolgar\\tsisters—the\\tchess\\tprodigies\\tmentioned\\tat\\tthe\\tbeginning\\tof\\tthis\\nchapter—are\\tevidence\\tof\\tthe\\tpowerful\\tand\\tlasting\\timpact\\tsocial\\tinfluences\\tcan\\nhave\\ton\\tour\\tbehavior.\\tThe\\tsisters\\tpracticed\\tchess\\tfor\\tmany\\thours\\teach\\tday\\tand\\ncontinued\\tthis\\tremarkable\\teffort\\tfor\\tdecades.\\tBut\\tthese\\thabits\\tand\\tbehaviors\\nmaintained\\ttheir\\tattractiveness,\\tin\\tpart,\\tbecause\\tthey\\twere\\tvalued\\tby\\ttheir\\nculture.\\tFrom\\tthe\\tpraise\\tof\\ttheir\\tparents\\tto\\tthe\\tachievement\\tof\\tdifferent\\tstatus\\nmarkers\\tlike\\tbecoming\\ta\\tgrandmaster,\\tthey\\thad\\tmany\\treasons\\tto\\tcontinue\\ttheir', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 99}), Document(page_content='effort.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 100}), Document(page_content='Chapter\\tSummary\\nThe\\tculture\\twe\\tlive\\tin\\tdetermines\\twhich\\tbehaviors\\tare\\tattractive\\tto\\tus.\\nWe\\ttend\\tto\\tadopt\\thabits\\tthat\\tare\\tpraised\\tand\\tapproved\\tof\\tby\\tour\\tculture\\nbecause\\twe\\thave\\ta\\tstrong\\tdesire\\tto\\tfit\\tin\\tand\\tbelong\\tto\\tthe\\ttribe.\\nWe\\ttend\\tto\\timitate\\tthe\\thabits\\tof\\tthree\\tsocial\\tgroups:\\tthe\\tclose\\t(family\\nand\\tfriends),\\tthe\\tmany\\t(the\\ttribe),\\tand\\tthe\\tpowerful\\t(those\\twith\\tstatus\\nand\\tprestige).\\nOne\\tof\\tthe\\tmost\\teffective\\tthings\\tyou\\tcan\\tdo\\tto\\tbuild\\tbetter\\thabits\\tis\\tto\\njoin\\ta\\tculture\\twhere\\t(1)\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior\\nand\\t(2)\\tyou\\talready\\thave\\tsomething\\tin\\tcommon\\twith\\tthe\\tgroup.\\nThe\\tnormal\\tbehavior\\tof\\tthe\\ttribe\\toften\\toverpowers\\tthe\\tdesired\\nbehavior\\tof\\tthe\\tindividual.\\tMost\\tdays,\\twe’d\\trather\\tbe\\twrong\\twith\\tthe\\ncrowd\\tthan\\tbe\\tright\\tby\\tourselves.\\nIf\\ta\\tbehavior\\tcan\\tget\\tus\\tapproval,\\trespect,\\tand\\tpraise,\\twe\\tfind\\tit\\nattractive.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 101}), Document(page_content='10\\nHow\\tto\\tFind\\tand\\tFix\\tthe\\tCauses\\tof\\tYour\\tBad\\nHabits\\nI\\nN\\n\\t\\nLATE\\t2012\\n,\\tI\\twas\\tsitting\\tin\\tan\\told\\tapartment\\tjust\\ta\\tfew\\tblocks\\tfrom\\tIstanbul’s\\tmost\\nfamous\\tstreet,\\tIstiklal\\tCaddesi.\\tI\\twas\\tin\\tthe\\tmiddle\\tof\\ta\\tfour-day\\ttrip\\tto\\tTurkey\\nand\\tmy\\tguide,\\tMike,\\twas\\trelaxing\\tin\\ta\\tworn-out\\tarmchair\\ta\\tfew\\tfeet\\taway.\\nMike\\twasn’t\\treally\\ta\\tguide.\\tHe\\twas\\tjust\\ta\\tguy\\tfrom\\tMaine\\twho\\thad\\tbeen\\nliving\\tin\\tTurkey\\tfor\\tfive\\tyears,\\tbut\\the\\toffered\\tto\\tshow\\tme\\taround\\twhile\\tI\\twas\\nvisiting\\tthe\\tcountry\\tand\\tI\\ttook\\thim\\tup\\ton\\tit.\\tOn\\tthis\\tparticular\\tnight,\\tI\\thad\\tbeen\\ninvited\\tto\\tdinner\\twith\\thim\\tand\\ta\\thandful\\tof\\this\\tTurkish\\tfriends.\\nThere\\twere\\tseven\\tof\\tus,\\tand\\tI\\twas\\tthe\\tonly\\tone\\twho\\thadn’t,\\tat\\tsome\\tpoint,\\nsmoked\\tat\\tleast\\tone\\tpack\\tof\\tcigarettes\\tper\\tday.\\tI\\tasked\\tone\\tof\\tthe\\tTurks\\thow\\the\\ngot\\tstarted.\\t“Friends,”\\the\\tsaid.\\t“It\\talways\\tstarts\\twith\\tyour\\tfriends.\\tOne\\tfriend\\nsmokes,\\tthen\\tyou\\ttry\\tit.”\\nWhat\\twas\\ttruly\\tfascinating\\twas\\tthat\\thalf\\tof\\tthe\\tpeople\\tin\\tthe\\troom\\thad\\nmanaged\\tto\\t\\nquit\\n\\tsmoking.\\tMike\\thad\\tbeen\\tsmoke-free\\tfor\\ta\\tfew\\tyears\\tat\\tthat\\npoint,\\tand\\the\\tswore\\tup\\tand\\tdown\\tthat\\the\\tbroke\\tthe\\thabit\\tbecause\\tof\\ta\\tbook\\ncalled\\t\\nAllen\\tCarr’s\\tEasy\\tWay\\tto\\tStop\\tSmoking\\n.\\n“It\\tfrees\\tyou\\tfrom\\tthe\\tmental\\tburden\\tof\\tsmoking,”\\the\\tsaid.\\t“It\\ttells\\t\\nyou:\\t‘Stop\\nlying\\tto\\tyourself.\\tYou\\tknow\\tyou\\tdon’t\\tactually\\twant\\tto\\tsmoke.\\tYou\\tknow\\tyou\\ndon’t\\treally\\tenjoy\\tthis.’\\tIt\\thelps\\tyou\\tfeel\\tlike\\tyou’re\\tnot\\tthe\\tvictim\\tanymore.\\tYou\\nstart\\tto\\trealize\\tthat\\tyou\\tdon’t\\t\\nneed\\n\\tto\\tsmoke.”\\nI\\thad\\tnever\\ttried\\ta\\tcigarette,\\tbut\\tI\\ttook\\ta\\tlook\\tat\\tthe\\tbook\\tafterward\\tout\\tof\\ncuriosity.\\tThe\\tauthor\\temploys\\tan\\tinteresting\\tstrategy\\tto\\thelp\\tsmokers\\teliminate\\ntheir\\tcravings.\\tHe\\tsystematically\\treframes\\teach\\tcue\\tassociated\\twith\\tsmoking\\tand\\ngives\\tit\\ta\\tnew\\tmeaning.\\nHe\\tsays\\tthings\\tlike:', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 102}), Document(page_content='You\\tthink\\tyou\\tare\\tquitting\\tsomething,\\tbut\\tyou’re\\tnot\\tquitting\\tanything\\nbecause\\tcigarettes\\tdo\\tnothing\\tfor\\tyou.\\nYou\\tthink\\tsmoking\\tis\\tsomething\\tyou\\tneed\\tto\\tdo\\tto\\tbe\\tsocial,\\tbut\\tit’s\\nnot.\\tYou\\tcan\\tbe\\tsocial\\twithout\\tsmoking\\tat\\tall.\\nYou\\tthink\\tsmoking\\tis\\tabout\\trelieving\\tstress,\\tbut\\tit’s\\tnot.\\tSmoking\\tdoes\\nnot\\trelieve\\tyour\\tnerves,\\tit\\tdestroys\\tthem.\\nOver\\tand\\tover,\\the\\trepeats\\tthese\\tphrases\\tand\\tothers\\tlike\\tthem.\\t“Get\\tit\\tclearly\\ninto\\tyour\\tmind,”\\the\\tsays.\\t“You\\tare\\tlosing\\tnothing\\tand\\tyou\\tare\\tmaking\\nmarvelous\\tpositive\\tgains\\tnot\\tonly\\tin\\thealth,\\tenergy\\tand\\tmoney\\tbut\\talso\\tin\\nconfidence,\\tself-respect,\\tfreedom\\tand,\\tmost\\timportant\\tof\\tall,\\tin\\tthe\\tlength\\tand\\nquality\\tof\\tyour\\tfuture\\tlife.”\\nBy\\tthe\\ttime\\tyou\\tget\\tto\\tthe\\tend\\tof\\tthe\\tbook,\\tsmoking\\tseems\\tlike\\tthe\\tmost\\nridiculous\\tthing\\tin\\tthe\\tworld\\tto\\tdo.\\tAnd\\tif\\tyou\\tno\\tlonger\\texpect\\tsmoking\\tto\\tbring\\nyou\\tany\\tbenefits,\\tyou\\thave\\tno\\treason\\tto\\tsmoke.\\tIt\\tis\\tan\\tinversion\\tof\\tthe\\t2nd\\tLaw\\nof\\tBehavior\\tChange:\\t\\nmake\\tit\\tunattractive\\n.\\nNow,\\tI\\tknow\\tthis\\tidea\\tmight\\tsound\\toverly\\tsimplistic.\\tJust\\tchange\\tyour\\tmind\\tand\\nyou\\tcan\\tquit\\tsmoking.\\tBut\\tstick\\twith\\tme\\tfor\\ta\\tminute.\\nWHERE\\tCRAVINGS\\tCOME\\tFROM\\nEvery\\tbehavior\\thas\\ta\\tsurface\\tlevel\\tcraving\\tand\\ta\\tdeeper,\\tunderlying\\tmotive.\\tI\\noften\\thave\\ta\\tcraving\\tthat\\tgoes\\tsomething\\tlike\\tthis:\\t“I\\twant\\tto\\teat\\ttacos.”\\tIf\\tyou\\nwere\\tto\\task\\tme\\twhy\\tI\\twant\\tto\\teat\\ttacos,\\t\\nI\\twouldn’t\\tsay,\\t“Because\\tI\\tneed\\tfood\\tto\\nsurvive.”\\tBut\\tthe\\ttruth\\tis,\\tsomewhere\\tdeep\\tdown,\\tI\\tam\\tmotivated\\tto\\teat\\ttacos\\nbecause\\tI\\thave\\tto\\teat\\tto\\tsurvive.\\tThe\\tunderlying\\tmotive\\tis\\tto\\tobtain\\tfood\\tand\\nwater\\teven\\tif\\tmy\\tspecific\\tcraving\\tis\\tfor\\ta\\ttaco.\\nSome\\tof\\tour\\tunderlying\\tmotives\\tinclude:\\n*\\nConserve\\tenergy\\nObtain\\tfood\\tand\\twater\\nFind\\tlove\\tand\\treproduce\\nConnect\\tand\\tbond\\twith\\tothers\\nWin\\tsocial\\tacceptance\\tand\\tapproval\\nReduce\\tuncertainty\\nAchieve\\tstatus\\tand\\tprestige', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 103}), Document(page_content='A\\tcraving\\tis\\tjust\\ta\\tspecific\\tmanifestation\\tof\\ta\\tdeeper\\tunderlying\\tmotive.\\tYour\\nbrain\\tdid\\tnot\\tevolve\\twith\\ta\\tdesire\\tto\\tsmoke\\tcigarettes\\tor\\tto\\tcheck\\tInstagram\\tor\\tto\\nplay\\tvideo\\tgames.\\tAt\\ta\\tdeep\\tlevel,\\tyou\\tsimply\\twant\\tto\\treduce\\tuncertainty\\tand\\nrelieve\\tanxiety,\\tto\\twin\\tsocial\\tacceptance\\tand\\tapproval,\\tor\\tto\\tachieve\\tstatus.\\nLook\\tat\\tnearly\\tany\\tproduct\\tthat\\tis\\thabit-forming\\tand\\tyou’ll\\tsee\\tthat\\tit\\tdoes\\tnot\\ncreate\\ta\\tnew\\tmotivation,\\tbut\\trather\\tlatches\\tonto\\tthe\\tunderlying\\tmotives\\tof\\nhuman\\tnature.\\nFind\\tlove\\tand\\treproduce\\t=\\tusing\\tTinder\\nConnect\\tand\\tbond\\twith\\tothers\\t=\\tbrowsing\\tFacebook\\nWin\\tsocial\\tacceptance\\tand\\tapproval\\t=\\tposting\\ton\\tInstagram\\nReduce\\tuncertainty\\t=\\tsearching\\ton\\tGoogle\\nAchieve\\tstatus\\tand\\tprestige\\t=\\tplaying\\tvideo\\tgames\\nYour\\thabits\\tare\\tmodern-day\\tsolutions\\tto\\tancient\\tdesires.\\tNew\\tversions\\tof\\told\\nvices.\\tThe\\tunderlying\\tmotives\\tbehind\\thuman\\tbehavior\\tremain\\tthe\\tsame.\\tThe\\nspecific\\thabits\\twe\\tperform\\tdiffer\\tbased\\ton\\tthe\\tperiod\\tof\\thistory.\\nHere’s\\tthe\\tpowerful\\tpart:\\tthere\\tare\\tmany\\tdifferent\\tways\\tto\\taddress\\tthe\\tsame\\nunderlying\\tmotive.\\tOne\\tperson\\tmight\\tlearn\\tto\\treduce\\tstress\\tby\\tsmoking\\ta\\ncigarette.\\tAnother\\tperson\\tlearns\\tto\\tease\\ttheir\\tanxiety\\tby\\tgoing\\tfor\\ta\\trun.\\tYour\\ncurrent\\thabits\\tare\\tnot\\tnecessarily\\tthe\\tbest\\tway\\tto\\tsolve\\tthe\\tproblems\\tyou\\tface;\\nthey\\tare\\tjust\\tthe\\tmethods\\tyou\\tlearned\\tto\\tuse.\\tOnce\\tyou\\tassociate\\ta\\tsolution\\twith\\nthe\\tproblem\\tyou\\tneed\\tto\\tsolve,\\tyou\\tkeep\\tcoming\\tback\\tto\\tit.\\nHabits\\tare\\tall\\tabout\\tassociations.\\tThese\\tassociations\\tdetermine\\twhether\\twe\\npredict\\ta\\thabit\\tto\\tbe\\tworth\\trepeating\\tor\\tnot.\\tAs\\twe\\tcovered\\tin\\tour\\tdiscussion\\tof\\nthe\\t1st\\tLaw,\\tyour\\tbrain\\tis\\tcontinually\\tabsorbing\\tinformation\\tand\\tnoticing\\tcues\\tin\\nthe\\tenvironment.\\tEvery\\ttime\\tyou\\tperceive\\ta\\tcue,\\tyour\\tbrain\\truns\\ta\\tsimulation\\nand\\tmakes\\ta\\tprediction\\tabout\\twhat\\tto\\tdo\\tin\\tthe\\tnext\\tmoment.\\nCue:\\tYou\\tnotice\\tthat\\tthe\\tstove\\tis\\thot.\\nPrediction:\\t\\nIf\\tI\\ttouch\\tit\\tI’ll\\tget\\tburned,\\tso\\tI\\tshould\\tavoid\\ttouching\\tit.\\nCue:\\tYou\\tsee\\tthat\\tthe\\ttraffic\\tlight\\tturned\\tgreen.\\nPrediction:\\t\\nIf\\tI\\tstep\\ton\\tthe\\tgas,\\tI’ll\\tmake\\tit\\tsafely\\tthrough\\tthe\\tintersection\\tand\\nget\\tcloser\\tto\\tmy\\tdestination,\\tso\\tI\\tshould\\tstep\\ton\\tthe\\tgas.\\nYou\\tsee\\ta\\tcue,\\tcategorize\\tit\\tbased\\ton\\tpast\\texperience,\\tand\\tdetermine\\tthe\\nappropriate\\tresponse.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 104}), Document(page_content='This\\tall\\thappens\\tin\\tan\\tinstant,\\tbut\\tit\\tplays\\ta\\tcrucial\\trole\\tin\\tyour\\thabits\\tbecause\\nevery\\taction\\tis\\tpreceded\\tby\\ta\\tprediction.\\tLife\\tfeels\\treactive,\\tbut\\tit\\tis\\tactually\\npredictive.\\tAll\\tday\\tlong,\\tyou\\tare\\tmaking\\tyour\\tbest\\tguess\\tof\\thow\\tto\\tact\\tgiven\\nwhat\\tyou’ve\\tjust\\tseen\\tand\\twhat\\thas\\tworked\\tfor\\tyou\\tin\\tthe\\tpast.\\tYou\\tare\\nendlessly\\tpredicting\\twhat\\twill\\thappen\\tin\\tthe\\tnext\\tmoment.\\nOur\\tbehavior\\tis\\theavily\\tdependent\\ton\\tthese\\tpredictions.\\tPut\\tanother\\tway,\\tour\\nbehavior\\tis\\theavily\\tdependent\\ton\\thow\\twe\\tinterpret\\tthe\\tevents\\tthat\\thappen\\tto\\tus,\\nnot\\tnecessarily\\tthe\\tobjective\\treality\\tof\\tthe\\tevents\\tthemselves.\\tTwo\\tpeople\\tcan\\nlook\\tat\\tthe\\tsame\\tcigarette,\\tand\\tone\\tfeels\\tthe\\turge\\tto\\tsmoke\\twhile\\tthe\\tother\\tis\\nrepulsed\\tby\\tthe\\tsmell.\\tThe\\tsame\\tcue\\tcan\\tspark\\ta\\tgood\\thabit\\tor\\ta\\tbad\\thabit\\ndepending\\ton\\tyour\\tprediction.\\tThe\\tcause\\tof\\tyour\\thabits\\tis\\tactually\\tthe\\tprediction\\nthat\\tprecedes\\tthem.\\nThese\\tpredictions\\tlead\\tto\\tfeelings,\\twhich\\tis\\thow\\twe\\ttypically\\tdescribe\\ta\\ncraving—a\\tfeeling,\\ta\\tdesire,\\tan\\turge.\\tFeelings\\tand\\temotions\\ttransform\\tthe\\tcues\\nwe\\tperceive\\tand\\tthe\\tpredictions\\twe\\tmake\\tinto\\ta\\tsignal\\tthat\\twe\\tcan\\tapply.\\tThey\\nhelp\\texplain\\twhat\\twe\\tare\\tcurrently\\tsensing.\\tFor\\tinstance,\\twhether\\tor\\tnot\\tyou\\nrealize\\tit,\\tyou\\tare\\tnoticing\\thow\\twarm\\tor\\tcold\\tyou\\tfeel\\tright\\tnow.\\tIf\\tthe\\ntemperature\\tdrops\\tby\\tone\\tdegree,\\tyou\\tprobably\\twon’t\\tdo\\tanything.\\tIf\\tthe\\ntemperature\\tdrops\\tten\\tdegrees,\\thowever,\\tyou’ll\\tfeel\\tcold\\tand\\tput\\ton\\tanother\\nlayer\\tof\\tclothing.\\tFeeling\\tcold\\twas\\tthe\\tsignal\\tthat\\tprompted\\tyou\\tto\\tact.\\tYou\\thave\\nbeen\\tsensing\\tthe\\tcues\\tthe\\tentire\\ttime,\\tbut\\tit\\tis\\tonly\\twhen\\tyou\\tpredict\\tthat\\tyou\\nwould\\tbe\\tbetter\\toff\\tin\\ta\\tdifferent\\tstate\\tthat\\tyou\\ttake\\taction.\\nA\\tcraving\\tis\\tthe\\tsense\\tthat\\tsomething\\tis\\tmissing.\\tIt\\tis\\tthe\\tdesire\\tto\\tchange\\nyour\\tinternal\\tstate.\\tWhen\\tthe\\ttemperature\\tfalls,\\tthere\\tis\\ta\\tgap\\tbetween\\twhat\\tyour\\nbody\\tis\\tcurrently\\tsensing\\tand\\twhat\\tit\\t\\nwants\\n\\tto\\tbe\\tsensing.\\tThis\\tgap\\tbetween\\tyour\\ncurrent\\tstate\\tand\\tyour\\tdesired\\tstate\\tprovides\\ta\\treason\\tto\\tact.\\nDesire\\tis\\tthe\\tdifference\\tbetween\\twhere\\tyou\\tare\\tnow\\tand\\twhere\\tyou\\t\\nwant\\tto\\tbe\\nin\\tthe\\tfuture.\\tEven\\tthe\\ttiniest\\taction\\tis\\ttinged\\twith\\tthe\\tmotivation\\tto\\tfeel\\ndifferently\\tthan\\tyou\\tdo\\tin\\tthe\\tmoment.\\tWhen\\tyou\\tbinge-eat\\tor\\tlight\\tup\\tor\\tbrowse\\nsocial\\tmedia,\\twhat\\tyou\\treally\\twant\\tis\\t\\nnot\\n\\ta\\tpotato\\tchip\\tor\\ta\\tcigarette\\tor\\ta\\tbunch\\nof\\tlikes.\\tWhat\\tyou\\treally\\twant\\tis\\tto\\t\\nfeel\\n\\tdifferent.\\nOur\\tfeelings\\tand\\temotions\\ttell\\tus\\twhether\\tto\\thold\\tsteady\\tin\\tour\\tcurrent\\tstate\\tor\\nto\\tmake\\ta\\tchange.\\tThey\\thelp\\tus\\tdecide\\tthe\\tbest\\tcourse\\tof\\taction.\\tNeurologists\\nhave\\tdiscovered\\tthat\\t\\nwhen\\temotions\\tand\\tfeelings\\tare\\timpaired,\\twe\\tactually\\tlose\\nthe\\tability\\tto\\tmake\\tdecisions.\\tWe\\thave\\tno\\tsignal\\tof\\twhat\\tto\\tpursue\\tand\\twhat\\tto\\navoid.\\t\\nAs\\tthe\\tneuroscientist\\tAntonio\\tDamasio\\texplains,\\t“It\\tis\\temotion\\tthat\\nallows\\tyou\\tto\\tmark\\tthings\\tas\\tgood,\\tbad,\\tor\\tindifferent.”\\nTo\\tsummarize,\\tthe\\tspecific\\tcravings\\tyou\\tfeel\\tand\\thabits\\tyou\\tperform\\tare\\nreally\\tan\\tattempt\\tto\\taddress\\tyour\\tfundamental\\tunderlying\\tmotives.\\tWhenever\\ta', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 105}), Document(page_content='habit\\tsuccessfully\\taddresses\\ta\\tmotive,\\tyou\\tdevelop\\ta\\tcraving\\tto\\tdo\\tit\\tagain.\\tIn\\ntime,\\tyou\\tlearn\\tto\\tpredict\\tthat\\tchecking\\tsocial\\tmedia\\twill\\thelp\\tyou\\tfeel\\tloved\\tor\\nthat\\twatching\\tYouTube\\twill\\tallow\\tyou\\tto\\tforget\\tyour\\tfears.\\tHabits\\tare\\tattractive\\nwhen\\twe\\tassociate\\tthem\\twith\\tpositive\\tfeelings,\\tand\\twe\\tcan\\tuse\\tthis\\tinsight\\tto\\tour\\nadvantage\\trather\\tthan\\tto\\tour\\tdetriment.\\nHOW\\tTO\\tREPROGRAM\\tYOUR\\tBRAIN\\tTO\\tENJOY\\tHARD\\tHABITS\\nYou\\tcan\\tmake\\thard\\thabits\\tmore\\tattractive\\tif\\tyou\\tcan\\tlearn\\tto\\tassociate\\tthem\\twith\\na\\tpositive\\texperience.\\tSometimes,\\tall\\tyou\\tneed\\tis\\ta\\tslight\\tmind-set\\tshift.\\tFor\\ninstance,\\twe\\toften\\ttalk\\tabout\\teverything\\twe\\thave\\tto\\tdo\\tin\\ta\\tgiven\\tday.\\tYou\\thave\\nto\\twake\\tup\\tearly\\tfor\\twork.\\tYou\\thave\\tto\\tmake\\tanother\\tsales\\tcall\\tfor\\tyour\\nbusiness.\\tYou\\thave\\tto\\tcook\\tdinner\\tfor\\tyour\\tfamily.\\nNow,\\timagine\\tchanging\\tjust\\tone\\tword:\\t\\nYou\\tdon’t\\t“have”\\tto.\\tYou\\t“get”\\tto.\\nYou\\t\\nget\\n\\tto\\twake\\tup\\tearly\\tfor\\twork.\\tYou\\t\\nget\\n\\tto\\tmake\\tanother\\tsales\\tcall\\tfor\\nyour\\tbusiness.\\tYou\\t\\nget\\n\\tto\\tcook\\tdinner\\tfor\\tyour\\tfamily.\\tBy\\tsimply\\tchanging\\tone\\nword,\\tyou\\tshift\\tthe\\tway\\tyou\\tview\\teach\\tevent.\\tYou\\ttransition\\tfrom\\tseeing\\tthese\\nbehaviors\\tas\\tburdens\\tand\\tturn\\tthem\\tinto\\topportunities.\\nThe\\tkey\\tpoint\\tis\\tthat\\tboth\\tversions\\tof\\treality\\tare\\ttrue.\\tYou\\t\\nhave\\n\\tto\\tdo\\tthose\\nthings,\\tand\\tyou\\talso\\t\\nget\\n\\tto\\tdo\\tthem.\\tWe\\tcan\\tfind\\tevidence\\tfor\\twhatever\\tmind-set\\nwe\\tchoose.\\nI\\tonce\\theard\\ta\\tstory\\tabout\\ta\\tman\\twho\\tuses\\ta\\twheelchair.\\tWhen\\tasked\\tif\\tit\\twas\\ndifficult\\tbeing\\tconfined,\\the\\tresponded,\\t“\\nI’m\\tnot\\tconfined\\tto\\tmy\\twheelchair—I\\nam\\tliberated\\tby\\tit.\\tIf\\tit\\twasn’t\\tfor\\tmy\\twheelchair,\\tI\\twould\\tbe\\tbed-bound\\tand\\nnever\\table\\tto\\tleave\\tmy\\thouse.”\\tThis\\tshift\\tin\\tperspective\\tcompletely\\ttransformed\\nhow\\the\\tlived\\teach\\tday.\\nReframing\\tyour\\thabits\\tto\\thighlight\\ttheir\\t\\nbenefits\\n\\trather\\tthan\\ttheir\\tdrawbacks\\tis\\na\\tfast\\tand\\tlightweight\\tway\\tto\\treprogram\\tyour\\tmind\\tand\\tmake\\ta\\thabit\\tseem\\tmore\\nattractive.\\nExercise.\\t\\nMany\\tpeople\\tassociate\\texercise\\twith\\tbeing\\ta\\tchallenging\\ttask\\tthat\\ndrains\\tenergy\\tand\\twears\\tyou\\tdown.\\tYou\\tcan\\tjust\\tas\\teasily\\tview\\tit\\tas\\ta\\tway\\tto\\ndevelop\\tskills\\tand\\tbuild\\tyou\\tup.\\tInstead\\tof\\ttelling\\tyourself\\t“I\\tneed\\tto\\tgo\\trun\\tin\\nthe\\tmorning,”\\tsay\\t“\\nIt’s\\ttime\\tto\\tbuild\\tendurance\\tand\\tget\\tfast.”\\nFinance.\\n\\tSaving\\tmoney\\tis\\toften\\tassociated\\twith\\tsacrifice.\\tHowever,\\tyou\\tcan\\nassociate\\tit\\twith\\tfreedom\\trather\\tthan\\tlimitation\\tif\\tyou\\trealize\\tone\\tsimple\\ttruth:\\nliving\\tbelow\\tyour\\tcurrent\\tmeans\\t\\nincreases\\n\\tyour\\tfuture\\tmeans.\\tThe\\tmoney\\tyou\\nsave\\tthis\\tmonth\\tincreases\\tyour\\tpurchasing\\tpower\\tnext\\tmonth.\\nMeditation.\\n\\tAnyone\\twho\\thas\\ttried\\tmeditation\\tfor\\tmore\\tthan\\tthree\\tseconds', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 106}), Document(page_content='knows\\thow\\tfrustrating\\tit\\tcan\\tbe\\twhen\\tthe\\tnext\\tdistraction\\t\\ninevitably\\tpops\\tinto\\nyour\\tmind.\\tYou\\tcan\\ttransform\\tfrustration\\tinto\\tdelight\\twhen\\tyou\\trealize\\tthat\\teach\\ninterruption\\tgives\\tyou\\ta\\tchance\\tto\\tpractice\\treturning\\tto\\tyour\\tbreath.\\tDistraction\\nis\\ta\\tgood\\tthing\\tbecause\\tyou\\tneed\\tdistractions\\tto\\tpractice\\tmeditation.\\nPregame\\tjitters.\\n\\tMany\\tpeople\\tfeel\\tanxious\\tbefore\\tdelivering\\ta\\tbig\\npresentation\\tor\\tcompeting\\tin\\tan\\timportant\\tevent.\\tThey\\texperience\\tquicker\\nbreathing,\\ta\\tfaster\\theart\\trate,\\theightened\\tarousal.\\tIf\\twe\\tinterpret\\tthese\\tfeelings\\nnegatively,\\tthen\\twe\\tfeel\\tthreatened\\tand\\ttense\\tup.\\tIf\\twe\\tinterpret\\tthese\\tfeelings\\npositively,\\tthen\\twe\\tcan\\trespond\\twith\\tfluidity\\tand\\tgrace.\\tYou\\tcan\\treframe\\t“I\\tam\\nnervous”\\tto\\t“I\\tam\\texcited\\tand\\t\\nI’m\\tgetting\\tan\\tadrenaline\\trush\\tto\\thelp\\tme\\nconcentrate.”\\nThese\\tlittle\\tmind-set\\tshifts\\taren’t\\tmagic,\\tbut\\tthey\\tcan\\thelp\\tchange\\tthe\\tfeelings\\nyou\\tassociate\\twith\\ta\\tparticular\\thabit\\tor\\tsituation.\\nIf\\tyou\\twant\\tto\\ttake\\tit\\ta\\tstep\\tfurther,\\tyou\\tcan\\tcreate\\ta\\t\\nmotivation\\tritual\\n.\\tYou\\nsimply\\tpractice\\tassociating\\tyour\\thabits\\twith\\tsomething\\tyou\\tenjoy,\\tthen\\tyou\\tcan\\nuse\\tthat\\tcue\\twhenever\\tyou\\tneed\\ta\\tbit\\tof\\tmotivation.\\tFor\\tinstance,\\tif\\tyou\\talways\\nplay\\tthe\\tsame\\tsong\\tbefore\\thaving\\tsex,\\tthen\\tyou’ll\\tbegin\\tto\\tlink\\tthe\\tmusic\\twith\\nthe\\tact.\\tWhenever\\tyou\\twant\\tto\\tget\\tin\\tthe\\tmood,\\tjust\\tpress\\tplay.\\nEd\\tLatimore,\\ta\\tboxer\\tand\\twriter\\tfrom\\tPittsburgh,\\tbenefited\\tfrom\\ta\\tsimilar\\nstrategy\\twithout\\tknowing\\tit.\\t“Odd\\trealization,”\\the\\twrote.\\t“My\\tfocus\\tand\\nconcentration\\tgoes\\tup\\tjust\\tby\\tputting\\tmy\\theadphones\\t[on]\\twhile\\twriting.\\tI\\tdon’t\\neven\\thave\\tto\\tplay\\tany\\tmusic.”\\tWithout\\trealizing\\tit,\\the\\twas\\tconditioning\\thimself.\\nIn\\tthe\\tbeginning,\\the\\tput\\this\\theadphones\\ton,\\tplayed\\tsome\\tmusic\\the\\tenjoyed,\\tand\\ndid\\tfocused\\twork.\\tAfter\\tdoing\\tit\\tfive,\\tten,\\ttwenty\\ttimes,\\tputting\\this\\theadphones\\non\\tbecame\\ta\\tcue\\tthat\\the\\tautomatically\\tassociated\\twith\\tincreased\\tfocus.\\tThe\\ncraving\\tfollowed\\tnaturally.\\nAthletes\\tuse\\tsimilar\\tstrategies\\tto\\tget\\tthemselves\\tin\\tthe\\tmind-set\\tto\\tperform.\\nDuring\\tmy\\tbaseball\\tcareer,\\tI\\tdeveloped\\ta\\tspecific\\tritual\\tof\\tstretching\\tand\\nthrowing\\tbefore\\teach\\tgame.\\tThe\\twhole\\tsequence\\ttook\\tabout\\tten\\tminutes,\\tand\\tI\\ndid\\tit\\tthe\\tsame\\tway\\tevery\\tsingle\\ttime.\\tWhile\\t\\nit\\tphysically\\twarmed\\tme\\tup\\tto\\tplay,\\nmore\\timportantly,\\tit\\tput\\tme\\tin\\tthe\\tright\\tmental\\tstate.\\tI\\tbegan\\tto\\tassociate\\tmy\\npregame\\tritual\\twith\\tfeeling\\tcompetitive\\tand\\tfocused.\\tEven\\tif\\tI\\twasn’t\\tmotivated\\nbeforehand,\\tby\\tthe\\ttime\\tI\\twas\\tdone\\twith\\tmy\\tritual,\\tI\\twas\\tin\\t“game\\tmode.”\\nYou\\tcan\\tadapt\\tthis\\tstrategy\\tfor\\tnearly\\tany\\tpurpose.\\tSay\\tyou\\twant\\tto\\tfeel\\nhappier\\tin\\tgeneral.\\tFind\\tsomething\\tthat\\tmakes\\tyou\\ttruly\\thappy—like\\tpetting\\nyour\\tdog\\tor\\ttaking\\ta\\tbubble\\tbath—and\\tthen\\tcreate\\ta\\tshort\\troutine\\tthat\\tyou\\nperform\\tevery\\ttime\\t\\nbefore\\n\\tyou\\tdo\\tthe\\tthing\\tyou\\tlove.\\tMaybe\\tyou\\ttake\\tthree\\tdeep\\nbreaths\\tand\\tsmile.\\nThree\\tdeep\\tbreaths.\\tSmile.\\tPet\\tthe\\tdog.\\tRepeat.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 107}), Document(page_content='Eventually,\\tyou’ll\\tbegin\\tto\\tassociate\\tthis\\tbreathe-and-smile\\troutine\\twith\\tbeing\\nin\\ta\\tgood\\tmood.\\tIt\\tbecomes\\ta\\tcue\\tthat\\t\\nmeans\\n\\tfeeling\\thappy.\\tOnce\\testablished,\\nyou\\tcan\\tbreak\\tit\\tout\\tanytime\\tyou\\tneed\\tto\\tchange\\tyour\\temotional\\tstate.\\tStressed\\nat\\twork?\\tTake\\tthree\\tdeep\\tbreaths\\tand\\tsmile.\\tSad\\tabout\\tlife?\\tThree\\tdeep\\tbreaths\\nand\\tsmile.\\tOnce\\ta\\thabit\\thas\\tbeen\\tbuilt,\\tthe\\tcue\\tcan\\tprompt\\ta\\tcraving,\\teven\\tif\\tit\\nhas\\tlittle\\tto\\tdo\\twith\\tthe\\toriginal\\tsituation.\\nThe\\tkey\\tto\\tfinding\\tand\\tfixing\\tthe\\tcauses\\tof\\tyour\\tbad\\thabits\\tis\\tto\\treframe\\tthe\\nassociations\\tyou\\thave\\tabout\\tthem.\\tIt’s\\tnot\\teasy,\\tbut\\tif\\tyou\\tcan\\treprogram\\tyour\\npredictions,\\tyou\\tcan\\ttransform\\ta\\thard\\thabit\\tinto\\tan\\tattractive\\tone.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 108}), Document(page_content='Chapter\\tSummary\\nThe\\tinversion\\tof\\tthe\\t2nd\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\nunattractive\\n.\\nEvery\\tbehavior\\thas\\ta\\tsurface\\tlevel\\tcraving\\tand\\ta\\tdeeper\\tunderlying\\nmotive.\\nYour\\thabits\\tare\\tmodern-day\\tsolutions\\tto\\tancient\\tdesires.\\nThe\\tcause\\tof\\tyour\\thabits\\tis\\tactually\\tthe\\tprediction\\tthat\\tprecedes\\tthem.\\nThe\\tprediction\\tleads\\tto\\ta\\tfeeling.\\nHighlight\\tthe\\tbenefits\\tof\\tavoiding\\ta\\tbad\\thabit\\tto\\tmake\\tit\\tseem\\nunattractive.\\nHabits\\tare\\tattractive\\twhen\\twe\\tassociate\\tthem\\twith\\tpositive\\tfeelings\\nand\\tunattractive\\twhen\\twe\\tassociate\\tthem\\twith\\tnegative\\tfeelings.\\nCreate\\ta\\tmotivation\\tritual\\tby\\tdoing\\tsomething\\tyou\\tenjoy\\timmediately\\nbefore\\ta\\tdifficult\\thabit.\\nHOW\\tTO\\tCREATE\\tA\\tGOOD\\tHABIT\\nThe\\t1st\\tLaw:\\tMake\\tIt\\tObvious\\n1.1:\\t\\nFill\\tout\\tthe\\tHabits\\tScorecard.\\tWrite\\tdown\\tyour\\tcurrent\\thabits\\tto\\tbecome\\taware\\tof\\tthem.\\n1.2:\\t\\nUse\\timplementation\\tintentions:\\t“I\\twill\\t[BEHAVIOR]\\tat\\t[TIME]\\tin\\t[LOCATION].”\\n1.3:\\t\\nUse\\thabit\\tstacking:\\t“After\\t[CURRENT\\tHABIT],\\tI\\twill\\t[NEW\\tHABIT].”\\n1.4:\\t\\nDesign\\tyour\\tenvironment.\\tMake\\tthe\\tcues\\tof\\tgood\\thabits\\tobvious\\tand\\tvisible.\\nThe\\t2nd\\tLaw:\\tMake\\tIt\\tAttractive\\n2.1:\\t\\nUse\\ttemptation\\tbundling.\\tPair\\tan\\taction\\tyou\\t\\nwant\\n\\tto\\tdo\\twith\\tan\\taction\\tyou\\t\\nneed\\n\\tto\\tdo.\\n2.2:\\t\\nJoin\\ta\\tculture\\twhere\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior.\\n2.3:\\t\\nCreate\\ta\\tmotivation\\tritual.\\tDo\\tsomething\\tyou\\tenjoy\\timmediately\\tbefore\\ta\\tdifficult\\thabit.\\nThe\\t3rd\\tLaw:\\tMake\\tIt\\tEasy\\nThe\\t4th\\tLaw:\\tMake\\tIt\\tSatisfying\\nHOW\\tTO\\tBREAK\\tA\\tBAD\\tHABIT\\nInversion\\tof\\tthe\\t1st\\tLaw:\\tMake\\tIt\\tInvisible\\n1.5:\\t\\nReduce\\texposure.\\tRemove\\tthe\\tcues\\tof\\tyour\\tbad\\thabits\\tfrom\\tyour\\tenvironment.\\nInversion\\tof\\tthe\\t2nd\\tLaw:\\tMake\\tIt\\tUnattractive\\n2.4:\\t\\nReframe\\tyour\\tmind-set.\\tHighlight\\tthe\\tbenefits\\tof\\tavoiding\\tyour\\tbad\\thabits.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 109}), Document(page_content='Inversion\\tof\\tthe\\t3rd\\tLaw:\\tMake\\tIt\\tDifficult\\nInversion\\tof\\tthe\\t4th\\tLaw:\\tMake\\tIt\\tUnsatisfying\\nYou\\tcan\\tdownload\\ta\\tprintable\\tversion\\tof\\tthis\\thabits\\tcheat\\tsheet\\tat:\\t\\natomichabits.com/cheatsheet', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 110}), Document(page_content='THE\\t3RD\\tLAW\\nMake\\tIt\\tEasy', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 111}), Document(page_content='11\\nWalk\\tSlowly,\\tbut\\tNever\\tBackward\\nO\\nN\\tTHE\\tFIRST\\t\\nday\\tof\\tclass,\\tJerry\\tUelsmann,\\ta\\tprofessor\\tat\\tthe\\tUniversity\\tof\\tFlorida,\\ndivided\\this\\tfilm\\tphotography\\tstudents\\tinto\\ttwo\\tgroups.\\nEveryone\\ton\\tthe\\tleft\\tside\\tof\\tthe\\tclassroom,\\the\\texplained,\\twould\\tbe\\tin\\tthe\\n“quantity”\\tgroup.\\tThey\\twould\\tbe\\tgraded\\tsolely\\ton\\tthe\\tamount\\tof\\twork\\tthey\\nproduced.\\tOn\\tthe\\tfinal\\tday\\tof\\tclass,\\the\\twould\\ttally\\tthe\\tnumber\\tof\\tphotos\\nsubmitted\\tby\\teach\\tstudent.\\tOne\\thundred\\tphotos\\twould\\trate\\tan\\tA,\\tninety\\tphotos\\ta\\nB,\\teighty\\tphotos\\ta\\tC,\\tand\\tso\\ton.\\nMeanwhile,\\teveryone\\ton\\tthe\\tright\\tside\\tof\\tthe\\troom\\twould\\tbe\\tin\\tthe\\t“quality”\\ngroup.\\tThey\\twould\\tbe\\tgraded\\tonly\\ton\\tthe\\texcellence\\tof\\ttheir\\twork.\\tThey\\twould\\nonly\\tneed\\tto\\tproduce\\tone\\tphoto\\tduring\\tthe\\tsemester,\\tbut\\tto\\tget\\tan\\tA,\\tit\\thad\\tto\\tbe\\na\\tnearly\\tperfect\\timage.\\nAt\\tthe\\tend\\tof\\tthe\\tterm,\\the\\twas\\tsurprised\\tto\\tfind\\tthat\\tall\\tthe\\tbest\\tphotos\\twere\\nproduced\\tby\\tthe\\t\\nquantity\\n\\tgroup.\\tDuring\\tthe\\tsemester,\\tthese\\tstudents\\twere\\tbusy\\ntaking\\tphotos,\\texperimenting\\twith\\tcomposition\\tand\\tlighting,\\ttesting\\tout\\tvarious\\nmethods\\tin\\tthe\\tdarkroom,\\tand\\tlearning\\tfrom\\ttheir\\tmistakes.\\tIn\\tthe\\tprocess\\tof\\ncreating\\thundreds\\tof\\tphotos,\\tthey\\thoned\\ttheir\\tskills.\\tMeanwhile,\\tthe\\t\\nquality\\ngroup\\tsat\\t\\naround\\tspeculating\\tabout\\tperfection.\\t\\nIn\\tthe\\tend,\\tthey\\thad\\tlittle\\tto\\tshow\\nfor\\ttheir\\tefforts\\tother\\tthan\\tunverified\\ttheories\\tand\\tone\\tmediocre\\tphoto.\\n*\\nIt\\tis\\teasy\\tto\\tget\\tbogged\\tdown\\ttrying\\tto\\tfind\\tthe\\toptimal\\tplan\\tfor\\tchange:\\tthe\\nfastest\\tway\\tto\\tlose\\tweight,\\tthe\\tbest\\tprogram\\tto\\tbuild\\tmuscle,\\tthe\\tperfect\\tidea\\tfor\\na\\tside\\thustle.\\tWe\\tare\\tso\\tfocused\\ton\\tfiguring\\tout\\tthe\\tbest\\tapproach\\tthat\\twe\\tnever\\nget\\taround\\tto\\ttaking\\taction.\\t\\nAs\\tVoltaire\\tonce\\twrote,\\t“The\\tbest\\tis\\tthe\\tenemy\\tof\\nthe\\tgood.”\\nI\\trefer\\tto\\tthis\\tas\\tthe\\tdifference\\tbetween\\tbeing\\tin\\tmotion\\tand\\ttaking\\taction.\\tThe\\ntwo\\tideas\\tsound\\tsimilar,\\tbut\\tthey’re\\tnot\\tthe\\tsame.\\tWhen\\tyou’re\\tin\\tmotion,\\nyou’re\\tplanning\\tand\\tstrategizing\\tand\\tlearning.\\tThose\\tare\\tall\\tgood\\tthings,\\tbut\\nthey\\tdon’t\\tproduce\\ta\\tresult.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 112}), Document(page_content='Action,\\ton\\tthe\\tother\\thand,\\tis\\tthe\\ttype\\tof\\tbehavior\\tthat\\twill\\tdeliver\\tan\\toutcome.\\nIf\\tI\\toutline\\ttwenty\\tideas\\tfor\\tarticles\\tI\\twant\\tto\\twrite,\\tthat’s\\tmotion.\\tIf\\tI\\tactually\\tsit\\ndown\\tand\\twrite\\tan\\tarticle,\\tthat’s\\taction.\\tIf\\tI\\tsearch\\tfor\\ta\\tbetter\\tdiet\\tplan\\tand\\tread\\na\\tfew\\tbooks\\ton\\tthe\\ttopic,\\tthat’s\\tmotion.\\tIf\\tI\\tactually\\teat\\ta\\thealthy\\tmeal,\\tthat’s\\naction.\\nSometimes\\tmotion\\tis\\tuseful,\\tbut\\tit\\twill\\tnever\\tproduce\\tan\\toutcome\\tby\\titself.\\tIt\\ndoesn’t\\tmatter\\thow\\tmany\\ttimes\\tyou\\tgo\\ttalk\\tto\\tthe\\tpersonal\\ttrainer,\\tthat\\tmotion\\nwill\\tnever\\tget\\tyou\\tin\\tshape.\\tOnly\\tthe\\taction\\tof\\tworking\\tout\\twill\\tget\\tthe\\tresult\\nyou’re\\tlooking\\tto\\tachieve.\\nIf\\tmotion\\tdoesn’t\\tlead\\tto\\tresults,\\twhy\\tdo\\twe\\tdo\\tit?\\tSometimes\\twe\\tdo\\tit\\nbecause\\twe\\tactually\\tneed\\tto\\tplan\\tor\\tlearn\\tmore.\\tBut\\tmore\\toften\\tthan\\tnot,\\twe\\tdo\\nit\\tbecause\\tmotion\\tallows\\tus\\tto\\tfeel\\tlike\\twe’re\\tmaking\\tprogress\\twithout\\trunning\\nthe\\trisk\\tof\\tfailure.\\tMost\\tof\\tus\\tare\\texperts\\tat\\tavoiding\\tcriticism.\\tIt\\tdoesn’t\\tfeel\\ngood\\tto\\tfail\\tor\\tto\\tbe\\tjudged\\tpublicly,\\tso\\twe\\ttend\\tto\\tavoid\\tsituations\\twhere\\tthat\\nmight\\thappen.\\tAnd\\tthat’s\\tthe\\tbiggest\\treason\\twhy\\tyou\\tslip\\tinto\\tmotion\\trather\\tthan\\ntaking\\taction:\\tyou\\twant\\tto\\tdelay\\tfailure.\\nIt’s\\teasy\\tto\\tbe\\tin\\tmotion\\tand\\tconvince\\tyourself\\tthat\\tyou’re\\tstill\\tmaking\\nprogress.\\tYou\\tthink,\\t\\n“I’ve\\tgot\\tconversations\\tgoing\\twith\\tfour\\tpotential\\tclients\\nright\\tnow.\\tThis\\tis\\tgood.\\tWe’re\\tmoving\\tin\\tthe\\tright\\tdirection.”\\t\\nOr,\\t\\n“I\\nbrainstormed\\tsome\\tideas\\tfor\\tthat\\tbook\\tI\\twant\\tto\\twrite.\\tThis\\tis\\tcoming\\ttogether.”\\nMotion\\tmakes\\tyou\\tfeel\\tlike\\tyou’re\\tgetting\\tthings\\tdone.\\tBut\\treally,\\tyou’re\\tjust\\npreparing\\tto\\tget\\tsomething\\tdone.\\tWhen\\tpreparation\\tbecomes\\ta\\tform\\tof\\nprocrastination,\\tyou\\tneed\\tto\\tchange\\tsomething.\\tYou\\tdon’t\\twant\\tto\\tmerely\\tbe\\nplanning.\\tYou\\twant\\tto\\tbe\\tpracticing.\\nIf\\tyou\\twant\\tto\\tmaster\\ta\\thabit,\\tthe\\tkey\\tis\\tto\\tstart\\twith\\trepetition,\\tnot\\tperfection.\\nYou\\tdon’t\\tneed\\tto\\tmap\\tout\\tevery\\tfeature\\tof\\ta\\tnew\\thabit.\\tYou\\tjust\\tneed\\tto\\npractice\\tit.\\tThis\\tis\\tthe\\tfirst\\ttakeaway\\tof\\tthe\\t3rd\\tLaw:\\tyou\\tjust\\tneed\\tto\\tget\\tyour\\nreps\\tin.\\nHOW\\tLONG\\tDOES\\tIT\\tACTUALLY\\tTAKE\\tTO\\tFORM\\tA\\tNEW\\tHABIT?\\nHabit\\tformation\\tis\\tthe\\tprocess\\tby\\twhich\\ta\\tbehavior\\tbecomes\\tprogressively\\tmore\\nautomatic\\tthrough\\trepetition.\\tThe\\tmore\\tyou\\trepeat\\tan\\tactivity,\\tthe\\tmore\\tthe\\nstructure\\tof\\tyour\\tbrain\\tchanges\\tto\\tbecome\\tefficient\\tat\\tthat\\tactivity.\\nNeuroscientists\\tcall\\tthis\\t\\nlong-term\\tpotentiation\\n,\\twhich\\trefers\\tto\\tthe\\tstrengthening\\nof\\tconnections\\tbetween\\tneurons\\tin\\tthe\\tbrain\\tbased\\ton\\trecent\\tpatterns\\tof\\tactivity.\\nWith\\teach\\trepetition,\\tcell-to-cell\\tsignaling\\timproves\\tand\\tthe\\tneural\\tconnections\\ntighten.\\tFirst\\tdescribed\\tby\\tneuropsychologist\\tDonald\\tHebb\\tin\\t1949,\\tthis', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 113}), Document(page_content='phenomenon\\tis\\tcommonly\\tknown\\tas\\tHebb’s\\tLaw:\\t“\\nNeurons\\tthat\\tfire\\ttogether\\nwire\\ttogether.”\\nRepeating\\ta\\thabit\\tleads\\tto\\tclear\\tphysical\\tchanges\\tin\\tthe\\tbrain.\\t\\nIn\\tmusicians,\\nthe\\tcerebellum—critical\\tfor\\tphysical\\tmovements\\tlike\\tplucking\\ta\\tguitar\\tstring\\tor\\npulling\\ta\\tviolin\\tbow—is\\tlarger\\tthan\\tit\\tis\\tin\\tnonmusicians.\\t\\nMathematicians,\\nmeanwhile,\\thave\\tincreased\\tgray\\tmatter\\tin\\t\\nthe\\tinferior\\tparietal\\tlobule,\\twhich\\nplays\\ta\\tkey\\trole\\tin\\tcomputation\\tand\\tcalculation.\\tIts\\tsize\\tis\\tdirectly\\tcorrelated\\nwith\\tthe\\tamount\\tof\\ttime\\tspent\\tin\\tthe\\tfield;\\tthe\\tolder\\tand\\tmore\\texperienced\\tthe\\nmathematician,\\tthe\\tgreater\\tthe\\tincrease\\tin\\tgray\\tmatter.\\nWhen\\tscientists\\tanalyzed\\tthe\\tbrains\\tof\\ttaxi\\tdrivers\\tin\\tLondon,\\tthey\\tfound\\tthat\\nthe\\thippocampus—a\\tregion\\tof\\tthe\\tbrain\\tinvolved\\tin\\tspatial\\tmemory—was\\nsignificantly\\tlarger\\tin\\ttheir\\tsubjects\\tthan\\tin\\tnon–taxi\\tdrivers.\\tEven\\tmore\\nfascinating,\\tthe\\thippocampus\\tdecreased\\tin\\tsize\\twhen\\ta\\tdriver\\tretired.\\tLike\\tthe\\nmuscles\\tof\\tthe\\tbody\\tresponding\\tto\\tregular\\tweight\\ttraining,\\tparticular\\tregions\\tof\\nthe\\tbrain\\tadapt\\tas\\tthey\\tare\\tused\\tand\\tatrophy\\tas\\tthey\\tare\\tabandoned.\\nOf\\tcourse,\\tthe\\timportance\\tof\\trepetition\\tin\\testablishing\\thabits\\twas\\trecognized\\nlong\\tbefore\\tneuroscientists\\tbegan\\tpoking\\taround.\\tIn\\t1860,\\tthe\\tEnglish\\nphilosopher\\tGeorge\\tH.\\tLewes\\tnoted,\\t“In\\tlearning\\tto\\tspeak\\ta\\tnew\\tlanguage,\\tto\\nplay\\ton\\ta\\tmusical\\tinstrument,\\tor\\tto\\tperform\\tunaccustomed\\tmovements,\\tgreat\\ndifficulty\\tis\\tfelt,\\tbecause\\tthe\\tchannels\\tthrough\\twhich\\teach\\tsensation\\thas\\tto\\tpass\\nhave\\tnot\\tbecome\\testablished;\\tbut\\tno\\tsooner\\thas\\tfrequent\\trepetition\\tcut\\ta\\npathway,\\tthan\\tthis\\tdifficulty\\tvanishes;\\t\\nthe\\tactions\\tbecome\\tso\\tautomatic\\tthat\\tthey\\ncan\\tbe\\tperformed\\twhile\\tthe\\tmind\\tis\\totherwise\\tengaged.”\\tBoth\\tcommon\\tsense\\nand\\tscientific\\tevidence\\tagree:\\t\\nrepetition\\tis\\ta\\tform\\tof\\tchange.\\nEach\\ttime\\tyou\\trepeat\\tan\\taction,\\tyou\\tare\\tactivating\\ta\\tparticular\\tneural\\tcircuit\\nassociated\\twith\\tthat\\thabit.\\tThis\\tmeans\\tthat\\tsimply\\tputting\\tin\\tyour\\treps\\tis\\tone\\tof\\nthe\\tmost\\tcritical\\tsteps\\tyou\\tcan\\ttake\\tto\\tencoding\\ta\\tnew\\thabit.\\tIt\\tis\\twhy\\tthe\\nstudents\\twho\\ttook\\ttons\\tof\\tphotos\\timproved\\ttheir\\tskills\\twhile\\tthose\\twho\\tmerely\\ntheorized\\tabout\\tperfect\\tphotos\\tdid\\tnot.\\tOne\\tgroup\\tengaged\\tin\\tactive\\tpractice,\\tthe\\nother\\tin\\tpassive\\tlearning.\\tOne\\tin\\taction,\\tthe\\tother\\tin\\tmotion.\\nAll\\thabits\\tfollow\\ta\\tsimilar\\ttrajectory\\tfrom\\teffortful\\tpractice\\tto\\tautomatic\\nbehavior,\\ta\\tprocess\\tknown\\tas\\t\\nautomaticity\\n.\\t\\nAutomaticity\\tis\\tthe\\tability\\tto\\tperform\\na\\tbehavior\\twithout\\tthinking\\tabout\\teach\\tstep,\\twhich\\toccurs\\twhen\\tthe\\nnonconscious\\tmind\\ttakes\\tover.\\nIt\\tlooks\\tsomething\\tlike\\tthis:\\nTHE\\tHABIT\\tLINE', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 114}), Document(page_content='FIGURE\\t11:\\tIn\\tthe\\tbeginning\\t(point\\tA),\\ta\\thabit\\trequires\\ta\\tgood\\tdeal\\tof\\teffort\\tand\\tconcentration\\tto\\tperform.\\tAfter\\ta\\tfew\\trepetitions\\t(point\\tB),\\tit\\tgets\\teasier,\\tbut\\tstill\\trequires\\tsome\\tconscious\\nattention.\\tWith\\tenough\\tpractice\\t(point\\tC),\\tthe\\thabit\\tbecomes\\tmore\\tautomatic\\tthan\\tconscious.\\tBeyond\\tthis\\tthreshold—\\nthe\\thabit\\tline\\n—the\\tbehavior\\tcan\\tbe\\tdone\\tmore\\tor\\tless\\twithout\\tthinking.\\nA\\tnew\\thabit\\thas\\tbeen\\tformed.\\nOn\\tthe\\tfollowing\\tpage,\\tyou’ll\\tsee\\twhat\\tit\\tlooks\\tlike\\twhen\\tresearchers\\ttrack\\tthe\\nlevel\\tof\\tautomaticity\\tfor\\tan\\tactual\\thabit\\tlike\\twalking\\tfor\\tten\\tminutes\\teach\\tday.\\nThe\\tshape\\tof\\tthese\\tcharts,\\twhich\\tscientists\\tcall\\n\\tlearning\\tcurves\\n,\\treveals\\tan\\nimportant\\ttruth\\tabout\\tbehavior\\tchange:\\t\\nhabits\\tform\\tbased\\ton\\tfrequency,\\tnot\\ntime.\\nWALKING\\t10\\tMINUTES\\tPER\\tDAY', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 115}), Document(page_content='FIGURE\\t12:\\tThis\\tgraph\\tshows\\tsomeone\\twho\\tbuilt\\tthe\\thabit\\tof\\twalking\\tfor\\tten\\tminutes\\tafter\\tbreakfast\\teach\\tday.\\tNotice\\tthat\\tas\\tthe\\trepetitions\\tincrease,\\tso\\tdoes\\tautomaticity,\\tuntil\\tthe\\nbehavior\\tis\\tas\\teasy\\tand\\tautomatic\\tas\\tit\\tcan\\tbe.\\nOne\\tof\\tthe\\tmost\\tcommon\\tquestions\\tI\\thear\\tis,\\t“How\\t\\nlong\\n\\tdoes\\tit\\ttake\\tto\\tbuild\\ta\\nnew\\thabit?”\\tBut\\twhat\\tpeople\\treally\\tshould\\tbe\\tasking\\tis,\\t“How\\t\\nmany\\n\\tdoes\\tit\\ttake\\nto\\tform\\ta\\tnew\\thabit?”\\tThat\\tis,\\thow\\tmany\\trepetitions\\tare\\trequired\\tto\\tmake\\ta\\thabit\\nautomatic?\\nThere\\tis\\tnothing\\tmagical\\tabout\\ttime\\tpassing\\twith\\tregard\\tto\\thabit\\tformation.\\tIt\\ndoesn’t\\tmatter\\tif\\tit’s\\tbeen\\ttwenty-one\\tdays\\tor\\tthirty\\tdays\\tor\\tthree\\thundred\\tdays.\\nWhat\\tmatters\\tis\\tthe\\trate\\tat\\twhich\\tyou\\tperform\\tthe\\tbehavior.\\tYou\\tcould\\tdo\\nsomething\\ttwice\\tin\\tthirty\\tdays,\\tor\\ttwo\\thundred\\ttimes.\\tIt’s\\tthe\\tfrequency\\tthat\\nmakes\\tthe\\tdifference.\\tYour\\tcurrent\\thabits\\thave\\tbeen\\tinternalized\\tover\\tthe\\tcourse\\nof\\thundreds,\\tif\\tnot\\tthousands,\\tof\\trepetitions.\\tNew\\thabits\\trequire\\tthe\\tsame\\tlevel\\nof\\t\\nfrequency.\\tYou\\tneed\\tto\\tstring\\ttogether\\tenough\\tsuccessful\\tattempts\\tuntil\\tthe\\nbehavior\\tis\\tfirmly\\tembedded\\tin\\tyour\\tmind\\tand\\tyou\\tcross\\tthe\\tHabit\\tLine.\\nIn\\tpractice,\\tit\\tdoesn’t\\treally\\tmatter\\thow\\tlong\\tit\\ttakes\\tfor\\ta\\thabit\\tto\\tbecome\\nautomatic.\\tWhat\\tmatters\\tis\\tthat\\tyou\\ttake\\tthe\\tactions\\tyou\\tneed\\tto\\ttake\\tto\\tmake\\nprogress.\\tWhether\\tan\\taction\\tis\\tfully\\tautomatic\\tis\\tof\\tless\\timportance.\\nTo\\tbuild\\ta\\thabit,\\tyou\\tneed\\tto\\tpractice\\tit.\\tAnd\\tthe\\tmost\\teffective\\tway\\tto\\tmake\\npractice\\thappen\\tis\\tto\\tadhere\\tto\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange:\\t\\nmake\\tit\\teasy\\n.\\nThe\\tchapters\\tthat\\tfollow\\twill\\tshow\\tyou\\thow\\tto\\tdo\\texactly\\tthat.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 116}), Document(page_content='Chapter\\tSummary\\nThe\\t3rd\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\teasy\\n.\\nThe\\tmost\\teffective\\tform\\tof\\tlearning\\tis\\tpractice,\\tnot\\tplanning.\\nFocus\\ton\\ttaking\\taction,\\tnot\\tbeing\\tin\\tmotion.\\nHabit\\tformation\\tis\\tthe\\tprocess\\tby\\twhich\\ta\\tbehavior\\tbecomes\\nprogressively\\tmore\\tautomatic\\tthrough\\trepetition.\\nThe\\tamount\\tof\\ttime\\tyou\\thave\\tbeen\\tperforming\\ta\\thabit\\tis\\tnot\\tas\\nimportant\\tas\\tthe\\tnumber\\tof\\ttimes\\tyou\\thave\\tperformed\\tit.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 117}), Document(page_content='12\\nThe\\tLaw\\tof\\tLeast\\tEffort\\nI\\nN\\tHIS\\tAWARD\\n-\\nWINNING\\tBOOK,\\n\\t\\nGuns,\\tGerms,\\tand\\tSteel\\n,\\tanthropologist\\tand\\tbiologist\\tJared\\nDiamond\\tpoints\\tout\\ta\\tsimple\\tfact:\\tdifferent\\tcontinents\\thave\\tdifferent\\tshapes.\\tAt\\nfirst\\tglance,\\tthis\\tstatement\\tseems\\trather\\tobvious\\tand\\tunimportant,\\tbut\\tit\\tturns\\tout\\nto\\thave\\ta\\tprofound\\timpact\\ton\\thuman\\tbehavior.\\nThe\\tprimary\\taxis\\tof\\tthe\\tAmericas\\truns\\tfrom\\tnorth\\tto\\tsouth.\\tThat\\tis,\\tthe\\nlandmass\\tof\\tNorth\\tand\\tSouth\\tAmerica\\ttends\\tto\\tbe\\ttall\\tand\\tthin\\trather\\tthan\\twide\\nand\\tfat.\\tThe\\tsame\\tis\\tgenerally\\ttrue\\tfor\\tAfrica.\\tMeanwhile,\\tthe\\tlandmass\\tthat\\nmakes\\tup\\tEurope,\\tAsia,\\tand\\tthe\\tMiddle\\tEast\\tis\\tthe\\topposite.\\tThis\\tmassive\\tstretch\\nof\\tland\\ttends\\tto\\tbe\\tmore\\teast-west\\tin\\tshape.\\tAccording\\tto\\tDiamond,\\t\\nthis\\ndifference\\tin\\tshape\\tplayed\\ta\\tsignificant\\trole\\tin\\tthe\\tspread\\tof\\tagriculture\\tover\\tthe\\ncenturies.\\nWhen\\tagriculture\\tbegan\\tto\\tspread\\taround\\tthe\\tglobe,\\tfarmers\\thad\\tan\\teasier\\ntime\\texpanding\\talong\\teast-west\\troutes\\tthan\\talong\\tnorth-south\\tones.\\tThis\\tis\\nbecause\\tlocations\\talong\\tthe\\tsame\\tlatitude\\tgenerally\\tshare\\tsimilar\\tclimates,\\namounts\\tof\\tsunlight\\tand\\trainfall,\\tand\\tchanges\\tin\\tseason.\\tThese\\tfactors\\tallowed\\nfarmers\\tin\\tEurope\\tand\\tAsia\\tto\\tdomesticate\\ta\\tfew\\tcrops\\tand\\tgrow\\tthem\\talong\\tthe\\nentire\\tstretch\\tof\\tland\\tfrom\\tFrance\\tto\\tChina.\\nTHE\\tSHAPE\\tOF\\tHUMAN\\tBEHAVIOR', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 118}), Document(page_content='FIGURE\\t13:\\tThe\\tprimary\\taxis\\tof\\tEurope\\tand\\tAsia\\tis\\teast-west.\\tThe\\tprimary\\taxis\\tof\\tthe\\tAmericas\\tand\\tAfrica\\tis\\tnorth-south.\\tThis\\tleads\\tto\\ta\\twider\\trange\\tof\\tclimates\\tup-and-down\\tthe\\nAmericas\\tthan\\tacross\\tEurope\\tand\\tAsia.\\tAs\\ta\\tresult,\\tagriculture\\tspread\\tnearly\\ttwice\\tas\\tfast\\tacross\\tEurope\\tand\\tAsia\\tthan\\tit\\tdid\\telsewhere.\\tThe\\tbehavior\\tof\\tfarmers—even\\tacross\\thundreds\\tor\\nthousands\\tof\\tyears—was\\tconstrained\\tby\\tthe\\tamount\\tof\\tfriction\\tin\\tthe\\tenvironment.\\nBy\\tcomparison,\\tthe\\tclimate\\tvaries\\tgreatly\\twhen\\ttraveling\\tfrom\\tnorth\\tto\\tsouth.\\nJust\\timagine\\thow\\tdifferent\\tthe\\tweather\\tis\\tin\\tFlorida\\tcompared\\tto\\tCanada.\\tYou\\ncan\\tbe\\tthe\\tmost\\ttalented\\tfarmer\\tin\\tthe\\tworld,\\tbut\\tit\\twon’t\\thelp\\tyou\\tgrow\\tFlorida\\noranges\\tin\\tthe\\tCanadian\\t\\nwinter.\\tSnow\\tis\\ta\\tpoor\\tsubstitute\\tfor\\tsoil.\\tIn\\torder\\tto\\nspread\\tcrops\\talong\\tnorth-south\\troutes,\\tfarmers\\twould\\tneed\\tto\\tfind\\tand\\ndomesticate\\tnew\\tplants\\twhenever\\tthe\\tclimate\\tchanged.\\nAs\\ta\\tresult,\\tagriculture\\tspread\\ttwo\\tto\\tthree\\ttimes\\tfaster\\tacross\\tAsia\\tand\\nEurope\\tthan\\tit\\tdid\\tup\\tand\\tdown\\tthe\\tAmericas.\\tOver\\tthe\\tspan\\tof\\tcenturies,\\tthis\\nsmall\\tdifference\\thad\\ta\\tvery\\tbig\\timpact.\\tIncreased\\tfood\\tproduction\\tallowed\\tfor\\nmore\\trapid\\tpopulation\\tgrowth.\\tWith\\tmore\\tpeople,\\tthese\\tcultures\\twere\\table\\tto\\nbuild\\tstronger\\tarmies\\tand\\twere\\tbetter\\tequipped\\tto\\tdevelop\\tnew\\ttechnologies.\\nThe\\tchanges\\tstarted\\tout\\tsmall—a\\tcrop\\tthat\\tspread\\tslightly\\tfarther,\\ta\\tpopulation\\nthat\\tgrew\\tslightly\\tfaster—but\\tcompounded\\tinto\\tsubstantial\\tdifferences\\tover\\ttime.\\nThe\\tspread\\tof\\tagriculture\\tprovides\\tan\\texample\\tof\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\nChange\\ton\\ta\\tglobal\\tscale.\\tConventional\\twisdom\\tholds\\tthat\\tmotivation\\tis\\tthe\\tkey\\nto\\thabit\\tchange.\\tMaybe\\tif\\tyou\\t\\nreally\\n\\twanted\\tit,\\tyou’d\\tactually\\tdo\\tit.\\tBut\\tthe\\ttruth\\nis,\\tour\\treal\\tmotivation\\tis\\tto\\tbe\\tlazy\\tand\\tto\\tdo\\twhat\\tis\\tconvenient.\\tAnd\\tdespite\\nwhat\\tthe\\tlatest\\tproductivity\\tbest\\tseller\\twill\\ttell\\tyou,\\tthis\\tis\\ta\\tsmart\\tstrategy,\\tnot\\ta', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 119}), Document(page_content='dumb\\tone.\\nEnergy\\tis\\tprecious,\\tand\\tthe\\tbrain\\tis\\twired\\tto\\tconserve\\tit\\twhenever\\tpossible.\\t\\nIt\\nis\\thuman\\tnature\\tto\\tfollow\\tthe\\tLaw\\tof\\tLeast\\tEffort,\\twhich\\tstates\\tthat\\twhen\\ndeciding\\tbetween\\ttwo\\tsimilar\\toptions,\\tpeople\\twill\\tnaturally\\tgravitate\\ttoward\\tthe\\noption\\tthat\\trequires\\tthe\\tleast\\tamount\\tof\\twork.\\n*\\n\\tFor\\texample,\\texpanding\\tyour\\nfarm\\tto\\tthe\\teast\\twhere\\tyou\\tcan\\tgrow\\tthe\\tsame\\tcrops\\trather\\tthan\\theading\\tnorth\\nwhere\\tthe\\tclimate\\tis\\tdifferent.\\tOut\\tof\\tall\\tthe\\tpossible\\tactions\\twe\\tcould\\ttake,\\tthe\\none\\tthat\\tis\\trealized\\tis\\tthe\\tone\\tthat\\tdelivers\\tthe\\tmost\\tvalue\\tfor\\tthe\\tleast\\teffort.\\tWe\\nare\\tmotivated\\tto\\tdo\\twhat\\tis\\teasy.\\nEvery\\taction\\trequires\\ta\\tcertain\\tamount\\tof\\tenergy.\\tThe\\tmore\\tenergy\\trequired,\\nthe\\tless\\tlikely\\tit\\tis\\tto\\toccur.\\tIf\\tyour\\tgoal\\tis\\tto\\tdo\\ta\\thundred\\tpush-ups\\tper\\tday,\\nthat’s\\ta\\tlot\\tof\\tenergy!\\tIn\\tthe\\tbeginning,\\twhen\\tyou’re\\tmotivated\\tand\\texcited,\\tyou\\ncan\\tmuster\\tthe\\tstrength\\tto\\tget\\tstarted.\\tBut\\tafter\\ta\\tfew\\tdays,\\tsuch\\ta\\tmassive\\teffort\\nfeels\\texhausting.\\tMeanwhile,\\tsticking\\tto\\tthe\\thabit\\tof\\tdoing\\tone\\tpush-up\\tper\\tday\\nrequires\\talmost\\tno\\tenergy\\tto\\tget\\tstarted.\\tAnd\\tthe\\tless\\tenergy\\ta\\thabit\\trequires,\\tthe\\nmore\\tlikely\\tit\\tis\\tto\\toccur.\\nLook\\tat\\tany\\tbehavior\\tthat\\tfills\\tup\\tmuch\\tof\\tyour\\tlife\\tand\\tyou’ll\\tsee\\tthat\\tit\\tcan\\nbe\\tperformed\\twith\\tvery\\tlow\\tlevels\\tof\\tmotivation.\\tHabits\\tlike\\tscrolling\\ton\\tour\\nphones,\\tchecking\\temail,\\tand\\twatching\\ttelevision\\tsteal\\tso\\tmuch\\tof\\tour\\ttime\\nbecause\\tthey\\tcan\\tbe\\tperformed\\talmost\\twithout\\teffort.\\tThey\\tare\\tremarkably\\nconvenient.\\nIn\\ta\\tsense,\\tevery\\thabit\\tis\\tjust\\tan\\tobstacle\\tto\\tgetting\\twhat\\tyou\\treally\\twant.\\nDieting\\tis\\tan\\tobstacle\\tto\\tgetting\\tfit.\\tMeditation\\tis\\tan\\tobstacle\\tto\\tfeeling\\tcalm.\\nJournaling\\tis\\tan\\tobstacle\\tto\\tthinking\\tclearly.\\tYou\\tdon’t\\tactually\\twant\\tthe\\thabit\\nitself.\\tWhat\\tyou\\treally\\twant\\tis\\tthe\\toutcome\\tthe\\thabit\\tdelivers.\\tThe\\tgreater\\tthe\\nobstacle—that\\tis,\\tthe\\tmore\\tdifficult\\tthe\\thabit—the\\tmore\\tfriction\\tthere\\tis\\tbetween\\nyou\\tand\\tyour\\tdesired\\tend\\tstate.\\tThis\\tis\\twhy\\tit\\tis\\tcrucial\\tto\\tmake\\tyour\\thabits\\tso\\neasy\\tthat\\tyou’ll\\tdo\\tthem\\teven\\twhen\\tyou\\tdon’t\\tfeel\\tlike\\tit.\\tIf\\tyou\\tcan\\tmake\\tyour\\ngood\\thabits\\tmore\\tconvenient,\\tyou’ll\\tbe\\tmore\\tlikely\\tto\\tfollow\\tthrough\\ton\\tthem.\\nBut\\twhat\\tabout\\tall\\tthe\\tmoments\\twhen\\twe\\tseem\\tto\\tdo\\tthe\\topposite?\\tIf\\twe’re\\tall\\nso\\tlazy,\\tthen\\thow\\tdo\\tyou\\texplain\\tpeople\\taccomplishing\\thard\\tthings\\tlike\\traising\\ta\\nchild\\tor\\tstarting\\ta\\tbusiness\\tor\\tclimbing\\tMount\\tEverest?\\nCertainly,\\tyou\\tare\\tcapable\\tof\\tdoing\\tvery\\thard\\tthings.\\tThe\\tproblem\\tis\\tthat\\nsome\\tdays\\tyou\\tfeel\\tlike\\tdoing\\tthe\\thard\\twork\\tand\\tsome\\tdays\\tyou\\tfeel\\tlike\\tgiving\\nin.\\tOn\\tthe\\ttough\\tdays,\\tit’s\\tcrucial\\tto\\thave\\tas\\tmany\\tthings\\tworking\\tin\\tyour\\tfavor\\nas\\tpossible\\tso\\tthat\\tyou\\tcan\\tovercome\\tthe\\tchallenges\\tlife\\tnaturally\\tthrows\\tyour\\nway.\\tThe\\tless\\tfriction\\tyou\\tface,\\tthe\\t\\neasier\\tit\\tis\\tfor\\tyour\\tstronger\\tself\\tto\\temerge.\\nThe\\tidea\\tbehind\\t\\nmake\\tit\\teasy\\t\\nis\\tnot\\tto\\t\\nonly\\n\\tdo\\teasy\\tthings.\\tThe\\tidea\\tis\\tto\\tmake\\tit\\nas\\teasy\\tas\\tpossible\\tin\\tthe\\tmoment\\tto\\tdo\\tthings\\tthat\\tpayoff\\tin\\tthe\\tlong\\trun.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 120}), Document(page_content='HOW\\tTO\\tACHIEVE\\tMORE\\tWITH\\tLESS\\tEFFORT\\nImagine\\tyou\\tare\\tholding\\t\\na\\tgarden\\those\\tthat\\tis\\tbent\\tin\\tthe\\tmiddle.\\tSome\\twater\\ncan\\tflow\\tthrough,\\tbut\\tnot\\tvery\\tmuch.\\tIf\\tyou\\twant\\tto\\tincrease\\tthe\\trate\\tat\\twhich\\nwater\\tpasses\\tthrough\\tthe\\those,\\tyou\\thave\\ttwo\\toptions.\\tThe\\tfirst\\toption\\tis\\tto\\tcrank\\nup\\tthe\\tvalve\\tand\\tforce\\tmore\\twater\\tout.\\tThe\\tsecond\\toption\\tis\\tto\\tsimply\\tremove\\nthe\\tbend\\tin\\tthe\\those\\tand\\tlet\\twater\\tflow\\tthrough\\tnaturally.\\nTrying\\tto\\tpump\\tup\\tyour\\tmotivation\\tto\\tstick\\twith\\ta\\thard\\thabit\\tis\\tlike\\ttrying\\tto\\nforce\\twater\\tthrough\\ta\\tbent\\those.\\tYou\\tcan\\tdo\\tit,\\tbut\\tit\\trequires\\ta\\tlot\\tof\\teffort\\tand\\nincreases\\tthe\\ttension\\tin\\tyour\\tlife.\\tMeanwhile,\\tmaking\\tyour\\thabits\\tsimple\\tand\\neasy\\tis\\tlike\\tremoving\\tthe\\tbend\\tin\\tthe\\those.\\tRather\\tthan\\ttrying\\tto\\tovercome\\tthe\\nfriction\\tin\\tyour\\tlife,\\tyou\\treduce\\tit.\\nOne\\tof\\tthe\\tmost\\teffective\\tways\\tto\\treduce\\tthe\\tfriction\\tassociated\\twith\\tyour\\nhabits\\tis\\tto\\tpractice\\tenvironment\\tdesign.\\tIn\\tChapter\\t6,\\twe\\tdiscussed\\tenvironment\\ndesign\\tas\\ta\\tmethod\\tfor\\tmaking\\tcues\\tmore\\tobvious,\\tbut\\tyou\\tcan\\talso\\toptimize\\nyour\\tenvironment\\tto\\tmake\\tactions\\teasier.\\tFor\\texample,\\twhen\\tdeciding\\twhere\\tto\\npractice\\ta\\tnew\\thabit,\\tit\\tis\\tbest\\tto\\tchoose\\ta\\tplace\\tthat\\tis\\talready\\talong\\tthe\\tpath\\tof\\nyour\\tdaily\\troutine.\\tHabits\\tare\\teasier\\tto\\tbuild\\twhen\\tthey\\tfit\\tinto\\tthe\\tflow\\tof\\tyour\\nlife.\\tYou\\tare\\tmore\\tlikely\\tto\\tgo\\tto\\tthe\\tgym\\tif\\tit\\tis\\ton\\tyour\\tway\\tto\\twork\\tbecause\\nstopping\\tdoesn’t\\tadd\\tmuch\\tfriction\\tto\\tyour\\tlifestyle.\\tBy\\tcomparison,\\tif\\tthe\\tgym\\nis\\toff\\tthe\\tpath\\tof\\tyour\\tnormal\\tcommute—even\\tby\\tjust\\ta\\tfew\\tblocks—now\\tyou’re\\ngoing\\t“out\\tof\\tyour\\tway”\\tto\\tget\\tthere.\\nPerhaps\\teven\\tmore\\teffective\\tis\\treducing\\tthe\\tfriction\\twithin\\tyour\\thome\\tor\\noffice.\\tToo\\toften,\\twe\\ttry\\tto\\tstart\\thabits\\tin\\thigh-friction\\tenvironments.\\tWe\\ttry\\tto\\nfollow\\ta\\tstrict\\tdiet\\twhile\\twe\\tare\\tout\\tto\\tdinner\\twith\\t\\nfriends.\\tWe\\ttry\\tto\\twrite\\ta\\nbook\\tin\\ta\\tchaotic\\thousehold.\\tWe\\ttry\\tto\\tconcentrate\\twhile\\tusing\\ta\\tsmartphone\\nfilled\\twith\\tdistractions.\\tIt\\tdoesn’t\\thave\\tto\\tbe\\tthis\\tway.\\tWe\\tcan\\tremove\\tthe\\tpoints\\nof\\tfriction\\tthat\\thold\\tus\\tback.\\tThis\\tis\\tprecisely\\twhat\\telectronics\\tmanufacturers\\tin\\nJapan\\tbegan\\tto\\tdo\\tin\\tthe\\t1970s.\\nIn\\tan\\tarticle\\tpublished\\tin\\tthe\\t\\nNew\\tYorker\\n\\ttitled\\t“Better\\tAll\\tthe\\tTime,”\\tJames\\nSuroweicki\\twrites:\\n“Japanese\\tfirms\\temphasized\\twhat\\tcame\\tto\\tbe\\tknown\\tas\\t‘lean\\tproduction,’\\nrelentlessly\\tlooking\\tto\\tremove\\twaste\\tof\\tall\\tkinds\\tfrom\\tthe\\tproduction\\tprocess,\\ndown\\tto\\tredesigning\\tworkspaces,\\tso\\tworkers\\tdidn’t\\thave\\tto\\twaste\\ttime\\ttwisting\\nand\\tturning\\tto\\treach\\ttheir\\ttools.\\tThe\\tresult\\twas\\tthat\\tJapanese\\tfactories\\twere\\tmore\\nefficient\\tand\\tJapanese\\tproducts\\twere\\tmore\\treliable\\tthan\\tAmerican\\tones.\\tIn\\t1974,\\nservice\\tcalls\\tfor\\tAmerican-made\\tcolor\\ttelevisions\\twere\\tfive\\ttimes\\tas\\tcommon\\tas\\nfor\\tJapanese\\ttelevisions.\\tBy\\t1979,\\t\\nit\\ttook\\tAmerican\\tworkers\\tthree\\ttimes\\tas\\tlong\\nto\\tassemble\\ttheir\\tsets.”', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 121}), Document(page_content='I\\tlike\\tto\\trefer\\tto\\tthis\\tstrategy\\tas\\t\\naddition\\tby\\tsubtraction\\n.\\n*\\n\\tThe\\tJapanese\\ncompanies\\tlooked\\tfor\\tevery\\tpoint\\tof\\tfriction\\tin\\tthe\\tmanufacturing\\tprocess\\tand\\neliminated\\tit.\\tAs\\tthey\\tsubtracted\\twasted\\teffort,\\tthey\\tadded\\tcustomers\\tand\\nrevenue.\\tSimilarly,\\twhen\\twe\\tremove\\tthe\\tpoints\\tof\\tfriction\\tthat\\tsap\\tour\\ttime\\tand\\nenergy,\\twe\\tcan\\tachieve\\tmore\\twith\\tless\\teffort.\\t(This\\tis\\tone\\treason\\ttidying\\tup\\tcan\\nfeel\\tso\\tgood:\\twe\\tare\\tsimultaneously\\tmoving\\tforward\\tand\\tlightening\\tthe\\ncognitive\\tload\\tour\\tenvironment\\tplaces\\ton\\tus.)\\nIf\\tyou\\tlook\\tat\\tthe\\tmost\\thabit-forming\\tproducts,\\tyou’ll\\tnotice\\tthat\\tone\\tof\\tthe\\nthings\\tthese\\tgoods\\tand\\tservices\\tdo\\tbest\\tis\\tremove\\tlittle\\tbits\\tof\\tfriction\\tfrom\\tyour\\nlife.\\tMeal\\tdelivery\\tservices\\treduce\\tthe\\tfriction\\tof\\tshopping\\tfor\\tgroceries.\\tDating\\napps\\treduce\\tthe\\tfriction\\tof\\tmaking\\t\\nsocial\\tintroductions.\\tRide-sharing\\tservices\\nreduce\\tthe\\tfriction\\tof\\tgetting\\tacross\\ttown.\\tText\\tmessaging\\treduces\\tthe\\tfriction\\tof\\nsending\\ta\\tletter\\tin\\tthe\\tmail.\\nLike\\ta\\tJapanese\\ttelevision\\tmanufacturer\\tredesigning\\ttheir\\tworkspace\\tto\\nreduce\\twasted\\tmotion,\\tsuccessful\\tcompanies\\tdesign\\ttheir\\tproducts\\tto\\tautomate,\\neliminate,\\tor\\tsimplify\\tas\\tmany\\tsteps\\tas\\tpossible.\\tThey\\treduce\\tthe\\tnumber\\tof\\nfields\\ton\\teach\\tform.\\tThey\\tpare\\tdown\\tthe\\tnumber\\tof\\tclicks\\trequired\\tto\\tcreate\\tan\\naccount.\\tThey\\tdeliver\\ttheir\\tproducts\\twith\\teasy-to-understand\\tdirections\\tor\\task\\ntheir\\tcustomers\\tto\\tmake\\tfewer\\tchoices.\\nWhen\\tthe\\tfirst\\tvoice-activated\\tspeakers\\twere\\treleased—products\\tlike\\tGoogle\\nHome,\\tAmazon\\tEcho,\\tand\\tApple\\tHomePod—I\\tasked\\ta\\tfriend\\twhat\\the\\tliked\\nabout\\tthe\\tproduct\\the\\thad\\tpurchased.\\tHe\\tsaid\\tit\\twas\\tjust\\teasier\\tto\\tsay\\t“Play\\tsome\\ncountry\\tmusic”\\tthan\\tto\\tpull\\tout\\this\\tphone,\\topen\\tthe\\tmusic\\tapp,\\tand\\tpick\\ta\\nplaylist.\\tOf\\tcourse,\\tjust\\ta\\tfew\\tyears\\tearlier,\\thaving\\tunlimited\\taccess\\tto\\tmusic\\tin\\nyour\\tpocket\\twas\\ta\\tremarkably\\tfrictionless\\tbehavior\\tcompared\\tto\\tdriving\\tto\\tthe\\nstore\\tand\\tbuying\\ta\\tCD.\\tBusiness\\tis\\ta\\tnever-ending\\tquest\\tto\\tdeliver\\tthe\\tsame\\nresult\\tin\\tan\\teasier\\tfashion.\\nSimilar\\tstrategies\\thave\\tbeen\\tused\\teffectively\\tby\\tgovernments.\\tWhen\\tthe\\nBritish\\tgovernment\\twanted\\tto\\tincrease\\ttax\\tcollection\\trates,\\tthey\\tswitched\\tfrom\\nsending\\tcitizens\\tto\\ta\\tweb\\tpage\\twhere\\tthe\\ttax\\tform\\tcould\\tbe\\tdownloaded\\tto\\nlinking\\tdirectly\\tto\\tthe\\tform.\\tReducing\\tthat\\tone\\tstep\\tin\\tthe\\tprocess\\tincreased\\tthe\\nresponse\\trate\\tfrom\\t19.2\\tpercent\\tto\\t23.4\\tpercent.\\tFor\\ta\\tcountry\\tlike\\tthe\\tUnited\\nKingdom,\\t\\nthose\\tpercentage\\tpoints\\trepresent\\tmillions\\tin\\ttax\\trevenue.\\nThe\\tcentral\\tidea\\tis\\tto\\tcreate\\tan\\tenvironment\\twhere\\tdoing\\tthe\\tright\\tthing\\tis\\tas\\neasy\\tas\\tpossible.\\tMuch\\tof\\tthe\\tbattle\\tof\\tbuilding\\tbetter\\thabits\\tcomes\\tdown\\tto\\nfinding\\tways\\tto\\treduce\\tthe\\tfriction\\tassociated\\twith\\tour\\tgood\\thabits\\tand\\tincrease\\nthe\\tfriction\\tassociated\\twith\\tour\\tbad\\tones.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 122}), Document(page_content='PRIME\\tTHE\\tENVIRONMENT\\tFOR\\tFUTURE\\tUSE\\nOswald\\tNuckols\\tis\\tan\\tIT\\tdeveloper\\tfrom\\tNatchez,\\tMississippi.\\tHe\\tis\\talso\\nsomeone\\twho\\tunderstands\\tthe\\tpower\\tof\\tpriming\\this\\tenvironment.\\nNuckols\\tdialed\\tin\\this\\tcleaning\\thabits\\tby\\tfollowing\\ta\\tstrategy\\the\\trefers\\tto\\tas\\n“resetting\\tthe\\troom.”\\tFor\\tinstance,\\twhen\\the\\tfinishes\\twatching\\ttelevision,\\the\\nplaces\\tthe\\tremote\\tback\\ton\\tthe\\tTV\\tstand,\\tarranges\\tthe\\tpillows\\ton\\tthe\\tcouch,\\tand\\nfolds\\tthe\\tblanket.\\tWhen\\the\\tleaves\\this\\tcar,\\the\\tthrows\\tany\\ttrash\\taway.\\tWhenever\\nhe\\ttakes\\ta\\tshower,\\the\\twipes\\tdown\\tthe\\ttoilet\\twhile\\tthe\\tshower\\tis\\twarming\\tup.\\t(As\\nhe\\tnotes,\\tthe\\t“\\nperfect\\ttime\\tto\\tclean\\tthe\\ttoilet\\tis\\tright\\tbefore\\tyou\\twash\\tyourself\\tin\\nthe\\tshower\\tanyway.”)\\tThe\\tpurpose\\tof\\tresetting\\teach\\troom\\tis\\tnot\\tsimply\\tto\\tclean\\nup\\tafter\\tthe\\tlast\\taction,\\tbut\\tto\\tprepare\\tfor\\tthe\\tnext\\taction.\\n“When\\tI\\twalk\\tinto\\ta\\troom\\teverything\\tis\\tin\\tits\\tright\\tplace,”\\tNuckols\\twrote.\\n“Because\\tI\\tdo\\tthis\\tevery\\tday\\tin\\tevery\\troom,\\tstuff\\talways\\tstays\\tin\\tgood\\tshape.\\t.\\t.\\t.\\nPeople\\tthink\\tI\\twork\\thard\\tbut\\tI’m\\tactually\\treally\\tlazy.\\tI’m\\tjust\\tproactively\\tlazy.\\tIt\\ngives\\tyou\\tso\\tmuch\\ttime\\tback.”\\nWhenever\\tyou\\torganize\\ta\\tspace\\tfor\\tits\\tintended\\tpurpose,\\tyou\\tare\\tpriming\\tit\\tto\\nmake\\tthe\\tnext\\taction\\teasy.\\tFor\\tinstance,\\tmy\\twife\\tkeeps\\ta\\tbox\\tof\\tgreeting\\tcards\\nthat\\tare\\tpresorted\\tby\\toccasion—birthday,\\tsympathy,\\twedding,\\tgraduation,\\tand\\nmore.\\tWhenever\\tnecessary,\\tshe\\tgrabs\\tan\\tappropriate\\tcard\\tand\\tsends\\tit\\toff.\\tShe\\tis\\nincredibly\\tgood\\tat\\tremembering\\tto\\tsend\\tcards\\tbecause\\tshe\\thas\\treduced\\tthe\\nfriction\\tof\\tdoing\\tso.\\tFor\\tyears,\\tI\\twas\\tthe\\topposite.\\tSomeone\\twould\\thave\\ta\\tbaby\\nand\\tI\\twould\\tthink,\\t“I\\tshould\\tsend\\ta\\tcard.”\\tBut\\tthen\\tweeks\\twould\\tpass\\tand\\tby\\tthe\\ntime\\tI\\tremembered\\tto\\tpick\\tone\\tup\\tat\\tthe\\tstore,\\tit\\twas\\ttoo\\tlate.\\tThe\\thabit\\twasn’t\\neasy.\\nThere\\tare\\tmany\\tways\\tto\\tprime\\tyour\\tenvironment\\tso\\tit’s\\tready\\tfor\\timmediate\\nuse.\\tIf\\tyou\\twant\\tto\\tcook\\ta\\thealthy\\tbreakfast,\\tplace\\tthe\\tskillet\\ton\\tthe\\tstove,\\tset\\tthe\\ncooking\\tspray\\ton\\tthe\\tcounter,\\tand\\tlay\\tout\\tany\\tplates\\tand\\tutensils\\tyou’ll\\tneed\\tthe\\nnight\\tbefore.\\tWhen\\tyou\\twake\\tup,\\tmaking\\tbreakfast\\twill\\tbe\\teasy.\\nWant\\tto\\tdraw\\tmore?\\tPut\\tyour\\tpencils,\\tpens,\\tnotebooks,\\tand\\tdrawing\\ntools\\ton\\ttop\\tof\\tyour\\tdesk,\\twithin\\teasy\\treach.\\nWant\\tto\\texercise?\\tSet\\tout\\tyour\\tworkout\\tclothes,\\tshoes,\\tgym\\tbag,\\tand\\nwater\\tbottle\\tahead\\tof\\ttime.\\nWant\\tto\\timprove\\tyour\\tdiet?\\tChop\\tup\\ta\\tton\\tof\\tfruits\\tand\\tvegetables\\ton\\nweekends\\tand\\tpack\\tthem\\tin\\tcontainers,\\tso\\tyou\\thave\\teasy\\taccess\\tto\\nhealthy,\\tready-to-eat\\toptions\\tduring\\tthe\\tweek.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 123}), Document(page_content='These\\tare\\tsimple\\tways\\tto\\tmake\\tthe\\tgood\\thabit\\tthe\\tpath\\tof\\tleast\\tresistance.\\nYou\\tcan\\talso\\tinvert\\tthis\\tprinciple\\tand\\tprime\\tthe\\tenvironment\\tto\\tmake\\tbad\\nbehaviors\\tdifficult.\\tIf\\tyou\\tfind\\tyourself\\twatching\\ttoo\\tmuch\\ttelevision,\\tfor\\nexample,\\tthen\\tunplug\\tit\\tafter\\teach\\tuse.\\tOnly\\tplug\\tit\\tback\\tin\\tif\\tyou\\tcan\\tsay\\tout\\nloud\\tthe\\tname\\tof\\tthe\\tshow\\tyou\\twant\\tto\\twatch.\\tThis\\tsetup\\tcreates\\tjust\\tenough\\nfriction\\tto\\tprevent\\tmindless\\tviewing.\\nIf\\tthat\\tdoesn’t\\tdo\\tit,\\tyou\\tcan\\ttake\\tit\\ta\\tstep\\tfurther.\\tUnplug\\tthe\\ttelevision\\tand\\ntake\\tthe\\tbatteries\\tout\\tof\\tthe\\tremote\\tafter\\teach\\tuse,\\tso\\tit\\ttakes\\tan\\textra\\tten\\tseconds\\nto\\tturn\\tit\\tback\\ton.\\tAnd\\tif\\tyou’re\\treally\\thard-core,\\tmove\\tthe\\ttelevision\\tout\\tof\\tthe\\nliving\\troom\\tand\\tinto\\ta\\tcloset\\tafter\\teach\\tuse.\\tYou\\tcan\\tbe\\tsure\\tyou’ll\\tonly\\ttake\\tit\\nout\\twhen\\tyou\\t\\nreally\\n\\twant\\tto\\twatch\\tsomething.\\tThe\\tgreater\\tthe\\tfriction,\\tthe\\tless\\nlikely\\tthe\\thabit.\\nWhenever\\tpossible,\\tI\\tleave\\tmy\\tphone\\tin\\ta\\tdifferent\\troom\\tuntil\\tlunch.\\tWhen\\nit’s\\tright\\tnext\\tto\\tme,\\tI’ll\\tcheck\\tit\\tall\\tmorning\\tfor\\tno\\treason\\tat\\tall.\\tBut\\twhen\\tit\\tis\\nin\\tanother\\troom,\\tI\\trarely\\tthink\\tabout\\tit.\\tAnd\\tthe\\tfriction\\tis\\thigh\\tenough\\tthat\\tI\\nwon’t\\tgo\\tget\\tit\\twithout\\ta\\treason.\\tAs\\ta\\tresult,\\tI\\tget\\tthree\\tto\\tfour\\thours\\teach\\nmorning\\twhen\\tI\\tcan\\twork\\twithout\\tinterruption.\\nIf\\tsticking\\tyour\\tphone\\tin\\tanother\\troom\\tdoesn’t\\tseem\\tlike\\tenough,\\ttell\\ta\\tfriend\\nor\\tfamily\\tmember\\tto\\thide\\tit\\tfrom\\tyou\\tfor\\ta\\tfew\\thours.\\tAsk\\ta\\tcoworker\\tto\\tkeep\\tit\\nat\\ttheir\\tdesk\\tin\\tthe\\tmorning\\tand\\tgive\\tit\\tback\\tto\\tyou\\tat\\tlunch.\\nIt\\tis\\tremarkable\\thow\\tlittle\\tfriction\\tis\\trequired\\tto\\tprevent\\tunwanted\\tbehavior.\\nWhen\\tI\\thide\\tbeer\\tin\\tthe\\tback\\tof\\tthe\\tfridge\\twhere\\tI\\tcan’t\\tsee\\tit,\\tI\\tdrink\\tless.\\tWhen\\nI\\tdelete\\tsocial\\tmedia\\tapps\\tfrom\\tmy\\tphone,\\tit\\tcan\\tbe\\tweeks\\tbefore\\tI\\tdownload\\nthem\\tagain\\tand\\tlog\\tin.\\tThese\\ttricks\\tare\\tunlikely\\tto\\tcurb\\ta\\ttrue\\taddiction,\\tbut\\tfor\\nmany\\tof\\tus,\\ta\\tlittle\\tbit\\tof\\tfriction\\tcan\\tbe\\tthe\\tdifference\\tbetween\\tsticking\\twith\\ta\\ngood\\thabit\\tor\\tsliding\\tinto\\ta\\tbad\\tone.\\tImagine\\tthe\\tcumulative\\timpact\\tof\\tmaking\\ndozens\\tof\\tthese\\tchanges\\tand\\tliving\\tin\\tan\\tenvironment\\tdesigned\\tto\\tmake\\tthe\\tgood\\nbehaviors\\teasier\\tand\\tthe\\tbad\\tbehaviors\\tharder.\\nWhether\\twe\\tare\\tapproaching\\tbehavior\\tchange\\tas\\tan\\tindividual,\\ta\\tparent,\\ta\\ncoach,\\tor\\ta\\tleader,\\twe\\tshould\\task\\tourselves\\tthe\\tsame\\tquestion:\\t“How\\tcan\\twe\\ndesign\\ta\\tworld\\twhere\\tit’s\\teasy\\tto\\tdo\\twhat’s\\tright?”\\tRedesign\\tyour\\tlife\\tso\\tthe\\nactions\\tthat\\tmatter\\tmost\\tare\\talso\\tthe\\tactions\\tthat\\tare\\teasiest\\tto\\tdo.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 124}), Document(page_content='Chapter\\tSummary\\nHuman\\tbehavior\\tfollows\\tthe\\tLaw\\tof\\tLeast\\tEffort.\\tWe\\twill\\tnaturally\\ngravitate\\ttoward\\tthe\\toption\\tthat\\trequires\\tthe\\tleast\\tamount\\tof\\twork.\\nCreate\\tan\\tenvironment\\twhere\\tdoing\\tthe\\tright\\tthing\\tis\\tas\\teasy\\tas\\npossible.\\nReduce\\tthe\\tfriction\\tassociated\\twith\\tgood\\tbehaviors.\\tWhen\\tfriction\\tis\\nlow,\\thabits\\tare\\teasy.\\nIncrease\\tthe\\tfriction\\tassociated\\twith\\tbad\\tbehaviors.\\tWhen\\tfriction\\tis\\nhigh,\\thabits\\tare\\tdifficult.\\nPrime\\tyour\\tenvironment\\tto\\tmake\\tfuture\\tactions\\teasier.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 125}), Document(page_content='13\\nHow\\tto\\tStop\\tProcrastinating\\tby\\tUsing\\tthe\\tTwo-\\nMinute\\tRule\\nT\\nWYLA\\n\\tT\\nHARP\\n\\t\\nIS\\n\\twidely\\tregarded\\tas\\tone\\tof\\tthe\\tgreatest\\tdancers\\tand\\tchoreographers\\nof\\tthe\\tmodern\\tera.\\tIn\\t1992,\\tshe\\twas\\tawarded\\ta\\tMacArthur\\tFellowship,\\toften\\nreferred\\tto\\tas\\tthe\\tGenius\\tGrant,\\tand\\tshe\\thas\\tspent\\tthe\\tbulk\\tof\\ther\\tcareer\\ttouring\\nthe\\tglobe\\tto\\tperform\\ther\\toriginal\\tworks.\\tShe\\talso\\tcredits\\tmuch\\tof\\ther\\tsuccess\\tto\\nsimple\\tdaily\\thabits.\\n“I\\tbegin\\teach\\tday\\tof\\tmy\\tlife\\twith\\ta\\tritual,”\\tshe\\twrites.\\t“I\\twake\\tup\\tat\\t5:30\\nA.M.,\\tput\\ton\\tmy\\tworkout\\tclothes,\\tmy\\tleg\\twarmers,\\tmy\\tsweat\\tshirt,\\tand\\tmy\\that.\\tI\\nwalk\\toutside\\tmy\\tManhattan\\thome,\\thail\\ta\\ttaxi,\\tand\\ttell\\tthe\\tdriver\\tto\\ttake\\tme\\tto\\nthe\\tPumping\\tIron\\tgym\\tat\\t91st\\tStreet\\tand\\tFirst\\tAvenue,\\twhere\\tI\\twork\\tout\\tfor\\ttwo\\nhours.\\n“The\\tritual\\tis\\tnot\\tthe\\tstretching\\tand\\tweight\\ttraining\\tI\\tput\\tmy\\tbody\\tthrough\\neach\\tmorning\\tat\\tthe\\tgym;\\tthe\\tritual\\tis\\tthe\\tcab.\\tThe\\tmoment\\tI\\ttell\\tthe\\tdriver\\nwhere\\tto\\tgo\\tI\\thave\\tcompleted\\tthe\\tritual.\\n“It’s\\ta\\tsimple\\tact,\\tbut\\tdoing\\tit\\tthe\\tsame\\tway\\teach\\tmorning\\thabitualizes\\tit—\\nmakes\\tit\\trepeatable,\\teasy\\tto\\tdo.\\tIt\\treduces\\tthe\\tchance\\tthat\\tI\\twould\\tskip\\tit\\tor\\tdo\\tit\\ndifferently.\\tIt\\tis\\tone\\tmore\\titem\\tin\\tmy\\t\\narsenal\\tof\\troutines,\\tand\\tone\\tless\\tthing\\tto\\nthink\\tabout.”\\nHailing\\ta\\tcab\\teach\\tmorning\\tmay\\tbe\\ta\\ttiny\\taction,\\tbut\\tit\\tis\\ta\\tsplendid\\texample\\nof\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange.\\nResearchers\\testimate\\tthat\\t\\n40\\tto\\t50\\tpercent\\tof\\tour\\tactions\\ton\\tany\\tgiven\\tday\\tare\\ndone\\tout\\tof\\thabit.\\tThis\\tis\\talready\\ta\\tsubstantial\\tpercentage,\\tbut\\tthe\\ttrue\\tinfluence\\nof\\tyour\\thabits\\tis\\teven\\tgreater\\tthan\\tthese\\tnumbers\\tsuggest.\\tHabits\\tare\\tautomatic\\nchoices\\tthat\\tinfluence\\tthe\\tconscious\\tdecisions\\tthat\\tfollow.\\tYes,\\ta\\thabit\\tcan\\tbe\\ncompleted\\tin\\tjust\\ta\\tfew\\tseconds,\\tbut\\tit\\tcan\\talso\\tshape\\tthe\\tactions\\tthat\\tyou\\ttake\\nfor\\tminutes\\tor\\thours\\tafterward.\\nHabits\\tare\\tlike\\tthe\\tentrance\\tramp\\tto\\ta\\thighway.\\tThey\\tlead\\tyou\\tdown\\ta\\tpath', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 126}), Document(page_content='and,\\tbefore\\tyou\\tknow\\tit,\\tyou’re\\tspeeding\\ttoward\\tthe\\tnext\\tbehavior.\\tIt\\tseems\\tto\\nbe\\teasier\\tto\\tcontinue\\twhat\\tyou\\tare\\talready\\tdoing\\tthan\\tto\\tstart\\tdoing\\tsomething\\ndifferent.\\tYou\\tsit\\tthrough\\ta\\tbad\\tmovie\\tfor\\ttwo\\thours.\\tYou\\tkeep\\tsnacking\\teven\\nwhen\\tyou’re\\talready\\tfull.\\tYou\\tcheck\\tyour\\tphone\\tfor\\t“just\\ta\\tsecond”\\tand\\tsoon\\nyou\\thave\\tspent\\ttwenty\\tminutes\\tstaring\\tat\\tthe\\tscreen.\\tIn\\tthis\\tway,\\tthe\\t\\nhabits\\tyou\\nfollow\\twithout\\tthinking\\toften\\tdetermine\\tthe\\tchoices\\tyou\\tmake\\twhen\\tyou\\tare\\nthinking.\\nEach\\tevening,\\tthere\\tis\\ta\\ttiny\\tmoment—usually\\taround\\t5:15\\tp.m.—that\\tshapes\\nthe\\trest\\tof\\tmy\\tnight.\\tMy\\twife\\twalks\\tin\\tthe\\tdoor\\tfrom\\twork\\tand\\teither\\twe\\tchange\\ninto\\tour\\tworkout\\tclothes\\tand\\thead\\tto\\tthe\\tgym\\tor\\twe\\tcrash\\tonto\\tthe\\tcouch,\\torder\\nIndian\\tfood,\\tand\\twatch\\t\\nThe\\tOffice\\n.\\n*\\n\\tSimilar\\tto\\tTwyla\\tTharp\\thailing\\tthe\\tcab,\\tthe\\nritual\\tis\\tchanging\\tinto\\tmy\\tworkout\\tclothes.\\tIf\\tI\\tchange\\tclothes,\\tI\\tknow\\tthe\\nworkout\\twill\\thappen.\\tEverything\\tthat\\tfollows—driving\\tto\\tthe\\tgym,\\tdeciding\\nwhich\\texercises\\tto\\tdo,\\tstepping\\tunder\\tthe\\tbar—is\\teasy\\tonce\\tI’ve\\ttaken\\tthe\\tfirst\\nstep.\\nEvery\\tday,\\tthere\\tare\\ta\\thandful\\tof\\tmoments\\tthat\\tdeliver\\tan\\toutsized\\timpact.\\tI\\nrefer\\tto\\tthese\\tlittle\\tchoices\\tas\\t\\ndecisive\\tmoments\\n.\\tThe\\tmoment\\tyou\\tdecide\\nbetween\\tordering\\ttakeout\\tor\\tcooking\\tdinner.\\tThe\\tmoment\\tyou\\tchoose\\tbetween\\ndriving\\tyour\\tcar\\tor\\triding\\tyour\\tbike.\\tThe\\tmoment\\tyou\\tdecide\\tbetween\\tstarting\\nyour\\thomework\\tor\\tgrabbing\\tthe\\tvideo\\tgame\\tcontroller.\\tThese\\tchoices\\tare\\ta\\tfork\\nin\\tthe\\troad.\\nDECISIVE\\tMOMENTS', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 127}), Document(page_content='FIGURE\\t14:\\tThe\\tdifference\\tbetween\\ta\\tgood\\tday\\tand\\ta\\tbad\\tday\\tis\\toften\\ta\\tfew\\tproductive\\tand\\thealthy\\tchoices\\tmade\\tat\\tdecisive\\tmoments.\\tEach\\tone\\tis\\tlike\\ta\\tfork\\tin\\tthe\\troad,\\tand\\tthese\\tchoices\\nstack\\tup\\tthroughout\\tthe\\tday\\tand\\tcan\\tultimately\\tlead\\tto\\tvery\\tdifferent\\toutcomes.\\nDecisive\\tmoments\\tset\\tthe\\toptions\\tavailable\\tto\\tyour\\tfuture\\tself.\\tFor\\t\\ninstance,\\nwalking\\tinto\\ta\\trestaurant\\tis\\ta\\tdecisive\\tmoment\\tbecause\\tit\\tdetermines\\twhat\\tyou’ll\\nbe\\teating\\tfor\\tlunch.\\tTechnically,\\tyou\\tare\\tin\\tcontrol\\tof\\twhat\\tyou\\torder,\\tbut\\tin\\ta\\nlarger\\tsense,\\tyou\\tcan\\tonly\\torder\\tan\\titem\\tif\\tit\\tis\\ton\\tthe\\tmenu.\\tIf\\tyou\\twalk\\tinto\\ta\\nsteakhouse,\\tyou\\tcan\\tget\\ta\\tsirloin\\tor\\ta\\trib\\teye,\\tbut\\tnot\\tsushi.\\tYour\\toptions\\tare\\nconstrained\\tby\\twhat’s\\tavailable.\\tThey\\tare\\tshaped\\tby\\tthe\\tfirst\\tchoice.\\nWe\\tare\\tlimited\\tby\\twhere\\tour\\thabits\\tlead\\tus.\\tThis\\tis\\twhy\\tmastering\\tthe\\ndecisive\\tmoments\\tthroughout\\tyour\\tday\\tis\\tso\\timportant.\\tEach\\tday\\tis\\tmade\\tup\\tof\\nmany\\tmoments,\\tbut\\tit\\tis\\treally\\ta\\tfew\\thabitual\\tchoices\\tthat\\tdetermine\\tthe\\tpath\\nyou\\ttake.\\tThese\\tlittle\\tchoices\\tstack\\tup,\\teach\\tone\\tsetting\\tthe\\ttrajectory\\tfor\\thow\\nyou\\tspend\\tthe\\tnext\\tchunk\\tof\\ttime.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 128}), Document(page_content='Habits\\tare\\tthe\\tentry\\tpoint,\\tnot\\tthe\\tend\\tpoint.\\tThey\\tare\\tthe\\tcab,\\tnot\\tthe\\tgym.\\nTHE\\tTWO-MINUTE\\tRULE\\nEven\\twhen\\tyou\\tknow\\tyou\\tshould\\tstart\\tsmall,\\tit’s\\teasy\\tto\\tstart\\ttoo\\tbig.\\tWhen\\tyou\\ndream\\tabout\\tmaking\\ta\\tchange,\\texcitement\\tinevitably\\ttakes\\tover\\tand\\tyou\\tend\\tup\\ntrying\\tto\\tdo\\ttoo\\tmuch\\ttoo\\tsoon.\\tThe\\tmost\\teffective\\tway\\tI\\tknow\\tto\\tcounteract\\tthis\\ntendency\\tis\\tto\\tuse\\tthe\\n\\tTwo-Minute\\tRule\\n,\\twhich\\tstates,\\t“When\\tyou\\tstart\\ta\\tnew\\nhabit,\\tit\\tshould\\ttake\\tless\\tthan\\ttwo\\tminutes\\tto\\tdo.”\\nYou’ll\\tfind\\tthat\\tnearly\\tany\\thabit\\tcan\\tbe\\tscaled\\tdown\\tinto\\ta\\ttwo-minute\\nversion:\\n“Read\\tbefore\\tbed\\teach\\tnight”\\tbecomes\\t“Read\\tone\\tpage.”\\n“Do\\tthirty\\tminutes\\tof\\tyoga”\\tbecomes\\t“Take\\tout\\tmy\\tyoga\\tmat.”\\n“Study\\tfor\\tclass”\\tbecomes\\t“Open\\tmy\\tnotes.”\\n“Fold\\tthe\\tlaundry”\\tbecomes\\t“Fold\\tone\\tpair\\tof\\tsocks.”\\n“Run\\tthree\\tmiles”\\tbecomes\\t“Tie\\tmy\\trunning\\tshoes.”\\nThe\\tidea\\tis\\tto\\tmake\\tyour\\thabits\\tas\\teasy\\tas\\tpossible\\tto\\tstart.\\tAnyone\\tcan\\nmeditate\\tfor\\tone\\tminute,\\tread\\tone\\tpage,\\tor\\tput\\tone\\titem\\tof\\tclothing\\taway.\\tAnd,\\nas\\twe\\thave\\tjust\\tdiscussed,\\tthis\\tis\\ta\\tpowerful\\tstrategy\\tbecause\\tonce\\tyou’ve\\tstarted\\ndoing\\tthe\\tright\\tthing,\\tit\\tis\\tmuch\\teasier\\tto\\tcontinue\\tdoing\\tit.\\tA\\tnew\\thabit\\tshould\\nnot\\tfeel\\tlike\\ta\\tchallenge.\\tThe\\tactions\\tthat\\t\\nfollow\\n\\tcan\\tbe\\tchallenging,\\tbut\\tthe\\tfirst\\ntwo\\tminutes\\tshould\\tbe\\teasy.\\tWhat\\tyou\\twant\\tis\\ta\\t“gateway\\thabit”\\tthat\\tnaturally\\nleads\\tyou\\tdown\\ta\\tmore\\tproductive\\tpath.\\nYou\\tcan\\tusually\\tfigure\\tout\\tthe\\tgateway\\thabits\\tthat\\twill\\tlead\\tto\\tyour\\tdesired\\noutcome\\tby\\tmapping\\tout\\tyour\\tgoals\\ton\\ta\\tscale\\tfrom\\t“very\\teasy”\\tto\\t“very\\thard.”\\nFor\\tinstance,\\trunning\\ta\\tmarathon\\tis\\tvery\\thard.\\tRunning\\ta\\t5K\\tis\\thard.\\tWalking\\nten\\tthousand\\tsteps\\tis\\tmoderately\\tdifficult.\\tWalking\\tten\\tminutes\\tis\\teasy.\\tAnd\\nputting\\ton\\tyour\\trunning\\tshoes\\tis\\tvery\\teasy.\\tYour\\tgoal\\tmight\\tbe\\tto\\trun\\ta\\nmarathon,\\tbut\\tyour\\tgateway\\thabit\\tis\\tto\\tput\\ton\\tyour\\trunning\\tshoes.\\tThat’s\\thow\\nyou\\tfollow\\tthe\\tTwo-Minute\\tRule.\\nVery\\teasy\\nEasy\\nModerate\\nHard\\nVery\\thard\\nPut\\ton\\tyour\\trunning\\tshoes\\nWalk\\tten\\tminutes\\nWalk\\tten\\tthousand\\tsteps\\nRun\\ta\\t5K\\nRun\\ta\\tmarathon\\nWrite\\tone\\tsentence\\nWrite\\tone\\tparagraph\\nWrite\\tone\\tthousand\\twords\\nWrite\\ta\\tfive-thousand-word\\tarticle\\nWrite\\ta\\tbook\\nOpen\\tyour\\tnotes\\nStudy\\tfor\\tten\\tminutes\\nStudy\\tfor\\tthree\\thours\\nGet\\tstraight\\tA’s\\nEarn\\ta\\tPhD', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 129}), Document(page_content='People\\toften\\tthink\\tit’s\\tweird\\tto\\tget\\thyped\\tabout\\treading\\tone\\tpage\\tor\\nmeditating\\tfor\\tone\\tminute\\tor\\tmaking\\tone\\tsales\\tcall.\\tBut\\tthe\\tpoint\\tis\\tnot\\tto\\tdo\\tone\\nthing.\\tThe\\tpoint\\tis\\tto\\tmaster\\tthe\\thabit\\tof\\tshowing\\tup.\\tThe\\ttruth\\tis,\\ta\\thabit\\tmust\\nbe\\testablished\\tbefore\\tit\\tcan\\tbe\\timproved.\\tIf\\tyou\\t\\ncan’t\\tlearn\\tthe\\tbasic\\tskill\\tof\\nshowing\\tup,\\tthen\\tyou\\thave\\tlittle\\thope\\tof\\tmastering\\tthe\\tfiner\\tdetails.\\tInstead\\tof\\ntrying\\tto\\tengineer\\ta\\tperfect\\thabit\\tfrom\\tthe\\tstart,\\tdo\\tthe\\teasy\\tthing\\ton\\ta\\tmore\\nconsistent\\tbasis.\\tYou\\thave\\tto\\tstandardize\\tbefore\\tyou\\tcan\\toptimize.\\nAs\\tyou\\tmaster\\tthe\\tart\\tof\\tshowing\\tup,\\tthe\\tfirst\\ttwo\\tminutes\\tsimply\\tbecome\\ta\\nritual\\tat\\tthe\\tbeginning\\tof\\ta\\tlarger\\troutine.\\tThis\\tis\\tnot\\tmerely\\ta\\thack\\tto\\tmake\\nhabits\\teasier\\tbut\\tactually\\tthe\\tideal\\tway\\tto\\tmaster\\ta\\tdifficult\\tskill.\\tThe\\tmore\\tyou\\nritualize\\tthe\\tbeginning\\tof\\ta\\tprocess,\\tthe\\tmore\\tlikely\\tit\\tbecomes\\tthat\\tyou\\tcan\\tslip\\ninto\\tthe\\tstate\\tof\\tdeep\\tfocus\\tthat\\tis\\trequired\\tto\\tdo\\tgreat\\tthings.\\tBy\\tdoing\\tthe\\tsame\\nwarm-up\\tbefore\\tevery\\tworkout,\\tyou\\tmake\\tit\\teasier\\tto\\tget\\tinto\\ta\\tstate\\tof\\tpeak\\nperformance.\\tBy\\tfollowing\\tthe\\tsame\\tcreative\\tritual,\\tyou\\tmake\\tit\\teasier\\tto\\tget\\ninto\\tthe\\thard\\twork\\tof\\tcreating.\\tBy\\tdeveloping\\ta\\tconsistent\\t\\npower-down\\thabit,\\nyou\\tmake\\tit\\teasier\\tto\\tget\\tto\\tbed\\tat\\ta\\treasonable\\ttime\\teach\\tnight.\\tYou\\tmay\\tnot\\tbe\\nable\\tto\\tautomate\\tthe\\twhole\\tprocess,\\tbut\\tyou\\tcan\\tmake\\tthe\\tfirst\\taction\\tmindless.\\nMake\\tit\\teasy\\tto\\tstart\\tand\\tthe\\trest\\twill\\tfollow.\\nThe\\tTwo-Minute\\tRule\\tcan\\tseem\\tlike\\ta\\ttrick\\tto\\tsome\\tpeople.\\tYou\\tknow\\tthat\\nthe\\t\\nreal\\n\\tgoal\\tis\\tto\\tdo\\tmore\\tthan\\tjust\\ttwo\\tminutes,\\tso\\tit\\tmay\\tfeel\\tlike\\tyou’re\\ntrying\\tto\\tfool\\tyourself.\\tNobody\\tis\\tactually\\taspiring\\tto\\tread\\tone\\tpage\\tor\\tdo\\tone\\npush-up\\tor\\topen\\ttheir\\tnotes.\\tAnd\\tif\\tyou\\tknow\\tit’s\\ta\\tmental\\ttrick,\\twhy\\twould\\tyou\\nfall\\tfor\\tit?\\nIf\\tthe\\tTwo-Minute\\tRule\\tfeels\\tforced,\\ttry\\tthis:\\tdo\\tit\\tfor\\ttwo\\tminutes\\tand\\tthen\\nstop.\\tGo\\tfor\\ta\\trun,\\tbut\\tyou\\t\\nmust\\n\\tstop\\tafter\\ttwo\\tminutes.\\tStart\\tmeditating,\\tbut\\tyou\\nmust\\n\\tstop\\tafter\\ttwo\\tminutes.\\tStudy\\tArabic,\\tbut\\tyou\\t\\nmust\\n\\tstop\\tafter\\ttwo\\tminutes.\\nIt’s\\tnot\\ta\\tstrategy\\tfor\\tstarting,\\tit’s\\tthe\\twhole\\tthing.\\tYour\\thabit\\tcan\\t\\nonly\\n\\tlast\\tone\\nhundred\\tand\\ttwenty\\tseconds.\\nOne\\tof\\tmy\\treaders\\tused\\tthis\\tstrategy\\tto\\tlose\\tover\\tone\\thundred\\tpounds.\\tIn\\tthe\\nbeginning,\\the\\twent\\tto\\tthe\\tgym\\teach\\tday,\\tbut\\the\\ttold\\thimself\\the\\twasn’t\\tallowed\\nto\\tstay\\tfor\\tmore\\tthan\\tfive\\tminutes.\\tHe\\twould\\tgo\\tto\\tthe\\tgym,\\texercise\\tfor\\tfive\\nminutes,\\tand\\tleave\\tas\\tsoon\\tas\\this\\ttime\\twas\\tup.\\tAfter\\ta\\tfew\\tweeks,\\the\\tlooked\\naround\\tand\\tthought,\\t“Well,\\tI’m\\t\\nalways\\tcoming\\there\\tanyway.\\tI\\tmight\\tas\\twell\\nstart\\tstaying\\ta\\tlittle\\tlonger.”\\tA\\tfew\\tyears\\tlater,\\tthe\\tweight\\twas\\tgone.\\nJournaling\\tprovides\\tanother\\texample.\\tNearly\\teveryone\\tcan\\tbenefit\\tfrom\\ngetting\\ttheir\\tthoughts\\tout\\tof\\ttheir\\thead\\tand\\tonto\\tpaper,\\tbut\\tmost\\tpeople\\tgive\\tup\\nafter\\ta\\tfew\\tdays\\tor\\tavoid\\tit\\tentirely\\tbecause\\tjournaling\\tfeels\\tlike\\ta\\tchore.\\n*\\n\\tThe\\nsecret\\tis\\tto\\talways\\tstay\\tbelow\\tthe\\tpoint\\twhere\\tit\\tfeels\\tlike\\twork.\\tGreg\\nMcKeown,\\ta\\tleadership\\tconsultant\\tfrom\\tthe\\tUnited\\tKingdom,\\tbuilt\\ta\\tdaily', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 130}), Document(page_content='journaling\\thabit\\tby\\tspecifically\\twriting\\t\\nless\\n\\tthan\\the\\tfelt\\tlike.\\t\\nHe\\talways\\tstopped\\njournaling\\tbefore\\tit\\tseemed\\tlike\\ta\\thassle.\\tErnest\\tHemingway\\tbelieved\\tin\\tsimilar\\nadvice\\tfor\\tany\\tkind\\tof\\twriting.\\t“The\\tbest\\tway\\tis\\tto\\talways\\tstop\\twhen\\tyou\\tare\\ngoing\\tgood,”\\the\\tsaid.\\nStrategies\\tlike\\tthis\\twork\\tfor\\tanother\\treason,\\ttoo:\\tthey\\treinforce\\tthe\\tidentity\\nyou\\twant\\tto\\tbuild.\\tIf\\tyou\\tshow\\tup\\tat\\tthe\\tgym\\tfive\\tdays\\tin\\ta\\trow—even\\tif\\tit’s\\tjust\\nfor\\ttwo\\tminutes—you\\tare\\tcasting\\tvotes\\tfor\\tyour\\tnew\\tidentity.\\tYou’re\\tnot\\nworried\\tabout\\tgetting\\tin\\tshape.\\tYou’re\\tfocused\\ton\\tbecoming\\tthe\\ttype\\tof\\tperson\\nwho\\tdoesn’t\\tmiss\\tworkouts.\\tYou’re\\ttaking\\tthe\\tsmallest\\taction\\tthat\\tconfirms\\tthe\\ntype\\tof\\tperson\\tyou\\twant\\tto\\tbe.\\nWe\\trarely\\tthink\\tabout\\tchange\\tthis\\tway\\tbecause\\teveryone\\tis\\tconsumed\\tby\\tthe\\nend\\tgoal.\\tBut\\tone\\tpush-up\\tis\\tbetter\\tthan\\tnot\\texercising.\\tOne\\tminute\\tof\\tguitar\\npractice\\tis\\tbetter\\tthan\\tnone\\tat\\tall.\\tOne\\tminute\\tof\\treading\\tis\\tbetter\\tthan\\tnever\\npicking\\tup\\ta\\tbook.\\tIt’s\\tbetter\\tto\\tdo\\tless\\tthan\\tyou\\thoped\\tthan\\tto\\tdo\\tnothing\\tat\\tall.\\nAt\\tsome\\tpoint,\\tonce\\tyou’ve\\testablished\\tthe\\thabit\\tand\\tyou’re\\tshowing\\tup\\teach\\nday,\\tyou\\tcan\\tcombine\\tthe\\tTwo-Minute\\tRule\\twith\\ta\\ttechnique\\twe\\tcall\\t\\nhabit\\nshaping\\n\\tto\\tscale\\tyour\\thabit\\tback\\tup\\ttoward\\tyour\\tultimate\\tgoal.\\tStart\\tby\\nmastering\\tthe\\tfirst\\ttwo\\tminutes\\tof\\tthe\\tsmallest\\tversion\\tof\\t\\nthe\\tbehavior.\\tThen,\\nadvance\\tto\\tan\\tintermediate\\tstep\\tand\\trepeat\\tthe\\tprocess—focusing\\ton\\tjust\\tthe\\tfirst\\ntwo\\tminutes\\tand\\tmastering\\tthat\\tstage\\tbefore\\tmoving\\ton\\tto\\tthe\\tnext\\tlevel.\\nEventually,\\tyou’ll\\tend\\tup\\twith\\tthe\\thabit\\tyou\\thad\\toriginally\\thoped\\tto\\tbuild\\twhile\\nstill\\tkeeping\\tyour\\tfocus\\twhere\\tit\\tshould\\tbe:\\ton\\tthe\\tfirst\\ttwo\\tminutes\\tof\\tthe\\nbehavior.\\nEXAMPLES\\tOF\\tHABIT\\tSHAPING\\nBecoming\\tan\\tEarly\\tRiser\\nPhase\\t1:\\t\\nBe\\thome\\tby\\t10\\tp.m.\\tevery\\tnight.\\nPhase\\t2:\\t\\nHave\\tall\\tdevices\\t(TV,\\tphone,\\tetc.)\\tturned\\toff\\tby\\t10\\tp.m.\\tevery\\tnight.\\nPhase\\t3:\\t\\nBe\\tin\\tbed\\tby\\t10\\tp.m.\\tevery\\tnight\\t(reading\\ta\\tbook,\\ttalking\\twith\\tyour\\tpartner).\\nPhase\\t4:\\t\\nLights\\toff\\tby\\t10\\tp.m.\\tevery\\tnight.\\nPhase\\t5:\\t\\nWake\\tup\\tat\\t6\\ta.m.\\tevery\\tday.\\nBecoming\\tVegan\\nPhase\\t1:\\t\\nStart\\teating\\tvegetables\\tat\\teach\\tmeal.\\nPhase\\t2:\\t\\nStop\\teating\\tanimals\\twith\\tfour\\tlegs\\t(cow,\\tpig,\\tlamb,\\tetc.).\\nPhase\\t3:\\t\\nStop\\teating\\tanimals\\twith\\ttwo\\tlegs\\t(chicken,\\tturkey,\\tetc.).\\nPhase\\t4:\\t\\nStop\\teating\\tanimals\\twith\\tno\\tlegs\\t(fish,\\tclams,\\tscallops,\\tetc.).\\nPhase\\t5:\\t\\nStop\\teating\\tall\\tanimal\\tproducts\\t(eggs,\\tmilk,\\tcheese).', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 131}), Document(page_content='Starting\\tto\\tExercise\\nPhase\\t1:\\t\\nChange\\tinto\\tworkout\\tclothes.\\nPhase\\t2:\\t\\nStep\\tout\\tthe\\tdoor\\t(try\\ttaking\\ta\\twalk).\\nPhase\\t3:\\t\\nDrive\\tto\\tthe\\tgym,\\texercise\\tfor\\tfive\\tminutes,\\tand\\tleave.\\nPhase\\t4:\\t\\nExercise\\tfor\\tfifteen\\tminutes\\tat\\tleast\\tonce\\tper\\tweek.\\nPhase\\t5:\\t\\nExercise\\tthree\\ttimes\\tper\\tweek.\\nNearly\\tany\\tlarger\\tlife\\tgoal\\tcan\\tbe\\ttransformed\\tinto\\ta\\ttwo-minute\\tbehavior.\\tI\\nwant\\tto\\tlive\\ta\\thealthy\\tand\\tlong\\tlife\\t>\\tI\\tneed\\tto\\tstay\\tin\\tshape\\t>\\tI\\tneed\\tto\\texercise\\n>\\tI\\tneed\\tto\\tchange\\tinto\\tmy\\tworkout\\tclothes.\\tI\\twant\\tto\\thave\\ta\\thappy\\tmarriage\\t>\\tI\\nneed\\tto\\tbe\\ta\\tgood\\tpartner\\t>\\tI\\tshould\\tdo\\tsomething\\teach\\tday\\tto\\tmake\\tmy\\npartner’s\\tlife\\teasier\\t>\\tI\\tshould\\tmeal\\tplan\\tfor\\tnext\\tweek.\\nWhenever\\tyou\\tare\\tstruggling\\tto\\tstick\\twith\\ta\\thabit,\\tyou\\tcan\\temploy\\tthe\\tTwo-\\nMinute\\tRule.\\tIt’s\\ta\\tsimple\\tway\\tto\\tmake\\tyour\\thabits\\teasy.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 132}), Document(page_content='Chapter\\tSummary\\nHabits\\tcan\\tbe\\tcompleted\\tin\\ta\\tfew\\tseconds\\tbut\\tcontinue\\tto\\timpact\\tyour\\nbehavior\\tfor\\tminutes\\tor\\thours\\tafterward.\\nMany\\thabits\\toccur\\tat\\tdecisive\\tmoments—choices\\tthat\\tare\\tlike\\ta\\tfork\\tin\\nthe\\troad—and\\teither\\tsend\\tyou\\tin\\tthe\\tdirection\\tof\\ta\\tproductive\\tday\\tor\\nan\\tunproductive\\tone.\\nThe\\tTwo-Minute\\tRule\\tstates,\\t“When\\tyou\\tstart\\ta\\tnew\\thabit,\\tit\\tshould\\ntake\\tless\\tthan\\ttwo\\tminutes\\tto\\tdo.”\\nThe\\tmore\\tyou\\tritualize\\tthe\\tbeginning\\tof\\ta\\tprocess,\\tthe\\tmore\\tlikely\\tit\\nbecomes\\tthat\\tyou\\tcan\\tslip\\tinto\\tthe\\tstate\\tof\\tdeep\\tfocus\\tthat\\tis\\trequired\\nto\\tdo\\tgreat\\tthings.\\nStandardize\\tbefore\\tyou\\toptimize.\\tYou\\tcan’t\\timprove\\ta\\thabit\\tthat\\ndoesn’t\\texist.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 133}), Document(page_content='14\\nHow\\tto\\tMake\\tGood\\tHabits\\tInevitable\\tand\\tBad\\nHabits\\tImpossible\\nI\\nN\\tTHE\\tSUMMER\\tOF\\t1830,\\t\\nVictor\\tHugo\\twas\\tfacing\\tan\\timpossible\\tdeadline.\\tTwelve\\tmonths\\nearlier,\\tthe\\tFrench\\tauthor\\thad\\tpromised\\this\\tpublisher\\ta\\tnew\\tbook.\\tBut\\tinstead\\tof\\nwriting,\\the\\tspent\\tthat\\tyear\\tpursuing\\tother\\tprojects,\\tentertaining\\tguests,\\tand\\ndelaying\\this\\twork.\\tFrustrated,\\tHugo’s\\tpublisher\\tresponded\\tby\\tsetting\\ta\\tdeadline\\nless\\tthan\\tsix\\tmonths\\taway.\\tThe\\tbook\\thad\\tto\\tbe\\tfinished\\tby\\tFebruary\\t1831.\\nHugo\\tconcocted\\ta\\tstrange\\tplan\\tto\\tbeat\\this\\tprocrastination.\\tHe\\tcollected\\tall\\tof\\nhis\\tclothes\\tand\\tasked\\tan\\tassistant\\tto\\tlock\\tthem\\taway\\tin\\ta\\tlarge\\tchest.\\tHe\\twas\\tleft\\nwith\\tnothing\\tto\\twear\\texcept\\ta\\tlarge\\tshawl.\\tLacking\\tany\\tsuitable\\tclothing\\tto\\tgo\\noutdoors,\\t\\nhe\\tremained\\tin\\this\\tstudy\\tand\\twrote\\tfuriously\\tduring\\tthe\\tfall\\tand\\twinter\\nof\\t1830.\\t\\nThe\\tHunchback\\tof\\tNotre\\tDame\\n\\twas\\tpublished\\ttwo\\tweeks\\tearly\\ton\\nJanuary\\t14,\\t1831.\\n*\\nSometimes\\tsuccess\\tis\\tless\\tabout\\tmaking\\tgood\\thabits\\teasy\\tand\\tmore\\tabout\\nmaking\\tbad\\thabits\\thard.\\tThis\\tis\\tan\\tinversion\\tof\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange:\\nmake\\tit\\tdifficult\\n.\\tIf\\tyou\\tfind\\tyourself\\tcontinually\\t\\nstruggling\\tto\\tfollow\\tthrough\\ton\\nyour\\tplans,\\tthen\\tyou\\tcan\\ttake\\ta\\tpage\\tfrom\\tVictor\\tHugo\\tand\\tmake\\tyour\\tbad\\nhabits\\tmore\\tdifficult\\tby\\tcreating\\twhat\\tpsychologists\\tcall\\ta\\t\\ncommitment\\tdevice\\n.\\nA\\tcommitment\\tdevice\\tis\\ta\\tchoice\\tyou\\tmake\\tin\\tthe\\tpresent\\tthat\\tcontrols\\tyour\\nactions\\tin\\tthe\\tfuture.\\tIt\\tis\\ta\\tway\\tto\\tlock\\tin\\tfuture\\tbehavior,\\tbind\\tyou\\tto\\tgood\\nhabits,\\tand\\trestrict\\tyou\\tfrom\\tbad\\tones.\\tWhen\\tVictor\\tHugo\\tshut\\this\\tclothes\\taway\\nso\\the\\tcould\\tfocus\\ton\\twriting,\\the\\twas\\tcreating\\ta\\tcommitment\\tdevice.\\n*\\nThere\\tare\\tmany\\tways\\tto\\tcreate\\ta\\tcommitment\\tdevice.\\tYou\\tcan\\treduce\\novereating\\tby\\tpurchasing\\tfood\\tin\\tindividual\\tpackages\\trather\\tthan\\tin\\tbulk\\tsize.\\nYou\\tcan\\tvoluntarily\\task\\tto\\tbe\\tadded\\tto\\tthe\\tbanned\\tlist\\tat\\tcasinos\\tand\\tonline\\npoker\\tsites\\tto\\tprevent\\tfuture\\tgambling\\tsprees.\\tI’ve\\teven\\theard\\tof\\tathletes\\twho\\nhave\\tto\\t“make\\tweight”\\tfor\\ta\\tcompetition\\tchoosing\\tto\\tleave\\ttheir\\twallets\\tat\\thome\\nduring\\tthe\\tweek\\tbefore\\tweigh-in\\tso\\tthey\\twon’t\\tbe\\ttempted\\tto\\tbuy\\tfast\\tfood.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 134}), Document(page_content='As\\tanother\\texample,\\tmy\\tfriend\\tand\\tfellow\\thabits\\texpert\\tNir\\tEyal\\tpurchased\\tan\\noutlet\\ttimer,\\twhich\\tis\\tan\\tadapter\\tthat\\the\\tplugged\\tin\\tbetween\\this\\tinternet\\trouter\\nand\\tthe\\tpower\\toutlet.\\tAt\\t10\\tp.m.\\teach\\tnight,\\tthe\\t\\noutlet\\ttimer\\tcuts\\toff\\tthe\\tpower\\tto\\nthe\\trouter.\\tWhen\\tthe\\tinternet\\tgoes\\toff,\\teveryone\\tknows\\tit\\tis\\ttime\\tto\\tgo\\tto\\tbed.\\nCommitment\\tdevices\\tare\\tuseful\\tbecause\\tthey\\tenable\\tyou\\tto\\ttake\\tadvantage\\tof\\ngood\\tintentions\\tbefore\\tyou\\tcan\\tfall\\tvictim\\tto\\ttemptation.\\tWhenever\\tI’m\\tlooking\\nto\\tcut\\tcalories,\\tfor\\texample,\\tI\\twill\\task\\tthe\\twaiter\\tto\\tsplit\\tmy\\tmeal\\tand\\tbox\\thalf\\tof\\nit\\tto\\tgo\\t\\nbefore\\n\\tthe\\tmeal\\tis\\tserved.\\tIf\\tI\\twaited\\tuntil\\tthe\\tmeal\\tcame\\tout\\tand\\ttold\\nmyself\\t“I’ll\\tjust\\teat\\thalf,”\\tit\\twould\\tnever\\twork.\\nThe\\tkey\\tis\\tto\\tchange\\tthe\\ttask\\tsuch\\tthat\\tit\\trequires\\tmore\\twork\\tto\\tget\\t\\nout\\n\\tof\\tthe\\ngood\\thabit\\tthan\\tto\\tget\\tstarted\\ton\\tit.\\tIf\\tyou’re\\tfeeling\\tmotivated\\tto\\tget\\tin\\tshape,\\nschedule\\ta\\tyoga\\tsession\\tand\\tpay\\tahead\\tof\\ttime.\\tIf\\tyou’re\\texcited\\tabout\\tthe\\nbusiness\\tyou\\twant\\tto\\tstart,\\temail\\tan\\tentrepreneur\\tyou\\trespect\\tand\\tset\\tup\\ta\\nconsulting\\tcall.\\tWhen\\tthe\\ttime\\tcomes\\tto\\tact,\\tthe\\tonly\\tway\\tto\\tbail\\tis\\tto\\tcancel\\tthe\\nmeeting,\\twhich\\trequires\\teffort\\tand\\tmay\\tcost\\tmoney.\\nCommitment\\tdevices\\tincrease\\tthe\\todds\\tthat\\tyou’ll\\tdo\\tthe\\tright\\tthing\\tin\\tthe\\nfuture\\tby\\tmaking\\tbad\\thabits\\tdifficult\\tin\\tthe\\tpresent.\\tHowever,\\twe\\tcan\\tdo\\teven\\nbetter.\\tWe\\tcan\\tmake\\tgood\\thabits\\tinevitable\\tand\\tbad\\thabits\\timpossible.\\nHOW\\tTO\\tAUTOMATE\\tA\\tHABIT\\tAND\\tNEVER\\tTHINK\\tABOUT\\tIT\\nAGAIN\\nJohn\\tHenry\\tPatterson\\twas\\tborn\\tin\\tDayton,\\tOhio,\\tin\\t1844.\\tHe\\tspent\\this\\tchildhood\\ndoing\\tchores\\ton\\tthe\\tfamily\\tfarm\\tand\\tworking\\tshifts\\tat\\this\\tfather’s\\tsawmill.\\tAfter\\nattending\\tcollege\\tat\\tDartmouth,\\tPatterson\\treturned\\tto\\tOhio\\tand\\topened\\ta\\tsmall\\nsupply\\tstore\\tfor\\tcoal\\tminers.\\nIt\\tseemed\\tlike\\ta\\tgood\\topportunity.\\tThe\\tstore\\tfaced\\tlittle\\tcompetition\\tand\\nenjoyed\\ta\\tsteady\\tstream\\tof\\tcustomers,\\tbut\\tstill\\tstruggled\\tto\\tmake\\tmoney.\\tThat\\nwas\\twhen\\tPatterson\\tdiscovered\\this\\temployees\\twere\\tstealing\\tfrom\\thim.\\nIn\\tthe\\tmid-1800s,\\temployee\\ttheft\\twas\\ta\\tcommon\\tproblem.\\tReceipts\\twere\\tkept\\nin\\tan\\topen\\tdrawer\\tand\\tcould\\teasily\\tbe\\taltered\\tor\\tdiscarded.\\tThere\\twere\\tno\\tvideo\\ncameras\\tto\\treview\\tbehavior\\tand\\tno\\tsoftware\\tto\\ttrack\\ttransactions.\\tUnless\\tyou\\nwere\\twilling\\tto\\thover\\tover\\tyour\\temployees\\tevery\\tminute\\tof\\tthe\\tday,\\tor\\tto\\nmanage\\tall\\ttransactions\\tyourself,\\tit\\twas\\tdifficult\\tto\\tprevent\\ttheft.\\nAs\\tPatterson\\tmulled\\tover\\this\\tpredicament,\\the\\tcame\\tacross\\tan\\tadvertisement\\nfor\\ta\\tnew\\tinvention\\tcalled\\tRitty’s\\tIncorruptible\\tCashier.\\t\\nDesigned\\tby\\tfellow\\nDayton\\tresident\\tJames\\tRitty,\\tit\\twas\\tthe\\tfirst\\tcash\\tregister.\\tThe\\tmachine\\nautomatically\\tlocked\\tthe\\tcash\\tand\\treceipts\\tinside\\tafter\\teach\\ttransaction.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 135}), Document(page_content='Patterson\\tbought\\ttwo\\tfor\\tfifty\\tdollars\\teach.\\nEmployee\\ttheft\\tat\\this\\tstore\\tvanished\\tovernight.\\tIn\\tthe\\tnext\\tsix\\tmonths,\\nPatterson’s\\tbusiness\\twent\\tfrom\\tlosing\\tmoney\\tto\\tmaking\\t$5,000\\tin\\tprofit—the\\nequivalent\\tof\\tmore\\tthan\\t$100,000\\ttoday.\\nPatterson\\twas\\tso\\timpressed\\twith\\tthe\\tmachine\\tthat\\the\\tchanged\\tbusinesses.\\tHe\\nbought\\tthe\\trights\\tto\\tRitty’s\\tinvention\\tand\\topened\\tthe\\tNational\\tCash\\tRegister\\nCompany.\\tTen\\tyears\\tlater,\\tNational\\tCash\\tRegister\\thad\\tover\\tone\\tthousand\\nemployees\\tand\\twas\\ton\\tits\\tway\\tto\\tbecoming\\tone\\tof\\tthe\\tmost\\tsuccessful\\nbusinesses\\tof\\tits\\ttime.\\nThe\\tbest\\tway\\tto\\tbreak\\ta\\tbad\\thabit\\tis\\tto\\tmake\\tit\\timpractical\\tto\\tdo.\\tIncrease\\tthe\\nfriction\\tuntil\\tyou\\tdon’t\\teven\\thave\\tthe\\toption\\tto\\tact.\\tThe\\tbrilliance\\tof\\tthe\\tcash\\nregister\\twas\\tthat\\tit\\tautomated\\tethical\\tbehavior\\tby\\tmaking\\tstealing\\tpractically\\nimpossible.\\tRather\\tthan\\ttrying\\tto\\tchange\\tthe\\temployees,\\tit\\tmade\\tthe\\tpreferred\\nbehavior\\tautomatic.\\nSome\\tactions—like\\tinstalling\\ta\\tcash\\tregister—pay\\toff\\tagain\\tand\\tagain.\\tThese\\nonetime\\tchoices\\trequire\\ta\\tlittle\\tbit\\tof\\teffort\\tup\\tfront\\tbut\\tcreate\\tincreasing\\tvalue\\nover\\ttime.\\tI’m\\tfascinated\\tby\\tthe\\tidea\\tthat\\ta\\tsingle\\tchoice\\tcan\\tdeliver\\treturns\\nagain\\tand\\tagain,\\tand\\tI\\tsurveyed\\tmy\\treaders\\ton\\ttheir\\tfavorite\\t\\nonetime\\tactions\\tthat\\nlead\\tto\\tbetter\\tlong-term\\thabits.\\tThe\\ttable\\ton\\tthe\\tfollowing\\tpage\\tshares\\tsome\\tof\\nthe\\tmost\\tpopular\\tanswers.\\nI’d\\twager\\tthat\\tif\\tthe\\taverage\\tperson\\twere\\tto\\tsimply\\tdo\\thalf\\tof\\tthe\\tonetime\\nactions\\ton\\tthis\\tlist—even\\tif\\tthey\\tdidn’t\\tgive\\tanother\\tthought\\tto\\ttheir\\thabits—\\nmost\\twould\\tfind\\tthemselves\\tliving\\ta\\tbetter\\tlife\\ta\\tyear\\tfrom\\tnow.\\tThese\\tonetime\\nactions\\tare\\ta\\tstraightforward\\tway\\tto\\temploy\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange.\\nThey\\tmake\\tit\\teasier\\tto\\tsleep\\twell,\\teat\\thealthy,\\tbe\\tproductive,\\tsave\\tmoney,\\tand\\ngenerally\\tlive\\tbetter.\\nONETIME\\tACTIONS\\tTHAT\\tLOCK\\tIN\\tGOOD\\tHABITS\\nNutrition\\nBuy\\ta\\twater\\tfilter\\tto\\tclean\\tyour\\tdrinking\\twater.\\nUse\\tsmaller\\tplates\\tto\\treduce\\tcaloric\\tintake.\\nSleep\\nBuy\\ta\\tgood\\tmattress.\\nGet\\tblackout\\tcurtains.\\nRemove\\tyour\\ttelevision\\tfrom\\tyour\\tbedroom.\\nProductivity\\nUnsubscribe\\tfrom\\temails.\\nTurn\\toff\\tnotifications\\tand\\tmute\\tgroup\\tchats.\\nSet\\tyour\\tphone\\tto\\tsilent.\\nUse\\temail\\tfilters\\tto\\tclear\\tup\\tyour\\tinbox.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 136}), Document(page_content='Delete\\tgames\\tand\\tsocial\\tmedia\\tapps\\ton\\tyour\\tphone.\\nHappiness\\nGet\\ta\\tdog.\\nMove\\tto\\ta\\tfriendly,\\tsocial\\tneighborhood.\\nGeneral\\tHealth\\nGet\\tvaccinated.\\nBuy\\tgood\\tshoes\\tto\\tavoid\\tback\\tpain.\\nBuy\\ta\\tsupportive\\tchair\\tor\\tstanding\\tdesk.\\nFinance\\nEnroll\\tin\\tan\\tautomatic\\tsavings\\tplan.\\nSet\\tup\\tautomatic\\tbill\\tpay.\\nCut\\tcable\\tservice.\\nAsk\\tservice\\tproviders\\tto\\tlower\\tyour\\tbills.\\nOf\\tcourse,\\tthere\\tare\\tmany\\tways\\tto\\tautomate\\tgood\\thabits\\tand\\teliminate\\tbad\\nones.\\tTypically,\\tthey\\tinvolve\\tputting\\ttechnology\\tto\\twork\\tfor\\tyou.\\tTechnology\\ncan\\ttransform\\tactions\\tthat\\twere\\tonce\\thard,\\tannoying,\\tand\\tcomplicated\\tinto\\nbehaviors\\tthat\\tare\\teasy,\\tpainless,\\tand\\tsimple.\\tIt\\tis\\tthe\\tmost\\treliable\\tand\\teffective\\nway\\tto\\tguarantee\\tthe\\tright\\tbehavior.\\nThis\\tis\\tparticularly\\tuseful\\tfor\\tbehaviors\\tthat\\thappen\\ttoo\\tinfrequently\\tto\\nbecome\\thabitual.\\tThings\\tyou\\thave\\tto\\tdo\\tmonthly\\tor\\tyearly—like\\trebalancing\\nyour\\tinvestment\\tportfolio—are\\tnever\\trepeated\\tfrequently\\tenough\\tto\\tbecome\\ta\\nhabit,\\tso\\tthey\\tbenefit\\tin\\tparticular\\tfrom\\ttechnology\\t“remembering”\\tto\\tdo\\tthem\\nfor\\tyou.\\nOther\\texamples\\tinclude:\\nMedicine:\\tPrescriptions\\tcan\\tbe\\tautomatically\\trefilled.\\nPersonal\\tfinance:\\tEmployees\\tcan\\tsave\\tfor\\tretirement\\twith\\tan\\tautomatic\\nwage\\tdeduction.\\nCooking:\\tMeal-delivery\\tservices\\tcan\\tdo\\tyour\\tgrocery\\tshopping.\\nProductivity:\\tSocial\\tmedia\\tbrowsing\\tcan\\tbe\\tcut\\toff\\twith\\ta\\twebsite\\nblocker.\\nWhen\\tyou\\tautomate\\tas\\tmuch\\tof\\tyour\\tlife\\tas\\tpossible,\\tyou\\tcan\\tspend\\tyour\\neffort\\ton\\tthe\\ttasks\\tmachines\\tcannot\\tdo\\tyet.\\tEach\\thabit\\tthat\\twe\\thand\\tover\\tto\\tthe\\nauthority\\tof\\ttechnology\\tfrees\\tup\\ttime\\tand\\tenergy\\tto\\tpour\\tinto\\tthe\\tnext\\tstage\\tof\\ngrowth.\\tAs\\tmathematician\\tand\\tphilosopher\\tAlfred\\tNorth\\tWhitehead\\twrote,\\n“\\nCivilization\\tadvances\\tby\\textending\\tthe\\tnumber\\tof\\toperations\\twe\\tcan\\tperform\\nwithout\\tthinking\\tabout\\tthem.”', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 137}), Document(page_content='Of\\tcourse,\\tthe\\tpower\\tof\\ttechnology\\tcan\\twork\\tagainst\\tus\\tas\\twell.\\tBinge-\\nwatching\\tbecomes\\ta\\thabit\\tbecause\\tyou\\thave\\tto\\tput\\tmore\\teffort\\tin\\tto\\t\\nstop\\n\\tlooking\\nat\\tthe\\tscreen\\tthan\\tto\\tcontinue\\tdoing\\tso.\\tInstead\\tof\\tpressing\\ta\\tbutton\\tto\\tadvance\\tto\\nthe\\tnext\\tepisode,\\tNetflix\\tor\\tYouTube\\twill\\tautoplay\\tit\\tfor\\tyou.\\tAll\\tyou\\thave\\tto\\tdo\\nis\\tkeep\\tyour\\teyes\\topen.\\nTechnology\\tcreates\\ta\\tlevel\\tof\\tconvenience\\tthat\\tenables\\tyou\\tto\\tact\\ton\\tyour\\nsmallest\\twhims\\tand\\tdesires.\\tAt\\tthe\\tmere\\tsuggestion\\tof\\thunger,\\tyou\\tcan\\thave\\nfood\\tdelivered\\tto\\tyour\\tdoor.\\tAt\\tthe\\tslightest\\thint\\tof\\tboredom,\\tyou\\tcan\\tget\\tlost\\tin\\nthe\\tvast\\texpanse\\tof\\tsocial\\tmedia.\\tWhen\\tthe\\teffort\\trequired\\tto\\tact\\ton\\tyour\\tdesires\\nbecomes\\teffectively\\tzero,\\tyou\\tcan\\tfind\\tyourself\\tslipping\\tinto\\twhatever\\timpulse\\narises\\tat\\tthe\\tmoment.\\tThe\\tdownside\\tof\\tautomation\\tis\\tthat\\twe\\tcan\\tfind\\tourselves\\njumping\\tfrom\\teasy\\ttask\\tto\\teasy\\ttask\\twithout\\tmaking\\ttime\\tfor\\tmore\\tdifficult,\\tbut\\nultimately\\tmore\\trewarding,\\twork.\\nI\\toften\\tfind\\tmyself\\tgravitating\\ttoward\\tsocial\\tmedia\\tduring\\tany\\t\\ndowntime.\\tIf\\tI\\nfeel\\tbored\\tfor\\tjust\\ta\\tfraction\\tof\\ta\\tsecond,\\tI\\treach\\tfor\\tmy\\tphone.\\tIt’s\\teasy\\tto\\twrite\\noff\\tthese\\tminor\\tdistractions\\tas\\t“just\\ttaking\\ta\\tbreak,”\\tbut\\tover\\ttime\\tthey\\tcan\\naccumulate\\tinto\\ta\\tserious\\tissue.\\tThe\\tconstant\\ttug\\tof\\t“just\\tone\\tmore\\tminute”\\tcan\\nprevent\\tme\\tfrom\\tdoing\\tanything\\tof\\tconsequence.\\t(I’m\\tnot\\tthe\\tonly\\tone.\\t\\nThe\\naverage\\tperson\\tspends\\tover\\ttwo\\thours\\tper\\tday\\ton\\tsocial\\tmedia.\\tWhat\\tcould\\tyou\\ndo\\twith\\tan\\textra\\tsix\\thundred\\thours\\tper\\tyear?)\\nDuring\\tthe\\tyear\\tI\\twas\\twriting\\tthis\\tbook,\\tI\\texperimented\\twith\\ta\\tnew\\ttime\\nmanagement\\tstrategy.\\tEvery\\tMonday,\\tmy\\tassistant\\twould\\treset\\tthe\\tpasswords\\ton\\nall\\tmy\\tsocial\\tmedia\\taccounts,\\twhich\\tlogged\\tme\\tout\\ton\\teach\\tdevice.\\tAll\\tweek\\tI\\nworked\\twithout\\tdistraction.\\tOn\\tFriday,\\tshe\\twould\\tsend\\tme\\tthe\\tnew\\tpasswords.\\tI\\nhad\\tthe\\tentire\\tweekend\\tto\\tenjoy\\twhat\\tsocial\\tmedia\\thad\\tto\\toffer\\tuntil\\tMonday\\nmorning\\twhen\\tshe\\twould\\tdo\\tit\\tagain.\\t(If\\tyou\\tdon’t\\thave\\tan\\tassistant,\\tteam\\tup\\nwith\\ta\\tfriend\\tor\\tfamily\\tmember\\tand\\treset\\teach\\tother’s\\tpasswords\\teach\\tweek.)\\nOne\\tof\\tthe\\tbiggest\\tsurprises\\twas\\thow\\tquickly\\tI\\tadapted.\\tWithin\\tthe\\tfirst\\tweek\\nof\\tlocking\\tmyself\\tout\\tof\\tsocial\\tmedia,\\tI\\trealized\\tthat\\tI\\tdidn’t\\tneed\\tto\\tcheck\\tit\\nnearly\\tas\\toften\\tas\\tI\\thad\\tbeen,\\tand\\tI\\tcertainly\\tdidn’t\\tneed\\tit\\teach\\tday.\\tIt\\thad\\nsimply\\tbeen\\tso\\teasy\\tthat\\tit\\thad\\tbecome\\tthe\\tdefault.\\tOnce\\tmy\\tbad\\thabit\\tbecame\\nimpossible,\\tI\\tdiscovered\\tthat\\tI\\t\\ndid\\n\\tactually\\thave\\tthe\\tmotivation\\tto\\twork\\ton\\tmore\\nmeaningful\\ttasks.\\tAfter\\tI\\tremoved\\tthe\\tmental\\tcandy\\tfrom\\tmy\\tenvironment,\\tit\\nbecame\\tmuch\\teasier\\tto\\teat\\tthe\\thealthy\\tstuff.\\nWhen\\tworking\\tin\\tyour\\tfavor,\\tautomation\\tcan\\tmake\\tyour\\tgood\\thabits\\ninevitable\\tand\\tyour\\tbad\\thabits\\timpossible.\\tIt\\tis\\tthe\\tultimate\\tway\\tto\\tlock\\tin\\tfuture\\nbehavior\\trather\\tthan\\trelying\\ton\\twillpower\\tin\\tthe\\tmoment.\\tBy\\tutilizing\\ncommitment\\tdevices,\\tstrategic\\tonetime\\tdecisions,\\tand\\ttechnology,\\tyou\\tcan\\ncreate\\tan\\tenvironment\\tof\\tinevitability—a\\tspace\\twhere\\tgood\\thabits\\tare\\tnot\\tjust\\tan', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 138}), Document(page_content='outcome\\tyou\\thope\\tfor\\tbut\\tan\\toutcome\\tthat\\tis\\tvirtually\\tguaranteed.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 139}), Document(page_content='Chapter\\tSummary\\nThe\\tinversion\\tof\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\tdifficult\\n.\\nA\\tcommitment\\tdevice\\tis\\ta\\tchoice\\tyou\\tmake\\tin\\tthe\\tpresent\\tthat\\tlocks\\tin\\nbetter\\tbehavior\\tin\\tthe\\tfuture.\\nThe\\tultimate\\tway\\tto\\tlock\\tin\\tfuture\\tbehavior\\tis\\tto\\tautomate\\tyour\\thabits.\\nOnetime\\tchoices—like\\tbuying\\ta\\tbetter\\tmattress\\tor\\tenrolling\\tin\\tan\\nautomatic\\tsavings\\tplan—are\\tsingle\\tactions\\tthat\\tautomate\\tyour\\tfuture\\nhabits\\tand\\tdeliver\\tincreasing\\treturns\\tover\\ttime.\\nUsing\\ttechnology\\tto\\tautomate\\tyour\\thabits\\tis\\tthe\\tmost\\treliable\\tand\\neffective\\tway\\tto\\tguarantee\\tthe\\tright\\tbehavior.\\nHOW\\tTO\\tCREATE\\tA\\tGOOD\\tHABIT\\nThe\\t1st\\tLaw:\\tMake\\tIt\\tObvious\\n1.1:\\n\\tFill\\tout\\tthe\\tHabits\\tScorecard.\\tWrite\\tdown\\tyour\\tcurrent\\thabits\\tto\\tbecome\\taware\\tof\\tthem.\\n1.2:\\n\\tUse\\timplementation\\tintentions:\\t“I\\twill\\t[BEHAVIOR]\\tat\\t[TIME]\\tin\\t[LOCATION].”\\n1.3:\\n\\tUse\\thabit\\tstacking:\\t“After\\t[CURRENT\\tHABIT],\\tI\\twill\\t[NEW\\tHABIT].”\\n1.4:\\n\\tDesign\\tyour\\tenvironment.\\tMake\\tthe\\tcues\\tof\\tgood\\thabits\\tobvious\\tand\\tvisible.\\nThe\\t2nd\\tLaw:\\tMake\\tIt\\tAttractive\\n2.1:\\n\\tUse\\ttemptation\\tbundling.\\tPair\\tan\\taction\\tyou\\t\\nwant\\n\\tto\\tdo\\twith\\tan\\taction\\tyou\\t\\nneed\\n\\tto\\tdo.\\n2.2:\\n\\tJoin\\ta\\tculture\\twhere\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior.\\n2.3:\\n\\tCreate\\ta\\tmotivation\\tritual.\\tDo\\tsomething\\tyou\\tenjoy\\timmediately\\tbefore\\ta\\tdifficult\\thabit.\\nThe\\t3rd\\tLaw:\\tMake\\tIt\\tEasy\\n3.1:\\n\\tReduce\\tfriction.\\tDecrease\\tthe\\tnumber\\tof\\tsteps\\tbetween\\tyou\\tand\\tyour\\tgood\\thabits.\\n3.2:\\n\\tPrime\\tthe\\tenvironment.\\tPrepare\\tyour\\tenvironment\\tto\\tmake\\tfuture\\tactions\\teasier.\\n3.3:\\n\\tMaster\\tthe\\tdecisive\\tmoment.\\tOptimize\\tthe\\tsmall\\tchoices\\tthat\\tdeliver\\toutsized\\timpact.\\n3.4:\\n\\tUse\\tthe\\tTwo-Minute\\tRule.\\tDownscale\\tyour\\thabits\\tuntil\\tthey\\tcan\\tbe\\tdone\\tin\\ttwo\\tminutes\\tor\\tless.\\n3.5:\\n\\tAutomate\\tyour\\thabits.\\tInvest\\tin\\ttechnology\\tand\\tonetime\\tpurchases\\tthat\\tlock\\tin\\tfuture\\tbehavior.\\nThe\\t4th\\tLaw:\\tMake\\tIt\\tSatisfying\\nHOW\\tTO\\tBREAK\\tA\\tBAD\\tHABIT\\nInversion\\tof\\tthe\\t1st\\tLaw:\\tMake\\tIt\\tInvisible\\n1.5:\\t\\nReduce\\texposure.\\tRemove\\tthe\\tcues\\tof\\tyour\\tbad\\thabits\\tfrom\\tyour\\tenvironment.\\nInversion\\tof\\tthe\\t2nd\\tLaw:\\tMake\\tIt\\tUnattractive\\n2.4:\\t\\nReframe\\tyour\\tmind-set.\\tHighlight\\tthe\\tbenefits\\tof\\tavoiding\\tyour\\tbad\\thabits.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 140}), Document(page_content='Inversion\\tof\\tthe\\t3rd\\tLaw:\\tMake\\tIt\\tDifficult\\n3.6:\\t\\nIncrease\\tfriction.\\tIncrease\\tthe\\tnumber\\tof\\tsteps\\tbetween\\tyou\\tand\\tyour\\tbad\\thabits.\\n3.7:\\t\\nUse\\ta\\tcommitment\\tdevice.\\tRestrict\\tyour\\tfuture\\tchoices\\tto\\tthe\\tones\\tthat\\tbenefit\\tyou.\\nInversion\\tof\\tthe\\t4th\\tLaw:\\tMake\\tIt\\tUnsatisfying\\nYou\\tcan\\tdownload\\ta\\tprintable\\tversion\\tof\\tthis\\thabits\\tcheat\\tsheet\\tat:\\t\\natomichabits.com/cheatsheet', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 141}), Document(page_content='THE\\t4TH\\tLAW\\nMake\\tIt\\tSatisfying', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 142}), Document(page_content='15\\nThe\\tCardinal\\tRule\\tof\\tBehavior\\tChange\\nI\\nN\\tTHE\\tLATE\\t1990S,\\n\\ta\\tpublic\\thealth\\tworker\\tnamed\\tStephen\\tLuby\\tleft\\this\\thometown\\tof\\nOmaha,\\tNebraska,\\tand\\tbought\\ta\\tone-way\\tticket\\tto\\tKarachi,\\tPakistan.\\nKarachi\\twas\\tone\\tof\\tthe\\tmost\\tpopulous\\tcities\\tin\\tthe\\tworld.\\tBy\\t1998,\\t\\nover\\tnine\\nmillion\\tpeople\\tcalled\\tit\\thome.\\tIt\\twas\\tthe\\teconomic\\tcenter\\tof\\tPakistan\\tand\\ta\\ntransportation\\thub,\\twith\\tsome\\tof\\tthe\\tmost\\tactive\\tairports\\tand\\tseaports\\tin\\tthe\\nregion.\\tIn\\tthe\\tcommercial\\tparts\\tof\\ttown,\\tyou\\tcould\\tfind\\tall\\tof\\tthe\\tstandard\\turban\\namenities\\tand\\tbustling\\tdowntown\\tstreets.\\tBut\\tKarachi\\twas\\talso\\tone\\tof\\tthe\\t\\nleast\\nlivable\\tcities\\tin\\tthe\\tworld.\\nOver\\t60\\tpercent\\tof\\tKarachi’s\\tresidents\\tlived\\tin\\tsquatter\\tsettlements\\tand\\tslums.\\nThese\\tdensely\\tpacked\\tneighborhoods\\twere\\tfilled\\twith\\tmakeshift\\thouses\\tcobbled\\ntogether\\tfrom\\told\\tboards,\\tcinder\\tblocks,\\tand\\tother\\tdiscarded\\tmaterials.\\tThere\\nwas\\tno\\twaste\\tremoval\\tsystem,\\tno\\telectricity\\tgrid,\\tno\\tclean\\twater\\tsupply.\\tWhen\\ndry,\\tthe\\tstreets\\twere\\ta\\tcombination\\tof\\tdust\\tand\\ttrash.\\tWhen\\twet,\\tthey\\tbecame\\ta\\nmuddy\\tpit\\tof\\tsewage.\\tMosquito\\tcolonies\\tthrived\\tin\\tpools\\tof\\tstagnant\\twater,\\tand\\nchildren\\tplayed\\tamong\\tthe\\tgarbage.\\nThe\\tunsanitary\\tconditions\\tlead\\tto\\twidespread\\tillness\\tand\\tdisease.\\nContaminated\\twater\\tsources\\tcaused\\tepidemics\\tof\\tdiarrhea,\\tvomiting,\\tand\\nabdominal\\tpain.\\tNearly\\tone\\tthird\\tof\\tthe\\tchildren\\tliving\\tthere\\twere\\tmalnourished.\\nWith\\tso\\tmany\\tpeople\\tcrammed\\tinto\\tsuch\\ta\\tsmall\\tspace,\\tviruses\\tand\\tbacterial\\ninfections\\tspread\\trapidly.\\t\\nIt\\twas\\tthis\\tpublic\\thealth\\tcrisis\\tthat\\thad\\tbrought\\nStephen\\tLuby\\tto\\tPakistan.\\nLuby\\tand\\this\\tteam\\trealized\\tthat\\tin\\tan\\tenvironment\\twith\\tpoor\\tsanitation,\\tthe\\nsimple\\thabit\\tof\\twashing\\tyour\\thands\\tcould\\tmake\\ta\\treal\\tdifference\\tin\\tthe\\thealth\\tof\\nthe\\tresidents.\\tBut\\tthey\\tsoon\\tdiscovered\\tthat\\tmany\\tpeople\\twere\\talready\\taware\\nthat\\thandwashing\\twas\\timportant.\\nAnd\\tyet,\\tdespite\\tthis\\tknowledge,\\tmany\\tresidents\\twere\\twashing\\ttheir\\thands\\tin\\na\\thaphazard\\tfashion.\\tSome\\tpeople\\twould\\tjust\\trun\\ttheir\\thands\\tunder\\tthe\\twater', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 143}), Document(page_content='quickly.\\tOthers\\twould\\tonly\\twash\\tone\\thand.\\tMany\\twould\\tsimply\\tforget\\tto\\twash\\ntheir\\thands\\tbefore\\tpreparing\\tfood.\\tEveryone\\t\\nsaid\\n\\thandwashing\\twas\\timportant,\\nbut\\tfew\\tpeople\\tmade\\ta\\thabit\\tout\\tof\\tit.\\tThe\\tproblem\\twasn’t\\tknowledge.\\tThe\\nproblem\\twas\\tconsistency.\\nThat\\twas\\twhen\\tLuby\\tand\\this\\tteam\\tpartnered\\twith\\tProcter\\t&\\tGamble\\tto\\tsupply\\nthe\\tneighborhood\\twith\\tSafeguard\\tsoap.\\tCompared\\tto\\tyour\\tstandard\\tbar\\tof\\tsoap,\\nusing\\tSafeguard\\twas\\ta\\tmore\\tenjoyable\\texperience.\\n“\\nIn\\tPakistan,\\tSafeguard\\twas\\ta\\tpremium\\tsoap,”\\tLuby\\ttold\\tme.\\t“The\\tstudy\\nparticipants\\tcommonly\\tmentioned\\thow\\tmuch\\tthey\\tliked\\tit.”\\tThe\\tsoap\\tfoamed\\neasily,\\tand\\tpeople\\twere\\table\\tto\\tlather\\ttheir\\thands\\twith\\tsuds.\\tIt\\tsmelled\\tgreat.\\nInstantly,\\thandwashing\\tbecame\\tslightly\\tmore\\tpleasurable.\\n“I\\tsee\\tthe\\tgoal\\tof\\thandwashing\\tpromotion\\tnot\\tas\\tbehavior\\tchange\\tbut\\tas\\thabit\\nadoption,”\\tLuby\\tsaid.\\t“It\\tis\\ta\\tlot\\teasier\\tfor\\tpeople\\tto\\tadopt\\ta\\tproduct\\tthat\\nprovides\\ta\\tstrong\\tpositive\\tsensory\\tsignal,\\tfor\\texample\\tthe\\tmint\\ttaste\\tof\\ntoothpaste,\\tthan\\tit\\tis\\tto\\tadopt\\ta\\thabit\\tthat\\tdoes\\tnot\\tprovide\\tpleasurable\\tsensory\\nfeedback,\\tlike\\tflossing\\tone’s\\tteeth.\\tThe\\tmarketing\\tteam\\tat\\tProcter\\t&\\tGamble\\ntalked\\tabout\\ttrying\\tto\\tcreate\\ta\\tpositive\\thandwashing\\texperience.”\\nWithin\\tmonths,\\tthe\\tresearchers\\tsaw\\ta\\trapid\\tshift\\tin\\tthe\\thealth\\tof\\tchildren\\tin\\nthe\\tneighborhood.\\t\\nThe\\trate\\tof\\tdiarrhea\\tfell\\tby\\t52\\tpercent;\\tpneumonia\\tby\\t48\\npercent;\\tand\\timpetigo,\\ta\\tbacterial\\tskin\\tinfection,\\tby\\t35\\tpercent.\\nThe\\tlong-term\\teffects\\twere\\teven\\tbetter.\\t“We\\twent\\tback\\tto\\tsome\\tof\\tthe\\nhouseholds\\tin\\tKarachi\\tsix\\tyears\\tafter,”\\tLuby\\ttold\\tme.\\t“\\nOver\\t95\\tpercent\\tof\\nhouseholds\\twho\\thad\\tbeen\\tgiven\\tthe\\tsoap\\tfor\\tfree\\tand\\tencouraged\\tto\\twash\\ttheir\\nhands\\thad\\ta\\thandwashing\\tstation\\twith\\tsoap\\tand\\twater\\tavailable\\twhen\\tour\\tstudy\\nteam\\tvisited.\\t.\\t.\\t.\\tWe\\thad\\tnot\\tgiven\\tany\\tsoap\\tto\\tthe\\tintervention\\tgroup\\tfor\\tover\\nfive\\tyears,\\tbut\\tduring\\tthe\\ttrial\\tthey\\thad\\tbecome\\tso\\thabituated\\tto\\twash\\ttheir\\nhands,\\tthat\\tthey\\thad\\tmaintained\\tthe\\tpractice.”\\tIt\\twas\\ta\\tpowerful\\texample\\tof\\tthe\\nfourth\\tand\\tfinal\\tLaw\\tof\\tBehavior\\tChange:\\t\\nmake\\tit\\tsatisfying.\\nWe\\tare\\tmore\\tlikely\\tto\\trepeat\\ta\\tbehavior\\twhen\\tthe\\texperience\\tis\\tsatisfying.\\nThis\\tis\\tentirely\\tlogical.\\tFeelings\\tof\\tpleasure—even\\tminor\\tones\\tlike\\twashing\\nyour\\thands\\twith\\tsoap\\tthat\\tsmells\\tnice\\tand\\tlathers\\twell—are\\tsignals\\tthat\\ttell\\tthe\\nbrain:\\t“This\\tfeels\\tgood.\\tDo\\tthis\\tagain,\\tnext\\ttime.”\\tPleasure\\tteaches\\tyour\\tbrain\\nthat\\ta\\tbehavior\\tis\\tworth\\tremembering\\tand\\trepeating.\\nTake\\tthe\\tstory\\tof\\tchewing\\tgum.\\t\\nChewing\\tgum\\thad\\tbeen\\tsold\\tcommercially\\nthroughout\\tthe\\t1800s,\\tbut\\tit\\twasn’t\\tuntil\\tWrigley\\tlaunched\\tin\\t1891\\tthat\\tit\\nbecame\\ta\\tworldwide\\thabit.\\tEarly\\tversions\\twere\\tmade\\tfrom\\trelatively\\tbland\\nresins—chewy,\\tbut\\tnot\\ttasty.\\t\\nWrigley\\trevolutionized\\tthe\\tindustry\\tby\\tadding\\nflavors\\tlike\\tSpearmint\\tand\\tJuicy\\tFruit,\\twhich\\tmade\\tthe\\tproduct\\tflavorful\\tand\\tfun\\nto\\tuse.\\tThen\\tthey\\twent\\ta\\tstep\\tfurther\\tand\\tbegan\\tpushing\\tchewing\\tgum\\tas\\ta', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 144}), Document(page_content='pathway\\tto\\ta\\tclean\\tmouth.\\tAdvertisements\\ttold\\treaders\\tto\\t“Refresh\\tYour\\tTaste.”\\nTasty\\tflavors\\tand\\tthe\\tfeeling\\tof\\ta\\tfresh\\tmouth\\tprovided\\tlittle\\tbits\\tof\\timmediate\\nreinforcement\\tand\\tmade\\tthe\\tproduct\\tsatisfying\\tto\\tuse.\\tConsumption\\tskyrocketed,\\nand\\t\\nWrigley\\tbecame\\tthe\\tlargest\\tchewing\\tgum\\tcompany\\tin\\tthe\\tworld.\\nToothpaste\\thad\\ta\\tsimilar\\ttrajectory.\\tManufacturers\\tenjoyed\\tgreat\\tsuccess\\nwhen\\tthey\\tadded\\tflavors\\tlike\\tspearmint,\\tpeppermint,\\tand\\tcinnamon\\tto\\ttheir\\nproducts.\\tThese\\tflavors\\tdon’t\\timprove\\tthe\\teffectiveness\\tof\\ttoothpaste.\\tThey\\nsimply\\tcreate\\ta\\t“clean\\tmouth”\\tfeel\\tand\\tmake\\tthe\\texperience\\tof\\tbrushing\\tyour\\nteeth\\tmore\\tpleasurable.\\tMy\\twife\\tactually\\tstopped\\tusing\\tSensodyne\\tbecause\\tshe\\ndidn’t\\tlike\\tthe\\taftertaste.\\tShe\\tswitched\\tto\\ta\\tbrand\\twith\\ta\\tstronger\\tmint\\tflavor,\\nwhich\\tproved\\tto\\tbe\\tmore\\tsatisfying.\\nConversely,\\tif\\tan\\texperience\\tis\\tnot\\tsatisfying,\\twe\\thave\\tlittle\\treason\\tto\\trepeat\\nit.\\tIn\\tmy\\tresearch,\\tI\\tcame\\tacross\\tthe\\tstory\\tof\\ta\\twoman\\twho\\thad\\ta\\tnarcissistic\\nrelative\\twho\\tdrove\\ther\\tnuts.\\tIn\\tan\\tattempt\\tto\\tspend\\tless\\ttime\\twith\\tthis\\negomaniac,\\tshe\\tacted\\tas\\tdull\\tand\\tas\\tboring\\tas\\tpossible\\twhenever\\the\\twas\\taround.\\nWithin\\ta\\tfew\\tencounters,\\t\\nhe\\n\\tstarted\\tavoiding\\t\\nher\\n\\tbecause\\the\\tfound\\ther\\tso\\nuninteresting.\\nStories\\tlike\\tthese\\tare\\tevidence\\tof\\tthe\\tCardinal\\tRule\\tof\\tBehavior\\tChange:\\t\\nWhat\\nis\\trewarded\\tis\\trepeated.\\tWhat\\tis\\tpunished\\tis\\tavoided.\\n\\tYou\\tlearn\\twhat\\tto\\tdo\\tin\\nthe\\tfuture\\tbased\\ton\\twhat\\tyou\\twere\\trewarded\\tfor\\tdoing\\t(or\\tpunished\\tfor\\tdoing)\\tin\\nthe\\tpast.\\tPositive\\temotions\\tcultivate\\thabits.\\tNegative\\temotions\\tdestroy\\tthem.\\nThe\\tfirst\\tthree\\tlaws\\tof\\tbehavior\\tchange—\\nmake\\tit\\tobvious,\\tmake\\tit\\tattractive,\\nand\\n\\tmake\\tit\\teasy\\n—increase\\tthe\\todds\\tthat\\ta\\tbehavior\\twill\\tbe\\tperformed\\t\\nthis\\n\\ttime.\\nThe\\tfourth\\tlaw\\tof\\tbehavior\\tchange—\\nmake\\tit\\tsatisfying\\n—increases\\tthe\\todds\\tthat\\na\\tbehavior\\twill\\tbe\\trepeated\\t\\nnext\\n\\ttime.\\tIt\\tcompletes\\tthe\\thabit\\tloop.\\nBut\\tthere\\tis\\ta\\ttrick.\\tWe\\tare\\tnot\\tlooking\\tfor\\tjust\\tany\\ttype\\tof\\tsatisfaction.\\tWe\\nare\\tlooking\\tfor\\timmediate\\tsatisfaction.\\nTHE\\tMISMATCH\\tBETWEEN\\tIMMEDIATE\\tAND\\tDELAYED\\nREWARDS\\nImagine\\tyou’re\\tan\\tanimal\\troaming\\tthe\\tplains\\tof\\tAfrica—a\\tgiraffe\\tor\\tan\\telephant\\nor\\ta\\tlion.\\tOn\\tany\\tgiven\\tday,\\tmost\\tof\\tyour\\tdecisions\\thave\\tan\\timmediate\\timpact.\\nYou\\tare\\talways\\tthinking\\tabout\\twhat\\tto\\teat\\tor\\twhere\\tto\\tsleep\\tor\\thow\\tto\\tavoid\\ta\\npredator.\\tYou\\tare\\tconstantly\\tfocused\\ton\\tthe\\tpresent\\tor\\tthe\\tvery\\tnear\\tfuture.\\tYou\\nlive\\tin\\twhat\\tscientists\\tcall\\tan\\t\\nimmediate-return\\tenvironment\\n\\tbecause\\tyour\\nactions\\tinstantly\\tdeliver\\tclear\\tand\\timmediate\\toutcomes.\\nNow\\tswitch\\tback\\tto\\tyour\\thuman\\tself.\\tIn\\tmodern\\tsociety,\\tmany\\tof\\tthe\\tchoices', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 145}), Document(page_content='you\\tmake\\ttoday\\twill\\t\\nnot\\n\\tbenefit\\tyou\\timmediately.\\tIf\\tyou\\tdo\\ta\\tgood\\tjob\\tat\\twork,\\nyou’ll\\tget\\ta\\tpaycheck\\tin\\ta\\tfew\\tweeks.\\tIf\\tyou\\texercise\\ttoday,\\tperhaps\\tyou\\twon’t\\nbe\\toverweight\\tnext\\tyear.\\tIf\\tyou\\tsave\\tmoney\\tnow,\\tmaybe\\tyou’ll\\thave\\tenough\\tfor\\nretirement\\tdecades\\tfrom\\tnow.\\tYou\\tlive\\tin\\twhat\\tscientists\\tcall\\ta\\t\\ndelayed-return\\nenvironment\\n\\tbecause\\tyou\\tcan\\twork\\tfor\\tyears\\tbefore\\tyour\\tactions\\tdeliver\\tthe\\nintended\\tpayoff.\\nThe\\thuman\\tbrain\\tdid\\tnot\\tevolve\\tfor\\tlife\\tin\\ta\\tdelayed-return\\tenvironment.\\t\\nThe\\nearliest\\tremains\\tof\\tmodern\\thumans,\\tknown\\tas\\t\\nHomo\\tsapiens\\tsapiens\\n,\\tare\\napproximately\\ttwo\\thundred\\tthousand\\tyears\\told.\\tThese\\twere\\tthe\\tfirst\\thumans\\tto\\nhave\\ta\\tbrain\\trelatively\\tsimilar\\tto\\tours.\\tIn\\tparticular,\\t\\nthe\\tneocortex—the\\tnewest\\npart\\tof\\tthe\\tbrain\\tand\\tthe\\tregion\\tresponsible\\tfor\\thigher\\tfunctions\\tlike\\tlanguage—\\nwas\\troughly\\tthe\\tsame\\tsize\\ttwo\\thundred\\tthousand\\tyears\\tago\\tas\\ttoday.\\tYou\\tare\\nwalking\\taround\\twith\\tthe\\tsame\\thardware\\tas\\tyour\\tPaleolithic\\tancestors.\\nIt\\tis\\tonly\\trecently—during\\tthe\\tlast\\tfive\\thundred\\tyears\\tor\\tso—that\\t\\nsociety\\thas\\nshifted\\tto\\ta\\tpredominantly\\tdelayed-return\\tenvironment.\\n*\\n\\t\\nCompared\\tto\\tthe\\tage\\tof\\nthe\\tbrain,\\tmodern\\tsociety\\tis\\tbrand-new.\\tIn\\tthe\\tlast\\tone\\thundred\\tyears,\\twe\\thave\\nseen\\tthe\\trise\\tof\\tthe\\tcar,\\tthe\\tairplane,\\tthe\\ttelevision,\\tthe\\tpersonal\\tcomputer,\\tthe\\ninternet,\\tthe\\tsmartphone,\\tand\\tBeyoncé.\\t\\nThe\\tworld\\thas\\tchanged\\tmuch\\tin\\trecent\\nyears,\\tbut\\thuman\\tnature\\thas\\tchanged\\tlittle.\\nSimilar\\tto\\tother\\tanimals\\ton\\tthe\\tAfrican\\tsavannah,\\tour\\tancestors\\tspent\\ttheir\\ndays\\tresponding\\tto\\tgrave\\tthreats,\\tsecuring\\tthe\\tnext\\tmeal,\\tand\\ttaking\\tshelter\\tfrom\\na\\tstorm.\\tIt\\tmade\\tsense\\tto\\tplace\\ta\\thigh\\tvalue\\ton\\tinstant\\tgratification.\\tThe\\tdistant\\nfuture\\twas\\tless\\tof\\ta\\tconcern.\\tAnd\\tafter\\tthousands\\tof\\tgenerations\\tin\\tan\\nimmediate-return\\tenvironment,\\t\\nour\\tbrains\\tevolved\\tto\\tprefer\\tquick\\tpayoffs\\tto\\nlong-term\\tones.\\nBehavioral\\teconomists\\trefer\\tto\\tthis\\ttendency\\tas\\t\\ntime\\tinconsistency\\n.\\tThat\\tis,\\nthe\\tway\\tyour\\tbrain\\tevaluates\\trewards\\tis\\tinconsistent\\tacross\\ttime.\\n*\\n\\tYou\\tvalue\\tthe\\npresent\\tmore\\tthan\\tthe\\tfuture.\\tUsually,\\tthis\\ttendency\\tserves\\tus\\twell.\\tA\\treward\\nthat\\tis\\t\\ncertain\\n\\tright\\tnow\\tis\\ttypically\\tworth\\tmore\\tthan\\tone\\tthat\\tis\\tmerely\\t\\npossible\\nin\\tthe\\tfuture.\\tBut\\toccasionally,\\tour\\tbias\\ttoward\\tinstant\\tgratification\\tcauses\\nproblems.\\nWhy\\twould\\tsomeone\\tsmoke\\tif\\tthey\\tknow\\tit\\tincreases\\tthe\\trisk\\tof\\tlung\\tcancer?\\nWhy\\twould\\tsomeone\\tovereat\\twhen\\tthey\\tknow\\tit\\tincreases\\ttheir\\trisk\\tof\\tobesity?\\nWhy\\twould\\tsomeone\\thave\\tunsafe\\tsex\\tif\\tthey\\tknow\\tit\\tcan\\tresult\\tin\\tsexually\\ntransmitted\\tdisease?\\tOnce\\tyou\\tunderstand\\thow\\tthe\\tbrain\\tprioritizes\\trewards,\\tthe\\nanswers\\tbecome\\tclear:\\tthe\\tconsequences\\tof\\tbad\\thabits\\tare\\tdelayed\\twhile\\tthe\\nrewards\\tare\\timmediate.\\tSmoking\\tmight\\tkill\\tyou\\tin\\tten\\tyears,\\tbut\\tit\\treduces\\tstress\\nand\\teases\\tyour\\tnicotine\\tcravings\\t\\nnow\\n.\\tOvereating\\tis\\tharmful\\tin\\tthe\\tlong\\trun\\tbut\\nappetizing\\tin\\tthe\\tmoment.\\tSex—safe\\tor\\tnot—provides\\tpleasure\\tright\\taway.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 146}), Document(page_content='Disease\\tand\\tinfection\\twon’t\\tshow\\tup\\tfor\\tdays\\tor\\tweeks,\\teven\\tyears.\\nEvery\\thabit\\tproduces\\tmultiple\\toutcomes\\tacross\\ttime.\\tUnfortunately,\\t\\nthese\\noutcomes\\tare\\toften\\tmisaligned.\\tWith\\tour\\tbad\\thabits,\\tthe\\timmediate\\toutcome\\nusually\\tfeels\\tgood,\\tbut\\tthe\\tultimate\\toutcome\\tfeels\\tbad.\\tWith\\tgood\\thabits,\\tit\\tis\\tthe\\nreverse:\\tthe\\timmediate\\toutcome\\tis\\tunenjoyable,\\tbut\\tthe\\tultimate\\toutcome\\tfeels\\ngood.\\tThe\\tFrench\\teconomist\\t\\nFrédéric\\tBastiat\\texplained\\tthe\\tproblem\\tclearly\\nwhen\\the\\twrote,\\t“It\\talmost\\talways\\thappens\\tthat\\twhen\\tthe\\timmediate\\tconsequence\\nis\\tfavorable,\\tthe\\tlater\\tconsequences\\tare\\tdisastrous,\\tand\\tvice\\tversa.\\t.\\t.\\t.\\tOften,\\tthe\\nsweeter\\tthe\\tfirst\\tfruit\\tof\\ta\\thabit,\\tthe\\tmore\\tbitter\\tare\\tits\\tlater\\tfruits.”\\nPut\\tanother\\tway,\\tthe\\tcosts\\tof\\tyour\\tgood\\thabits\\tare\\tin\\tthe\\tpresent.\\tThe\\tcosts\\tof\\nyour\\tbad\\thabits\\tare\\tin\\tthe\\tfuture.\\nThe\\tbrain’s\\ttendency\\tto\\tprioritize\\tthe\\tpresent\\tmoment\\tmeans\\tyou\\tcan’t\\trely\\ton\\ngood\\tintentions.\\tWhen\\tyou\\tmake\\ta\\tplan—to\\tlose\\tweight,\\twrite\\ta\\tbook,\\tor\\tlearn\\ta\\nlanguage—you\\tare\\tactually\\tmaking\\tplans\\tfor\\tyour\\tfuture\\tself.\\tAnd\\twhen\\tyou\\nenvision\\twhat\\tyou\\twant\\tyour\\tlife\\tto\\tbe\\tlike,\\tit\\tis\\teasy\\tto\\tsee\\tthe\\tvalue\\tin\\ttaking\\nactions\\twith\\tlong-term\\tbenefits.\\tWe\\tall\\twant\\tbetter\\tlives\\tfor\\tour\\tfuture\\tselves.\\nHowever,\\twhen\\tthe\\tmoment\\tof\\tdecision\\tarrives,\\tinstant\\tgratification\\tusually\\nwins.\\tYou\\tare\\tno\\tlonger\\tmaking\\ta\\tchoice\\tfor\\t\\nFuture\\tYou,\\twho\\tdreams\\tof\\tbeing\\nfitter\\tor\\twealthier\\tor\\thappier.\\tYou\\tare\\tchoosing\\tfor\\tPresent\\tYou,\\twho\\twants\\tto\\tbe\\nfull,\\tpampered,\\tand\\tentertained.\\tAs\\ta\\tgeneral\\trule,\\tthe\\tmore\\timmediate\\tpleasure\\nyou\\tget\\tfrom\\tan\\taction,\\tthe\\tmore\\tstrongly\\tyou\\tshould\\tquestion\\twhether\\tit\\taligns\\nwith\\tyour\\tlong-term\\tgoals.\\n*\\nWith\\ta\\tfuller\\tunderstanding\\tof\\twhat\\tcauses\\tour\\tbrain\\tto\\trepeat\\tsome\\tbehaviors\\nand\\tavoid\\tothers,\\tlet’s\\tupdate\\tthe\\tCardinal\\tRule\\tof\\tBehavior\\tChange:\\tWhat\\tis\\nimmediately\\n\\trewarded\\tis\\trepeated.\\tWhat\\tis\\t\\nimmediately\\n\\tpunished\\tis\\tavoided.\\nOur\\tpreference\\tfor\\tinstant\\tgratification\\treveals\\tan\\timportant\\ttruth\\tabout\\nsuccess:\\tbecause\\tof\\thow\\twe\\tare\\twired,\\tmost\\tpeople\\twill\\tspend\\tall\\tday\\tchasing\\nquick\\thits\\tof\\tsatisfaction.\\tThe\\troad\\tless\\ttraveled\\tis\\tthe\\troad\\tof\\tdelayed\\ngratification.\\tIf\\tyou’re\\twilling\\tto\\twait\\tfor\\tthe\\trewards,\\tyou’ll\\tface\\tless\\ncompetition\\tand\\toften\\tget\\ta\\tbigger\\tpayoff.\\tAs\\tthe\\tsaying\\tgoes,\\tthe\\tlast\\tmile\\tis\\nalways\\tthe\\tleast\\tcrowded.\\nThis\\tis\\tprecisely\\twhat\\tresearch\\thas\\tshown.\\t\\nPeople\\twho\\tare\\tbetter\\tat\\tdelaying\\ngratification\\thave\\thigher\\tSAT\\tscores,\\tlower\\tlevels\\tof\\tsubstance\\tabuse,\\tlower\\nlikelihood\\tof\\tobesity,\\tbetter\\tresponses\\tto\\tstress,\\tand\\tsuperior\\tsocial\\tskills.\\tWe’ve\\nall\\tseen\\tthis\\tplay\\tout\\tin\\tour\\town\\tlives.\\tIf\\tyou\\tdelay\\twatching\\ttelevision\\tand\\tget\\nyour\\thomework\\tdone,\\tyou’ll\\tgenerally\\tlearn\\tmore\\tand\\tget\\tbetter\\tgrades.\\tIf\\tyou\\ndon’t\\tbuy\\tdesserts\\tand\\tchips\\tat\\tthe\\tstore,\\tyou’ll\\toften\\teat\\thealthier\\tfood\\twhen\\nyou\\tget\\thome.\\tAt\\tsome\\tpoint,\\tsuccess\\tin\\tnearly\\tevery\\tfield\\trequires\\tyou\\tto\\tignore\\nan\\timmediate\\treward\\tin\\tfavor\\tof\\ta\\tdelayed\\treward.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 147}), Document(page_content='Here’s\\tthe\\tproblem:\\tmost\\tpeople\\t\\nknow\\n\\tthat\\tdelaying\\tgratification\\tis\\tthe\\twise\\napproach.\\tThey\\twant\\tthe\\tbenefits\\tof\\tgood\\thabits:\\tto\\tbe\\thealthy,\\tproductive,\\tat\\npeace.\\tBut\\tthese\\toutcomes\\tare\\tseldom\\ttop-of-mind\\tat\\tthe\\tdecisive\\tmoment.\\nThankfully,\\tit’s\\tpossible\\tto\\ttrain\\tyourself\\tto\\tdelay\\tgratification—but\\tyou\\tneed\\tto\\nwork\\twith\\tthe\\tgrain\\tof\\thuman\\tnature,\\tnot\\tagainst\\tit.\\tThe\\tbest\\tway\\tto\\tdo\\tthis\\tis\\tto\\nadd\\ta\\tlittle\\tbit\\tof\\timmediate\\tpleasure\\tto\\tthe\\thabits\\tthat\\tpay\\toff\\tin\\tthe\\tlong-run\\nand\\ta\\tlittle\\tbit\\tof\\timmediate\\tpain\\tto\\tones\\tthat\\tdon’t.\\nHOW\\tTO\\tTURN\\tINSTANT\\tGRATIFICATION\\tTO\\tYOUR\\tADVANTAGE\\nThe\\tvital\\tthing\\tin\\tgetting\\ta\\thabit\\tto\\tstick\\tis\\tto\\tfeel\\tsuccessful—even\\tif\\tit’s\\tin\\ta\\nsmall\\tway.\\tThe\\tfeeling\\tof\\tsuccess\\tis\\ta\\tsignal\\tthat\\tyour\\thabit\\tpaid\\toff\\tand\\tthat\\tthe\\nwork\\twas\\tworth\\tthe\\teffort.\\nIn\\ta\\tperfect\\tworld,\\tthe\\treward\\tfor\\ta\\tgood\\thabit\\tis\\tthe\\thabit\\titself.\\tIn\\t\\nthe\\treal\\nworld,\\tgood\\thabits\\ttend\\tto\\tfeel\\tworthwhile\\tonly\\tafter\\tthey\\thave\\tprovided\\tyou\\nwith\\tsomething.\\tEarly\\ton,\\tit’s\\tall\\tsacrifice.\\tYou’ve\\tgone\\tto\\tthe\\tgym\\ta\\tfew\\ttimes,\\nbut\\tyou’re\\tnot\\tstronger\\tor\\tfitter\\tor\\tfaster—at\\tleast,\\tnot\\tin\\tany\\tnoticeable\\tsense.\\nIt’s\\tonly\\tmonths\\tlater,\\tonce\\tyou\\tshed\\ta\\tfew\\tpounds\\tor\\tyour\\tarms\\tgain\\tsome\\ndefinition,\\tthat\\tit\\tbecomes\\teasier\\tto\\texercise\\tfor\\tits\\town\\tsake.\\tIn\\tthe\\tbeginning,\\nyou\\tneed\\ta\\treason\\tto\\tstay\\ton\\ttrack.\\tThis\\tis\\twhy\\timmediate\\trewards\\tare\\tessential.\\nThey\\tkeep\\tyou\\texcited\\twhile\\tthe\\tdelayed\\trewards\\taccumulate\\tin\\tthe\\tbackground.\\nWhat\\twe’re\\treally\\ttalking\\tabout\\there—when\\twe’re\\tdiscussing\\timmediate\\nrewards—is\\tthe\\tending\\tof\\ta\\tbehavior.\\tThe\\tending\\tof\\tany\\texperience\\tis\\tvital\\nbecause\\twe\\ttend\\tto\\tremember\\tit\\tmore\\tthan\\tother\\tphases.\\tYou\\twant\\tthe\\tending\\tof\\nyour\\thabit\\tto\\tbe\\tsatisfying.\\tThe\\tbest\\tapproach\\tis\\tto\\tuse\\t\\nreinforcement\\n,\\twhich\\nrefers\\tto\\tthe\\tprocess\\tof\\tusing\\tan\\timmediate\\treward\\tto\\tincrease\\tthe\\trate\\tof\\ta\\nbehavior.\\tHabit\\tstacking,\\twhich\\twe\\tcovered\\tin\\tChapter\\t5,\\tties\\tyour\\thabit\\tto\\tan\\nimmediate\\tcue,\\twhich\\tmakes\\tit\\tobvious\\twhen\\tto\\tstart.\\tReinforcement\\tties\\tyour\\nhabit\\tto\\tan\\timmediate\\treward,\\twhich\\tmakes\\tit\\tsatisfying\\twhen\\tyou\\tfinish.\\nImmediate\\treinforcement\\tcan\\tbe\\tespecially\\thelpful\\twhen\\tdealing\\twith\\t\\nhabits\\nof\\tavoidance\\n,\\twhich\\tare\\tbehaviors\\tyou\\twant\\tto\\tstop\\tdoing.\\tIt\\tcan\\tbe\\tchallenging\\nto\\tstick\\twith\\thabits\\tlike\\t“no\\tfrivolous\\tpurchases”\\tor\\t“no\\talcohol\\tthis\\tmonth”\\nbecause\\tnothing\\thappens\\twhen\\tyou\\tskip\\thappy\\thour\\tdrinks\\tor\\tdon’t\\tbuy\\tthat\\tpair\\nof\\tshoes.\\tIt\\tcan\\tbe\\thard\\tto\\tfeel\\tsatisfied\\twhen\\tthere\\tis\\tno\\taction\\tin\\tthe\\tfirst\\tplace.\\nAll\\tyou’re\\tdoing\\tis\\tresisting\\ttemptation,\\tand\\tthere\\tisn’t\\tmuch\\tsatisfying\\tabout\\nthat.\\nOne\\tsolution\\tis\\tto\\tturn\\tthe\\tsituation\\ton\\tits\\thead.\\tYou\\twant\\tto\\tmake\\tavoidance\\nvisible.\\tOpen\\ta\\tsavings\\taccount\\tand\\tlabel\\tit\\tfor\\tsomething\\tyou\\twant—maybe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 148}), Document(page_content='“Leather\\tJacket.”\\tWhenever\\tyou\\tpass\\ton\\ta\\tpurchase,\\tput\\tthe\\tsame\\tamount\\tof\\nmoney\\tin\\tthe\\taccount.\\tSkip\\tyour\\tmorning\\tlatte?\\tTransfer\\t$5.\\tPass\\ton\\tanother\\nmonth\\tof\\tNetflix?\\tMove\\t$10\\tover.\\tIt’s\\tlike\\tcreating\\ta\\tloyalty\\tprogram\\tfor\\nyourself.\\tThe\\timmediate\\treward\\tof\\tseeing\\tyourself\\tsave\\tmoney\\ttoward\\tthe\\nleather\\tjacket\\tfeels\\t\\na\\tlot\\tbetter\\tthan\\tbeing\\tdeprived.\\tYou\\tare\\tmaking\\tit\\tsatisfying\\nto\\tdo\\tnothing.\\nOne\\tof\\tmy\\treaders\\tand\\this\\twife\\tused\\ta\\tsimilar\\tsetup.\\tThey\\twanted\\tto\\tstop\\neating\\tout\\tso\\tmuch\\tand\\tstart\\tcooking\\ttogether\\tmore.\\tThey\\tlabeled\\ttheir\\tsavings\\naccount\\t“Trip\\tto\\tEurope.”\\tWhenever\\tthey\\tskipped\\tgoing\\tout\\tto\\teat,\\tthey\\ntransferred\\t$50\\tinto\\tthe\\taccount.\\tAt\\tthe\\tend\\tof\\tthe\\tyear,\\tthey\\tput\\tthe\\tmoney\\ntoward\\tthe\\tvacation.\\nIt\\tis\\tworth\\tnoting\\tthat\\tit\\tis\\timportant\\tto\\tselect\\tshort-term\\trewards\\tthat\\nreinforce\\tyour\\tidentity\\trather\\tthan\\tones\\tthat\\tconflict\\twith\\tit.\\tBuying\\ta\\tnew\\tjacket\\nis\\tfine\\tif\\tyou’re\\ttrying\\tto\\tlose\\tweight\\tor\\tread\\tmore\\tbooks,\\tbut\\tit\\tdoesn’t\\twork\\tif\\nyou’re\\ttrying\\tto\\tbudget\\tand\\tsave\\tmoney.\\tInstead,\\ttaking\\ta\\tbubble\\tbath\\tor\\tgoing\\non\\ta\\tleisurely\\twalk\\tare\\tgood\\texamples\\tof\\trewarding\\tyourself\\twith\\tfree\\ttime,\\nwhich\\taligns\\twith\\tyour\\tultimate\\tgoal\\tof\\tmore\\tfreedom\\tand\\tfinancial\\nindependence.\\tSimilarly,\\tif\\tyour\\treward\\tfor\\texercising\\tis\\teating\\ta\\tbowl\\tof\\tice\\ncream,\\tthen\\tyou’re\\tcasting\\tvotes\\tfor\\tconflicting\\tidentities,\\tand\\tit\\tends\\tup\\tbeing\\ta\\nwash.\\tInstead,\\tmaybe\\tyour\\treward\\tis\\ta\\tmassage,\\twhich\\tis\\tboth\\ta\\tluxury\\tand\\ta\\nvote\\ttoward\\ttaking\\tcare\\tof\\tyour\\tbody.\\tNow\\tthe\\tshort-term\\treward\\tis\\taligned\\twith\\nyour\\tlong-term\\tvision\\tof\\tbeing\\ta\\thealthy\\tperson.\\nEventually,\\tas\\tintrinsic\\trewards\\tlike\\ta\\tbetter\\tmood,\\tmore\\tenergy,\\tand\\treduced\\nstress\\tkick\\tin,\\tyou’ll\\tbecome\\tless\\tconcerned\\twith\\tchasing\\tthe\\tsecondary\\treward.\\nThe\\tidentity\\titself\\tbecomes\\tthe\\treinforcer.\\tYou\\tdo\\tit\\tbecause\\tit’s\\twho\\tyou\\tare\\nand\\tit\\tfeels\\tgood\\tto\\tbe\\tyou.\\tThe\\tmore\\ta\\thabit\\tbecomes\\tpart\\tof\\tyour\\tlife,\\tthe\\tless\\nyou\\tneed\\toutside\\tencouragement\\tto\\tfollow\\tthrough.\\tIncentives\\tcan\\tstart\\ta\\thabit.\\nIdentity\\tsustains\\ta\\thabit.\\nThat\\tsaid,\\tit\\ttakes\\ttime\\tfor\\tthe\\tevidence\\tto\\taccumulate\\tand\\ta\\tnew\\tidentity\\tto\\nemerge.\\tImmediate\\treinforcement\\thelps\\tmaintain\\tmotivation\\tin\\tthe\\tshort\\tterm\\nwhile\\tyou’re\\twaiting\\tfor\\tthe\\tlong-term\\trewards\\tto\\tarrive.\\nIn\\tsummary,\\ta\\thabit\\tneeds\\tto\\tbe\\tenjoyable\\tfor\\tit\\tto\\tlast.\\tSimple\\tbits\\t\\nof\\nreinforcement—like\\tsoap\\tthat\\tsmells\\tgreat\\tor\\ttoothpaste\\tthat\\thas\\ta\\trefreshing\\nmint\\tflavor\\tor\\tseeing\\t$50\\thit\\tyour\\tsavings\\taccount—can\\toffer\\tthe\\timmediate\\npleasure\\tyou\\tneed\\tto\\tenjoy\\ta\\thabit.\\tAnd\\tchange\\tis\\teasy\\twhen\\tit\\tis\\tenjoyable.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 149}), Document(page_content='Chapter\\tSummary\\nThe\\t4th\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\tsatisfying\\n.\\nWe\\tare\\tmore\\tlikely\\tto\\trepeat\\ta\\tbehavior\\twhen\\tthe\\texperience\\tis\\nsatisfying.\\nThe\\thuman\\tbrain\\tevolved\\tto\\tprioritize\\timmediate\\trewards\\tover\\tdelayed\\nrewards.\\nThe\\tCardinal\\tRule\\tof\\tBehavior\\tChange:\\t\\nWhat\\tis\\timmediately\\trewarded\\nis\\trepeated.\\tWhat\\tis\\timmediately\\tpunished\\tis\\tavoided.\\nTo\\tget\\ta\\thabit\\tto\\tstick\\tyou\\tneed\\tto\\tfeel\\timmediately\\tsuccessful—even\\nif\\tit’s\\tin\\ta\\tsmall\\tway.\\nThe\\tfirst\\tthree\\tlaws\\tof\\tbehavior\\tchange—\\nmake\\tit\\tobvious,\\tmake\\tit\\nattractive,\\t\\nand\\n\\tmake\\tit\\teasy\\n—increase\\tthe\\todds\\tthat\\ta\\tbehavior\\twill\\tbe\\nperformed\\tthis\\ttime.\\tThe\\tfourth\\tlaw\\tof\\tbehavior\\tchange—\\nmake\\tit\\nsatisfying\\n—increases\\tthe\\todds\\tthat\\ta\\tbehavior\\twill\\tbe\\trepeated\\tnext\\ntime.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 150}), Document(page_content='16\\nHow\\tto\\tStick\\twith\\tGood\\tHabits\\tEvery\\tDay\\nI\\nN\\t1993\\n,\\ta\\tbank\\tin\\tAbbotsford,\\tCanada,\\thired\\ta\\ttwenty-three-year-old\\tstockbroker\\nnamed\\tTrent\\tDyrsmid.\\tAbbotsford\\twas\\ta\\trelatively\\tsmall\\tsuburb,\\ttucked\\taway\\tin\\nthe\\tshadow\\tof\\tnearby\\tVancouver,\\twhere\\tmost\\tof\\tthe\\tbig\\tbusiness\\tdeals\\twere\\nbeing\\tmade.\\tGiven\\tthe\\tlocation,\\tand\\tthe\\tfact\\tthat\\tDyrsmid\\twas\\ta\\trookie,\\tnobody\\nexpected\\ttoo\\tmuch\\tof\\thim.\\tBut\\the\\tmade\\tbrisk\\tprogress\\tthanks\\tto\\ta\\tsimple\\tdaily\\nhabit.\\nDyrsmid\\tbegan\\teach\\tmorning\\twith\\ttwo\\tjars\\ton\\this\\tdesk.\\tOne\\twas\\tfilled\\twith\\n120\\tpaper\\tclips.\\tThe\\tother\\twas\\tempty.\\tAs\\tsoon\\tas\\the\\tsettled\\tin\\teach\\tday,\\the\\nwould\\tmake\\ta\\tsales\\tcall.\\tImmediately\\tafter,\\the\\twould\\tmove\\tone\\tpaper\\tclip\\tfrom\\nthe\\tfull\\tjar\\tto\\tthe\\tempty\\tjar\\tand\\tthe\\tprocess\\twould\\tbegin\\tagain.\\t“Every\\tmorning\\t\\nI\\nwould\\tstart\\twith\\t120\\tpaper\\tclips\\tin\\tone\\tjar\\tand\\tI\\twould\\tkeep\\tdialing\\tthe\\tphone\\nuntil\\tI\\thad\\tmoved\\tthem\\tall\\tto\\tthe\\tsecond\\tjar,”\\the\\ttold\\tme.\\nWithin\\teighteen\\tmonths,\\tDyrsmid\\twas\\tbringing\\tin\\t$5\\tmillion\\tto\\tthe\\tfirm.\\tBy\\nage\\ttwenty-four,\\the\\twas\\tmaking\\t$75,000\\tper\\tyear—the\\tequivalent\\tof\\t$125,000\\ntoday.\\tNot\\tlong\\tafter,\\the\\tlanded\\ta\\tsix-figure\\tjob\\twith\\tanother\\tcompany.\\nI\\tlike\\tto\\trefer\\tto\\tthis\\ttechnique\\tas\\tthe\\tPaper\\tClip\\tStrategy\\tand,\\tover\\t\\nthe\\tyears,\\nI’ve\\theard\\tfrom\\treaders\\twho\\thave\\temployed\\tit\\tin\\ta\\tvariety\\tof\\tways.\\tOne\\twoman\\nshifted\\ta\\thairpin\\tfrom\\tone\\tcontainer\\tto\\tanother\\twhenever\\tshe\\twrote\\ta\\tpage\\tof\\ther\\nbook.\\tAnother\\tman\\tmoved\\ta\\tmarble\\tfrom\\tone\\tbin\\tto\\tthe\\tnext\\tafter\\teach\\tset\\tof\\npush-ups.\\nMaking\\tprogress\\tis\\tsatisfying,\\tand\\tvisual\\tmeasures—like\\tmoving\\tpaper\\tclips\\nor\\thairpins\\tor\\tmarbles—provide\\tclear\\tevidence\\tof\\tyour\\tprogress.\\tAs\\ta\\tresult,\\nthey\\treinforce\\tyour\\tbehavior\\tand\\tadd\\ta\\tlittle\\tbit\\tof\\timmediate\\tsatisfaction\\tto\\tany\\nactivity.\\tVisual\\tmeasurement\\tcomes\\tin\\tmany\\tforms:\\tfood\\tjournals,\\tworkout\\tlogs,\\nloyalty\\tpunch\\tcards,\\tthe\\tprogress\\tbar\\ton\\ta\\tsoftware\\tdownload,\\teven\\tthe\\tpage\\nnumbers\\tin\\ta\\tbook.\\tBut\\tperhaps\\tthe\\tbest\\tway\\tto\\tmeasure\\tyour\\tprogress\\tis\\twith\\ta\\nhabit\\ttracker\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 151}), Document(page_content='HOW\\tTO\\tKEEP\\tYOUR\\tHABITS\\tON\\tTRACK\\nA\\thabit\\ttracker\\tis\\ta\\tsimple\\tway\\tto\\tmeasure\\twhether\\tyou\\tdid\\ta\\thabit.\\tThe\\tmost\\nbasic\\tformat\\tis\\tto\\tget\\ta\\tcalendar\\tand\\tcross\\toff\\teach\\tday\\tyou\\tstick\\twith\\tyour\\nroutine.\\tFor\\texample,\\tif\\tyou\\tmeditate\\ton\\tMonday,\\tWednesday,\\tand\\tFriday,\\teach\\nof\\tthose\\tdates\\tgets\\tan\\t\\nX\\n.\\tAs\\ttime\\trolls\\tby,\\tthe\\tcalendar\\tbecomes\\ta\\trecord\\tof\\tyour\\nhabit\\tstreak.\\nCountless\\tpeople\\thave\\ttracked\\ttheir\\thabits,\\tbut\\tperhaps\\tthe\\tmost\\tfamous\\twas\\nBenjamin\\tFranklin.\\tBeginning\\tat\\tage\\ttwenty,\\tFranklin\\tcarried\\ta\\tsmall\\tbooklet\\neverywhere\\the\\twent\\tand\\tused\\tit\\tto\\ttrack\\tthirteen\\tpersonal\\tvirtues.\\tThis\\tlist\\nincluded\\tgoals\\tlike\\t“Lose\\tno\\ttime.\\tBe\\talways\\temployed\\tin\\tsomething\\tuseful”\\nand\\t“Avoid\\ttrifling\\tconversation.”\\tAt\\tthe\\tend\\tof\\teach\\tday,\\tFranklin\\twould\\topen\\nhis\\tbooklet\\tand\\trecord\\this\\tprogress.\\nJerry\\tSeinfeld\\treportedly\\tuses\\ta\\thabit\\ttracker\\tto\\tstick\\twith\\this\\tstreak\\tof\\twriting\\njokes.\\tIn\\tthe\\tdocumentary\\t\\nComedian\\n,\\the\\texplains\\tthat\\this\\tgoal\\tis\\tsimply\\tto\\n“never\\tbreak\\tthe\\tchain”\\tof\\twriting\\tjokes\\tevery\\tday.\\tIn\\tother\\twords,\\the\\tis\\tnot\\nfocused\\ton\\thow\\tgood\\tor\\tbad\\ta\\tparticular\\tjoke\\tis\\t\\nor\\thow\\tinspired\\the\\tfeels.\\tHe\\tis\\nsimply\\tfocused\\ton\\tshowing\\tup\\tand\\tadding\\tto\\this\\tstreak.\\n“Don’t\\tbreak\\tthe\\tchain”\\tis\\ta\\tpowerful\\tmantra.\\tDon’t\\tbreak\\tthe\\tchain\\tof\\tsales\\ncalls\\tand\\tyou’ll\\tbuild\\ta\\tsuccessful\\tbook\\tof\\tbusiness.\\tDon’t\\tbreak\\tthe\\tchain\\tof\\nworkouts\\tand\\tyou’ll\\tget\\tfit\\tfaster\\tthan\\tyou’d\\texpect.\\t\\nDon’t\\tbreak\\tthe\\tchain\\tof\\ncreating\\tevery\\tday\\tand\\tyou\\twill\\tend\\tup\\twith\\tan\\timpressive\\tportfolio.\\tHabit\\ntracking\\tis\\tpowerful\\tbecause\\tit\\tleverages\\tmultiple\\tLaws\\tof\\tBehavior\\tChange.\\tIt\\nsimultaneously\\tmakes\\ta\\tbehavior\\tobvious,\\tattractive,\\tand\\tsatisfying.\\nLet’s\\tbreak\\tdown\\teach\\tone.\\nBenefit\\t#1:\\tHabit\\ttracking\\tis\\tobvious.\\nRecording\\tyour\\tlast\\taction\\tcreates\\ta\\ttrigger\\tthat\\tcan\\tinitiate\\tyour\\tnext\\tone.\\tHabit\\ntracking\\tnaturally\\tbuilds\\ta\\tseries\\tof\\tvisual\\tcues\\tlike\\tthe\\tstreak\\tof\\t\\nX\\n’s\\ton\\tyour\\ncalendar\\tor\\tthe\\tlist\\tof\\tmeals\\tin\\tyour\\tfood\\tlog.\\tWhen\\tyou\\tlook\\tat\\tthe\\tcalendar\\tand\\nsee\\tyour\\tstreak,\\tyou’ll\\tbe\\treminded\\tto\\tact\\tagain.\\tResearch\\thas\\tshown\\tthat\\t\\npeople\\nwho\\ttrack\\ttheir\\tprogress\\ton\\tgoals\\tlike\\tlosing\\tweight,\\tquitting\\tsmoking,\\tand\\nlowering\\tblood\\tpressure\\tare\\tall\\tmore\\tlikely\\tto\\timprove\\tthan\\tthose\\twho\\tdon’t.\\nOne\\tstudy\\tof\\tmore\\tthan\\tsixteen\\thundred\\tpeople\\tfound\\tthat\\t\\nthose\\twho\\tkept\\ta\\ndaily\\tfood\\tlog\\tlost\\ttwice\\tas\\tmuch\\tweight\\tas\\tthose\\twho\\tdid\\tnot.\\tThe\\tmere\\tact\\tof\\ntracking\\ta\\tbehavior\\tcan\\tspark\\tthe\\turge\\tto\\tchange\\tit.\\nHabit\\ttracking\\talso\\tkeeps\\tyou\\thonest.\\tMost\\tof\\tus\\thave\\ta\\tdistorted\\tview\\tof\\tour\\nown\\tbehavior.\\tWe\\tthink\\twe\\tact\\tbetter\\tthan\\twe\\tdo.\\tMeasurement\\toffers\\tone\\tway', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 152}), Document(page_content='to\\tovercome\\tour\\tblindness\\tto\\tour\\town\\tbehavior\\tand\\tnotice\\twhat’s\\treally\\tgoing\\non\\teach\\tday.\\tOne\\tglance\\tat\\tthe\\tpaper\\tclips\\tin\\tthe\\tcontainer\\tand\\tyou\\timmediately\\nknow\\thow\\tmuch\\twork\\tyou\\thave\\t(or\\thaven’t)\\tbeen\\tputting\\tin.\\tWhen\\tthe\\tevidence\\nis\\tright\\tin\\tfront\\tof\\tyou,\\tyou’re\\tless\\tlikely\\tto\\tlie\\tto\\tyourself.\\nBenefit\\t#2:\\tHabit\\ttracking\\tis\\tattractive.\\nThe\\tmost\\teffective\\tform\\tof\\tmotivation\\tis\\tprogress.\\tWhen\\twe\\tget\\ta\\tsignal\\tthat\\twe\\nare\\tmoving\\tforward,\\twe\\tbecome\\tmore\\tmotivated\\tto\\tcontinue\\tdown\\tthat\\tpath.\\tIn\\nthis\\tway,\\thabit\\ttracking\\tcan\\thave\\tan\\taddictive\\teffect\\ton\\tmotivation.\\tEach\\tsmall\\nwin\\tfeeds\\tyour\\tdesire.\\nThis\\tcan\\tbe\\tparticularly\\tpowerful\\ton\\ta\\tbad\\tday.\\tWhen\\tyou’re\\tfeeling\\tdown,\\nit’s\\teasy\\tto\\tforget\\tabout\\tall\\tthe\\tprogress\\tyou\\thave\\talready\\tmade.\\tHabit\\ttracking\\nprovides\\tvisual\\tproof\\tof\\tyour\\thard\\twork—a\\tsubtle\\treminder\\tof\\thow\\tfar\\tyou’ve\\ncome.\\tPlus,\\tthe\\tempty\\tsquare\\tyou\\tsee\\teach\\tmorning\\tcan\\tmotivate\\tyou\\tto\\tget\\nstarted\\tbecause\\tyou\\tdon’t\\twant\\tto\\tlose\\tyour\\tprogress\\tby\\tbreaking\\tthe\\tstreak.\\nBenefit\\t#3:\\tHabit\\ttracking\\tis\\tsatisfying.\\nThis\\tis\\tthe\\tmost\\tcrucial\\tbenefit\\tof\\tall.\\tTracking\\tcan\\tbecome\\tits\\town\\tform\\tof\\nreward.\\tIt\\tis\\tsatisfying\\tto\\tcross\\tan\\titem\\toff\\tyour\\tto-do\\tlist,\\tto\\tcomplete\\tan\\tentry\\nin\\tyour\\tworkout\\tlog,\\tor\\tto\\tmark\\tan\\t\\nX\\n\\ton\\tthe\\tcalendar.\\tIt\\tfeels\\tgood\\tto\\twatch\\tyour\\nresults\\tgrow—the\\tsize\\tof\\tyour\\tinvestment\\tportfolio,\\tthe\\tlength\\tof\\tyour\\tbook\\nmanuscript—and\\tif\\tit\\tfeels\\tgood,\\tthen\\tyou’re\\tmore\\tlikely\\tto\\tendure.\\nHabit\\ttracking\\talso\\thelps\\tkeep\\tyour\\teye\\ton\\tthe\\tball:\\tyou’re\\tfocused\\ton\\tthe\\nprocess\\trather\\tthan\\tthe\\tresult.\\tYou’re\\tnot\\tfixated\\ton\\tgetting\\tsix-pack\\tabs,\\tyou’re\\njust\\ttrying\\tto\\tkeep\\tthe\\tstreak\\talive\\tand\\tbecome\\tthe\\ttype\\tof\\tperson\\twho\\tdoesn’t\\nmiss\\tworkouts.\\nIn\\tsummary,\\thabit\\ttracking\\t(1)\\tcreates\\ta\\tvisual\\tcue\\tthat\\tcan\\tremind\\tyou\\tto\\tact,\\n(2)\\tis\\tinherently\\tmotivating\\tbecause\\tyou\\tsee\\tthe\\tprogress\\tyou\\tare\\tmaking\\tand\\ndon’t\\twant\\tto\\tlose\\tit,\\tand\\t(3)\\tfeels\\tsatisfying\\twhenever\\tyou\\trecord\\tanother\\nsuccessful\\tinstance\\tof\\tyour\\thabit.\\tFurthermore,\\thabit\\ttracking\\tprovides\\tvisual\\nproof\\tthat\\tyou\\tare\\tcasting\\tvotes\\t\\nfor\\tthe\\ttype\\tof\\tperson\\tyou\\twish\\tto\\tbecome,\\nwhich\\tis\\ta\\tdelightful\\tform\\tof\\timmediate\\tand\\tintrinsic\\tgratification.\\n*\\nYou\\tmay\\tbe\\twondering,\\tif\\thabit\\ttracking\\tis\\tso\\tuseful,\\twhy\\thave\\tI\\twaited\\tso\\nlong\\tto\\ttalk\\tabout\\tit?\\nDespite\\tall\\tthe\\tbenefits,\\tI’ve\\tleft\\tthis\\tdiscussion\\tuntil\\tnow\\tfor\\ta\\tsimple\\treason:\\nmany\\tpeople\\tresist\\tthe\\tidea\\tof\\ttracking\\tand\\tmeasuring.\\tIt\\tcan\\tfeel\\tlike\\ta\\tburden', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 153}), Document(page_content='because\\tit\\tforces\\tyou\\tinto\\t\\ntwo\\n\\thabits:\\tthe\\thabit\\tyou’re\\ttrying\\tto\\tbuild\\tand\\tthe\\nhabit\\tof\\ttracking\\tit.\\tCounting\\tcalories\\tsounds\\tlike\\ta\\thassle\\twhen\\tyou’re\\talready\\nstruggling\\tto\\tfollow\\ta\\tdiet.\\tWriting\\tdown\\tevery\\tsales\\tcall\\tseems\\ttedious\\twhen\\nyou’ve\\tgot\\twork\\tto\\tdo.\\tIt\\tfeels\\teasier\\tto\\tsay,\\t“I’ll\\tjust\\teat\\tless.”\\tOr,\\t“I’ll\\ttry\\nharder.”\\tOr,\\t“I’ll\\tremember\\tto\\tdo\\tit.”\\tPeople\\tinevitably\\ttell\\tme\\tthings\\tlike,\\t“I\\nhave\\ta\\tdecision\\tjournal,\\tbut\\tI\\twish\\tI\\tused\\tit\\tmore.”\\tOr,\\t“I\\trecorded\\tmy\\tworkouts\\nfor\\ta\\tweek,\\tbut\\tthen\\tquit.”\\tI’ve\\tbeen\\tthere\\tmyself.\\tI\\tonce\\tmade\\ta\\tfood\\tlog\\tto\\ntrack\\tmy\\tcalories.\\tI\\tmanaged\\tto\\tdo\\tit\\tfor\\t\\none\\tmeal\\n\\tand\\tthen\\tgave\\tup.\\nTracking\\tisn’t\\tfor\\teveryone,\\tand\\tthere\\tis\\tno\\tneed\\tto\\tmeasure\\tyour\\tentire\\tlife.\\nBut\\tnearly\\tanyone\\tcan\\tbenefit\\tfrom\\tit\\tin\\tsome\\tform—even\\tif\\tit’s\\tonly\\ttemporary.\\nWhat\\tcan\\twe\\tdo\\tto\\tmake\\ttracking\\teasier?\\nFirst,\\twhenever\\tpossible,\\tmeasurement\\tshould\\tbe\\tautomated.\\tYou’ll\\tprobably\\nbe\\tsurprised\\tby\\thow\\tmuch\\tyou’re\\talready\\ttracking\\twithout\\tknowing\\tit.\\tYour\\ncredit\\tcard\\tstatement\\ttracks\\thow\\toften\\tyou\\tgo\\tout\\tto\\teat.\\tYour\\tFitbit\\tregisters\\nhow\\tmany\\tsteps\\tyou\\ttake\\tand\\thow\\tlong\\tyou\\tsleep.\\tYour\\tcalendar\\trecords\\thow\\nmany\\tnew\\tplaces\\tyou\\ttravel\\tto\\teach\\tyear.\\tOnce\\tyou\\tknow\\twhere\\tto\\tget\\tthe\\tdata,\\nadd\\ta\\tnote\\tto\\tyour\\tcalendar\\tto\\treview\\tit\\teach\\tweek\\tor\\teach\\tmonth,\\twhich\\tis\\tmore\\npractical\\tthan\\ttracking\\tit\\tevery\\tday.\\nSecond,\\tmanual\\ttracking\\tshould\\tbe\\tlimited\\tto\\tyour\\tmost\\timportant\\t\\nhabits.\\tIt\\tis\\nbetter\\tto\\tconsistently\\ttrack\\tone\\thabit\\tthan\\tto\\tsporadically\\ttrack\\tten.\\nFinally,\\trecord\\teach\\tmeasurement\\timmediately\\tafter\\tthe\\thabit\\toccurs.\\tThe\\ncompletion\\tof\\tthe\\tbehavior\\tis\\tthe\\tcue\\tto\\twrite\\tit\\tdown.\\tThis\\tapproach\\tallows\\tyou\\nto\\tcombine\\tthe\\thabitstacking\\tmethod\\tmentioned\\tin\\tChapter\\t5\\twith\\thabit\\ttracking.\\nThe\\thabit\\tstacking\\t+\\thabit\\ttracking\\tformula\\tis:\\nAfter\\t[CURRENT\\tHABIT],\\tI\\twill\\t[TRACK\\tMY\\tHABIT].\\nAfter\\tI\\thang\\tup\\tthe\\tphone\\tfrom\\ta\\tsales\\tcall,\\tI\\twill\\tmove\\tone\\tpaper\\tclip\\nover.\\nAfter\\tI\\tfinish\\teach\\tset\\tat\\tthe\\tgym,\\tI\\twill\\trecord\\tit\\tin\\tmy\\tworkout\\njournal.\\nAfter\\tI\\tput\\tmy\\tplate\\tin\\tthe\\tdishwasher,\\tI\\twill\\twrite\\tdown\\twhat\\tI\\tate.\\nThese\\ttactics\\tcan\\tmake\\ttracking\\tyour\\thabits\\teasier.\\tEven\\tif\\tyou\\taren’t\\tthe\\ttype\\nof\\tperson\\twho\\tenjoys\\trecording\\tyour\\tbehavior,\\tI\\tthink\\tyou’ll\\tfind\\ta\\tfew\\tweeks\\tof\\nmeasurements\\tto\\tbe\\tinsightful.\\tIt’s\\talways\\tinteresting\\tto\\tsee\\thow\\tyou’ve\\t\\nactually', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 154}), Document(page_content='been\\tspending\\tyour\\ttime.\\nThat\\tsaid,\\tevery\\thabit\\tstreak\\tends\\tat\\tsome\\tpoint.\\tAnd,\\tmore\\timportant\\tthan\\nany\\tsingle\\tmeasurement,\\tis\\thaving\\ta\\tgood\\tplan\\tfor\\twhen\\tyour\\thabits\\tslide\\toff\\ntrack.\\nHOW\\tTO\\tRECOVER\\tQUICKLY\\tWHEN\\tYOUR\\tHABITS\\tBREAK\\tDOWN\\nNo\\tmatter\\thow\\tconsistent\\tyou\\tare\\twith\\tyour\\thabits,\\tit\\tis\\tinevitable\\tthat\\tlife\\twill\\ninterrupt\\tyou\\tat\\tsome\\tpoint.\\tPerfection\\tis\\tnot\\tpossible.\\tBefore\\tlong,\\tan\\nemergency\\twill\\tpop\\tup—you\\tget\\tsick\\tor\\tyou\\thave\\tto\\ttravel\\tfor\\twork\\tor\\tyour\\nfamily\\tneeds\\ta\\tlittle\\tmore\\tof\\tyour\\ttime.\\nWhenever\\tthis\\thappens\\tto\\tme,\\tI\\ttry\\tto\\tremind\\tmyself\\tof\\ta\\tsimple\\trule:\\tnever\\nmiss\\ttwice.\\nIf\\tI\\tmiss\\tone\\tday,\\tI\\ttry\\tto\\tget\\tback\\tinto\\tit\\tas\\tquickly\\tas\\tpossible.\\tMissing\\tone\\nworkout\\thappens,\\tbut\\tI’m\\tnot\\tgoing\\tto\\tmiss\\ttwo\\tin\\ta\\trow.\\tMaybe\\tI’ll\\teat\\tan\\nentire\\tpizza,\\tbut\\tI’ll\\tfollow\\tit\\tup\\twith\\ta\\thealthy\\tmeal.\\tI\\tcan’t\\tbe\\tperfect,\\tbut\\tI\\tcan\\navoid\\ta\\tsecond\\tlapse.\\tAs\\tsoon\\tas\\tone\\tstreak\\tends,\\tI\\tget\\tstarted\\ton\\tthe\\tnext\\tone.\\nThe\\tfirst\\tmistake\\tis\\tnever\\tthe\\tone\\tthat\\truins\\tyou.\\tIt\\tis\\tthe\\tspiral\\tof\\trepeated\\nmistakes\\tthat\\tfollows.\\t\\nMissing\\tonce\\tis\\tan\\taccident.\\tMissing\\ttwice\\tis\\tthe\\tstart\\tof\\ta\\nnew\\thabit.\\nThis\\tis\\ta\\tdistinguishing\\tfeature\\tbetween\\twinners\\tand\\tlosers.\\tAnyone\\tcan\\thave\\na\\tbad\\tperformance,\\ta\\tbad\\tworkout,\\tor\\ta\\tbad\\tday\\tat\\twork.\\tBut\\twhen\\tsuccessful\\npeople\\tfail,\\tthey\\trebound\\tquickly.\\tThe\\tbreaking\\tof\\ta\\thabit\\tdoesn’t\\tmatter\\tif\\tthe\\nreclaiming\\tof\\tit\\tis\\tfast.\\nI\\tthink\\tthis\\tprinciple\\tis\\tso\\timportant\\tthat\\tI’ll\\tstick\\tto\\tit\\teven\\tif\\tI\\tcan’t\\tdo\\ta\\nhabit\\tas\\twell\\tor\\tas\\tcompletely\\tas\\tI\\twould\\tlike.\\tToo\\toften,\\twe\\tfall\\tinto\\tan\\tall-or-\\nnothing\\tcycle\\twith\\tour\\thabits.\\tThe\\tproblem\\tis\\tnot\\tslipping\\tup;\\tthe\\tproblem\\tis\\nthinking\\tthat\\tif\\tyou\\tcan’t\\tdo\\tsomething\\tperfectly,\\tthen\\tyou\\tshouldn’t\\tdo\\tit\\tat\\tall.\\nYou\\tdon’t\\trealize\\thow\\tvaluable\\tit\\tis\\tto\\tjust\\tshow\\tup\\ton\\tyour\\tbad\\t(or\\tbusy)\\ndays.\\tLost\\tdays\\thurt\\tyou\\tmore\\tthan\\tsuccessful\\tdays\\thelp\\tyou.\\tIf\\tyou\\tstart\\twith\\n$100,\\tthen\\ta\\t50\\tpercent\\tgain\\twill\\ttake\\tyou\\tto\\t$150.\\tBut\\tyou\\tonly\\tneed\\ta\\t33\\npercent\\tloss\\tto\\ttake\\tyou\\tback\\tto\\t$100.\\tIn\\tother\\twords,\\tavoiding\\ta\\t33\\tpercent\\tloss\\nis\\tjust\\tas\\tvaluable\\tas\\tachieving\\ta\\t50\\tpercent\\tgain.\\tAs\\tCharlie\\tMunger\\tsays,\\t“The\\nfirst\\trule\\tof\\tcompounding:\\tNever\\tinterrupt\\tit\\tunnecessarily.”\\nThis\\tis\\twhy\\tthe\\t“bad”\\tworkouts\\tare\\toften\\tthe\\tmost\\timportant\\tones.\\tSluggish\\ndays\\tand\\tbad\\tworkouts\\tmaintain\\tthe\\tcompound\\tgains\\tyou\\taccrued\\tfrom\\tprevious\\ngood\\tdays.\\tSimply\\tdoing\\tsomething—ten\\tsquats,\\tfive\\tsprints,\\ta\\tpush-up,\\nanything\\treally—is\\thuge.\\tDon’t\\tput\\tup\\ta\\tzero.\\tDon’t\\tlet\\tlosses\\teat\\tinto\\tyour', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 155}), Document(page_content='compounding.\\nFurthermore,\\tit’s\\tnot\\talways\\tabout\\twhat\\thappens\\tduring\\tthe\\tworkout.\\tIt’s\\nabout\\tbeing\\tthe\\ttype\\tof\\tperson\\twho\\tdoesn’t\\tmiss\\tworkouts.\\tIt’s\\teasy\\tto\\ttrain\\nwhen\\tyou\\tfeel\\tgood,\\tbut\\tit’s\\tcrucial\\tto\\tshow\\tup\\twhen\\tyou\\tdon’t\\tfeel\\tlike\\tit—\\neven\\tif\\tyou\\tdo\\tless\\tthan\\tyou\\thope.\\tGoing\\tto\\tthe\\tgym\\tfor\\tfive\\tminutes\\tmay\\tnot\\nimprove\\tyour\\tperformance,\\tbut\\tit\\treaffirms\\tyour\\tidentity.\\nThe\\tall-or-nothing\\tcycle\\tof\\tbehavior\\tchange\\tis\\tjust\\tone\\tpitfall\\tthat\\tcan\\tderail\\nyour\\thabits.\\tAnother\\tpotential\\tdanger—especially\\tif\\tyou\\tare\\tusing\\ta\\thabit\\ttracker\\n—is\\tmeasuring\\tthe\\twrong\\tthing.\\nKNOWING\\tWHEN\\t(AND\\tWHEN\\tNOT)\\tTO\\tTRACK\\tA\\tHABIT\\nSay\\tyou’re\\trunning\\ta\\trestaurant\\tand\\tyou\\twant\\tto\\tknow\\tif\\tyour\\tchef\\tis\\tdoing\\ta\\ngood\\tjob.\\tOne\\tway\\tto\\tmeasure\\tsuccess\\tis\\tto\\ttrack\\thow\\tmany\\tcustomers\\tpay\\tfor\\ta\\nmeal\\teach\\tday.\\tIf\\tmore\\tcustomers\\tcome\\tin,\\tthe\\tfood\\tmust\\tbe\\tgood.\\tIf\\tfewer\\ncustomers\\tcome\\tin,\\tsomething\\tmust\\tbe\\twrong.\\nHowever,\\tthis\\tone\\tmeasurement—daily\\trevenue—only\\tgives\\ta\\tlimited\\tpicture\\nof\\twhat’s\\treally\\tgoing\\ton.\\tJust\\tbecause\\tsomeone\\tpays\\tfor\\ta\\tmeal\\tdoesn’t\\tmean\\nthey\\t\\nenjoy\\n\\tthe\\tmeal.\\tEven\\tdissatisfied\\tcustomers\\tare\\tunlikely\\tto\\tdine\\tand\\tdash.\\nIn\\tfact,\\tif\\tyou’re\\tonly\\tmeasuring\\trevenue,\\tthe\\tfood\\tmight\\tbe\\tgetting\\tworse\\tbut\\nyou’re\\tmaking\\tup\\tfor\\tit\\twith\\tmarketing\\tor\\tdiscounts\\tor\\tsome\\tother\\tmethod.\\nInstead,\\tit\\tmay\\tbe\\tmore\\teffective\\tto\\ttrack\\thow\\tmany\\tcustomers\\t\\nfinish\\n\\ttheir\\tmeal\\nor\\tperhaps\\tthe\\tpercentage\\tof\\tcustomers\\twho\\tleave\\ta\\tgenerous\\ttip.\\nThe\\tdark\\tside\\tof\\ttracking\\ta\\tparticular\\tbehavior\\tis\\tthat\\twe\\tbecome\\tdriven\\tby\\nthe\\tnumber\\trather\\tthan\\tthe\\tpurpose\\tbehind\\tit.\\tIf\\tyour\\tsuccess\\tis\\tmeasured\\tby\\nquarterly\\tearnings,\\tyou\\twill\\toptimize\\tsales,\\trevenue,\\tand\\taccounting\\tfor\\nquarterly\\tearnings.\\tIf\\tyour\\tsuccess\\tis\\tmeasured\\tby\\ta\\tlower\\tnumber\\ton\\tthe\\tscale,\\nyou\\twill\\toptimize\\tfor\\ta\\tlower\\tnumber\\t\\non\\tthe\\tscale,\\teven\\tif\\tthat\\tmeans\\tembracing\\ncrash\\tdiets,\\tjuice\\tcleanses,\\tand\\tfat-loss\\tpills.\\tThe\\thuman\\tmind\\twants\\tto\\t“win”\\nwhatever\\tgame\\tis\\tbeing\\tplayed.\\nThis\\tpitfall\\tis\\tevident\\tin\\tmany\\tareas\\tof\\tlife.\\tWe\\tfocus\\ton\\tworking\\tlong\\thours\\ninstead\\tof\\tgetting\\tmeaningful\\twork\\tdone.\\tWe\\tcare\\tmore\\tabout\\tgetting\\tten\\nthousand\\tsteps\\tthan\\twe\\tdo\\tabout\\tbeing\\thealthy.\\tWe\\tteach\\tfor\\tstandardized\\ttests\\ninstead\\tof\\temphasizing\\tlearning,\\tcuriosity,\\tand\\tcritical\\tthinking.\\tIn\\tshort,\\twe\\noptimize\\tfor\\twhat\\twe\\tmeasure.\\tWhen\\twe\\tchoose\\tthe\\twrong\\tmeasurement,\\twe\\tget\\nthe\\twrong\\tbehavior.\\nThis\\tis\\tsometimes\\treferred\\tto\\tas\\tGoodhart’s\\tLaw.\\tNamed\\tafter\\tthe\\teconomist\\nCharles\\tGoodhart,\\tthe\\tprinciple\\tstates,\\t“\\nWhen\\ta\\tmeasure\\tbecomes\\ta\\ttarget,\\tit', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 156}), Document(page_content='ceases\\tto\\tbe\\ta\\tgood\\tmeasure.”\\tMeasurement\\tis\\tonly\\tuseful\\twhen\\tit\\tguides\\tyou\\nand\\tadds\\tcontext\\tto\\ta\\tlarger\\tpicture,\\tnot\\twhen\\tit\\tconsumes\\tyou.\\tEach\\tnumber\\tis\\nsimply\\tone\\tpiece\\tof\\tfeedback\\tin\\tthe\\toverall\\tsystem.\\nIn\\tour\\tdata-driven\\tworld,\\twe\\ttend\\tto\\tovervalue\\tnumbers\\tand\\tundervalue\\nanything\\tephemeral,\\tsoft,\\tand\\tdifficult\\tto\\tquantify.\\tWe\\tmistakenly\\tthink\\tthe\\nfactors\\twe\\tcan\\tmeasure\\tare\\tthe\\tonly\\tfactors\\tthat\\texist.\\tBut\\tjust\\tbecause\\tyou\\tcan\\nmeasure\\tsomething\\tdoesn’t\\tmean\\tit’s\\tthe\\tmost\\timportant\\tthing.\\tAnd\\tjust\\tbecause\\nyou\\t\\ncan’t\\n\\tmeasure\\tsomething\\tdoesn’t\\tmean\\tit’s\\tnot\\timportant\\tat\\tall.\\nAll\\tof\\tthis\\tto\\tsay,\\tit’s\\tcrucial\\tto\\tkeep\\thabit\\ttracking\\tin\\tits\\tproper\\tplace.\\tIt\\tcan\\nfeel\\tsatisfying\\tto\\trecord\\ta\\thabit\\tand\\ttrack\\tyour\\tprogress,\\tbut\\tthe\\tmeasurement\\tis\\nnot\\tthe\\tonly\\tthing\\tthat\\tmatters.\\tFurthermore,\\tthere\\tare\\tmany\\tways\\tto\\tmeasure\\nprogress,\\tand\\tsometimes\\tit\\thelps\\tto\\tshift\\tyour\\tfocus\\tto\\tsomething\\tentirely\\ndifferent.\\nThis\\tis\\twhy\\t\\nnonscale\\tvictories\\n\\tcan\\tbe\\teffective\\tfor\\tweight\\tloss.\\tThe\\tnumber\\non\\tthe\\tscale\\tmay\\tbe\\tstubborn,\\tso\\tif\\tyou\\tfocus\\tsolely\\ton\\tthat\\tnumber,\\tyour\\nmotivation\\twill\\tsag.\\tBut\\tyou\\tmay\\tnotice\\tthat\\tyour\\tskin\\tlooks\\tbetter\\tor\\tyou\\twake\\nup\\tearlier\\tor\\tyour\\tsex\\tdrive\\tgot\\ta\\tboost.\\tAll\\tof\\tthese\\tare\\tvalid\\tways\\tto\\ttrack\\tyour\\nimprovement.\\tIf\\tyou’re\\tnot\\tfeeling\\t\\nmotivated\\tby\\tthe\\tnumber\\ton\\tthe\\tscale,\\nperhaps\\tit’s\\ttime\\tto\\tfocus\\ton\\ta\\tdifferent\\tmeasurement—one\\tthat\\tgives\\tyou\\tmore\\nsignals\\tof\\tprogress.\\nNo\\tmatter\\thow\\tyou\\tmeasure\\tyour\\timprovement,\\thabit\\ttracking\\toffers\\ta\\tsimple\\nway\\tto\\tmake\\tyour\\thabits\\tmore\\tsatisfying.\\tEach\\tmeasurement\\tprovides\\ta\\tlittle\\tbit\\nof\\tevidence\\tthat\\tyou’re\\tmoving\\tin\\tthe\\tright\\tdirection\\tand\\ta\\tbrief\\tmoment\\tof\\nimmediate\\tpleasure\\tfor\\ta\\tjob\\twell\\tdone.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 157}), Document(page_content='Chapter\\tSummary\\nOne\\tof\\tthe\\tmost\\tsatisfying\\tfeelings\\tis\\tthe\\tfeeling\\tof\\tmaking\\tprogress.\\nA\\thabit\\ttracker\\tis\\ta\\tsimple\\tway\\tto\\tmeasure\\twhether\\tyou\\tdid\\ta\\thabit—\\nlike\\tmarking\\tan\\tX\\ton\\ta\\tcalendar.\\nHabit\\ttrackers\\tand\\tother\\tvisual\\tforms\\tof\\tmeasurement\\tcan\\tmake\\tyour\\nhabits\\tsatisfying\\tby\\tproviding\\tclear\\tevidence\\tof\\tyour\\tprogress.\\nDon’t\\tbreak\\tthe\\tchain.\\tTry\\tto\\tkeep\\tyour\\thabit\\tstreak\\talive.\\nNever\\tmiss\\ttwice.\\tIf\\tyou\\tmiss\\tone\\tday,\\ttry\\tto\\tget\\tback\\ton\\ttrack\\tas\\nquickly\\tas\\tpossible.\\nJust\\tbecause\\tyou\\tcan\\tmeasure\\tsomething\\tdoesn’t\\tmean\\tit’s\\tthe\\tmost\\nimportant\\tthing.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 158}), Document(page_content='17\\nHow\\tan\\tAccountability\\tPartner\\tCan\\tChange\\nEverything\\nA\\nFTER\\tSERVING\\tAS\\t\\na\\tpilot\\tin\\tWorld\\tWar\\tII,\\tRoger\\tFisher\\tattended\\tHarvard\\tLaw\\tSchool\\nand\\tspent\\tthirty-four\\tyears\\tspecializing\\tin\\tnegotiation\\tand\\tconflict\\tmanagement.\\nHe\\tfounded\\tthe\\tHarvard\\tNegotiation\\tProject\\tand\\tworked\\twith\\tnumerous\\ncountries\\tand\\tworld\\tleaders\\ton\\tpeace\\tresolutions,\\thostage\\tcrises,\\tand\\tdiplomatic\\ncompromises.\\tBut\\tit\\twas\\tin\\tthe\\t1970s\\tand\\t1980s,\\tas\\tthe\\tthreat\\tof\\tnuclear\\twar\\nescalated,\\tthat\\tFisher\\tdeveloped\\tperhaps\\this\\tmost\\tinteresting\\tidea.\\nAt\\tthe\\ttime,\\tFisher\\twas\\tfocused\\ton\\tdesigning\\tstrategies\\tthat\\tcould\\tprevent\\nnuclear\\twar,\\tand\\the\\thad\\tnoticed\\ta\\ttroubling\\tfact.\\tAny\\tsitting\\tpresident\\twould\\nhave\\taccess\\tto\\tlaunch\\tcodes\\tthat\\tcould\\tkill\\tmillions\\tof\\tpeople\\tbut\\twould\\tnever\\nactually\\tsee\\tanyone\\tdie\\tbecause\\the\\twould\\talways\\tbe\\tthousands\\tof\\tmiles\\taway.\\n“My\\tsuggestion\\twas\\tquite\\tsimple,”\\the\\twrote\\tin\\t1981.\\t“Put\\tthat\\t[nuclear]\\tcode\\nnumber\\tin\\ta\\tlittle\\tcapsule,\\tand\\tthen\\timplant\\tthat\\tcapsule\\tright\\tnext\\tto\\tthe\\theart\\tof\\na\\tvolunteer.\\tThe\\tvolunteer\\twould\\tcarry\\twith\\thim\\ta\\tbig,\\theavy\\tbutcher\\tknife\\tas\\the\\naccompanied\\tthe\\tPresident.\\tIf\\tever\\tthe\\tPresident\\twanted\\tto\\tfire\\tnuclear\\tweapons,\\nthe\\tonly\\tway\\the\\tcould\\tdo\\t\\nso\\twould\\tbe\\tfor\\thim\\tfirst,\\twith\\this\\town\\thands,\\tto\\tkill\\none\\thuman\\tbeing.\\tThe\\tPresident\\tsays,\\t‘George,\\tI’m\\tsorry\\tbut\\ttens\\tof\\tmillions\\nmust\\tdie.’\\tHe\\thas\\tto\\tlook\\tat\\tsomeone\\tand\\trealize\\twhat\\tdeath\\tis—what\\tan\\ninnocent\\tdeath\\tis.\\tBlood\\ton\\tthe\\tWhite\\tHouse\\tcarpet.\\tIt’s\\treality\\tbrought\\thome.\\n“\\nWhen\\tI\\tsuggested\\tthis\\tto\\tfriends\\tin\\tthe\\tPentagon\\tthey\\tsaid,\\t‘My\\tGod,\\tthat’s\\nterrible.\\tHaving\\tto\\tkill\\tsomeone\\twould\\tdistort\\tthe\\tPresident’s\\tjudgment.\\tHe\\nmight\\tnever\\tpush\\tthe\\tbutton.’”\\nThroughout\\tour\\tdiscussion\\tof\\tthe\\t4th\\tLaw\\tof\\tBehavior\\tChange\\twe\\thave\\ncovered\\tthe\\timportance\\tof\\tmaking\\tgood\\thabits\\timmediately\\tsatisfying.\\tFisher’s\\nproposal\\tis\\tan\\tinversion\\tof\\tthe\\t4th\\tLaw:\\t\\nMake\\tit\\timmediately\\tunsatisfying.\\nJust\\tas\\twe\\tare\\tmore\\tlikely\\tto\\trepeat\\tan\\texperience\\twhen\\tthe\\tending\\tis\\nsatisfying,\\twe\\tare\\talso\\tmore\\tlikely\\tto\\tavoid\\tan\\texperience\\twhen\\tthe\\tending\\tis', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 159}), Document(page_content='painful.\\tPain\\tis\\tan\\teffective\\tteacher.\\tIf\\ta\\tfailure\\tis\\tpainful,\\tit\\tgets\\tfixed.\\tIf\\ta\\nfailure\\tis\\trelatively\\tpainless,\\tit\\tgets\\tignored.\\tThe\\tmore\\timmediate\\tand\\tmore\\ncostly\\ta\\tmistake\\tis,\\tthe\\tfaster\\tyou\\twill\\tlearn\\tfrom\\tit.\\tThe\\tthreat\\tof\\ta\\tbad\\treview\\nforces\\ta\\tplumber\\tto\\tbe\\tgood\\tat\\this\\tjob.\\tThe\\tpossibility\\tof\\ta\\tcustomer\\tnever\\nreturning\\tmakes\\trestaurants\\tcreate\\tgood\\tfood.\\tThe\\tcost\\tof\\tcutting\\tthe\\twrong\\nblood\\tvessel\\tmakes\\ta\\tsurgeon\\tmaster\\thuman\\tanatomy\\tand\\tcut\\tcarefully.\\tWhen\\nthe\\tconsequences\\tare\\tsevere,\\tpeople\\tlearn\\tquickly.\\nThe\\tmore\\timmediate\\tthe\\tpain,\\tthe\\tless\\tlikely\\tthe\\tbehavior.\\tIf\\tyou\\twant\\tto\\nprevent\\tbad\\thabits\\tand\\teliminate\\tunhealthy\\tbehaviors,\\tthen\\tadding\\tan\\tinstant\\tcost\\nto\\tthe\\taction\\tis\\ta\\tgreat\\tway\\tto\\treduce\\ttheir\\todds.\\nWe\\trepeat\\tbad\\thabits\\tbecause\\tthey\\tserve\\tus\\tin\\tsome\\tway,\\tand\\tthat\\tmakes\\tthem\\nhard\\tto\\tabandon.\\tThe\\tbest\\tway\\tI\\tknow\\tto\\tovercome\\tthis\\tpredicament\\tis\\tto\\nincrease\\tthe\\tspeed\\tof\\tthe\\tpunishment\\tassociated\\twith\\tthe\\tbehavior.\\tThere\\tcan’t\\nbe\\ta\\tgap\\tbetween\\tthe\\taction\\tand\\tthe\\tconsequences.\\nAs\\tsoon\\tas\\tactions\\tincur\\tan\\timmediate\\tconsequence,\\tbehavior\\tbegins\\tto\\nchange.\\tCustomers\\tpay\\ttheir\\tbills\\ton\\ttime\\twhen\\tthey\\tare\\tcharged\\ta\\tlate\\tfee.\\nStudents\\tshow\\tup\\tto\\tclass\\twhen\\ttheir\\tgrade\\tis\\tlinked\\tto\\tattendance.\\tWe’ll\\tjump\\nthrough\\ta\\tlot\\tof\\thoops\\tto\\tavoid\\ta\\tlittle\\tbit\\tof\\timmediate\\tpain.\\nThere\\tis,\\tof\\tcourse,\\ta\\tlimit\\tto\\tthis.\\tIf\\tyou’re\\tgoing\\tto\\trely\\ton\\tpunishment\\tto\\nchange\\tbehavior,\\tthen\\tthe\\tstrength\\tof\\tthe\\tpunishment\\tmust\\tmatch\\tthe\\trelative\\nstrength\\tof\\tthe\\tbehavior\\tit\\tis\\ttrying\\tto\\tcorrect.\\tTo\\tbe\\tproductive,\\tthe\\tcost\\tof\\nprocrastination\\tmust\\tbe\\tgreater\\tthan\\tthe\\tcost\\tof\\taction.\\tTo\\tbe\\thealthy,\\tthe\\tcost\\tof\\nlaziness\\tmust\\tbe\\tgreater\\tthan\\tthe\\tcost\\tof\\texercise.\\tGetting\\tfined\\tfor\\tsmoking\\tin\\ta\\nrestaurant\\tor\\tfailing\\tto\\trecycle\\tadds\\tconsequence\\tto\\tan\\taction.\\tBehavior\\tonly\\nshifts\\tif\\tthe\\tpunishment\\tis\\tpainful\\tenough\\tand\\treliably\\tenforced.\\nIn\\tgeneral,\\tthe\\tmore\\tlocal,\\ttangible,\\tconcrete,\\tand\\timmediate\\tthe\\tconsequence,\\nthe\\tmore\\tlikely\\tit\\tis\\tto\\tinfluence\\tindividual\\tbehavior.\\tThe\\tmore\\tglobal,\\nintangible,\\tvague,\\tand\\tdelayed\\tthe\\tconsequence,\\tthe\\tless\\tlikely\\tit\\tis\\tto\\tinfluence\\nindividual\\tbehavior.\\nThankfully,\\tthere\\tis\\ta\\tstraightforward\\tway\\tto\\tadd\\tan\\timmediate\\tcost\\tto\\tany\\nbad\\thabit:\\tcreate\\ta\\t\\nhabit\\tcontract\\n.\\nTHE\\tHABIT\\tCONTRACT\\nThe\\tfirst\\tseat\\tbelt\\tlaw\\twas\\tpassed\\tin\\tNew\\tYork\\ton\\tDecember\\t1,\\t1984.\\tAt\\tthe\\ntime,\\tjust\\t14\\tpercent\\tof\\tpeople\\tin\\tthe\\tUnited\\tStates\\tregularly\\twore\\ta\\tseat\\tbelt—\\nbut\\tthat\\twas\\tall\\tabout\\tto\\tchange.\\nWithin\\tfive\\tyears,\\tover\\thalf\\tof\\tthe\\tnation\\thad\\tseat\\tbelt\\tlaws.\\tToday,\\t\\nwearing\\ta', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 160}), Document(page_content='seat\\tbelt\\tis\\tenforceable\\tby\\tlaw\\tin\\tforty-nine\\tof\\tthe\\tfifty\\tstates.\\tAnd\\tit’s\\tnot\\tjust\\nthe\\tlegislation,\\tthe\\tnumber\\tof\\tpeople\\twearing\\tseat\\tbelts\\thas\\tchanged\\tdramatically\\nas\\twell.\\tIn\\t2016,\\t\\nover\\t88\\tpercent\\tof\\tAmericans\\tbuckled\\tup\\teach\\ttime\\tthey\\tgot\\tin\\na\\tcar.\\tIn\\tjust\\tover\\tthirty\\tyears,\\tthere\\twas\\ta\\tcomplete\\treversal\\tin\\tthe\\thabits\\tof\\nmillions\\tof\\tpeople.\\nLaws\\tand\\tregulations\\tare\\tan\\texample\\tof\\thow\\tgovernment\\tcan\\tchange\\tour\\nhabits\\tby\\tcreating\\ta\\tsocial\\tcontract.\\tAs\\ta\\tsociety,\\twe\\tcollectively\\tagree\\tto\\tabide\\nby\\tcertain\\trules\\tand\\tthen\\tenforce\\tthem\\tas\\ta\\tgroup.\\tWhenever\\ta\\tnew\\tpiece\\tof\\nlegislation\\timpacts\\tbehavior—seat\\tbelt\\tlaws,\\tbanning\\tsmoking\\tinside\\nrestaurants,\\tmandatory\\trecycling—it\\tis\\tan\\texample\\tof\\ta\\tsocial\\tcontract\\tshaping\\nour\\thabits.\\tThe\\tgroup\\tagrees\\tto\\tact\\tin\\ta\\tcertain\\tway,\\tand\\tif\\tyou\\tdon’t\\tfollow\\nalong,\\tyou’ll\\tbe\\tpunished.\\nJust\\tas\\tgovernments\\tuse\\tlaws\\tto\\thold\\tcitizens\\taccountable,\\tyou\\tcan\\tcreate\\ta\\nhabit\\tcontract\\tto\\thold\\tyourself\\taccountable.\\tA\\thabit\\tcontract\\tis\\ta\\tverbal\\tor\\nwritten\\tagreement\\tin\\twhich\\tyou\\tstate\\tyour\\tcommitment\\tto\\ta\\tparticular\\thabit\\tand\\nthe\\tpunishment\\tthat\\twill\\toccur\\tif\\tyou\\tdon’t\\tfollow\\tthrough.\\tThen\\tyou\\tfind\\tone\\tor\\ntwo\\tpeople\\tto\\tact\\tas\\tyour\\taccountability\\tpartners\\tand\\tsign\\toff\\ton\\tthe\\tcontract\\nwith\\tyou.\\nBryan\\tHarris,\\tan\\tentrepreneur\\tfrom\\tNashville,\\tTennessee,\\twas\\tthe\\tfirst\\tperson\\nI\\tsaw\\tput\\tthis\\tstrategy\\tinto\\taction.\\tShortly\\tafter\\tthe\\tbirth\\tof\\this\\tson,\\tHarris\\nrealized\\the\\twanted\\tto\\tshed\\ta\\tfew\\tpounds.\\tHe\\twrote\\tup\\ta\\thabit\\tcontract\\tbetween\\nhimself,\\this\\twife,\\tand\\this\\tpersonal\\ttrainer.\\tThe\\tfirst\\tversion\\tread,\\t“Bryan’s\\t#1\\nobjective\\tfor\\tQ1\\tof\\t2017\\tis\\tto\\tstart\\teating\\tcorrectly\\tagain\\tso\\the\\tfeels\\tbetter,\\tlooks\\nbetter,\\tand\\tis\\table\\tto\\thit\\this\\tlong-term\\tgoal\\tof\\t200\\tpounds\\tat\\t10%\\tbody\\tfat.”\\nBelow\\tthat\\tstatement,\\tHarris\\tlaid\\tout\\ta\\troad\\tmap\\tfor\\tachieving\\this\\tideal\\noutcome:\\nPhase\\t#1:\\tGet\\tback\\tto\\ta\\tstrict\\t“slow-carb”\\tdiet\\tin\\tQ1.\\nPhase\\t#2:\\tStart\\ta\\tstrict\\tmacronutrient\\ttracking\\tprogram\\tin\\tQ2.\\nPhase\\t#3:\\tRefine\\tand\\tmaintain\\tthe\\tdetails\\tof\\this\\tdiet\\tand\\tworkout\\nprogram\\tin\\tQ3.\\nFinally,\\the\\twrote\\tout\\teach\\tof\\tthe\\tdaily\\thabits\\tthat\\twould\\tget\\thim\\tto\\t\\nhis\\tgoal.\\nFor\\texample,\\t“Write\\tdown\\tall\\tfood\\tthat\\the\\tconsumes\\teach\\tday\\tand\\tweigh\\nhimself\\teach\\tday.”\\nAnd\\tthen\\the\\tlisted\\tthe\\tpunishment\\tif\\the\\tfailed:\\t“If\\tBryan\\tdoesn’t\\tdo\\tthese\\ttwo\\nitems\\tthen\\tthe\\tfollowing\\tconsequence\\twill\\tbe\\tenforced:\\tHe\\twill\\thave\\tto\\tdress\\tup', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 161}), Document(page_content='each\\tworkday\\tand\\teach\\tSunday\\tmorning\\tfor\\tthe\\trest\\tof\\tthe\\tquarter.\\tDress\\tup\\tis\\ndefined\\tas\\tnot\\twearing\\tjeans,\\tt-shirts,\\thoodies,\\tor\\tshorts.\\tHe\\twill\\talso\\tgive\\tJoey\\n(his\\ttrainer)\\t$200\\tto\\tuse\\tas\\the\\tsees\\tfit\\tif\\the\\tmisses\\tone\\tday\\tof\\tlogging\\tfood.”\\nAt\\tthe\\tbottom\\tof\\tthe\\tpage,\\tHarris,\\this\\twife,\\tand\\this\\ttrainer\\tall\\tsigned\\tthe\\ncontract.\\nMy\\tinitial\\treaction\\twas\\tthat\\ta\\tcontract\\tlike\\tthis\\tseemed\\toverly\\tformal\\tand\\nunnecessary,\\tespecially\\tthe\\tsignatures.\\tBut\\tHarris\\tconvinced\\tme\\tthat\\tsigning\\tthe\\ncontract\\twas\\tan\\tindication\\tof\\tseriousness.\\t“Anytime\\tI\\tskip\\tthis\\tpart,”\\the\\tsaid,\\t“I\\nstart\\tslacking\\talmost\\timmediately.”\\nThree\\tmonths\\tlater,\\tafter\\thitting\\this\\ttargets\\tfor\\tQ1,\\tHarris\\tupgraded\\this\\tgoals.\\nThe\\tconsequences\\tescalated,\\ttoo.\\tIf\\the\\tmissed\\this\\tcarbohydrate\\tand\\tprotein\\ntargets,\\the\\thad\\tto\\tpay\\this\\ttrainer\\t$100.\\tAnd\\tif\\the\\tfailed\\tto\\tweigh\\thimself,\\the\\thad\\nto\\tgive\\this\\twife\\t$500\\tto\\tuse\\tas\\tshe\\tsaw\\tfit.\\tPerhaps\\tmost\\tpainfully,\\tif\\the\\tforgot\\tto\\nrun\\tsprints,\\the\\thad\\tto\\tdress\\tup\\tfor\\twork\\tevery\\tday\\tand\\twear\\tan\\tAlabama\\that\\tthe\\nrest\\tof\\tthe\\tquarter—the\\tbitter\\trival\\tof\\this\\tbeloved\\tAuburn\\tteam.\\nThe\\tstrategy\\tworked.\\tWith\\this\\twife\\tand\\ttrainer\\tacting\\tas\\taccountability\\npartners\\tand\\twith\\tthe\\thabit\\tcontract\\tclarifying\\texactly\\twhat\\tto\\tdo\\teach\\tday,\\nHarris\\tlost\\tthe\\tweight.\\n*\\nTo\\tmake\\tbad\\thabits\\tunsatisfying,\\tyour\\tbest\\toption\\tis\\tto\\tmake\\tthem\\tpainful\\tin\\nthe\\tmoment.\\tCreating\\ta\\thabit\\tcontract\\tis\\ta\\tstraightforward\\tway\\tto\\tdo\\texactly\\tthat.\\nEven\\tif\\tyou\\tdon’t\\twant\\tto\\tcreate\\ta\\tfull-blown\\thabit\\tcontract,\\tsimply\\t\\nhaving\\tan\\naccountability\\tpartner\\tis\\tuseful.\\tThe\\tcomedian\\tMargaret\\tCho\\twrites\\ta\\tjoke\\tor\\nsong\\tevery\\tday.\\t\\nShe\\tdoes\\tthe\\t“song\\ta\\tday”\\tchallenge\\twith\\ta\\tfriend,\\twhich\\thelps\\nthem\\tboth\\tstay\\taccountable.\\tKnowing\\tthat\\tsomeone\\tis\\twatching\\tcan\\tbe\\ta\\npowerful\\tmotivator.\\tYou\\tare\\tless\\tlikely\\tto\\tprocrastinate\\tor\\tgive\\tup\\tbecause\\tthere\\nis\\tan\\timmediate\\tcost.\\tIf\\tyou\\tdon’t\\tfollow\\tthrough,\\tperhaps\\tthey’ll\\tsee\\tyou\\tas\\nuntrustworthy\\tor\\tlazy.\\tSuddenly,\\tyou\\tare\\tnot\\tonly\\tfailing\\tto\\tuphold\\tyour\\npromises\\tto\\tyourself,\\tbut\\talso\\tfailing\\tto\\tuphold\\tyour\\tpromises\\tto\\tothers.\\nYou\\tcan\\teven\\tautomate\\tthis\\tprocess.\\t\\nThomas\\tFrank,\\tan\\tentrepreneur\\tin\\nBoulder,\\tColorado,\\twakes\\tup\\tat\\t5:55\\teach\\tmorning.\\tAnd\\tif\\the\\tdoesn’t,\\the\\thas\\ta\\ntweet\\tautomatically\\tscheduled\\tthat\\tsays,\\t“It’s\\t6:10\\tand\\tI’m\\tnot\\tup\\tbecause\\tI’m\\nlazy!\\tReply\\tto\\tthis\\tfor\\t$5\\tvia\\tPayPal\\t(limit\\t5),\\tassuming\\tmy\\talarm\\tdidn’t\\nmalfunction.”\\nWe\\tare\\talways\\ttrying\\tto\\tpresent\\tour\\tbest\\tselves\\tto\\tthe\\tworld.\\tWe\\tcomb\\tour\\nhair\\tand\\tbrush\\tour\\tteeth\\tand\\tdress\\tourselves\\tcarefully\\tbecause\\twe\\tknow\\tthese\\nhabits\\tare\\tlikely\\tto\\tget\\ta\\tpositive\\treaction.\\tWe\\twant\\tto\\tget\\tgood\\tgrades\\tand\\ngraduate\\tfrom\\ttop\\tschools\\tto\\timpress\\tpotential\\temployers\\tand\\tmates\\tand\\tour\\nfriends\\tand\\tfamily.\\tWe\\tcare\\tabout\\tthe\\topinions\\tof\\tthose\\taround\\tus\\tbecause\\tit\\nhelps\\tif\\tothers\\tlike\\tus.\\tThis\\tis\\tprecisely\\twhy\\tgetting\\tan\\taccountability\\tpartner\\tor', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 162}), Document(page_content='signing\\ta\\thabit\\tcontract\\tcan\\twork\\tso\\twell.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 163}), Document(page_content='Chapter\\tSummary\\nThe\\tinversion\\tof\\tthe\\t4th\\tLaw\\tof\\tBehavior\\tChange\\tis\\t\\nmake\\tit\\nunsatisfying\\n.\\nWe\\tare\\tless\\tlikely\\tto\\trepeat\\ta\\tbad\\thabit\\tif\\tit\\tis\\tpainful\\tor\\tunsatisfying.\\nAn\\taccountability\\tpartner\\tcan\\tcreate\\tan\\timmediate\\tcost\\tto\\tinaction.\\tWe\\ncare\\tdeeply\\tabout\\twhat\\tothers\\tthink\\tof\\tus,\\tand\\twe\\tdo\\tnot\\twant\\tothers\\nto\\thave\\ta\\tlesser\\topinion\\tof\\tus.\\nA\\thabit\\tcontract\\tcan\\tbe\\tused\\tto\\tadd\\ta\\tsocial\\tcost\\tto\\tany\\tbehavior.\\tIt\\nmakes\\tthe\\tcosts\\tof\\tviolating\\tyour\\tpromises\\tpublic\\tand\\tpainful.\\nKnowing\\tthat\\tsomeone\\telse\\tis\\twatching\\tyou\\tcan\\tbe\\ta\\tpowerful\\nmotivator.\\nHOW\\tTO\\tCREATE\\tA\\tGOOD\\tHABIT\\nThe\\t1st\\tLaw:\\tMake\\tIt\\tObvious\\n1.1:\\n\\tFill\\tout\\tthe\\tHabits\\tScorecard.\\tWrite\\tdown\\tyour\\tcurrent\\thabits\\tto\\tbecome\\taware\\tof\\tthem.\\n1.2:\\n\\tUse\\timplementation\\tintentions:\\t“I\\twill\\t[BEHAVIOR]\\tat\\t[TIME]\\tin\\t[LOCATION].”\\n1.3:\\n\\tUse\\thabit\\tstacking:\\t“After\\t[CURRENT\\tHABIT],\\tI\\twill\\t[NEW\\tHABIT].”\\n1.4:\\n\\tDesign\\tyour\\tenvironment.\\tMake\\tthe\\tcues\\tof\\tgood\\thabits\\tobvious\\tand\\tvisible.\\nThe\\t2nd\\tLaw:Make\\tIt\\tAttractive\\n2.1:\\n\\tUse\\ttemptation\\tbundling.\\tPair\\tan\\taction\\tyou\\t\\nwant\\n\\tto\\tdo\\twith\\tan\\taction\\tyou\\t\\nneed\\n\\tto\\tdo.\\n2.2:\\n\\tJoin\\ta\\tculture\\twhere\\tyour\\tdesired\\tbehavior\\tis\\tthe\\tnormal\\tbehavior.\\n2.3:\\n\\tCreate\\ta\\tmotivation\\tritual.\\tDo\\tsomething\\tyou\\tenjoy\\timmediately\\tbefore\\ta\\tdifficult\\thabit.\\nThe\\t3rd\\tLaw:\\tMake\\tIt\\tEasy\\n3.1:\\n\\tReduce\\tfriction.\\tDecrease\\tthe\\tnumber\\tof\\tsteps\\tbetween\\tyou\\tand\\tyour\\tgood\\thabits.\\n3.2:\\n\\tPrime\\tthe\\tenvironment.\\tPrepare\\tyour\\tenvironment\\tto\\tmake\\tfuture\\tactions\\teasier.\\n3.3:\\n\\tMaster\\tthe\\tdecisive\\tmoment.\\tOptimize\\tthe\\tsmall\\tchoices\\tthat\\tdeliver\\toutsized\\timpact.\\n3.4:\\n\\tUse\\tthe\\tTwo-Minute\\tRule.\\tDownscale\\tyour\\thabits\\tuntil\\tthey\\tcan\\tbe\\tdone\\tin\\ttwo\\tminutes\\tor\\tless.\\n3.5:\\n\\tAutomate\\tyour\\thabits.\\tInvest\\tin\\ttechnology\\tand\\tonetime\\tpurchases\\tthat\\tlock\\tin\\tfuture\\tbehavior.\\nThe\\t4th\\tLaw:\\tMake\\tIt\\tSatisfying\\n4.1:\\n\\tUse\\treinforcement.\\tGive\\tyourself\\tan\\timmediate\\treward\\twhen\\tyou\\tcomplete\\tyour\\thabit.\\n4.2:\\n\\tMake\\t“doing\\tnothing”\\tenjoyable.\\tWhen\\tavoiding\\ta\\tbad\\thabit,\\tdesign\\ta\\tway\\tto\\tsee\\tthe\\tbenefits.\\n4.3:\\n\\tUse\\ta\\thabit\\ttracker.\\tKeep\\ttrack\\tof\\tyour\\thabit\\tstreak\\tand\\t“don’t\\tbreak\\tthe\\tchain.”\\n4.4:\\n\\tNever\\tmiss\\ttwice.\\tWhen\\tyou\\tforget\\tto\\tdo\\ta\\thabit,\\tmake\\tsure\\tyou\\tget\\tback\\ton\\ttrack\\timmediately.\\nHOW\\tTO\\tBREAK\\tA\\tBAD\\tHABIT\\nInversion\\tof\\tthe\\t1st\\tLaw:\\tMake\\tIt\\tInvisible', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 164}), Document(page_content='1.5:\\n\\tReduce\\texposure.\\tRemove\\tthe\\tcues\\tof\\tyour\\tbad\\thabits\\tfrom\\tyour\\tenvironment.\\nInversion\\tof\\tthe\\t2nd\\tLaw:\\tMake\\tIt\\tUnattractive\\n2.4:\\n\\tReframe\\tyour\\tmind-set.\\tHighlight\\tthe\\tbenefits\\tof\\tavoiding\\tyour\\tbad\\thabits.\\nInversion\\tof\\tthe\\t3rd\\tLaw:\\tMake\\tIt\\tDifficult\\n3.6:\\n\\tIncrease\\tfriction.\\tIncrease\\tthe\\tnumber\\tof\\tsteps\\tbetween\\tyou\\tand\\tyour\\tbad\\thabits.\\n3.7:\\n\\tUse\\ta\\tcommitment\\tdevice.\\tRestrict\\tyour\\tfuture\\tchoices\\tto\\tthe\\tones\\tthat\\tbenefit\\tyou.\\nInversion\\tof\\tthe\\t4th\\tLaw:\\tMake\\tIt\\tUnsatisfying\\n4.5:\\n\\tGet\\tan\\taccountability\\tpartner.\\tAsk\\tsomeone\\tto\\twatch\\tyour\\tbehavior.\\n4.6:\\n\\tCreate\\ta\\thabit\\tcontract.\\tMake\\tthe\\tcosts\\tof\\tyour\\tbad\\thabits\\tpublic\\tand\\tpainful.\\nYou\\tcan\\tdownload\\ta\\tprintable\\tversion\\tof\\tthis\\thabits\\tcheat\\tsheet\\tat:\\t\\natomichabits.com/cheatsheet', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 165}), Document(page_content='ADVANCED\\tTACTICS\\nHow\\tto\\tGo\\tfrom\\tBeing\\tMerely\\tGood\\tto\\tBeing\\nTruly\\tGreat', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 166}), Document(page_content='18\\nThe\\tTruth\\tAbout\\tTalent\\t(When\\tGenes\\tMatter\\nand\\tWhen\\tThey\\tDon’t)\\nM\\nANY\\tPEOPLE\\tARE\\t\\nfamiliar\\twith\\tMichael\\tPhelps,\\twho\\tis\\twidely\\tconsidered\\tto\\tbe\\tone\\tof\\nthe\\tgreatest\\tathletes\\tin\\thistory.\\t\\nPhelps\\thas\\twon\\tmore\\tOlympic\\tmedals\\tnot\\tonly\\nthan\\tany\\tswimmer\\tbut\\talso\\tmore\\tthan\\tany\\tOlympian\\tin\\t\\nany\\n\\tsport.\\nFewer\\tpeople\\tknow\\tthe\\tname\\tHicham\\t\\nEl\\tGuerrouj,\\tbut\\the\\twas\\ta\\tfantastic\\nathlete\\tin\\this\\town\\tright.\\tEl\\tGuerrouj\\tis\\ta\\tMoroccan\\trunner\\twho\\tholds\\ttwo\\nOlympic\\tgold\\tmedals\\tand\\tis\\tone\\tof\\tthe\\tgreatest\\tmiddle-distance\\trunners\\tof\\tall\\ntime.\\tFor\\tmany\\tyears,\\the\\theld\\tthe\\tworld\\trecord\\tin\\tthe\\tmile,\\t1,500-meter,\\tand\\n2,000-meter\\traces.\\tAt\\tthe\\tOlympic\\tGames\\tin\\tAthens,\\tGreece,\\tin\\t2004,\\the\\twon\\ngold\\tin\\tthe\\t1,500-meter\\tand\\t5,000-meter\\traces.\\nThese\\ttwo\\tathletes\\tare\\twildly\\tdifferent\\tin\\tmany\\tways.\\t(For\\tstarters,\\tone\\ncompeted\\ton\\tland\\tand\\tthe\\tother\\tin\\twater.)\\tBut\\tmost\\tnotably,\\t\\nthey\\tdiffer\\nsignificantly\\tin\\theight.\\tEl\\tGuerrouj\\tis\\tfive\\tfeet,\\tnine\\tinches\\ttall.\\tPhelps\\tis\\tsix\\nfeet,\\tfour\\tinches\\ttall.\\tDespite\\tthis\\tseven-inch\\tdifference\\tin\\theight,\\tthe\\ttwo\\tmen\\nare\\tidentical\\tin\\tone\\trespect:\\tMichael\\tPhelps\\tand\\tHicham\\tEl\\tGuerrouj\\twear\\tthe\\nsame\\tlength\\tinseam\\ton\\ttheir\\tpants.\\nHow\\tis\\tthis\\tpossible?\\tPhelps\\thas\\trelatively\\tshort\\tlegs\\tfor\\this\\theight\\tand\\ta\\tvery\\nlong\\ttorso,\\tthe\\tperfect\\tbuild\\tfor\\tswimming.\\tEl\\tGuerrouj\\thas\\tincredibly\\tlong\\tlegs\\nand\\ta\\tshort\\tupper\\tbody,\\tan\\tideal\\tframe\\tfor\\tdistance\\trunning.\\nNow,\\timagine\\tif\\tthese\\tworld-class\\tathletes\\twere\\tto\\tswitch\\tsports.\\tGiven\\this\\nremarkable\\tathleticism,\\tcould\\tMichael\\tPhelps\\tbecome\\tan\\tOlympic-caliber\\ndistance\\trunner\\twith\\tenough\\ttraining?\\tIt’s\\tunlikely.\\tAt\\tpeak\\tfitness,\\tPhelps\\nweighed\\t194\\tpounds,\\twhich\\tis\\t40\\tpercent\\theavier\\tthan\\tEl\\tGuerrouj,\\twho\\ncompeted\\tat\\tan\\tultralight\\t138\\tpounds.\\tTaller\\trunners\\tare\\theavier\\trunners,\\tand\\nevery\\textra\\tpound\\tis\\ta\\tcurse\\twhen\\tit\\tcomes\\tto\\tdistance\\trunning.\\tAgainst\\telite\\ncompetition,\\tPhelps\\twould\\tbe\\tdoomed\\tfrom\\tthe\\tstart.\\nSimilarly,\\tEl\\tGuerrouj\\tmight\\tbe\\tone\\tof\\tthe\\tbest\\trunners\\tin\\thistory,\\tbut\\tit’s', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 167}), Document(page_content='doubtful\\the\\twould\\tever\\tqualify\\tfor\\tthe\\tOlympics\\tas\\ta\\tswimmer.\\tSince\\t1976,\\tthe\\naverage\\theight\\tof\\tOlympic\\tgold\\tmedalists\\tin\\tthe\\tmen’s\\t1,500-meter\\trun\\tis\\tfive\\nfeet,\\tten\\tinches.\\tIn\\tcomparison,\\tthe\\t\\naverage\\theight\\tof\\tOlympic\\tgold\\tmedalists\\tin\\nthe\\tmen’s\\t100-meter\\tfreestyle\\tswim\\tis\\tsix\\tfeet,\\tfour\\tinches.\\tSwimmers\\ttend\\tto\\tbe\\ntall\\tand\\thave\\tlong\\tbacks\\tand\\tarms,\\twhich\\tare\\tideal\\tfor\\tpulling\\tthrough\\tthe\\twater.\\nEl\\tGuerrouj\\twould\\tbe\\tat\\ta\\tsevere\\tdisadvantage\\tbefore\\the\\tever\\ttouched\\tthe\\tpool.\\nThe\\tsecret\\tto\\tmaximizing\\tyour\\todds\\tof\\tsuccess\\tis\\tto\\tchoose\\tthe\\tright\\tfield\\tof\\ncompetition.\\tThis\\tis\\tjust\\tas\\ttrue\\twith\\thabit\\tchange\\tas\\tit\\tis\\twith\\tsports\\tand\\nbusiness.\\tHabits\\tare\\teasier\\tto\\tperform,\\tand\\tmore\\tsatisfying\\tto\\tstick\\twith,\\twhen\\nthey\\talign\\twith\\tyour\\tnatural\\tinclinations\\tand\\tabilities.\\tLike\\tMichael\\tPhelps\\tin\\tthe\\npool\\tor\\tHicham\\tEl\\tGuerrouj\\ton\\tthe\\ttrack,\\tyou\\twant\\tto\\tplay\\ta\\tgame\\twhere\\tthe\\nodds\\tare\\tin\\tyour\\tfavor.\\nEmbracing\\tthis\\tstrategy\\trequires\\tthe\\tacceptance\\tof\\tthe\\tsimple\\ttruth\\tthat\\tpeople\\nare\\tborn\\twith\\tdifferent\\tabilities.\\tSome\\tpeople\\tdon’t\\tlike\\tto\\tdiscuss\\tthis\\tfact.\\tOn\\nthe\\tsurface,\\tyour\\tgenes\\tseem\\tto\\tbe\\tfixed,\\tand\\tit’s\\t\\nno\\tfun\\tto\\ttalk\\tabout\\tthings\\tyou\\ncannot\\tcontrol.\\tPlus,\\tphrases\\tlike\\t\\nbiological\\tdeterminism\\n\\tmakes\\tit\\tsound\\tlike\\ncertain\\tindividuals\\tare\\tdestined\\tfor\\tsuccess\\tand\\tothers\\tdoomed\\tto\\tfailure.\\tBut\\nthis\\tis\\ta\\tshortsighted\\tview\\tof\\tthe\\tinfluence\\tof\\tgenes\\ton\\tbehavior.\\nThe\\tstrength\\tof\\tgenetics\\tis\\talso\\ttheir\\tweakness.\\tGenes\\tcannot\\tbe\\teasily\\nchanged,\\twhich\\tmeans\\tthey\\tprovide\\ta\\tpowerful\\tadvantage\\tin\\tfavorable\\ncircumstances\\tand\\ta\\tserious\\tdisadvantage\\tin\\tunfavorable\\tcircumstances.\\tIf\\tyou\\nwant\\tto\\tdunk\\ta\\tbasketball,\\tbeing\\tseven\\tfeet\\ttall\\tis\\tvery\\tuseful.\\tIf\\tyou\\twant\\tto\\nperform\\ta\\tgymnastics\\troutine,\\tbeing\\tseven\\tfeet\\ttall\\tis\\ta\\tgreat\\thindrance.\\tOur\\nenvironment\\tdetermines\\tthe\\tsuitability\\tof\\tour\\tgenes\\tand\\tthe\\tutility\\tof\\tour\\tnatural\\ntalents.\\tWhen\\tour\\tenvironment\\tchanges,\\tso\\tdo\\tthe\\tqualities\\tthat\\tdetermine\\nsuccess.\\nThis\\tis\\ttrue\\tnot\\tjust\\tfor\\tphysical\\tcharacteristics\\tbut\\tfor\\tmental\\tones\\tas\\twell.\\nI’m\\tsmart\\tif\\tyou\\task\\tme\\tabout\\thabits\\tand\\thuman\\tbehavior;\\tnot\\tso\\tmuch\\twhen\\tit\\ncomes\\tto\\tknitting,\\trocket\\tpropulsion,\\tor\\tguitar\\tchords.\\tCompetence\\tis\\thighly\\ndependent\\ton\\tcontext.\\nThe\\tpeople\\tat\\tthe\\ttop\\tof\\tany\\tcompetitive\\tfield\\tare\\tnot\\tonly\\twell\\ttrained,\\tthey\\nare\\talso\\twell\\tsuited\\tto\\tthe\\ttask.\\tAnd\\tthis\\tis\\twhy,\\tif\\tyou\\twant\\tto\\tbe\\ttruly\\tgreat,\\nselecting\\tthe\\tright\\tplace\\tto\\tfocus\\tis\\tcrucial.\\nIn\\tshort:\\tgenes\\tdo\\tnot\\tdetermine\\tyour\\tdestiny.\\tThey\\tdetermine\\tyour\\tareas\\tof\\nopportunity.\\tAs\\tphysician\\tGabor\\tMate\\tnotes,\\t“\\nGenes\\tcan\\tpredispose,\\tbut\\tthey\\ndon’t\\tpredetermine.”\\tThe\\tareas\\twhere\\tyou\\tare\\tgenetically\\tpredisposed\\tto\\tsuccess\\nare\\tthe\\tareas\\twhere\\thabits\\tare\\tmore\\tlikely\\tto\\tbe\\tsatisfying.\\tThe\\tkey\\tis\\tto\\tdirect\\nyour\\teffort\\ttoward\\tareas\\tthat\\tboth\\texcite\\tyou\\tand\\tmatch\\tyour\\tnatural\\tskills,\\tto\\nalign\\tyour\\tambition\\twith\\tyour\\tability.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 168}), Document(page_content='The\\tobvious\\tquestion\\tis,\\t“How\\tdo\\tI\\tfigure\\tout\\twhere\\tthe\\todds\\tare\\tin\\tmy\\nfavor?\\tHow\\tdo\\tI\\tidentify\\tthe\\topportunities\\tand\\thabits\\tthat\\tare\\tright\\tfor\\tme?”\\tThe\\nfirst\\tplace\\twe\\twill\\tlook\\tfor\\tan\\tanswer\\tis\\tby\\tunderstanding\\tyour\\tpersonality.\\nHOW\\tYOUR\\tPERSONALITY\\tINFLUENCES\\tYOUR\\tHABITS\\nYour\\tgenes\\tare\\toperating\\tbeneath\\tthe\\tsurface\\tof\\tevery\\thabit.\\tIndeed,\\tbeneath\\tthe\\nsurface\\tof\\tevery\\t\\nbehavior\\n.\\t\\nGenes\\thave\\tbeen\\tshown\\tto\\tinfluence\\teverything\\tfrom\\nthe\\tnumber\\tof\\thours\\tyou\\tspend\\twatching\\ttelevision\\tto\\tyour\\tlikelihood\\tto\\tmarry\\nor\\tdivorce\\tto\\tyour\\ttendency\\tto\\tget\\taddicted\\tto\\tdrugs,\\talcohol,\\tor\\tnicotine.\\t\\nThere’s\\na\\tstrong\\tgenetic\\tcomponent\\tto\\thow\\tobedient\\tor\\trebellious\\tyou\\tare\\twhen\\tfacing\\nauthority,\\thow\\tvulnerable\\tor\\tresistant\\tyou\\tare\\tto\\tstressful\\tevents,\\thow\\tproactive\\nor\\treactive\\tyou\\ttend\\tto\\tbe,\\tand\\teven\\thow\\tcaptivated\\tor\\tbored\\tyou\\tfeel\\tduring\\nsensory\\texperiences\\tlike\\tattending\\ta\\tconcert.\\tAs\\t\\nRobert\\tPlomin,\\ta\\tbehavioral\\ngeneticist\\tat\\tKing’s\\tCollege\\tin\\tLondon,\\ttold\\tme,\\t“It\\tis\\tnow\\tat\\tthe\\tpoint\\twhere\\twe\\nhave\\tstopped\\ttesting\\tto\\tsee\\tif\\ttraits\\thave\\ta\\tgenetic\\tcomponent\\tbecause\\twe\\nliterally\\tcan’t\\tfind\\ta\\tsingle\\tone\\tthat\\tisn’t\\tinfluenced\\tby\\tour\\tgenes.”\\nBundled\\ttogether,\\tyour\\tunique\\tcluster\\tof\\tgenetic\\ttraits\\tpredispose\\tyou\\tto\\ta\\nparticular\\tpersonality.\\tYour\\tpersonality\\tis\\tthe\\tset\\tof\\tcharacteristics\\tthat\\tis\\nconsistent\\tfrom\\tsituation\\tto\\tsituation.\\tThe\\tmost\\tproven\\tscientific\\tanalysis\\tof\\npersonality\\ttraits\\tis\\tknown\\tas\\tthe\\t“Big\\tFive,”\\twhich\\tbreaks\\tthem\\tdown\\tinto\\tfive\\nspectrums\\tof\\tbehavior.\\n1.\\t\\nOpenness\\tto\\texperience:\\tfrom\\tcurious\\tand\\tinventive\\ton\\tone\\tend\\tto\\ncautious\\tand\\tconsistent\\ton\\tthe\\tother.\\n2.\\t\\nConscientiousness:\\torganized\\tand\\tefficient\\tto\\teasygoing\\tand\\nspontaneous.\\n3.\\t\\nExtroversion:\\toutgoing\\tand\\tenergetic\\tto\\tsolitary\\tand\\treserved\\t(you\\nlikely\\tknow\\tthem\\tas\\textroverts\\tvs.\\tintroverts).\\n4.\\t\\nAgreeableness:\\tfriendly\\tand\\tcompassionate\\tto\\tchallenging\\tand\\ndetached.\\n5.\\t\\nNeuroticism:\\tanxious\\tand\\tsensitive\\tto\\tconfident,\\tcalm,\\tand\\tstable.\\nAll\\tfive\\tcharacteristics\\thave\\tbiological\\tunderpinnings.\\tExtroversion,\\tfor\\ninstance,\\tcan\\tbe\\ttracked\\tfrom\\tbirth.\\tIf\\tscientists\\tplay\\ta\\tloud\\tnoise\\tin\\tthe\\tnursing\\nward,\\tsome\\tbabies\\tturn\\ttoward\\tit\\twhile\\tothers\\tturn\\taway.\\tWhen\\tthe\\tresearchers\\ntracked\\tthese\\tchildren\\tthrough\\tlife,\\tthey\\tfound\\tthat\\tthe\\tbabies\\twho\\tturned\\ttoward', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 169}), Document(page_content='the\\tnoise\\twere\\tmore\\tlikely\\tto\\tgrow\\tup\\tto\\tbe\\textroverts.\\tThose\\twho\\tturned\\taway\\nwere\\t\\nmore\\tlikely\\tto\\tbecome\\tintroverts.\\nPeople\\twho\\tare\\thigh\\tin\\tagreeableness\\tare\\tkind,\\tconsiderate,\\tand\\twarm.\\t\\nThey\\nalso\\ttend\\tto\\thave\\thigher\\tnatural\\toxytocin\\tlevels,\\ta\\thormone\\tthat\\tplays\\tan\\nimportant\\trole\\tin\\tsocial\\tbonding,\\tincreases\\tfeelings\\tof\\ttrust,\\tand\\tcan\\tact\\tas\\ta\\nnatural\\tantidepressant.\\tYou\\tcan\\teasily\\timagine\\thow\\tsomeone\\twith\\tmore\\noxytocin\\tmight\\tbe\\tinclined\\tto\\tbuild\\thabits\\tlike\\twriting\\tthank-you\\tnotes\\tor\\norganizing\\tsocial\\tevents.\\nAs\\ta\\tthird\\texample,\\tconsider\\tneuroticism,\\twhich\\tis\\ta\\tpersonality\\ttrait\\tall\\npeople\\tpossess\\tto\\tvarious\\tdegrees.\\tPeople\\twho\\tare\\thigh\\tin\\tneuroticism\\ttend\\tto\\tbe\\nanxious\\tand\\tworry\\tmore\\tthan\\tothers.\\tThis\\ttrait\\thas\\tbeen\\tlinked\\tto\\nhypersensitivity\\tof\\tthe\\tamygdala,\\tthe\\tportion\\tof\\tthe\\tbrain\\tresponsible\\tfor\\nnoticing\\tthreats.\\tIn\\tother\\twords,\\tpeople\\twho\\tare\\tmore\\tsensitive\\tto\\tnegative\\tcues\\nin\\ttheir\\tenvironment\\tare\\tmore\\tlikely\\tto\\tscore\\thigh\\tin\\tneuroticism.\\nOur\\thabits\\tare\\tnot\\tsolely\\tdetermined\\tby\\tour\\tpersonalities,\\tbut\\tthere\\tis\\tno\\tdoubt\\nthat\\tour\\tgenes\\tnudge\\tus\\tin\\ta\\tcertain\\tdirection.\\t\\nOur\\tdeeply\\trooted\\tpreferences\\nmake\\tcertain\\tbehaviors\\teasier\\tfor\\tsome\\tpeople\\tthan\\tfor\\tothers.\\tYou\\tdon’t\\thave\\tto\\napologize\\tfor\\tthese\\tdifferences\\tor\\tfeel\\tguilty\\tabout\\tthem,\\tbut\\tyou\\tdo\\thave\\tto\\nwork\\twith\\tthem.\\tA\\tperson\\twho\\tscores\\tlower\\ton\\tconscientiousness,\\tfor\\texample,\\nwill\\tbe\\tless\\tlikely\\tto\\tbe\\torderly\\tby\\tnature\\tand\\tmay\\tneed\\tto\\trely\\tmore\\theavily\\ton\\nenvironment\\tdesign\\tto\\tstick\\twith\\tgood\\thabits.\\t(As\\ta\\treminder\\tfor\\tthe\\tless\\nconscientious\\treaders\\tamong\\tus,\\tenvironment\\tdesign\\tis\\ta\\tstrategy\\twe\\tdiscussed\\nin\\tChapters\\t6\\tand\\t12.)\\nThe\\ttakeaway\\tis\\tthat\\tyou\\tshould\\tbuild\\thabits\\tthat\\twork\\tfor\\tyour\\t\\npersonality.\\n*\\nPeople\\tcan\\tget\\tripped\\tworking\\tout\\tlike\\ta\\tbodybuilder,\\tbut\\tif\\tyou\\tprefer\\trock\\nclimbing\\tor\\tcycling\\tor\\trowing,\\tthen\\tshape\\tyour\\texercise\\thabit\\taround\\tyour\\ninterests.\\t\\nIf\\tyour\\tfriend\\tfollows\\ta\\tlow-carb\\tdiet\\tbut\\tyou\\tfind\\tthat\\tlow-fat\\tworks\\nfor\\tyou,\\tthen\\tmore\\tpower\\tto\\tyou.\\tIf\\tyou\\twant\\tto\\tread\\tmore,\\tdon’t\\tbe\\tembarrassed\\nif\\tyou\\tprefer\\tsteamy\\tromance\\tnovels\\tover\\tnonfiction.\\tRead\\twhatever\\tfascinates\\nyou.\\n*\\n\\tYou\\tdon’t\\thave\\tto\\tbuild\\tthe\\thabits\\teveryone\\ttells\\tyou\\tto\\tbuild.\\tChoose\\tthe\\nhabit\\tthat\\tbest\\tsuits\\tyou,\\tnot\\tthe\\tone\\tthat\\tis\\tmost\\tpopular.\\nThere\\tis\\ta\\tversion\\tof\\tevery\\thabit\\tthat\\tcan\\tbring\\tyou\\tjoy\\tand\\tsatisfaction.\\tFind\\nit.\\tHabits\\tneed\\tto\\tbe\\tenjoyable\\tif\\tthey\\tare\\tgoing\\tto\\tstick.\\tThis\\tis\\tthe\\tcore\\tidea\\nbehind\\tthe\\t4th\\tLaw.\\nTailoring\\tyour\\thabits\\tto\\tyour\\tpersonality\\tis\\ta\\tgood\\tstart,\\tbut\\tthis\\tis\\tnot\\tthe\\tend\\nof\\tthe\\tstory.\\tLet’s\\tturn\\tour\\tattention\\tto\\tfinding\\tand\\tdesigning\\tsituations\\twhere\\nyou’re\\tat\\ta\\tnatural\\tadvantage.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 170}), Document(page_content='HOW\\tTO\\tFIND\\tA\\tGAME\\tWHERE\\tTHE\\tODDS\\tARE\\tIN\\tYOUR\\tFAVOR\\nLearning\\tto\\tplay\\ta\\tgame\\twhere\\tthe\\todds\\tare\\tin\\tyour\\tfavor\\tis\\tcritical\\tfor\\nmaintaining\\tmotivation\\tand\\tfeeling\\tsuccessful.\\tIn\\ttheory,\\tyou\\tcan\\tenjoy\\talmost\\nanything.\\tIn\\tpractice,\\tyou\\tare\\tmore\\tlikely\\tto\\tenjoy\\tthe\\tthings\\tthat\\tcome\\teasily\\tto\\nyou.\\tPeople\\twho\\tare\\ttalented\\tin\\ta\\tparticular\\tarea\\ttend\\tto\\tbe\\tmore\\tcompetent\\tat\\nthat\\ttask\\tand\\tare\\tthen\\tpraised\\tfor\\tdoing\\ta\\tgood\\tjob.\\tThey\\tstay\\tenergized\\tbecause\\nthey\\tare\\tmaking\\tprogress\\twhere\\tothers\\thave\\tfailed,\\tand\\tbecause\\tthey\\tget\\nrewarded\\twith\\tbetter\\tpay\\tand\\tbigger\\topportunities,\\twhich\\tnot\\tonly\\tmakes\\tthem\\nhappier\\tbut\\talso\\tpropels\\tthem\\tto\\tproduce\\teven\\thigher-quality\\twork.\\tIt’s\\ta\\nvirtuous\\tcycle.\\nPick\\tthe\\tright\\thabit\\tand\\tprogress\\tis\\teasy.\\tPick\\tthe\\twrong\\thabit\\tand\\tlife\\tis\\ta\\nstruggle.\\nHow\\tdo\\tyou\\tpick\\tthe\\tright\\thabit?\\tThe\\tfirst\\tstep\\tis\\tsomething\\twe\\tcovered\\tin\\tthe\\n3rd\\tLaw:\\t\\nmake\\tit\\teasy\\n.\\tIn\\tmany\\tcases,\\twhen\\tpeople\\tpick\\tthe\\twrong\\thabit,\\tit\\nsimply\\tmeans\\tthey\\tpicked\\ta\\thabit\\tthat\\twas\\ttoo\\tdifficult.\\tWhen\\ta\\thabit\\tis\\teasy,\\nyou\\tare\\tmore\\tlikely\\tto\\tbe\\tsuccessful.\\tWhen\\tyou\\tare\\tsuccessful,\\tyou\\tare\\tmore\\nlikely\\tto\\tfeel\\tsatisfied.\\tHowever,\\tthere\\tis\\tanother\\tlevel\\tto\\tconsider.\\tIn\\tthe\\tlong-\\nrun,\\tif\\tyou\\tcontinue\\tto\\tadvance\\tand\\timprove,\\tany\\tarea\\tcan\\tbecome\\tchallenging.\\nAt\\tsome\\tpoint,\\tyou\\tneed\\tto\\tmake\\tsure\\tyou’re\\tplaying\\tthe\\tright\\tgame\\tfor\\tyour\\nskillset.\\tHow\\tdo\\tyou\\tfigure\\tthat\\tout?\\nThe\\tmost\\tcommon\\tapproach\\tis\\ttrial\\tand\\terror.\\tOf\\tcourse,\\tthere’s\\ta\\tproblem\\nwith\\tthis\\tstrategy:\\tlife\\tis\\tshort.\\tYou\\tdon’t\\thave\\ttime\\tto\\ttry\\tevery\\tcareer,\\tdate\\nevery\\teligible\\tbachelor,\\tor\\tplay\\tevery\\tmusical\\tinstrument.\\tThankfully,\\tthere\\tis\\tan\\neffective\\tway\\tto\\tmanage\\tthis\\tconundrum,\\tand\\tit\\tis\\tknown\\tas\\tthe\\t\\nexplore/exploit\\ntrade-off\\n.\\nIn\\tthe\\tbeginning\\tof\\ta\\tnew\\tactivity,\\tthere\\tshould\\tbe\\ta\\tperiod\\tof\\texploration.\\tIn\\nrelationships,\\tit’s\\tcalled\\tdating.\\tIn\\tcollege,\\tit’s\\tcalled\\tthe\\tliberal\\tarts.\\tIn\\tbusiness,\\nit’s\\tcalled\\tsplit\\ttesting.\\tThe\\tgoal\\tis\\tto\\ttry\\tout\\tmany\\tpossibilities,\\tresearch\\ta\\tbroad\\nrange\\tof\\tideas,\\tand\\tcast\\ta\\twide\\tnet.\\nAfter\\tthis\\tinitial\\tperiod\\tof\\texploration,\\tshift\\tyour\\tfocus\\tto\\tthe\\tbest\\tsolution\\nyou’ve\\tfound—but\\tkeep\\texperimenting\\toccasionally.\\tThe\\tproper\\tbalance\\ndepends\\ton\\twhether\\tyou’re\\twinning\\tor\\tlosing.\\tIf\\tyou\\tare\\tcurrently\\twinning,\\tyou\\nexploit,\\texploit,\\texploit.\\tIf\\tyou\\tare\\tcurrently\\tlosing,\\tyou\\tcontinue\\tto\\texplore,\\nexplore,\\texplore.\\nIn\\tthe\\tlong-run\\tit\\tis\\tprobably\\tmost\\teffective\\tto\\twork\\ton\\tthe\\tstrategy\\tthat\\tseems\\nto\\tdeliver\\tthe\\tbest\\tresults\\tabout\\t80\\tto\\t90\\tpercent\\tof\\tthe\\ttime\\tand\\tkeep\\texploring\\nwith\\tthe\\tremaining\\t10\\tto\\t20\\tpercent.\\t\\nGoogle\\tfamously\\tasks\\temployees\\tto\\tspend\\n80\\tpercent\\tof\\tthe\\tworkweek\\ton\\ttheir\\tofficial\\tjob\\tand\\t20\\tpercent\\ton\\tprojects\\tof', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 171}), Document(page_content='their\\tchoice,\\twhich\\thas\\tled\\tto\\tthe\\tcreation\\tof\\tblockbuster\\tproducts\\tlike\\tAdWords\\nand\\tGmail.\\nThe\\toptimal\\tapproach\\talso\\tdepends\\ton\\thow\\tmuch\\ttime\\tyou\\thave.\\tIf\\tyou\\thave\\na\\tlot\\tof\\ttime—like\\tsomeone\\tat\\tthe\\tbeginning\\tof\\ttheir\\tcareer—it\\tmakes\\tmore\\nsense\\tto\\texplore\\tbecause\\tonce\\tyou\\tfind\\tthe\\tright\\tthing,\\tyou\\tstill\\thave\\ta\\tgood\\namount\\tof\\ttime\\tto\\texploit\\tit.\\tIf\\tyou’re\\tpressed\\tfor\\ttime—say,\\tas\\tyou\\tcome\\tup\\ton\\nthe\\tdeadline\\tfor\\ta\\tproject—you\\tshould\\timplement\\tthe\\tbest\\tsolution\\tyou’ve\\tfound\\nso\\tfar\\tand\\tget\\tsome\\tresults.\\nAs\\tyou\\texplore\\tdifferent\\toptions,\\tthere\\tare\\ta\\tseries\\tof\\tquestions\\tyou\\tcan\\task\\nyourself\\tto\\tcontinually\\tnarrow\\tin\\ton\\tthe\\thabits\\tand\\tareas\\tthat\\twill\\tbe\\tmost\\nsatisfying\\tto\\tyou:\\nWhat\\tfeels\\tlike\\tfun\\tto\\tme,\\tbut\\twork\\tto\\tothers?\\t\\nThe\\tmark\\tof\\twhether\\tyou\\nare\\tmade\\tfor\\ta\\ttask\\tis\\tnot\\twhether\\tyou\\tlove\\tit\\tbut\\twhether\\tyou\\tcan\\thandle\\nthe\\tpain\\tof\\tthe\\ttask\\teasier\\tthan\\tmost\\tpeople.\\tWhen\\tare\\tyou\\tenjoying\\nyourself\\twhile\\tother\\tpeople\\tare\\tcomplaining?\\tThe\\twork\\tthat\\thurts\\tyou\\tless\\nthan\\tit\\thurts\\tothers\\tis\\tthe\\twork\\tyou\\twere\\tmade\\tto\\tdo.\\nWhat\\tmakes\\tme\\tlose\\ttrack\\tof\\ttime?\\t\\nFlow\\tis\\tthe\\tmental\\tstate\\tyou\\tenter\\nwhen\\tyou\\tare\\tso\\tfocused\\ton\\tthe\\ttask\\tat\\thand\\tthat\\tthe\\trest\\tof\\tthe\\tworld\\tfades\\naway.\\tThis\\tblend\\tof\\thappiness\\tand\\tpeak\\tperformance\\tis\\twhat\\tathletes\\tand\\nperformers\\texperience\\twhen\\tthey\\tare\\t“in\\tthe\\tzone.”\\tIt\\tis\\tnearly\\timpossible\\nto\\texperience\\ta\\tflow\\tstate\\tand\\tnot\\tfind\\tthe\\ttask\\tsatisfying\\tat\\tleast\\tto\\tsome\\ndegree.\\nWhere\\tdo\\tI\\tget\\tgreater\\treturns\\tthan\\tthe\\taverage\\tperson?\\n\\tWe\\tare\\ncontinually\\tcomparing\\tourselves\\tto\\tthose\\taround\\tus,\\tand\\ta\\tbehavior\\tis\\tmore\\nlikely\\tto\\tbe\\tsatisfying\\twhen\\tthe\\tcomparison\\tis\\tin\\tour\\tfavor.\\tWhen\\tI\\tstarted\\nwriting\\tat\\tjamesclear.com,\\tmy\\temail\\tlist\\tgrew\\tvery\\tquickly.\\tI\\twasn’t\\tquite\\nsure\\twhat\\tI\\twas\\tdoing\\twell,\\tbut\\tI\\tknew\\tthat\\tresults\\tseemed\\tto\\tbe\\tcoming\\nfaster\\tfor\\tme\\tthan\\tfor\\tsome\\tof\\tmy\\tcolleagues,\\twhich\\tmotivated\\tme\\tto\\tkeep\\nwriting.\\nWhat\\tcomes\\tnaturally\\tto\\tme?\\t\\nFor\\tjust\\ta\\tmoment,\\tignore\\twhat\\tyou\\thave\\nbeen\\ttaught.\\tIgnore\\twhat\\tsociety\\thas\\ttold\\tyou.\\tIgnore\\twhat\\tothers\\texpect\\tof\\nyou.\\tLook\\tinside\\tyourself\\tand\\task,\\t“What\\tfeels\\tnatural\\tto\\tme?\\tWhen\\thave\\tI', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 172}), Document(page_content='felt\\talive?\\tWhen\\thave\\tI\\tfelt\\tlike\\tthe\\treal\\tme?”\\tNo\\tinternal\\tjudgments\\tor\\npeople-pleasing.\\tNo\\tsecond-guessing\\tor\\tself-criticism.\\tJust\\tfeelings\\tof\\nengagement\\tand\\tenjoyment.\\tWhenever\\tyou\\tfeel\\tauthentic\\tand\\tgenuine,\\tyou\\nare\\theaded\\tin\\tthe\\tright\\tdirection.\\nTo\\tbe\\thonest,\\tsome\\tof\\tthis\\tprocess\\tis\\tjust\\tluck.\\tMichael\\tPhelps\\tand\\tHicham\\tEl\\nGuerrouj\\twere\\tlucky\\tto\\tbe\\tborn\\twith\\ta\\trare\\tset\\tof\\tabilities\\tthat\\tare\\thighly\\tvalued\\nby\\tsociety\\tand\\tto\\tbe\\tplaced\\tin\\tthe\\tideal\\tenvironment\\tfor\\tthose\\tabilities.\\tWe\\tall\\nhave\\tlimited\\ttime\\ton\\tthis\\tplanet,\\tand\\tthe\\ttruly\\tgreat\\tamong\\tus\\tare\\tthe\\tones\\twho\\nnot\\tonly\\twork\\thard\\tbut\\talso\\thave\\tthe\\tgood\\tfortune\\tto\\tbe\\texposed\\tto\\topportunities\\nthat\\tfavor\\tus.\\nBut\\twhat\\tif\\tyou\\tdon’t\\twant\\tto\\tleave\\tit\\tup\\tto\\tluck?\\nIf\\tyou\\tcan’t\\tfind\\ta\\tgame\\twhere\\tthe\\todds\\tare\\tstacked\\tin\\tyour\\tfavor,\\tcreate\\tone.\\nScott\\tAdams,\\tthe\\tcartoonist\\tbehind\\t\\nDilbert\\n,\\tsays,\\t“\\nEveryone\\thas\\tat\\tleast\\ta\\tfew\\nareas\\tin\\twhich\\tthey\\tcould\\tbe\\tin\\tthe\\ttop\\t25%\\twith\\tsome\\teffort.\\tIn\\tmy\\tcase,\\tI\\tcan\\ndraw\\tbetter\\tthan\\tmost\\tpeople,\\tbut\\tI’m\\thardly\\tan\\tartist.\\tAnd\\tI’m\\tnot\\tany\\tfunnier\\nthan\\tthe\\taverage\\tstandup\\tcomedian\\twho\\tnever\\tmakes\\tit\\tbig,\\tbut\\tI’m\\tfunnier\\tthan\\nmost\\tpeople.\\tThe\\tmagic\\tis\\tthat\\tfew\\tpeople\\tcan\\tdraw\\twell\\tand\\twrite\\tjokes.\\tIt’s\\tthe\\ncombination\\tof\\tthe\\ttwo\\tthat\\tmakes\\twhat\\tI\\tdo\\tso\\trare.\\tAnd\\twhen\\tyou\\tadd\\tin\\tmy\\nbusiness\\tbackground,\\tsuddenly\\tI\\thad\\ta\\ttopic\\tthat\\tfew\\tcartoonists\\tcould\\thope\\tto\\nunderstand\\twithout\\tliving\\tit.”\\nWhen\\tyou\\tcan’t\\twin\\tby\\tbeing\\tbetter,\\tyou\\tcan\\twin\\tby\\tbeing\\tdifferent.\\tBy\\ncombining\\tyour\\tskills,\\tyou\\treduce\\tthe\\tlevel\\tof\\tcompetition,\\twhich\\tmakes\\tit\\neasier\\tto\\tstand\\tout.\\tYou\\tcan\\tshortcut\\tthe\\tneed\\tfor\\ta\\tgenetic\\tadvantage\\t(or\\tfor\\nyears\\tof\\tpractice)\\tby\\trewriting\\tthe\\trules.\\tA\\tgood\\tplayer\\tworks\\thard\\tto\\twin\\tthe\\ngame\\teveryone\\telse\\tis\\tplaying.\\tA\\tgreat\\t\\nplayer\\tcreates\\ta\\tnew\\tgame\\tthat\\tfavors\\ntheir\\tstrengths\\tand\\tavoids\\ttheir\\tweaknesses.\\nIn\\tcollege,\\tI\\tdesigned\\tmy\\town\\tmajor,\\tbiomechanics,\\twhich\\twas\\ta\\tcombination\\nof\\tphysics,\\tchemistry,\\tbiology,\\tand\\tanatomy.\\tI\\twasn’t\\tsmart\\tenough\\tto\\tstand\\tout\\namong\\tthe\\ttop\\tphysics\\tor\\tbiology\\tmajors,\\tso\\tI\\tcreated\\tmy\\town\\tgame.\\tAnd\\nbecause\\tit\\tsuited\\tme—I\\twas\\tonly\\ttaking\\tthe\\tcourses\\tI\\twas\\tinterested\\tin—\\nstudying\\tfelt\\tlike\\tless\\tof\\ta\\tchore.\\tIt\\twas\\talso\\teasier\\tto\\tavoid\\tthe\\ttrap\\tof\\ncomparing\\tmyself\\tto\\teveryone\\telse.\\tAfter\\tall,\\tnobody\\telse\\twas\\ttaking\\tthe\\tsame\\ncombination\\tof\\tclasses,\\tso\\twho\\tcould\\tsay\\tif\\tthey\\twere\\tbetter\\tor\\tworse?\\nSpecialization\\tis\\ta\\tpowerful\\tway\\tto\\tovercome\\tthe\\t“accident”\\tof\\tbad\\tgenetics.\\nThe\\tmore\\tyou\\tmaster\\ta\\tspecific\\tskill,\\tthe\\tharder\\tit\\tbecomes\\tfor\\tothers\\tto\\tcompete\\nwith\\tyou.\\tMany\\tbodybuilders\\tare\\tstronger\\tthan\\tthe\\taverage\\tarm\\twrestler,\\tbut\\neven\\ta\\tmassive\\tbodybuilder\\tmay\\tlose\\tat\\tarm\\twrestling\\tbecause\\tthe\\tarm\\twrestling', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 173}), Document(page_content='champ\\thas\\tvery\\tspecific\\tstrength.\\tEven\\tif\\tyou’re\\tnot\\tthe\\tmost\\tnaturally\\tgifted,\\nyou\\tcan\\toften\\twin\\tby\\tbeing\\tthe\\tbest\\tin\\ta\\tvery\\tnarrow\\tcategory.\\nBoiling\\twater\\twill\\tsoften\\ta\\tpotato\\tbut\\tharden\\tan\\tegg.\\tYou\\tcan’t\\tcontrol\\nwhether\\tyou’re\\ta\\tpotato\\tor\\tan\\tegg,\\tbut\\tyou\\tcan\\tdecide\\tto\\tplay\\ta\\tgame\\twhere\\tit’s\\nbetter\\tto\\tbe\\thard\\tor\\tsoft.\\tIf\\tyou\\tcan\\tfind\\ta\\tmore\\tfavorable\\tenvironment,\\tyou\\tcan\\ntransform\\tthe\\tsituation\\tfrom\\tone\\twhere\\tthe\\todds\\tare\\tagainst\\tyou\\tto\\tone\\twhere\\nthey\\tare\\tin\\tyour\\tfavor.\\nHOW\\tTO\\tGET\\tTHE\\tMOST\\tOUT\\tOF\\tYOUR\\tGENES\\nOur\\tgenes\\tdo\\tnot\\teliminate\\tthe\\tneed\\tfor\\thard\\twork.\\tThey\\tclarify\\tit.\\tThey\\ttell\\tus\\nwhat\\n\\tto\\twork\\thard\\ton.\\tOnce\\twe\\trealize\\tour\\tstrengths,\\twe\\tknow\\twhere\\tto\\tspend\\nour\\ttime\\tand\\tenergy.\\tWe\\tknow\\twhich\\ttypes\\tof\\topportunities\\tto\\tlook\\tfor\\tand\\nwhich\\ttypes\\tof\\tchallenges\\tto\\tavoid.\\tThe\\tbetter\\twe\\tunderstand\\tour\\tnature,\\tthe\\nbetter\\tour\\tstrategy\\tcan\\tbe.\\nBiological\\tdifferences\\tmatter.\\tEven\\tso,\\tit’s\\tmore\\tproductive\\tto\\tfocus\\t\\non\\nwhether\\tyou\\tare\\tfulfilling\\tyour\\town\\tpotential\\tthan\\tcomparing\\tyourself\\tto\\nsomeone\\telse.\\tThe\\tfact\\tthat\\tyou\\thave\\ta\\tnatural\\tlimit\\tto\\tany\\tspecific\\tability\\thas\\nnothing\\tto\\tdo\\twith\\twhether\\tyou\\tare\\treaching\\tthe\\tceiling\\tof\\tyour\\tcapabilities.\\nPeople\\tget\\tso\\tcaught\\tup\\tin\\tthe\\tfact\\tthat\\tthey\\t\\nhave\\n\\tlimits\\tthat\\tthey\\trarely\\texert\\tthe\\neffort\\trequired\\tto\\tget\\tclose\\tto\\tthem.\\nFurthermore,\\tgenes\\tcan’t\\tmake\\tyou\\tsuccessful\\tif\\tyou’re\\tnot\\tdoing\\tthe\\twork.\\nYes,\\tit’s\\tpossible\\tthat\\tthe\\tripped\\ttrainer\\tat\\tthe\\tgym\\thas\\tbetter\\tgenes,\\tbut\\tif\\tyou\\nhaven’t\\tput\\tin\\tthe\\tsame\\treps,\\tit’s\\timpossible\\tto\\tsay\\tif\\tyou\\thave\\tbeen\\tdealt\\ta\\nbetter\\tor\\tworse\\tgenetic\\thand.\\tUntil\\tyou\\twork\\tas\\thard\\tas\\tthose\\tyou\\tadmire,\\tdon’t\\nexplain\\taway\\ttheir\\tsuccess\\tas\\tluck.\\nIn\\tsummary,\\tone\\tof\\tthe\\tbest\\tways\\tto\\tensure\\tyour\\thabits\\tremain\\tsatisfying\\tover\\nthe\\tlong-run\\tis\\tto\\tpick\\tbehaviors\\tthat\\talign\\twith\\tyour\\tpersonality\\tand\\tskills.\\nWork\\thard\\ton\\tthe\\tthings\\tthat\\tcome\\teasy.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 174}), Document(page_content='Chapter\\tSummary\\nThe\\tsecret\\tto\\tmaximizing\\tyour\\todds\\tof\\tsuccess\\tis\\tto\\tchoose\\tthe\\tright\\nfield\\tof\\tcompetition.\\nPick\\tthe\\tright\\thabit\\tand\\tprogress\\tis\\teasy.\\tPick\\tthe\\twrong\\thabit\\tand\\tlife\\nis\\ta\\tstruggle.\\nGenes\\tcannot\\tbe\\teasily\\tchanged,\\twhich\\tmeans\\tthey\\tprovide\\ta\\tpowerful\\nadvantage\\tin\\tfavorable\\tcircumstances\\tand\\ta\\tserious\\tdisadvantage\\tin\\nunfavorable\\tcircumstances.\\nHabits\\tare\\teasier\\twhen\\tthey\\talign\\twith\\tyour\\tnatural\\tabilities.\\tChoose\\nthe\\thabits\\tthat\\tbest\\tsuit\\tyou.\\nPlay\\ta\\tgame\\tthat\\tfavors\\tyour\\tstrengths.\\tIf\\tyou\\tcan’t\\tfind\\ta\\tgame\\tthat\\nfavors\\tyou,\\tcreate\\tone.\\nGenes\\tdo\\tnot\\teliminate\\tthe\\tneed\\tfor\\thard\\twork.\\tThey\\tclarify\\tit.\\tThey\\ntell\\tus\\t\\nwhat\\n\\tto\\twork\\thard\\ton.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 175}), Document(page_content='19\\nThe\\tGoldilocks\\tRule:\\tHow\\tto\\tStay\\tMotivated\\tin\\nLife\\tand\\tWork\\nI\\nN\\t1955\\n,\\tDisneyland\\thad\\tjust\\topened\\tin\\tAnaheim,\\tCalifornia,\\twhen\\ta\\tten-year-old\\nboy\\twalked\\tin\\tand\\tasked\\tfor\\ta\\tjob.\\tLabor\\tlaws\\twere\\tloose\\tback\\tthen\\tand\\tthe\\tboy\\nmanaged\\tto\\tland\\ta\\tposition\\tselling\\tguidebooks\\tfor\\t$0.50\\tapiece.\\nWithin\\ta\\tyear,\\the\\thad\\ttransitioned\\tto\\tDisney’s\\tmagic\\tshop,\\twhere\\the\\tlearned\\ntricks\\tfrom\\tthe\\tolder\\temployees.\\tHe\\texperimented\\twith\\tjokes\\tand\\ttried\\tout\\nsimple\\troutines\\ton\\tvisitors.\\tSoon\\the\\tdiscovered\\tthat\\twhat\\the\\tloved\\twas\\tnot\\nperforming\\tmagic\\tbut\\tperforming\\tin\\tgeneral.\\tHe\\tset\\this\\tsights\\ton\\tbecoming\\ta\\ncomedian.\\nBeginning\\tin\\this\\tteenage\\tyears,\\the\\tstarted\\tperforming\\tin\\tlittle\\tclubs\\taround\\nLos\\tAngeles.\\tThe\\tcrowds\\twere\\tsmall\\tand\\this\\tact\\twas\\tshort.\\tHe\\twas\\trarely\\ton\\nstage\\tfor\\tmore\\tthan\\tfive\\tminutes.\\tMost\\tof\\tthe\\tpeople\\tin\\tthe\\tcrowd\\twere\\ttoo\\tbusy\\ndrinking\\tor\\ttalking\\twith\\tfriends\\tto\\tpay\\tattention.\\tOne\\tnight,\\the\\tliterally\\tdelivered\\nhis\\tstandup\\troutine\\tto\\tan\\tempty\\tclub.\\nIt\\twasn’t\\tglamorous\\twork,\\tbut\\tthere\\twas\\tno\\tdoubt\\the\\twas\\tgetting\\tbetter.\\tHis\\nfirst\\troutines\\twould\\tonly\\tlast\\tone\\tor\\ttwo\\tminutes.\\tBy\\thigh\\tschool,\\this\\tmaterial\\nhad\\texpanded\\tto\\tinclude\\ta\\tfive-minute\\tact\\tand,\\ta\\tfew\\tyears\\tlater,\\ta\\tten-minute\\nshow.\\tAt\\tnineteen,\\the\\twas\\tperforming\\tweekly\\tfor\\ttwenty\\tminutes\\tat\\ta\\ttime.\\tHe\\nhad\\tto\\tread\\tthree\\tpoems\\tduring\\tthe\\tshow\\tjust\\tto\\tmake\\tthe\\troutine\\tlong\\tenough,\\nbut\\this\\tskills\\tcontinued\\tto\\tprogress.\\nHe\\tspent\\tanother\\tdecade\\texperimenting,\\tadjusting,\\tand\\tpracticing.\\tHe\\ttook\\ta\\njob\\tas\\ta\\ttelevision\\twriter\\tand,\\tgradually,\\the\\twas\\table\\tto\\tland\\this\\town\\tappearances\\non\\ttalk\\tshows.\\tBy\\tthe\\tmid-1970s,\\the\\thad\\tworked\\this\\tway\\tinto\\tbeing\\ta\\tregular\\nguest\\ton\\t\\nThe\\tTonight\\tShow\\n\\tand\\t\\nSaturday\\tNight\\tLive\\n.\\nFinally,\\tafter\\tnearly\\tfifteen\\tyears\\tof\\twork,\\tthe\\tyoung\\tman\\trose\\tto\\tfame.\\tHe\\ntoured\\tsixty\\tcities\\tin\\tsixty-three\\tdays.\\tThen\\tseventy-two\\tcities\\tin\\teighty\\tdays.\\nThen\\teighty-five\\tcities\\tin\\tninety\\tdays.\\tHe\\thad\\t18,695\\tpeople\\tattend\\tone\\tshow\\tin', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 176}), Document(page_content='Ohio.\\tAnother\\t45,000\\ttickets\\twere\\tsold\\tfor\\this\\tthree-day\\tshow\\tin\\tNew\\tYork.\\tHe\\ncatapulted\\tto\\tthe\\ttop\\tof\\this\\tgenre\\tand\\tbecame\\tone\\tof\\tthe\\t\\nmost\\tsuccessful\\ncomedians\\tof\\this\\ttime.\\nHis\\tname\\tis\\tSteve\\tMartin.\\nMartin’s\\tstory\\toffers\\ta\\tfascinating\\tperspective\\ton\\twhat\\tit\\ttakes\\tto\\tstick\\twith\\nhabits\\tfor\\tthe\\tlong\\trun.\\tComedy\\tis\\tnot\\tfor\\tthe\\ttimid.\\tIt\\tis\\thard\\tto\\timagine\\ta\\nsituation\\tthat\\twould\\tstrike\\tfear\\tinto\\tthe\\thearts\\tof\\tmore\\tpeople\\tthan\\tperforming\\nalone\\ton\\tstage\\tand\\tfailing\\tto\\tget\\ta\\tsingle\\tlaugh.\\tAnd\\tyet\\tSteve\\tMartin\\tfaced\\tthis\\nfear\\tevery\\tweek\\tfor\\teighteen\\tyears.\\tIn\\this\\twords,\\t“10\\tyears\\tspent\\tlearning,\\t4\\nyears\\tspent\\trefining,\\tand\\t\\n4\\tyears\\tas\\ta\\twild\\tsuccess.”\\nWhy\\tis\\tit\\tthat\\tsome\\tpeople,\\tlike\\tMartin,\\tstick\\twith\\ttheir\\thabits—whether\\npracticing\\tjokes\\tor\\tdrawing\\tcartoons\\tor\\tplaying\\tguitar—while\\tmost\\tof\\tus\\nstruggle\\tto\\tstay\\tmotivated?\\tHow\\tdo\\twe\\tdesign\\thabits\\tthat\\tpull\\tus\\tin\\trather\\tthan\\nones\\tthat\\tfade\\taway?\\tScientists\\thave\\tbeen\\t\\nstudying\\tthis\\tquestion\\tfor\\tmany\\tyears.\\nWhile\\tthere\\tis\\tstill\\tmuch\\tto\\tlearn,\\tone\\tof\\tthe\\tmost\\tconsistent\\tfindings\\tis\\tthat\\tthe\\nway\\tto\\tmaintain\\tmotivation\\tand\\tachieve\\tpeak\\tlevels\\tof\\tdesire\\tis\\tto\\twork\\ton\\ttasks\\nof\\t“\\njust\\tmanageable\\tdifficulty.”\\nThe\\thuman\\tbrain\\tloves\\ta\\tchallenge,\\tbut\\tonly\\tif\\tit\\tis\\twithin\\tan\\toptimal\\tzone\\tof\\ndifficulty.\\tIf\\tyou\\tlove\\ttennis\\tand\\ttry\\tto\\tplay\\ta\\tserious\\tmatch\\tagainst\\ta\\tfour-year-\\nold,\\tyou\\twill\\tquickly\\tbecome\\tbored.\\tIt’s\\ttoo\\teasy.\\tYou’ll\\twin\\tevery\\tpoint.\\tIn\\ncontrast,\\tif\\tyou\\tplay\\ta\\tprofessional\\ttennis\\tplayer\\tlike\\tRoger\\tFederer\\tor\\tSerena\\nWilliams,\\tyou\\twill\\tquickly\\tlose\\tmotivation\\tbecause\\tthe\\tmatch\\tis\\ttoo\\tdifficult.\\nNow\\tconsider\\tplaying\\ttennis\\tagainst\\tsomeone\\twho\\tis\\tyour\\tequal.\\tAs\\tthe\\tgame\\nprogresses,\\tyou\\twin\\ta\\tfew\\tpoints\\tand\\tyou\\tlose\\ta\\tfew.\\tYou\\thave\\ta\\tgood\\tchance\\tof\\nwinning,\\tbut\\tonly\\tif\\tyou\\treally\\ttry.\\tYour\\tfocus\\tnarrows,\\tdistractions\\tfade\\taway,\\nand\\tyou\\tfind\\tyourself\\tfully\\tinvested\\tin\\tthe\\ttask\\tat\\thand.\\tThis\\tis\\ta\\tchallenge\\tof\\njust\\tmanageable\\tdifficulty\\tand\\tit\\tis\\ta\\tprime\\texample\\tof\\tthe\\t\\nGoldilocks\\tRule\\n.\\nThe\\tGoldilocks\\tRule\\tstates\\tthat\\thumans\\texperience\\tpeak\\tmotivation\\twhen\\nworking\\ton\\ttasks\\tthat\\tare\\tright\\ton\\tthe\\tedge\\tof\\ttheir\\tcurrent\\tabilities.\\tNot\\ttoo\\nhard.\\tNot\\ttoo\\teasy.\\tJust\\tright.\\nTHE\\tGOLDILOCKS\\tRULE', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 177}), Document(page_content='FIGURE\\t15:\\tMaximum\\tmotivation\\toccurs\\twhen\\tfacing\\ta\\tchallenge\\tof\\tjust\\tmanageable\\tdifficulty.\\tIn\\tpsychology\\tresearch\\tthis\\tis\\tknown\\tas\\tthe\\tYerkes–Dodson\\tlaw,\\twhich\\tdescribes\\tthe\\noptimal\\tlevel\\tof\\tarousal\\tas\\tthe\\tmidpoint\\tbetween\\tboredom\\tand\\tanxiety.\\nMartin’s\\tcomedy\\tcareer\\tis\\tan\\texcellent\\texample\\tof\\tthe\\tGoldilocks\\tRule\\tin\\npractice.\\tEach\\tyear,\\the\\texpanded\\this\\tcomedy\\troutine—but\\tonly\\tby\\ta\\tminute\\tor\\ntwo.\\tHe\\twas\\talways\\tadding\\tnew\\tmaterial,\\tbut\\the\\talso\\tkept\\ta\\tfew\\tjokes\\tthat\\twere\\nguaranteed\\tto\\tget\\tlaughs.\\tThere\\twere\\tjust\\tenough\\tvictories\\tto\\tkeep\\thim\\nmotivated\\tand\\tjust\\tenough\\tmistakes\\tto\\tkeep\\thim\\tworking\\thard.\\nWhen\\tyou’re\\tstarting\\ta\\tnew\\thabit,\\tit’s\\timportant\\tto\\tkeep\\tthe\\tbehavior\\tas\\teasy\\nas\\tpossible\\tso\\tyou\\tcan\\tstick\\twith\\tit\\teven\\twhen\\tconditions\\taren’t\\tperfect.\\tThis\\tis\\nan\\tidea\\twe\\tcovered\\tin\\tdetail\\twhile\\tdiscussing\\tthe\\t3rd\\tLaw\\tof\\tBehavior\\tChange.\\nOnce\\ta\\thabit\\thas\\tbeen\\testablished,\\thowever,\\tit’s\\timportant\\tto\\tcontinue\\tto\\nadvance\\tin\\tsmall\\tways.\\tThese\\tlittle\\timprovements\\tand\\tnew\\t\\nchallenges\\tkeep\\tyou\\nengaged.\\tAnd\\tif\\tyou\\thit\\tthe\\tGoldilocks\\tZone\\tjust\\tright,\\tyou\\tcan\\tachieve\\ta\\t\\nflow\\nstate\\n.\\n*\\nA\\tflow\\tstate\\tis\\tthe\\texperience\\tof\\tbeing\\t“in\\tthe\\tzone”\\tand\\tfully\\timmersed\\tin\\tan\\nactivity.\\tScientists\\thave\\ttried\\tto\\tquantify\\tthis\\tfeeling.\\tThey\\tfound\\tthat\\tto\\tachieve\\na\\tstate\\tof\\tflow,\\ta\\ttask\\tmust\\tbe\\troughly\\t\\n4\\tpercent\\tbeyond\\tyour\\tcurrent\\tability.\\tIn\\nreal\\tlife\\tit’s\\ttypically\\tnot\\tfeasible\\tto\\tquantify\\tthe\\tdifficulty\\tof\\tan\\taction\\tin\\tthis', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 178}), Document(page_content='way,\\tbut\\tthe\\tcore\\tidea\\tof\\tthe\\tGoldilocks\\tRule\\tremains:\\tworking\\ton\\tchallenges\\tof\\njust\\tmanageable\\tdifficulty—something\\ton\\tthe\\tperimeter\\tof\\tyour\\tability—seems\\ncrucial\\tfor\\tmaintaining\\tmotivation.\\nImprovement\\trequires\\ta\\tdelicate\\tbalance.\\tYou\\tneed\\tto\\tregularly\\tsearch\\tfor\\nchallenges\\tthat\\tpush\\tyou\\tto\\tyour\\tedge\\twhile\\tcontinuing\\tto\\tmake\\tenough\\tprogress\\nto\\tstay\\tmotivated.\\tBehaviors\\tneed\\tto\\tremain\\tnovel\\tin\\torder\\tfor\\tthem\\tto\\tstay\\nattractive\\tand\\tsatisfying.\\tWithout\\tvariety,\\twe\\tget\\tbored.\\tAnd\\tboredom\\tis\\tperhaps\\nthe\\tgreatest\\tvillain\\ton\\tthe\\tquest\\tfor\\tselfimprovement.\\nHOW\\tTO\\tSTAY\\tFOCUSED\\tWHEN\\tYOU\\tGET\\tBORED\\tWORKING\\tON\\nYOUR\\tGOALS\\nAfter\\tmy\\tbaseball\\tcareer\\tended,\\tI\\twas\\tlooking\\tfor\\ta\\tnew\\tsport.\\tI\\tjoined\\ta\\nweightlifting\\tteam\\tand\\tone\\tday\\tan\\telite\\tcoach\\tvisited\\tour\\tgym.\\tHe\\thad\\tworked\\nwith\\tthousands\\tof\\tathletes\\tduring\\this\\tlong\\tcareer,\\tincluding\\ta\\tfew\\tOlympians.\\tI\\nintroduced\\tmyself\\tand\\twe\\tbegan\\ttalking\\tabout\\tthe\\tprocess\\tof\\timprovement.\\n“What’s\\tthe\\tdifference\\tbetween\\tthe\\tbest\\tathletes\\tand\\teveryone\\telse?”\\tI\\tasked.\\n“What\\tdo\\tthe\\treally\\tsuccessful\\tpeople\\tdo\\tthat\\tmost\\tdon’t?”\\nHe\\tmentioned\\tthe\\tfactors\\tyou\\tmight\\texpect:\\tgenetics,\\tluck,\\ttalent.\\tBut\\tthen\\the\\nsaid\\tsomething\\tI\\twasn’t\\texpecting:\\t“At\\tsome\\tpoint\\tit\\tcomes\\tdown\\tto\\twho\\tcan\\nhandle\\tthe\\tboredom\\tof\\ttraining\\tevery\\tday,\\tdoing\\tthe\\tsame\\tlifts\\tover\\tand\\tover\\tand\\nover.”\\nHis\\tanswer\\tsurprised\\tme\\tbecause\\tit’s\\ta\\tdifferent\\tway\\tof\\tthinking\\t\\nabout\\twork\\nethic.\\tPeople\\ttalk\\tabout\\tgetting\\t“amped\\tup”\\tto\\twork\\ton\\ttheir\\tgoals.\\tWhether\\tit’s\\nbusiness\\tor\\tsports\\tor\\tart,\\tyou\\thear\\tpeople\\tsay\\tthings\\tlike,\\t“It\\tall\\tcomes\\tdown\\tto\\npassion.”\\tOr,\\t“You\\thave\\tto\\treally\\twant\\tit.”\\tAs\\ta\\tresult,\\tmany\\tof\\tus\\tget\\tdepressed\\nwhen\\twe\\tlose\\tfocus\\tor\\tmotivation\\tbecause\\twe\\tthink\\tthat\\tsuccessful\\tpeople\\thave\\nsome\\tbottomless\\treserve\\tof\\tpassion.\\tBut\\tthis\\tcoach\\twas\\tsaying\\tthat\\treally\\nsuccessful\\tpeople\\t\\nfeel\\n\\tthe\\tsame\\tlack\\tof\\tmotivation\\tas\\teveryone\\telse.\\tThe\\ndifference\\tis\\tthat\\tthey\\tstill\\tfind\\ta\\tway\\tto\\tshow\\tup\\tdespite\\tthe\\tfeelings\\tof\\nboredom.\\nMastery\\trequires\\tpractice.\\tBut\\tthe\\tmore\\tyou\\tpractice\\tsomething,\\tthe\\tmore\\nboring\\tand\\troutine\\tit\\tbecomes.\\tOnce\\tthe\\tbeginner\\tgains\\thave\\tbeen\\tmade\\tand\\twe\\nlearn\\twhat\\tto\\texpect,\\tour\\tinterest\\tstarts\\tto\\tfade.\\tSometimes\\tit\\thappens\\teven\\tfaster\\nthan\\tthat.\\tAll\\tyou\\thave\\tto\\tdo\\tis\\thit\\tthe\\tgym\\ta\\tfew\\tdays\\tin\\ta\\trow\\tor\\tpublish\\ta\\ncouple\\tof\\tblog\\tposts\\ton\\ttime\\tand\\tletting\\tone\\tday\\tslip\\tdoesn’t\\tfeel\\tlike\\tmuch.\\nThings\\tare\\tgoing\\twell.\\tIt’s\\teasy\\tto\\trationalize\\ttaking\\ta\\tday\\toff\\tbecause\\tyou’re\\tin\\na\\tgood\\tplace.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 179}), Document(page_content='The\\tgreatest\\tthreat\\tto\\tsuccess\\tis\\tnot\\tfailure\\tbut\\tboredom.\\tWe\\tget\\tbored\\twith\\nhabits\\tbecause\\tthey\\tstop\\tdelighting\\tus.\\tThe\\toutcome\\tbecomes\\texpected.\\tAnd\\tas\\nour\\thabits\\tbecome\\tordinary,\\twe\\tstart\\tderailing\\tour\\tprogress\\tto\\tseek\\tnovelty.\\nPerhaps\\tthis\\tis\\twhy\\twe\\tget\\tcaught\\tup\\tin\\ta\\tnever-ending\\tcycle,\\tjumping\\tfrom\\tone\\nworkout\\tto\\tthe\\tnext,\\tone\\tdiet\\tto\\tthe\\tnext,\\tone\\tbusiness\\tidea\\tto\\tthe\\tnext.\\tAs\\tsoon\\nas\\twe\\texperience\\tthe\\tslightest\\tdip\\tin\\tmotivation,\\twe\\tbegin\\tseeking\\ta\\tnew\\tstrategy\\n—even\\tif\\tthe\\told\\tone\\twas\\tstill\\tworking.\\tAs\\tMachiavelli\\tnoted,\\t“\\nMen\\tdesire\\nnovelty\\tto\\tsuch\\tan\\textent\\tthat\\tthose\\twho\\tare\\tdoing\\twell\\twish\\tfor\\ta\\tchange\\tas\\nmuch\\tas\\tthose\\twho\\tare\\tdoing\\tbadly.”\\nPerhaps\\tthis\\tis\\twhy\\tmany\\tof\\tthe\\tmost\\thabit-forming\\tproducts\\tare\\tthose\\tthat\\nprovide\\tcontinuous\\tforms\\tof\\tnovelty.\\tVideo\\tgames\\tprovide\\tvisual\\tnovelty.\\tPorn\\nprovides\\tsexual\\tnovelty.\\tJunk\\tfoods\\tprovide\\tculinary\\tnovelty.\\tEach\\tof\\tthese\\nexperiences\\toffer\\tcontinual\\telements\\tof\\tsurprise.\\nIn\\tpsychology,\\tthis\\tis\\tknown\\tas\\ta\\t\\nvariable\\treward\\n.\\n*\\n\\tSlot\\tmachines\\tare\\tthe\\nmost\\tcommon\\treal-world\\texample.\\tA\\tgambler\\thits\\tthe\\tjackpot\\tevery\\tnow\\tand\\nthen\\tbut\\tnot\\tat\\tany\\tpredictable\\tinterval.\\tThe\\tpace\\tof\\trewards\\tvaries.\\t\\nThis\\nvariance\\tleads\\tto\\tthe\\tgreatest\\tspike\\tof\\tdopamine,\\tenhances\\tmemory\\trecall,\\tand\\naccelerates\\thabit\\tformation.\\nVariable\\trewards\\twon’t\\t\\ncreate\\n\\ta\\tcraving—that\\tis,\\tyou\\tcan’t\\ttake\\ta\\treward\\npeople\\tare\\tuninterested\\tin,\\tgive\\tit\\tto\\tthem\\tat\\ta\\tvariable\\tinterval,\\tand\\thope\\tit\\twill\\nchange\\ttheir\\tmind—but\\tthey\\tare\\ta\\tpowerful\\tway\\tto\\tamplify\\tthe\\tcravings\\twe\\nalready\\texperience\\tbecause\\tthey\\treduce\\tboredom.\\nThe\\tsweet\\tspot\\tof\\tdesire\\toccurs\\tat\\ta\\t50/50\\tsplit\\tbetween\\tsuccess\\tand\\tfailure.\\nHalf\\tof\\tthe\\ttime\\tyou\\tget\\twhat\\tyou\\twant.\\tHalf\\tof\\tthe\\ttime\\tyou\\tdon’t.\\tYou\\tneed\\njust\\tenough\\t“winning”\\tto\\texperience\\tsatisfaction\\tand\\tjust\\tenough\\t“wanting”\\tto\\nexperience\\tdesire.\\tThis\\tis\\tone\\tof\\tthe\\tbenefits\\tof\\tfollowing\\tthe\\tGoldilocks\\tRule.\\tIf\\nyou’re\\talready\\tinterested\\tin\\ta\\thabit,\\tworking\\ton\\tchallenges\\tof\\tjust\\tmanageable\\ndifficulty\\tis\\ta\\tgood\\tway\\tto\\tkeep\\tthings\\tinteresting.\\nOf\\tcourse,\\tnot\\tall\\thabits\\thave\\ta\\tvariable\\treward\\tcomponent,\\tand\\tyou\\twouldn’t\\nwant\\tthem\\tto.\\tIf\\tGoogle\\tonly\\tdelivered\\ta\\tuseful\\tsearch\\tresult\\tsome\\tof\\tthe\\ttime,\\tI\\nwould\\tswitch\\tto\\ta\\tcompetitor\\tpretty\\tquickly.\\tIf\\tUber\\tonly\\tpicked\\tup\\thalf\\tof\\tmy\\ntrips,\\tI\\tdoubt\\tI’d\\tbe\\tusing\\tthat\\tservice\\tmuch\\tlonger.\\tAnd\\tif\\tI\\tflossed\\tmy\\tteeth\\neach\\tnight\\tand\\tonly\\tsometimes\\tended\\tup\\twith\\ta\\tclean\\tmouth,\\tI\\tthink\\tI’d\\tskip\\tit.\\nVariable\\trewards\\tor\\tnot,\\tno\\thabit\\twill\\tstay\\tinteresting\\tforever.\\tAt\\tsome\\tpoint,\\neveryone\\tfaces\\tthe\\tsame\\tchallenge\\ton\\tthe\\tjourney\\tof\\tselfimprovement:\\tyou\\thave\\nto\\tfall\\tin\\tlove\\twith\\tboredom.\\nWe\\tall\\thave\\tgoals\\tthat\\twe\\twould\\tlike\\tto\\tachieve\\tand\\tdreams\\tthat\\twe\\t\\nwould\\nlike\\tto\\tfulfill,\\tbut\\tit\\tdoesn’t\\tmatter\\twhat\\tyou\\tare\\ttrying\\tto\\tbecome\\tbetter\\tat,\\tif\\tyou\\nonly\\tdo\\tthe\\twork\\twhen\\tit’s\\tconvenient\\tor\\texciting,\\tthen\\tyou’ll\\tnever\\tbe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 180}), Document(page_content='consistent\\tenough\\tto\\tachieve\\tremarkable\\tresults.\\nI\\tcan\\tguarantee\\tthat\\tif\\tyou\\tmanage\\tto\\tstart\\ta\\thabit\\tand\\tkeep\\tsticking\\tto\\tit,\\tthere\\nwill\\tbe\\tdays\\twhen\\tyou\\tfeel\\tlike\\tquitting.\\tWhen\\tyou\\tstart\\ta\\tbusiness,\\tthere\\twill\\tbe\\ndays\\twhen\\tyou\\tdon’t\\tfeel\\tlike\\tshowing\\tup.\\tWhen\\tyou’re\\tat\\tthe\\tgym,\\tthere\\twill\\tbe\\nsets\\tthat\\tyou\\tdon’t\\tfeel\\tlike\\tfinishing.\\tWhen\\tit’s\\ttime\\tto\\twrite,\\tthere\\twill\\tbe\\tdays\\nthat\\tyou\\tdon’t\\tfeel\\tlike\\ttyping.\\tBut\\tstepping\\tup\\twhen\\tit’s\\tannoying\\tor\\tpainful\\tor\\ndraining\\tto\\tdo\\tso,\\tthat’s\\twhat\\tmakes\\tthe\\tdifference\\tbetween\\ta\\tprofessional\\tand\\nan\\tamateur.\\nProfessionals\\tstick\\tto\\tthe\\tschedule;\\tamateurs\\tlet\\tlife\\tget\\tin\\tthe\\tway.\\nProfessionals\\tknow\\twhat\\tis\\timportant\\tto\\tthem\\tand\\twork\\ttoward\\tit\\twith\\tpurpose;\\namateurs\\tget\\tpulled\\toff\\tcourse\\tby\\tthe\\turgencies\\tof\\tlife.\\nDavid\\tCain,\\tan\\tauthor\\tand\\tmeditation\\tteacher,\\tencourages\\this\\tstudents\\tto\\navoid\\tbeing\\t“fair-weather\\tmeditators.”\\tSimilarly,\\tyou\\tdon’t\\twant\\tto\\tbe\\ta\\tfair-\\nweather\\tathlete\\tor\\ta\\tfair-weather\\twriter\\tor\\ta\\tfair-weather\\tanything.\\tWhen\\ta\\thabit\\nis\\ttruly\\timportant\\tto\\tyou,\\tyou\\thave\\tto\\tbe\\twilling\\tto\\tstick\\tto\\tit\\tin\\tany\\tmood.\\nProfessionals\\ttake\\taction\\teven\\twhen\\tthe\\tmood\\tisn’t\\tright.\\tThey\\tmight\\tnot\\tenjoy\\nit,\\tbut\\tthey\\tfind\\ta\\tway\\tto\\tput\\tthe\\treps\\tin.\\nThere\\thave\\tbeen\\ta\\tlot\\tof\\tsets\\tthat\\tI\\thaven’t\\tfelt\\tlike\\tfinishing,\\tbut\\tI’ve\\tnever\\nregretted\\tdoing\\tthe\\tworkout.\\tThere\\thave\\tbeen\\ta\\tlot\\tof\\tarticles\\tI\\thaven’t\\tfelt\\tlike\\nwriting,\\tbut\\tI’ve\\tnever\\tregretted\\tpublishing\\ton\\tschedule.\\tThere\\thave\\tbeen\\ta\\tlot\\tof\\ndays\\tI’ve\\tfelt\\tlike\\trelaxing,\\tbut\\tI’ve\\tnever\\tregretted\\tshowing\\tup\\tand\\tworking\\ton\\nsomething\\tthat\\twas\\timportant\\tto\\tme.\\nThe\\tonly\\tway\\tto\\tbecome\\texcellent\\tis\\tto\\tbe\\tendlessly\\tfascinated\\tby\\tdoing\\tthe\\nsame\\tthing\\tover\\tand\\tover.\\tYou\\thave\\tto\\tfall\\tin\\tlove\\twith\\tboredom.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 181}), Document(page_content='Chapter\\tSummary\\nThe\\tGoldilocks\\tRule\\tstates\\tthat\\thumans\\texperience\\tpeak\\tmotivation\\nwhen\\tworking\\ton\\ttasks\\tthat\\tare\\tright\\ton\\tthe\\tedge\\tof\\ttheir\\tcurrent\\nabilities.\\nThe\\tgreatest\\tthreat\\tto\\tsuccess\\tis\\tnot\\tfailure\\tbut\\tboredom.\\nAs\\thabits\\tbecome\\troutine,\\tthey\\tbecome\\tless\\tinteresting\\tand\\tless\\nsatisfying.\\tWe\\tget\\tbored.\\nAnyone\\tcan\\twork\\thard\\twhen\\tthey\\tfeel\\tmotivated.\\tIt’s\\tthe\\tability\\tto\\nkeep\\tgoing\\twhen\\twork\\tisn’t\\texciting\\tthat\\tmakes\\tthe\\tdifference.\\nProfessionals\\tstick\\tto\\tthe\\tschedule;\\tamateurs\\tlet\\tlife\\tget\\tin\\tthe\\tway.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 182}), Document(page_content='20\\nThe\\tDownside\\tof\\tCreating\\tGood\\tHabits\\nH\\nABITS\\tCREATE\\n\\t\\nTHE\\n\\t\\nFOUNDATION\\n\\t\\nFOR\\tMASTERY.\\n\\tIn\\tchess,\\tit\\tis\\tonly\\tafter\\tthe\\tbasic\\tmovements\\tof\\tthe\\npieces\\thave\\tbecome\\tautomatic\\tthat\\ta\\tplayer\\tcan\\tfocus\\ton\\tthe\\tnext\\tlevel\\tof\\tthe\\ngame.\\tEach\\tchunk\\tof\\tinformation\\tthat\\tis\\tmemorized\\topens\\tup\\tthe\\tmental\\tspace\\nfor\\tmore\\teffortful\\tthinking.\\tThis\\tis\\ttrue\\tfor\\tany\\tendeavor.\\tWhen\\tyou\\tknow\\tthe\\nsimple\\tmovements\\tso\\twell\\tthat\\tyou\\tcan\\tperform\\tthem\\twithout\\tthinking,\\tyou\\tare\\nfree\\tto\\tpay\\tattention\\tto\\tmore\\tadvanced\\tdetails.\\tIn\\tthis\\tway,\\thabits\\tare\\tthe\\nbackbone\\tof\\tany\\tpursuit\\tof\\texcellence.\\nHowever,\\tthe\\tbenefits\\tof\\thabits\\tcome\\tat\\ta\\tcost.\\tAt\\tfirst,\\teach\\trepetition\\ndevelops\\tfluency,\\tspeed,\\tand\\tskill.\\tBut\\tthen,\\tas\\ta\\thabit\\tbecomes\\tautomatic,\\tyou\\nbecome\\tless\\tsensitive\\tto\\tfeedback.\\tYou\\tfall\\tinto\\tmindless\\trepetition.\\tIt\\tbecomes\\neasier\\tto\\tlet\\tmistakes\\tslide.\\tWhen\\tyou\\tcan\\tdo\\tit\\t“good\\tenough”\\ton\\tautopilot,\\tyou\\nstop\\tthinking\\tabout\\thow\\tto\\tdo\\tit\\tbetter.\\nThe\\tupside\\tof\\thabits\\tis\\tthat\\twe\\tcan\\tdo\\tthings\\twithout\\tthinking.\\tThe\\tdownside\\nof\\thabits\\tis\\tthat\\tyou\\tget\\tused\\tto\\tdoing\\tthings\\ta\\tcertain\\tway\\tand\\tstop\\tpaying\\nattention\\tto\\tlittle\\terrors.\\tYou\\tassume\\tyou’re\\tgetting\\tbetter\\tbecause\\tyou’re\\ngaining\\texperience.\\tIn\\treality,\\tyou\\tare\\tmerely\\t\\nreinforcing\\tyour\\tcurrent\\thabits—\\nnot\\timproving\\tthem.\\tIn\\tfact,\\tsome\\tresearch\\thas\\tshown\\tthat\\tonce\\ta\\tskill\\thas\\tbeen\\nmastered\\t\\nthere\\tis\\tusually\\ta\\tslight\\t\\ndecline\\n\\tin\\tperformance\\tover\\ttime.\\nUsually,\\tthis\\tminor\\tdip\\tin\\tperformance\\tis\\tno\\tcause\\tfor\\tworry.\\tYou\\tdon’t\\tneed\\na\\tsystem\\tto\\tcontinuously\\timprove\\thow\\twell\\tyou\\tbrush\\tyour\\tteeth\\tor\\ttie\\tyour\\nshoes\\tor\\tmake\\tyour\\tmorning\\tcup\\tof\\ttea.\\tWith\\thabits\\tlike\\tthese,\\tgood\\tenough\\tis\\nusually\\tgood\\tenough.\\tThe\\tless\\tenergy\\tyou\\tspend\\ton\\ttrivial\\tchoices,\\tthe\\tmore\\tyou\\ncan\\tspend\\tit\\ton\\twhat\\treally\\tmatters.\\nHowever,\\twhen\\tyou\\twant\\tto\\tmaximize\\tyour\\tpotential\\tand\\tachieve\\telite\\tlevels\\nof\\tperformance,\\tyou\\tneed\\ta\\tmore\\tnuanced\\tapproach.\\tYou\\tcan’t\\trepeat\\tthe\\tsame\\nthings\\tblindly\\tand\\texpect\\tto\\tbecome\\texceptional.\\tHabits\\tare\\tnecessary,\\tbut\\tnot\\nsufficient\\tfor\\tmastery.\\tWhat\\tyou\\tneed\\tis\\ta\\tcombination\\tof\\tautomatic\\thabits\\tand', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 183}), Document(page_content='deliberate\\tpractice.\\nHabits\\t+\\tDeliberate\\tPractice\\t=\\tMastery\\nTo\\tbecome\\tgreat,\\tcertain\\tskills\\t\\ndo\\n\\tneed\\tto\\tbecome\\tautomatic.\\tBasketball\\nplayers\\tneed\\tto\\tbe\\table\\tto\\tdribble\\twithout\\tthinking\\tbefore\\tthey\\tcan\\tmove\\ton\\tto\\nmastering\\tlayups\\twith\\ttheir\\tnondominant\\thand.\\tSurgeons\\tneed\\tto\\trepeat\\tthe\\tfirst\\nincision\\tso\\tmany\\ttimes\\tthat\\tthey\\tcould\\tdo\\tit\\twith\\ttheir\\teyes\\tclosed,\\tso\\tthat\\tthey\\ncan\\tfocus\\ton\\tthe\\thundreds\\tof\\tvariables\\tthat\\tarise\\tduring\\tsurgery.\\tBut\\tafter\\tone\\nhabit\\thas\\tbeen\\tmastered,\\tyou\\thave\\tto\\treturn\\tto\\tthe\\teffortful\\tpart\\tof\\tthe\\twork\\tand\\nbegin\\tbuilding\\tthe\\tnext\\thabit.\\nMastery\\tis\\tthe\\tprocess\\tof\\tnarrowing\\tyour\\tfocus\\tto\\ta\\ttiny\\telement\\tof\\tsuccess,\\nrepeating\\tit\\tuntil\\tyou\\thave\\tinternalized\\tthe\\tskill,\\tand\\tthen\\tusing\\tthis\\tnew\\thabit\\tas\\nthe\\tfoundation\\tto\\tadvance\\tto\\tthe\\tnext\\tfrontier\\tof\\tyour\\tdevelopment.\\tOld\\ttasks\\nbecome\\teasier\\tthe\\tsecond\\ttime\\taround,\\tbut\\tit\\tdoesn’t\\tget\\teasier\\toverall\\tbecause\\nnow\\tyou’re\\tpouring\\tyour\\tenergy\\tinto\\tthe\\tnext\\tchallenge.\\tEach\\thabit\\tunlocks\\tthe\\nnext\\tlevel\\tof\\tperformance.\\tIt’s\\tan\\tendless\\tcycle.\\nMASTERING\\tONE\\tHABIT\\nMASTERING\\tA\\tFIELD', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 184}), Document(page_content='FIGURE\\t16:\\tThe\\tprocess\\tof\\tmastery\\trequires\\tthat\\tyou\\tprogressively\\tlayer\\timprovements\\ton\\ttop\\tof\\tone\\tanother,\\teach\\thabit\\tbuilding\\tupon\\tthe\\tlast\\tuntil\\ta\\tnew\\tlevel\\tof\\tperformance\\thas\\tbeen\\nreached\\tand\\ta\\thigher\\trange\\tof\\tskills\\thas\\tbeen\\tinternalized.\\nAlthough\\thabits\\tare\\tpowerful,\\twhat\\tyou\\tneed\\tis\\ta\\tway\\tto\\tremain\\tconscious\\tof\\nyour\\tperformance\\tover\\ttime,\\tso\\tyou\\tcan\\tcontinue\\tto\\t\\nrefine\\tand\\timprove.\\tIt\\tis\\nprecisely\\tat\\tthe\\tmoment\\twhen\\tyou\\tbegin\\tto\\tfeel\\tlike\\tyou\\thave\\tmastered\\ta\\tskill—\\nright\\twhen\\tthings\\tare\\tstarting\\tto\\tfeel\\tautomatic\\tand\\tyou\\tare\\tbecoming\\ncomfortable—that\\tyou\\tmust\\tavoid\\tslipping\\tinto\\tthe\\ttrap\\tof\\tcomplacency.\\nThe\\tsolution?\\tEstablish\\ta\\tsystem\\tfor\\treflection\\tand\\treview.\\nHOW\\tTO\\tREVIEW\\tYOUR\\tHABITS\\tAND\\tMAKE\\tADJUSTMENTS\\nIn\\t1986,\\tthe\\tLos\\tAngeles\\tLakers\\thad\\tone\\tof\\tthe\\tmost\\ttalented\\tbasketball\\tteams\\never\\tassembled,\\tbut\\tthey\\tare\\trarely\\tremembered\\tthat\\tway.\\tThe\\tteam\\tstarted\\tthe\\n1985–1986\\tNBA\\tseason\\twith\\tan\\tastounding\\t29–5\\trecord.\\t“\\nThe\\tpundits\\twere\\nsaying\\tthat\\twe\\tmight\\tbe\\tthe\\tbest\\tteam\\tin\\tthe\\thistory\\tof\\tbasketball,”\\thead\\tcoach\\nPat\\tRiley\\tsaid\\tafter\\tthe\\tseason.\\tSurprisingly,\\tthe\\tLakers\\tstumbled\\tin\\tthe\\t1986\\nplayoffs\\tand\\tsuffered\\ta\\tseason-ending\\tdefeat\\tin\\tthe\\tWestern\\tConference\\tFinals.\\nThe\\t“best\\tteam\\tin\\tthe\\thistory\\tof\\tbasketball”\\tdidn’t\\teven\\tplay\\tfor\\tthe\\tNBA\\nchampionship.\\nAfter\\tthat\\tblow,\\tRiley\\twas\\ttired\\tof\\thearing\\tabout\\thow\\tmuch\\ttalent\\this\\tplayers\\nhad\\tand\\tabout\\thow\\tmuch\\tpromise\\this\\tteam\\theld.\\tHe\\tdidn’t\\twant\\tto\\tsee\\tflashes\\tof\\nbrilliance\\tfollowed\\tby\\ta\\tgradual\\tfade\\tin\\tperformance.\\tHe\\twanted\\tthe\\tLakers\\tto', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 185}), Document(page_content='play\\tup\\tto\\ttheir\\tpotential,\\tnight\\tafter\\tnight.\\tIn\\tthe\\tsummer\\tof\\t1986,\\the\\tcreated\\ta\\nplan\\tto\\tdo\\texactly\\tthat,\\t\\na\\tsystem\\tthat\\the\\tcalled\\tthe\\tCareer\\tBest\\tEffort\\tprogram\\tor\\nCBE.\\n“When\\tplayers\\tfirst\\tjoin\\tthe\\tLakers,”\\tRiley\\texplained,\\t“we\\ttrack\\ttheir\\nbasketball\\tstatistics\\tall\\tthe\\tway\\tback\\tto\\thigh\\tschool.\\tI\\tcall\\tthis\\tTaking\\tTheir\\nNumber.\\tWe\\tlook\\tfor\\tan\\taccurate\\tgauge\\tof\\twhat\\ta\\tplayer\\tcan\\tdo,\\tthen\\tbuild\\thim\\ninto\\tour\\tplan\\tfor\\tthe\\tteam,\\tbased\\ton\\tthe\\tnotion\\tthat\\the\\twill\\tmaintain\\tand\\tthen\\nimprove\\tupon\\this\\taverages.”\\nAfter\\tdetermining\\ta\\tplayer’s\\tbaseline\\tlevel\\tof\\tperformance,\\tRiley\\tadded\\ta\\tkey\\nstep.\\tHe\\tasked\\teach\\tplayer\\tto\\t“improve\\ttheir\\toutput\\tby\\tat\\t\\nleast\\t1\\tpercent\\tover\\tthe\\ncourse\\tof\\tthe\\tseason.\\t\\nIf\\tthey\\tsucceeded,\\tit\\twould\\tbe\\ta\\tCBE,\\tor\\tCareer\\tBest\\nEffort.”\\tSimilar\\tto\\tthe\\tBritish\\tCycling\\tteam\\tthat\\twe\\tdiscussed\\tin\\tChapter\\t1,\\tthe\\nLakers\\tsought\\tpeak\\tperformance\\tby\\tgetting\\tslightly\\tbetter\\teach\\tday.\\nRiley\\twas\\tcareful\\tto\\tpoint\\tout\\tthat\\tCBE\\twas\\tnot\\tmerely\\tabout\\tpoints\\tor\\nstatistics\\tbut\\tabout\\tgiving\\tyour\\t“best\\teffort\\tspiritually\\tand\\tmentally\\tand\\nphysically.”\\tPlayers\\tgot\\tcredit\\tfor\\t“allowing\\tan\\topponent\\tto\\trun\\tinto\\tyou\\twhen\\nyou\\tknow\\tthat\\ta\\tfoul\\twill\\tbe\\tcalled\\tagainst\\thim,\\tdiving\\tfor\\tloose\\tballs,\\tgoing\\nafter\\trebounds\\twhether\\tyou\\tare\\tlikely\\tto\\tget\\tthem\\tor\\tnot,\\thelping\\ta\\tteammate\\nwhen\\tthe\\tplayer\\the’s\\tguarding\\thas\\tsurged\\tpast\\thim,\\tand\\tother\\t‘unsung\\thero’\\ndeeds.”\\nAs\\tan\\texample,\\tlet’s\\tsay\\tthat\\tMagic\\tJohnson—the\\tLakers\\tstar\\tplayer\\tat\\tthe\\ntime—had\\t11\\tpoints,\\t8\\trebounds,\\t12\\tassists,\\t2\\tsteals,\\tand\\t5\\tturnovers\\tin\\ta\\tgame.\\nMagic\\talso\\tgot\\tcredit\\tfor\\tan\\t“unsung\\thero”\\tdeed\\tby\\tdiving\\tafter\\ta\\tloose\\tball\\t(+1).\\nFinally,\\the\\tplayed\\ta\\ttotal\\tof\\t33\\tminutes\\tin\\tthis\\timaginary\\tgame.\\nThe\\tpositive\\tnumbers\\t(11\\t+\\t8\\t+\\t12\\t+\\t2\\t+\\t1)\\tadd\\tup\\tto\\t34.\\tThen,\\twe\\tsubtract\\nthe\\t5\\tturnovers\\t(34–5)\\tto\\tget\\t29.\\tFinally,\\twe\\tdivide\\t29\\tby\\t33\\tminutes\\tplayed.\\n29/33\\t=\\t0.879\\nMagic’s\\tCBE\\tnumber\\there\\twould\\tbe\\t879.\\tThis\\tnumber\\twas\\tcalculated\\tfor\\tall\\nof\\ta\\tplayer’s\\tgames,\\tand\\tit\\twas\\tthe\\taverage\\tCBE\\tthat\\ta\\tplayer\\twas\\tasked\\tto\\nimprove\\tby\\t1\\tpercent\\tover\\tthe\\tseason.\\tRiley\\tcompared\\teach\\tplayer’s\\tcurrent\\nCBE\\tto\\tnot\\tonly\\ttheir\\tpast\\tperformances\\tbut\\talso\\tthose\\tof\\tother\\tplayers\\tin\\tthe\\nleague.\\tAs\\tRiley\\tput\\tit,\\t“We\\trank\\tteam\\tmembers\\talongside\\tleague\\topponents\\nwho\\tplay\\tthe\\tsame\\tposition\\tand\\thave\\tsimilar\\trole\\tdefinitions.”\\nSportswriter\\tJackie\\tMacMullan\\tnoted,\\t“Riley\\ttrumpeted\\tthe\\ttop\\tperformers\\tin\\nthe\\tleague\\tin\\tbold\\tlettering\\ton\\tthe\\tblackboard\\teach\\tweek\\t\\nand\\tmeasured\\tthem', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 186}), Document(page_content='against\\tthe\\tcorresponding\\tplayers\\ton\\this\\town\\troster.\\tSolid,\\treliable\\tplayers\\ngenerally\\trated\\ta\\tscore\\tin\\tthe\\t600s,\\twhile\\telite\\tplayers\\tscored\\tat\\tleast\\t800.\\tMagic\\nJohnson,\\twho\\tsubmitted\\t138\\ttriple-doubles\\tin\\this\\tcareer,\\toften\\tscored\\tover\\n1,000.”\\nThe\\tLakers\\talso\\temphasized\\tyear-over-year\\tprogress\\tby\\tmaking\\thistorical\\ncomparisons\\tof\\tCBE\\tdata.\\tRiley\\tsaid,\\t“We\\tstacked\\tthe\\tmonth\\tof\\tNovember\\n1986,\\tnext\\tto\\tNovember\\t1985,\\tand\\tshowed\\tthe\\tplayers\\twhether\\tthey\\twere\\tdoing\\nbetter\\tor\\tworse\\tthan\\tat\\tthe\\tsame\\tpoint\\tlast\\tseason.\\tThen\\twe\\tshowed\\tthem\\thow\\ntheir\\tperformance\\tfigures\\tfor\\tDecember\\t1986,\\tstacked\\tup\\tagainst\\tNovember’s.”\\nThe\\tLakers\\trolled\\tout\\tCBE\\tin\\tOctober\\t1986.\\tEight\\tmonths\\tlater,\\tthey\\twere\\nNBA\\tchampions.\\tThe\\tfollowing\\tyear,\\tPat\\tRiley\\tled\\this\\tteam\\tto\\tanother\\ttitle\\tas\\nthe\\tLakers\\tbecame\\tthe\\tfirst\\tteam\\tin\\ttwenty\\tyears\\tto\\twin\\tback-to-back\\tNBA\\nchampionships.\\tAfterward,\\the\\tsaid,\\t“\\nSustaining\\tan\\teffort\\tis\\tthe\\tmost\\timportant\\nthing\\tfor\\tany\\tenterprise.\\tThe\\tway\\tto\\tbe\\tsuccessful\\tis\\tto\\tlearn\\thow\\tto\\tdo\\tthings\\nright,\\tthen\\tdo\\tthem\\tthe\\tsame\\tway\\tevery\\ttime.”\\nThe\\tCBE\\tprogram\\tis\\ta\\tprime\\texample\\tof\\tthe\\tpower\\tof\\treflection\\tand\\treview.\\nThe\\tLakers\\twere\\talready\\ttalented.\\tCBE\\thelped\\tthem\\tget\\tthe\\tmost\\tout\\tof\\twhat\\nthey\\thad,\\tand\\tmade\\tsure\\ttheir\\thabits\\timproved\\trather\\tthan\\tdeclined.\\nReflection\\tand\\treview\\tenables\\tthe\\tlong-term\\timprovement\\tof\\tall\\thabits\\nbecause\\tit\\tmakes\\tyou\\taware\\tof\\tyour\\tmistakes\\tand\\thelps\\tyou\\tconsider\\tpossible\\npaths\\tfor\\timprovement.\\tWithout\\treflection,\\twe\\tcan\\tmake\\texcuses,\\tcreate\\nrationalizations,\\tand\\tlie\\tto\\tourselves.\\tWe\\thave\\tno\\tprocess\\tfor\\tdetermining\\nwhether\\twe\\tare\\tperforming\\tbetter\\tor\\tworse\\tcompared\\tto\\tyesterday.\\nTop\\tperformers\\tin\\tall\\tfields\\tengage\\tin\\tvarious\\ttypes\\tof\\treflection\\tand\\treview,\\nand\\tthe\\tprocess\\tdoesn’t\\thave\\tto\\tbe\\tcomplex.\\tKenyan\\trunner\\t\\nEliud\\tKipchoge\\tis\\none\\tof\\tthe\\tgreatest\\tmarathoners\\tof\\tall\\ttime\\tand\\tan\\tOlympic\\tgold\\tmedalist.\\tHe\\nstill\\ttakes\\tnotes\\tafter\\tevery\\tpractice\\tin\\t\\nwhich\\the\\treviews\\this\\ttraining\\tfor\\tthe\\tday\\nand\\tsearches\\tfor\\tareas\\tthat\\tcan\\tbe\\timproved.\\tSimilarly,\\tgold\\tmedal\\tswimmer\\nKatie\\tLedecky\\trecords\\ther\\twellness\\ton\\ta\\tscale\\tof\\t1\\tto\\t10\\tand\\tincludes\\tnotes\\ton\\nher\\tnutrition\\tand\\thow\\twell\\tshe\\tslept.\\tShe\\talso\\trecords\\tthe\\ttimes\\tposted\\tby\\tother\\nswimmers.\\tAt\\tthe\\tend\\tof\\teach\\tweek,\\t\\nher\\tcoach\\tgoes\\tover\\ther\\tnotes\\tand\\tadds\\this\\nthoughts.\\nIt’s\\tnot\\tjust\\tathletes,\\teither.\\t\\nWhen\\tcomedian\\tChris\\tRock\\tis\\tpreparing\\tfresh\\nmaterial,\\the\\twill\\tfirst\\tappear\\tat\\tsmall\\tnightclubs\\tdozens\\tof\\ttimes\\tand\\ttest\\nhundreds\\tof\\tjokes.\\tHe\\tbrings\\ta\\tnotepad\\ton\\tstage\\tand\\trecords\\twhich\\tbits\\tgo\\tover\\nwell\\tand\\twhere\\the\\tneeds\\tto\\tmake\\tadjustments.\\tThe\\tfew\\tkiller\\tlines\\tthat\\tsurvive\\nwill\\tform\\tthe\\tbackbone\\tof\\this\\tnew\\tshow.\\nI\\tknow\\tof\\texecutives\\tand\\tinvestors\\twho\\tkeep\\ta\\t“decision\\tjournal”\\tin\\twhich\\nthey\\trecord\\tthe\\tmajor\\tdecisions\\tthey\\tmake\\teach\\tweek,\\twhy\\tthey\\tmade\\tthem,\\tand', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 187}), Document(page_content='what\\tthey\\texpect\\tthe\\toutcome\\tto\\tbe.\\tThey\\treview\\ttheir\\tchoices\\tat\\tthe\\tend\\tof\\teach\\nmonth\\tor\\tyear\\tto\\tsee\\twhere\\tthey\\twere\\tcorrect\\tand\\twhere\\tthey\\twent\\twrong.\\n*\\nImprovement\\tis\\tnot\\tjust\\tabout\\tlearning\\thabits,\\tit’s\\talso\\tabout\\tfine-tuning\\tthem.\\nReflection\\tand\\treview\\tensures\\tthat\\tyou\\tspend\\tyour\\ttime\\ton\\tthe\\tright\\tthings\\tand\\nmake\\tcourse\\tcorrections\\twhenever\\tnecessary—like\\tPat\\tRiley\\tadjusting\\tthe\\teffort\\nof\\this\\tplayers\\ton\\ta\\tnightly\\tbasis.\\tYou\\tdon’t\\twant\\tto\\tkeep\\tpracticing\\ta\\thabit\\tif\\tit\\nbecomes\\tineffective.\\nPersonally,\\tI\\temploy\\ttwo\\tprimary\\tmodes\\tof\\treflection\\tand\\treview.\\tEach\\nDecember,\\tI\\tperform\\tan\\t\\nAnnual\\tReview\\n,\\tin\\twhich\\tI\\treflect\\ton\\tthe\\tprevious\\tyear.\\tI\\ntally\\tmy\\thabits\\tfor\\tthe\\tyear\\tby\\tcounting\\tup\\thow\\tmany\\tarticles\\tI\\tpublished,\\thow\\nmany\\tworkouts\\tI\\tput\\tin,\\thow\\tmany\\tnew\\tplaces\\tI\\tvisited,\\tand\\tmore.\\n*\\n\\tThen,\\tI\\nreflect\\ton\\tmy\\tprogress\\t(or\\tlack\\tthereof)\\tby\\tanswering\\tthree\\tquestions:\\n1.\\t\\nWhat\\twent\\twell\\tthis\\tyear?\\n2.\\t\\nWhat\\tdidn’t\\tgo\\tso\\twell\\tthis\\tyear?\\n3.\\t\\nWhat\\tdid\\tI\\tlearn?\\nSix\\tmonths\\tlater,\\twhen\\tsummer\\trolls\\taround,\\tI\\tconduct\\tan\\t\\nIntegrity\\tReport\\n.\\nLike\\teveryone,\\tI\\tmake\\ta\\tlot\\tof\\tmistakes.\\tMy\\tIntegrity\\tReport\\thelps\\tme\\trealize\\nwhere\\tI\\twent\\twrong\\tand\\tmotivates\\tme\\tto\\tget\\tback\\ton\\tcourse.\\tI\\tuse\\tit\\tas\\ta\\ttime\\tto\\nrevisit\\tmy\\tcore\\tvalues\\tand\\tconsider\\twhether\\tI\\thave\\tbeen\\tliving\\tin\\taccordance\\nwith\\tthem.\\tThis\\tis\\twhen\\tI\\treflect\\ton\\tmy\\tidentity\\tand\\thow\\tI\\tcan\\twork\\ttoward\\nbeing\\tthe\\ttype\\tof\\tperson\\tI\\twish\\tto\\tbecome.\\n*\\nMy\\tyearly\\tIntegrity\\tReport\\tanswers\\tthree\\tquestions:\\n1.\\t\\nWhat\\tare\\tthe\\tcore\\tvalues\\tthat\\tdrive\\tmy\\tlife\\tand\\twork?\\n2.\\t\\nHow\\tam\\tI\\tliving\\tand\\tworking\\twith\\tintegrity\\tright\\tnow?\\n3.\\t\\nHow\\tcan\\tI\\tset\\ta\\thigher\\tstandard\\tin\\tthe\\tfuture?\\nThese\\ttwo\\treports\\tdon’t\\ttake\\tvery\\tlong—just\\ta\\tfew\\thours\\tper\\tyear—but\\tthey\\nare\\tcrucial\\tperiods\\tof\\trefinement.\\tThey\\tprevent\\tthe\\tgradual\\tslide\\tthat\\thappens\\nwhen\\tI\\tdon’t\\tpay\\tclose\\tattention.\\tThey\\tprovide\\tan\\tannual\\treminder\\tto\\trevisit\\tmy\\ndesired\\tidentity\\tand\\tconsider\\thow\\tmy\\thabits\\tare\\thelping\\tme\\tbecome\\tthe\\ttype\\tof\\nperson\\tI\\twish\\tto\\tbe.\\tThey\\tindicate\\twhen\\tI\\tshould\\tupgrade\\tmy\\thabits\\tand\\ttake\\ton\\nnew\\tchallenges\\tand\\twhen\\tI\\tshould\\tdial\\tmy\\tefforts\\tback\\tand\\tfocus\\ton\\tthe\\nfundamentals.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 188}), Document(page_content='Reflection\\tcan\\talso\\tbring\\ta\\tsense\\tof\\tperspective.\\tDaily\\thabits\\tare\\tpowerful\\nbecause\\tof\\thow\\tthey\\tcompound,\\tbut\\tworrying\\ttoo\\tmuch\\tabout\\tevery\\tdaily\\tchoice\\nis\\tlike\\tlooking\\tat\\tyourself\\tin\\tthe\\tmirror\\tfrom\\tan\\tinch\\taway.\\tYou\\tcan\\tsee\\tevery\\nimperfection\\tand\\tlose\\tsight\\tof\\tthe\\t\\nbigger\\tpicture.\\tThere\\tis\\ttoo\\tmuch\\tfeedback.\\nConversely,\\tnever\\treviewing\\tyour\\thabits\\tis\\tlike\\tnever\\tlooking\\tin\\tthe\\tmirror.\\tYou\\naren’t\\taware\\tof\\teasily\\tfixable\\tflaws—a\\tspot\\ton\\tyour\\tshirt,\\ta\\tbit\\tof\\tfood\\tin\\tyour\\nteeth.\\tThere\\tis\\ttoo\\tlittle\\tfeedback.\\tPeriodic\\treflection\\tand\\treview\\tis\\tlike\\tviewing\\nyourself\\tin\\tthe\\tmirror\\tfrom\\ta\\tconversational\\tdistance.\\tYou\\tcan\\tsee\\tthe\\timportant\\nchanges\\tyou\\tshould\\tmake\\twithout\\tlosing\\tsight\\tof\\tthe\\tbigger\\tpicture.\\tYou\\twant\\tto\\nview\\tthe\\tentire\\tmountain\\trange,\\tnot\\tobsess\\tover\\teach\\tpeak\\tand\\tvalley.\\nFinally,\\treflection\\tand\\treview\\toffers\\tan\\tideal\\ttime\\tto\\trevisit\\tone\\tof\\tthe\\tmost\\nimportant\\taspects\\tof\\tbehavior\\tchange:\\tidentity.\\nHOW\\tTO\\tBREAK\\tTHE\\tBELIEFS\\tTHAT\\tHOLD\\tYOU\\tBACK\\nIn\\tthe\\tbeginning,\\trepeating\\ta\\thabit\\tis\\tessential\\tto\\tbuild\\tup\\tevidence\\tof\\tyour\\ndesired\\tidentity.\\tAs\\tyou\\tlatch\\ton\\tto\\tthat\\tnew\\tidentity,\\thowever,\\tthose\\tsame\\nbeliefs\\tcan\\thold\\tyou\\tback\\tfrom\\tthe\\tnext\\tlevel\\tof\\tgrowth.\\tWhen\\tworking\\tagainst\\nyou,\\tyour\\tidentity\\tcreates\\ta\\tkind\\tof\\t“pride”\\tthat\\tencourages\\tyou\\tto\\tdeny\\tyour\\nweak\\tspots\\tand\\tprevents\\tyou\\tfrom\\ttruly\\tgrowing.\\tThis\\tis\\tone\\tof\\tthe\\tgreatest\\ndownsides\\tof\\tbuilding\\thabits.\\nThe\\tmore\\tsacred\\tan\\tidea\\tis\\tto\\tus—that\\tis,\\tthe\\tmore\\tdeeply\\tit\\tis\\ttied\\tto\\tour\\nidentity—the\\tmore\\tstrongly\\twe\\twill\\tdefend\\tit\\tagainst\\tcriticism.\\tYou\\tsee\\tthis\\tin\\nevery\\tindustry.\\tThe\\tschoolteacher\\twho\\tignores\\tinnovative\\tteaching\\tmethods\\tand\\nsticks\\twith\\ther\\ttried-and-true\\tlesson\\tplans.\\tThe\\tveteran\\tmanager\\twho\\tis\\ncommitted\\tto\\tdoing\\tthings\\t“his\\tway.”\\tThe\\tsurgeon\\twho\\tdismisses\\tthe\\tideas\\tof\\nher\\tyounger\\tcolleagues.\\tThe\\tband\\twho\\tproduces\\ta\\tmind-blowing\\tfirst\\talbum\\tand\\nthen\\tgets\\tstuck\\tin\\ta\\trut.\\tThe\\ttighter\\twe\\tcling\\tto\\tan\\tidentity,\\tthe\\tharder\\tit\\tbecomes\\nto\\tgrow\\tbeyond\\tit.\\nOne\\tsolution\\tis\\tto\\tavoid\\tmaking\\tany\\tsingle\\taspect\\tof\\tyour\\tidentity\\tan\\noverwhelming\\tportion\\tof\\twho\\tyou\\tare.\\tIn\\tthe\\twords\\tof\\tinvestor\\tPaul\\t\\nGraham,\\n“\\nkeep\\tyour\\tidentity\\tsmall.”\\tThe\\tmore\\tyou\\tlet\\ta\\tsingle\\tbelief\\tdefine\\tyou,\\tthe\\tless\\ncapable\\tyou\\tare\\tof\\tadapting\\twhen\\tlife\\tchallenges\\tyou.\\tIf\\tyou\\ttie\\teverything\\tup\\tin\\nbeing\\tthe\\tpoint\\tguard\\tor\\tthe\\tpartner\\tat\\tthe\\tfirm\\tor\\twhatever\\telse,\\tthen\\tthe\\tloss\\tof\\nthat\\tfacet\\tof\\tyour\\tlife\\twill\\twreck\\tyou.\\tIf\\tyou’re\\ta\\tvegan\\tand\\tthen\\tdevelop\\ta\\nhealth\\tcondition\\tthat\\tforces\\tyou\\tto\\tchange\\tyour\\tdiet,\\tyou’ll\\thave\\tan\\tidentity\\tcrisis\\non\\tyour\\thands.\\tWhen\\tyou\\tcling\\ttoo\\ttightly\\tto\\tone\\tidentity,\\tyou\\tbecome\\tbrittle.\\nLose\\tthat\\tone\\tthing\\tand\\tyou\\tlose\\tyourself.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 189}), Document(page_content='For\\tmost\\tof\\tmy\\tyoung\\tlife,\\tbeing\\tan\\tathlete\\twas\\ta\\tmajor\\tpart\\tof\\tmy\\tidentity.\\nAfter\\tmy\\tbaseball\\tcareer\\tended,\\tI\\tstruggled\\tto\\tfind\\tmyself.\\tWhen\\tyou\\tspend\\tyour\\nwhole\\tlife\\tdefining\\tyourself\\tin\\tone\\tway\\tand\\tthat\\tdisappears,\\twho\\tare\\tyou\\tnow?\\nMilitary\\tveterans\\tand\\tformer\\tentrepreneurs\\treport\\tsimilar\\tfeelings.\\tIf\\tyour\\nidentity\\tis\\twrapped\\tup\\tin\\ta\\tbelief\\tlike\\t“I’m\\ta\\tgreat\\tsoldier,”\\twhat\\thappens\\twhen\\nyour\\tperiod\\tof\\tservice\\tends?\\tFor\\tmany\\tbusiness\\towners,\\ttheir\\tidentity\\tis\\nsomething\\talong\\tthe\\tlines\\tof\\t“I’m\\tthe\\tCEO”\\tor\\t“I’m\\tthe\\tfounder.”\\tIf\\tyou\\thave\\nspent\\tevery\\twaking\\tmoment\\tworking\\ton\\tyour\\tbusiness,\\thow\\twill\\tyou\\tfeel\\tafter\\nyou\\tsell\\tthe\\tcompany?\\nThe\\tkey\\tto\\tmitigating\\tthese\\tlosses\\tof\\tidentity\\tis\\tto\\tredefine\\tyourself\\tsuch\\tthat\\nyou\\tget\\tto\\tkeep\\timportant\\taspects\\tof\\tyour\\tidentity\\teven\\tif\\tyour\\tparticular\\trole\\nchanges.\\n“I’m\\tan\\tathlete”\\tbecomes\\t“I’m\\tthe\\ttype\\tof\\tperson\\twho\\tis\\tmentally\\ntough\\tand\\tloves\\ta\\tphysical\\tchallenge.”\\n“I’m\\ta\\tgreat\\tsoldier”\\ttransforms\\tinto\\t“I’m\\tthe\\ttype\\tof\\tperson\\twho\\tis\\ndisciplined,\\treliable,\\tand\\tgreat\\ton\\ta\\tteam.”\\n“I’m\\tthe\\tCEO”\\ttranslates\\tto\\t“I’m\\tthe\\ttype\\tof\\tperson\\twho\\tbuilds\\tand\\ncreates\\tthings.”\\nWhen\\tchosen\\teffectively,\\tan\\tidentity\\tcan\\tbe\\tflexible\\trather\\tthan\\t\\nbrittle.\\tLike\\nwater\\tflowing\\taround\\tan\\tobstacle,\\tyour\\tidentity\\tworks\\twith\\tthe\\tchanging\\ncircumstances\\trather\\tthan\\tagainst\\tthem.\\nThe\\tfollowing\\tquote\\tfrom\\tthe\\t\\nTao\\tTe\\tChing\\n\\tencapsulates\\tthe\\tideas\\tperfectly:\\nMen\\tare\\tborn\\tsoft\\tand\\tsupple;\\ndead,\\tthey\\tare\\tstiff\\tand\\thard.\\nPlants\\tare\\tborn\\ttender\\tand\\tpliant;\\ndead,\\tthey\\tare\\tbrittle\\tand\\tdry.\\nThus\\twhoever\\tis\\tstiff\\tand\\tinflexible\\nis\\ta\\tdisciple\\tof\\tdeath.\\nWhoever\\tis\\tsoft\\tand\\tyielding\\nis\\ta\\tdisciple\\tof\\tlife.\\nThe\\thard\\tand\\tstiff\\twill\\tbe\\tbroken.\\nThe\\tsoft\\tand\\tsupple\\twill\\tprevail.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 190}), Document(page_content='—L\\nAO\\n\\tT\\nZU\\nHabits\\tdeliver\\tnumerous\\tbenefits,\\tbut\\tthe\\tdownside\\tis\\tthat\\tthey\\tcan\\tlock\\tus\\ninto\\tour\\tprevious\\tpatterns\\tof\\tthinking\\tand\\tacting—even\\twhen\\tthe\\tworld\\tis\\nshifting\\taround\\tus.\\tEverything\\tis\\timpermanent.\\tLife\\tis\\tconstantly\\tchanging,\\tso\\nyou\\tneed\\tto\\tperiodically\\tcheck\\tin\\tto\\tsee\\tif\\tyour\\told\\thabits\\tand\\tbeliefs\\tare\\tstill\\nserving\\tyou.\\nA\\tlack\\tof\\tself-awareness\\tis\\tpoison.\\tReflection\\tand\\treview\\tis\\tthe\\tantidote.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 191}), Document(page_content='Chapter\\tSummary\\nThe\\tupside\\tof\\thabits\\tis\\tthat\\twe\\tcan\\tdo\\tthings\\twithout\\tthinking.\\tThe\\ndownside\\tis\\tthat\\twe\\tstop\\tpaying\\tattention\\tto\\tlittle\\terrors.\\nHabits\\t+\\tDeliberate\\tPractice\\t=\\tMastery\\nReflection\\tand\\treview\\tis\\ta\\tprocess\\tthat\\tallows\\tyou\\tto\\tremain\\tconscious\\nof\\tyour\\tperformance\\tover\\ttime.\\nThe\\ttighter\\twe\\tcling\\tto\\tan\\tidentity,\\tthe\\tharder\\tit\\tbecomes\\tto\\tgrow\\nbeyond\\tit.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 192}), Document(page_content='Conclusion\\nThe\\tSecret\\tto\\tResults\\tThat\\tLast\\nT\\nHERE\\tIS\\tAN\\t\\nancient\\tGreek\\tparable\\tknown\\tas\\tthe\\tSorites\\tParadox,\\n*\\n\\twhich\\ttalks\\tabout\\nthe\\teffect\\tone\\tsmall\\taction\\tcan\\thave\\twhen\\trepeated\\tenough\\ttimes.\\tOne\\nformulation\\tof\\tthe\\tparadox\\tgoes\\tas\\tfollows:\\tCan\\tone\\tcoin\\tmake\\ta\\tperson\\trich?\\tIf\\nyou\\tgive\\ta\\tperson\\ta\\tpile\\tof\\tten\\tcoins,\\tyou\\twouldn’t\\tclaim\\tthat\\the\\tor\\tshe\\tis\\trich.\\nBut\\twhat\\tif\\tyou\\tadd\\tanother?\\tAnd\\tanother?\\tAnd\\tanother?\\tAt\\tsome\\tpoint,\\tyou\\nwill\\thave\\tto\\tadmit\\tthat\\t\\nno\\tone\\tcan\\tbe\\trich\\tunless\\tone\\tcoin\\tcan\\tmake\\thim\\tor\\ther\\nso.\\nWe\\tcan\\tsay\\tthe\\tsame\\tabout\\tatomic\\thabits.\\tCan\\tone\\ttiny\\tchange\\ttransform\\tyour\\nlife?\\tIt’s\\tunlikely\\tyou\\twould\\tsay\\tso.\\tBut\\twhat\\tif\\tyou\\tmade\\tanother?\\tAnd\\nanother?\\tAnd\\tanother?\\tAt\\tsome\\tpoint,\\tyou\\twill\\thave\\tto\\tadmit\\tthat\\tyour\\tlife\\twas\\ntransformed\\tby\\tone\\tsmall\\tchange.\\nThe\\tholy\\tgrail\\tof\\thabit\\tchange\\tis\\tnot\\ta\\tsingle\\t1\\tpercent\\timprovement,\\tbut\\ta\\nthousand\\tof\\tthem.\\tIt’s\\ta\\tbunch\\tof\\tatomic\\thabits\\tstacking\\tup,\\teach\\tone\\ta\\nfundamental\\tunit\\tof\\tthe\\toverall\\tsystem.\\nIn\\tthe\\tbeginning,\\tsmall\\timprovements\\tcan\\toften\\tseem\\tmeaningless\\tbecause\\nthey\\tget\\twashed\\taway\\tby\\tthe\\tweight\\tof\\tthe\\tsystem.\\tJust\\tas\\tone\\t\\ncoin\\twon’t\\tmake\\nyou\\trich,\\tone\\tpositive\\tchange\\tlike\\tmeditating\\tfor\\tone\\tminute\\tor\\treading\\tone\\tpage\\neach\\tday\\tis\\tunlikely\\tto\\tdeliver\\ta\\tnoticeable\\tdifference.\\nGradually,\\tthough,\\tas\\tyou\\tcontinue\\tto\\tlayer\\tsmall\\tchanges\\ton\\ttop\\tof\\tone\\nanother,\\tthe\\tscales\\tof\\tlife\\tstart\\tto\\tmove.\\tEach\\timprovement\\tis\\tlike\\tadding\\ta\\tgrain\\nof\\tsand\\tto\\tthe\\tpositive\\tside\\tof\\tthe\\tscale,\\tslowly\\ttilting\\tthings\\tin\\tyour\\tfavor.\\nEventually,\\tif\\tyou\\tstick\\twith\\tit,\\tyou\\thit\\ta\\ttipping\\tpoint.\\tSuddenly,\\tit\\tfeels\\teasier\\nto\\tstick\\twith\\tgood\\thabits.\\tThe\\tweight\\tof\\tthe\\tsystem\\tis\\tworking\\tfor\\tyou\\trather\\nthan\\tagainst\\tyou.\\nOver\\tthe\\tcourse\\tof\\tthis\\tbook,\\twe’ve\\tlooked\\tat\\tdozens\\tof\\tstories\\tabout\\ttop\\nperformers.\\tWe’ve\\theard\\tabout\\tOlympic\\tgold\\tmedalists,\\taward-winning\\tartists,\\nbusiness\\tleaders,\\tlifesaving\\tphysicians,\\tand\\tstar\\tcomedians\\twho\\thave\\tall\\tused\\tthe\\nscience\\tof\\tsmall\\thabits\\tto\\tmaster\\ttheir\\tcraft\\tand\\tvault\\tto\\tthe\\ttop\\tof\\ttheir\\tfield.\\nEach\\tof\\tthe\\tpeople,\\tteams,\\tand\\tcompanies\\twe\\thave\\tcovered\\thas\\tfaced\\tdifferent\\ncircumstances,\\tbut\\tultimately\\tprogressed\\tin\\tthe\\tsame\\tway:\\tthrough\\ta\\ncommitment\\tto\\ttiny,\\tsustainable,\\tunrelenting\\timprovements.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 193}), Document(page_content='Success\\tis\\tnot\\ta\\tgoal\\tto\\treach\\tor\\ta\\tfinish\\tline\\tto\\tcross.\\tIt\\tis\\ta\\tsystem\\tto\\nimprove,\\tan\\tendless\\tprocess\\tto\\trefine.\\tIn\\tChapter\\t1,\\tI\\tsaid,\\t“If\\tyou’re\\thaving\\ntrouble\\tchanging\\tyour\\thabits,\\tthe\\tproblem\\tisn’t\\tyou.\\tThe\\tproblem\\tis\\tyour\\tsystem.\\nBad\\thabits\\trepeat\\tthemselves\\tagain\\tand\\tagain\\tnot\\tbecause\\tyou\\tdon’t\\twant\\tto\\nchange,\\tbut\\tbecause\\tyou\\thave\\tthe\\twrong\\tsystem\\tfor\\tchange.”\\nAs\\tthis\\tbook\\tdraws\\tto\\ta\\tclose,\\tI\\thope\\tthe\\topposite\\tis\\ttrue.\\tWith\\tthe\\tFour\\tLaws\\nof\\tBehavior\\tChange,\\tyou\\thave\\ta\\tset\\tof\\ttools\\tand\\tstrategies\\tthat\\tyou\\tcan\\tuse\\tto\\nbuild\\tbetter\\tsystems\\tand\\tshape\\tbetter\\thabits.\\tSometimes\\ta\\thabit\\twill\\tbe\\thard\\tto\\nremember\\tand\\tyou’ll\\tneed\\tto\\t\\nmake\\tit\\tobvious\\n.\\tOther\\ttimes\\tyou\\twon’t\\tfeel\\tlike\\nstarting\\tand\\tyou’ll\\tneed\\tto\\t\\nmake\\tit\\tattractive\\n.\\tIn\\tmany\\tcases,\\tyou\\tmay\\tfind\\tthat\\ta\\nhabit\\twill\\tbe\\ttoo\\tdifficult\\tand\\tyou’ll\\tneed\\tto\\t\\nmake\\tit\\teasy\\n.\\tAnd\\tsometimes,\\tyou\\nwon’t\\tfeel\\tlike\\tsticking\\twith\\tit\\tand\\tyou’ll\\tneed\\tto\\t\\nmake\\tit\\tsatisfying\\n.\\n\\t\\nBehaviors\\tare\\teffortless\\there.\\nBehaviors\\tare\\tdifficult\\there.\\nObvious\\nInvisible\\nAttractive\\nUnattractive\\nEasy\\nHard\\nSatisfying\\nUnsatisfying\\nYou\\twant\\tto\\tpush\\tyour\\tgood\\thabits\\ttoward\\tthe\\tleft\\tside\\tof\\tthe\\tspectrum\\tby\\tmaking\\tthem\\tobvious,\\tattractive,\\teasy,\\tand\\tsatisfying.\\tMeanwhile,\\tyou\\twant\\tto\\tcluster\\tyour\\tbad\\thabits\\ttoward\\tthe\\nright\\tside\\tby\\tmaking\\tthem\\tinvisible,\\tunattractive,\\thard,\\tand\\tunsatisfying.\\nThis\\tis\\ta\\tcontinuous\\tprocess.\\tThere\\tis\\tno\\tfinish\\tline.\\tThere\\tis\\tno\\tpermanent\\nsolution.\\tWhenever\\tyou’re\\tlooking\\tto\\timprove,\\tyou\\tcan\\trotate\\tthrough\\tthe\\tFour\\nLaws\\tof\\tBehavior\\tChange\\tuntil\\tyou\\tfind\\tthe\\tnext\\tbottleneck.\\t\\nMake\\tit\\tobvious.\\nMake\\tit\\tattractive.\\tMake\\tit\\teasy.\\tMake\\tit\\tsatisfying.\\n\\tRound\\tand\\tround.\\tAlways\\nlooking\\tfor\\tthe\\tnext\\tway\\tto\\tget\\t1\\tpercent\\tbetter.\\nThe\\tsecret\\tto\\tgetting\\tresults\\tthat\\tlast\\tis\\tto\\tnever\\tstop\\tmaking\\timprovements.\\nIt’s\\tremarkable\\twhat\\tyou\\tcan\\tbuild\\tif\\tyou\\tjust\\tdon’t\\tstop.\\tIt’s\\tremarkable\\tthe\\nbusiness\\tyou\\tcan\\tbuild\\tif\\tyou\\tdon’t\\tstop\\tworking.\\tIt’s\\tremarkable\\tthe\\tbody\\tyou\\ncan\\tbuild\\tif\\tyou\\tdon’t\\tstop\\ttraining.\\tIt’s\\tremarkable\\tthe\\tknowledge\\tyou\\tcan\\tbuild\\nif\\tyou\\tdon’t\\tstop\\tlearning.\\tIt’s\\tremarkable\\tthe\\tfortune\\tyou\\tcan\\tbuild\\tif\\tyou\\tdon’t\\nstop\\tsaving.\\tIt’s\\tremarkable\\tthe\\tfriendships\\tyou\\tcan\\tbuild\\tif\\tyou\\tdon’t\\tstop\\ncaring.\\tSmall\\thabits\\tdon’t\\tadd\\tup.\\tThey\\tcompound.\\nThat’s\\tthe\\tpower\\tof\\tatomic\\thabits.\\tTiny\\tchanges.\\tRemarkable\\t\\nresults.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 194}), Document(page_content='Appendix', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 195}), Document(page_content='What\\tShould\\tYou\\tRead\\tNext?\\nT\\nHANK\\tYOU\\tSO\\t\\nmuch\\tfor\\ttaking\\tthe\\ttime\\tto\\tread\\tthis\\tbook.\\tIt\\thas\\tbeen\\ta\\tpleasure\\nsharing\\tmy\\twork\\twith\\tyou.\\tIf\\tyou\\tare\\tlooking\\tfor\\tsomething\\tto\\tread\\tnext,\\tallow\\nme\\tto\\toffer\\ta\\tsuggestion.\\nIf\\tyou\\tenjoyed\\t\\nAtomic\\tHabits\\n,\\tthen\\tyou\\tmay\\tlike\\tmy\\tother\\twriting\\tas\\twell.\\tMy\\nlatest\\tarticles\\tare\\tsent\\tout\\tin\\tmy\\tfree\\tweekly\\tnewsletter.\\tSubscribers\\tare\\talso\\tthe\\nfirst\\tto\\thear\\tabout\\tmy\\tnewest\\tbooks\\tand\\tprojects.\\tFinally,\\tin\\taddition\\tto\\tmy\\town\\nwork,\\teach\\tyear\\tI\\tsend\\tout\\ta\\treading\\tlist\\tof\\tmy\\tfavorite\\tbooks\\tfrom\\tother\\tauthors\\non\\ta\\twide\\trange\\tof\\tsubjects.\\nYou\\tcan\\tsign\\tup\\tat:\\njamesclear.com/newsletter', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 196}), Document(page_content='Little\\tLessons\\tfrom\\tthe\\tFour\\tLaws\\nI\\nN\\tTHIS\\tBOOK\\n,\\tI\\thave\\tintroduced\\ta\\tfour-step\\tmodel\\tfor\\thuman\\tbehavior:\\tcue,\\tcraving,\\nresponse,\\treward.\\tThis\\tframework\\tnot\\tonly\\tteaches\\tus\\thow\\tto\\tcreate\\tnew\\thabits\\nbut\\talso\\treveals\\tsome\\tinteresting\\tinsights\\tabout\\thuman\\tbehavior.\\nProblem\\tphase\\n1.\\tCue\\n2.\\tCraving\\nSolution\\tphase\\n3.\\tResponse\\n4.\\tReward\\nIn\\tthis\\tsection,\\tI\\thave\\tcompiled\\tsome\\tlessons\\t(and\\ta\\tfew\\tbits\\tof\\tcommon\\nsense)\\tthat\\tare\\tconfirmed\\tby\\tthe\\tmodel.\\tThe\\tpurpose\\tof\\tthese\\texamples\\tis\\tto\\nclarify\\tjust\\thow\\tuseful\\tand\\twide-ranging\\tthis\\tframework\\tis\\twhen\\tdescribing\\nhuman\\tbehavior.\\tOnce\\tyou\\tunderstand\\tthe\\tmodel,\\tyou’ll\\tsee\\texamples\\tof\\tit\\neverywhere.\\nAwareness\\tcomes\\tbefore\\tdesire.\\n\\tA\\tcraving\\tis\\tcreated\\twhen\\tyou\\tassign\\nmeaning\\tto\\ta\\tcue.\\tYour\\tbrain\\tconstructs\\tan\\temotion\\tor\\tfeeling\\tto\\tdescribe\\tyour\\ncurrent\\tsituation,\\tand\\tthat\\tmeans\\ta\\tcraving\\tcan\\tonly\\toccur\\tafter\\tyou\\thave\\tnoticed\\nan\\topportunity.\\nHappiness\\tis\\tsimply\\tthe\\tabsence\\tof\\tdesire.\\n\\tWhen\\tyou\\tobserve\\ta\\t\\ncue,\\tbut\\tdo\\nnot\\tdesire\\tto\\tchange\\tyour\\tstate,\\tyou\\tare\\tcontent\\twith\\tthe\\tcurrent\\tsituation.\\nHappiness\\tis\\tnot\\tabout\\tthe\\tachievement\\tof\\tpleasure\\t(which\\tis\\tjoy\\tor\\tsatisfaction),\\nbut\\tabout\\tthe\\tlack\\tof\\tdesire.\\tIt\\tarrives\\twhen\\tyou\\thave\\tno\\turge\\tto\\tfeel\\tdifferently.\\nHappiness\\tis\\tthe\\tstate\\tyou\\tenter\\twhen\\tyou\\tno\\tlonger\\twant\\tto\\tchange\\tyour\\tstate.\\nHowever,\\thappiness\\tis\\tfleeting\\tbecause\\ta\\tnew\\tdesire\\talways\\tcomes\\talong.\\tAs\\nCaed\\tBudris\\tsays,\\t“\\nHappiness\\tis\\tthe\\tspace\\tbetween\\tone\\tdesire\\tbeing\\tfulfilled\\tand\\na\\tnew\\tdesire\\tforming.”\\tLikewise,\\tsuffering\\tis\\tthe\\tspace\\tbetween\\tcraving\\ta\\nchange\\tin\\tstate\\tand\\tgetting\\tit.\\nIt\\tis\\tthe\\t\\nidea\\n\\tof\\tpleasure\\tthat\\twe\\tchase.\\n\\tWe\\tseek\\tthe\\timage\\tof\\tpleasure\\tthat\\nwe\\tgenerate\\tin\\tour\\tminds.\\tAt\\tthe\\ttime\\tof\\taction,\\twe\\tdo\\tnot\\tknow\\twhat\\tit\\twill\\tbe', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 197}), Document(page_content='like\\tto\\tattain\\tthat\\timage\\t(or\\teven\\tif\\tit\\twill\\tsatisfy\\tus).\\tThe\\tfeeling\\tof\\tsatisfaction\\nonly\\tcomes\\tafterward.\\tThis\\tis\\twhat\\tthe\\tAustrian\\tneurologist\\tVictor\\tFrankl\\tmeant\\nwhen\\the\\tsaid\\tthat\\t\\nhappiness\\tcannot\\tbe\\tpursued,\\tit\\tmust\\tensue.\\tDesire\\tis\\tpursued.\\nPleasure\\tensues\\tfrom\\taction.\\nPeace\\toccurs\\twhen\\tyou\\tdon’t\\tturn\\tyour\\tobservations\\tinto\\tproblems.\\n\\tThe\\nfirst\\tstep\\tin\\tany\\tbehavior\\tis\\tobservation.\\tYou\\tnotice\\ta\\tcue,\\ta\\tbit\\tof\\tinformation,\\nan\\tevent.\\tIf\\tyou\\tdo\\tnot\\tdesire\\tto\\tact\\ton\\twhat\\tyou\\tobserve,\\tthen\\tyou\\tare\\tat\\tpeace.\\nCraving\\tis\\tabout\\twanting\\tto\\tfix\\teverything.\\tObservation\\twithout\\tcraving\\tis\\tthe\\nrealization\\tthat\\tyou\\tdo\\tnot\\tneed\\tto\\tfix\\tanything.\\tYour\\tdesires\\tare\\tnot\\trunning\\nrampant.\\tYou\\tdo\\tnot\\tcrave\\ta\\tchange\\tin\\tstate.\\tYour\\tmind\\tdoes\\tnot\\tgenerate\\ta\\nproblem\\tfor\\tyou\\tto\\tsolve.\\tYou’re\\tsimply\\tobserving\\tand\\texisting.\\nWith\\ta\\tbig\\tenough\\t\\nwhy\\n\\tyou\\tcan\\tovercome\\tany\\t\\nhow\\n.\\n\\tFriedrich\\tNietzsche,\\nthe\\tGerman\\tphilosopher\\tand\\tpoet,\\tfamously\\twrote,\\t“\\nHe\\twho\\thas\\ta\\twhy\\tto\\tlive\\nfor\\tcan\\tbear\\talmost\\tany\\thow.”\\tThis\\tphrase\\tharbors\\tan\\timportant\\ttruth\\tabout\\nhuman\\tbehavior.\\tIf\\tyour\\tmotivation\\tand\\tdesire\\tare\\tgreat\\tenough\\t(that\\tis,\\t\\nwhy\\n\\tare\\nyou\\tare\\tacting),\\tyou’ll\\ttake\\taction\\t\\neven\\twhen\\tit\\tis\\tquite\\tdifficult.\\tGreat\\tcraving\\ncan\\tpower\\tgreat\\taction—even\\twhen\\tfriction\\tis\\thigh.\\nBeing\\tcurious\\tis\\tbetter\\tthan\\tbeing\\tsmart.\\n\\tBeing\\tmotivated\\tand\\tcurious\\ncounts\\tfor\\tmore\\tthan\\tbeing\\tsmart\\tbecause\\tit\\tleads\\tto\\taction.\\tBeing\\tsmart\\twill\\nnever\\tdeliver\\tresults\\ton\\tits\\town\\tbecause\\tit\\tdoesn’t\\tget\\tyou\\tto\\tact.\\tIt\\tis\\tdesire,\\tnot\\nintelligence,\\tthat\\tprompts\\tbehavior.\\tAs\\tNaval\\tRavikant\\tsays,\\t“The\\ttrick\\tto\\tdoing\\nanything\\tis\\tfirst\\tcultivating\\ta\\tdesire\\tfor\\tit.”\\nEmotions\\tdrive\\tbehavior.\\n\\tEvery\\tdecision\\tis\\tan\\temotional\\tdecision\\tat\\tsome\\nlevel.\\tWhatever\\tyour\\tlogical\\treasons\\tare\\tfor\\ttaking\\taction,\\tyou\\tonly\\tfeel\\ncompelled\\tto\\tact\\ton\\tthem\\tbecause\\tof\\temotion.\\tIn\\tfact,\\tpeople\\twith\\tdamage\\tto\\nemotional\\tcenters\\tof\\tthe\\tbrain\\tcan\\tlist\\tmany\\treasons\\tfor\\ttaking\\taction\\tbut\\tstill\\nwill\\tnot\\tact\\tbecause\\tthey\\tdo\\tnot\\thave\\temotions\\tto\\tdrive\\tthem.\\tThis\\tis\\twhy\\ncraving\\tcomes\\t\\nbefore\\n\\tresponse.\\tThe\\tfeeling\\tcomes\\tfirst,\\tand\\tthen\\tthe\\tbehavior.\\nWe\\tcan\\tonly\\tbe\\trational\\tand\\tlogical\\t\\nafter\\n\\twe\\thave\\tbeen\\temotional.\\n\\tThe\\nprimary\\tmode\\tof\\tthe\\tbrain\\tis\\tto\\tfeel;\\tthe\\tsecondary\\tmode\\tis\\tto\\tthink.\\tOur\\tfirst\\nresponse—the\\tfast,\\tnonconscious\\tportion\\tof\\tthe\\tbrain—is\\toptimized\\tfor\\tfeeling\\nand\\tanticipating.\\tOur\\tsecond\\tresponse—the\\tslow,\\tconscious\\tportion\\tof\\tthe\\tbrain\\n—is\\tthe\\tpart\\tthat\\tdoes\\tthe\\t“thinking.”\\nPsychologists\\trefer\\tto\\tthis\\tas\\tSystem\\t1\\t(feelings\\tand\\trapid\\tjudgments)\\tversus\\nSystem\\t2\\t(rational\\tanalysis).\\t\\nThe\\tfeeling\\tcomes\\tfirst\\t(System\\t1);\\tthe\\trationality\\nonly\\tintervenes\\tlater\\t(System\\t2).\\tThis\\tworks\\tgreat\\twhen\\tthe\\ttwo\\tare\\taligned,\\tbut\\nit\\tresults\\tin\\tillogical\\tand\\temotional\\tthinking\\twhen\\tthey\\tare\\tnot.\\nYour\\tresponse\\ttends\\tto\\tfollow\\tyour\\temotions.\\n\\tOur\\tthoughts\\tand\\tactions\\tare\\nrooted\\tin\\twhat\\twe\\tfind\\tattractive,\\tnot\\tnecessarily\\tin\\twhat\\tis\\tlogical.\\tTwo\\tpeople', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 198}), Document(page_content='can\\tnotice\\tthe\\tsame\\tset\\tof\\tfacts\\tand\\trespond\\tvery\\tdifferently\\tbecause\\tthey\\trun\\nthose\\tfacts\\tthrough\\ttheir\\tunique\\temotional\\tfilter.\\tThis\\tis\\tone\\treason\\twhy\\nappealing\\tto\\temotion\\tis\\ttypically\\t\\nmore\\tpowerful\\tthan\\tappealing\\tto\\treason.\\tIf\\ta\\ntopic\\tmakes\\tsomeone\\tfeel\\temotional,\\tthey\\twill\\trarely\\tbe\\tinterested\\tin\\tthe\\tdata.\\nThis\\tis\\twhy\\temotions\\tcan\\tbe\\tsuch\\ta\\tthreat\\tto\\twise\\tdecision\\tmaking.\\nPut\\tanother\\tway:\\tmost\\tpeople\\tbelieve\\tthat\\tthe\\treasonable\\tresponse\\tis\\tthe\\tone\\nthat\\tbenefits\\tthem:\\tthe\\tone\\tthat\\tsatisfies\\ttheir\\tdesires.\\tTo\\tapproach\\ta\\tsituation\\nfrom\\ta\\tmore\\tneutral\\temotional\\tposition\\tallows\\tyou\\tto\\tbase\\tyour\\tresponse\\ton\\tthe\\ndata\\trather\\tthan\\tthe\\temotion.\\nSuffering\\tdrives\\tprogress.\\n\\tThe\\tsource\\tof\\tall\\tsuffering\\tis\\tthe\\tdesire\\tfor\\ta\\nchange\\tin\\tstate.\\tThis\\tis\\talso\\tthe\\tsource\\tof\\tall\\tprogress.\\tThe\\tdesire\\tto\\tchange\\tyour\\nstate\\tis\\twhat\\tpowers\\tyou\\tto\\ttake\\taction.\\tIt\\tis\\twanting\\tmore\\tthat\\tpushes\\thumanity\\nto\\tseek\\timprovements,\\tdevelop\\tnew\\ttechnologies,\\tand\\treach\\tfor\\ta\\thigher\\tlevel.\\nWith\\tcraving,\\twe\\tare\\tdissatisfied\\tbut\\tdriven.\\tWithout\\tcraving,\\twe\\tare\\tsatisfied\\nbut\\tlack\\tambition.\\nYour\\tactions\\treveal\\thow\\tbadly\\tyou\\twant\\tsomething.\\n\\tIf\\tyou\\tkeep\\tsaying\\nsomething\\tis\\ta\\tpriority\\tbut\\tyou\\tnever\\tact\\ton\\tit,\\tthen\\tyou\\tdon’t\\treally\\twant\\tit.\\tIt’s\\ntime\\tto\\thave\\tan\\thonest\\tconversation\\twith\\tyourself.\\tYour\\tactions\\treveal\\tyour\\ttrue\\nmotivations.\\nReward\\tis\\ton\\tthe\\tother\\tside\\tof\\tsacrifice.\\n\\tResponse\\t(sacrifice\\tof\\tenergy)\\nalways\\tprecedes\\treward\\t(the\\tcollection\\tof\\tresources).\\tThe\\t“runner’s\\thigh”\\tonly\\ncomes\\tafter\\tthe\\thard\\trun.\\tThe\\treward\\tonly\\tcomes\\tafter\\tthe\\tenergy\\tis\\tspent.\\nSelf-control\\tis\\tdifficult\\tbecause\\tit\\tis\\tnot\\tsatisfying.\\n\\tA\\treward\\tis\\tan\\toutcome\\nthat\\tsatisfies\\tyour\\tcraving.\\tThis\\tmakes\\tself-control\\tineffective\\tbecause\\tinhibiting\\nour\\tdesires\\tdoes\\tnot\\tusually\\tresolve\\tthem.\\tResisting\\ttemptation\\tdoes\\tnot\\tsatisfy\\nyour\\tcraving;\\tit\\tjust\\tignores\\tit.\\tIt\\tcreates\\tspace\\tfor\\tthe\\tcraving\\tto\\tpass.\\tSelf-\\ncontrol\\trequires\\tyou\\tto\\trelease\\ta\\tdesire\\trather\\tthan\\tsatisfy\\tit.\\nOur\\texpectations\\tdetermine\\tour\\tsatisfaction.\\n\\tThe\\tgap\\tbetween\\tour\\tcravings\\nand\\tour\\trewards\\tdetermines\\thow\\tsatisfied\\twe\\tfeel\\tafter\\ttaking\\taction.\\tIf\\tthe\\nmismatch\\tbetween\\texpectations\\tand\\toutcomes\\tis\\tpositive\\t(surprise\\tand\\tdelight),\\nthen\\twe\\tare\\tmore\\tlikely\\tto\\trepeat\\ta\\t\\nbehavior\\tin\\tthe\\tfuture.\\tIf\\tthe\\tmismatch\\tis\\nnegative\\t(disappointment\\tand\\tfrustration),\\tthen\\twe\\tare\\tless\\tlikely\\tto\\tdo\\tso.\\nFor\\texample,\\tif\\tyou\\texpect\\tto\\tget\\t$10\\tand\\tget\\t$100,\\tyou\\tfeel\\tgreat.\\tIf\\tyou\\nexpect\\tto\\tget\\t$100\\tand\\tget\\t$10,\\tyou\\tfeel\\tdisappointed.\\tYour\\texpectation\\tchanges\\nyour\\tsatisfaction.\\tAn\\taverage\\texperience\\tpreceded\\tby\\thigh\\texpectations\\tis\\ta\\ndisappointment.\\tAn\\taverage\\texperience\\tpreceded\\tby\\tlow\\texpectations\\tis\\ta\\ndelight.\\tWhen\\tliking\\tand\\twanting\\tare\\tapproximately\\tthe\\tsame,\\tyou\\tfeel\\tsatisfied.\\nSatisfaction\\t=\\tLiking\\t–\\tWanting', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 199}), Document(page_content='Satisfaction\\t=\\tLiking\\t–\\tWanting\\nThis\\tis\\tthe\\twisdom\\tbehind\\tSeneca’s\\tfamous\\tquote,\\t“\\nBeing\\tpoor\\tis\\tnot\\thaving\\ntoo\\tlittle,\\tit\\tis\\twanting\\tmore.”\\tIf\\tyour\\twants\\toutpace\\tyour\\tlikes,\\tyou’ll\\talways\\tbe\\nunsatisfied.\\tYou’re\\tperpetually\\tputting\\tmore\\tweight\\ton\\tthe\\tproblem\\tthan\\tthe\\nsolution.\\nHappiness\\tis\\trelative.\\tWhen\\tI\\tfirst\\tbegan\\tsharing\\tmy\\twriting\\tpublicly\\tit\\ttook\\nme\\tthree\\tmonths\\tto\\tget\\tone\\tthousand\\tsubscribers.\\tWhen\\tI\\thit\\tthat\\tmilestone,\\tI\\ntold\\tmy\\tparents\\tand\\tmy\\tgirlfriend.\\tWe\\tcelebrated.\\tI\\tfelt\\texcited\\tand\\tmotivated.\\tA\\nfew\\tyears\\tlater,\\tI\\trealized\\tthat\\tone\\tthousand\\tpeople\\twere\\tsigning\\tup\\teach\\tday.\\nAnd\\tyet\\tI\\tdidn’t\\teven\\tthink\\tto\\ttell\\tanyone.\\tIt\\tfelt\\tnormal.\\tI\\twas\\tgetting\\tresults\\nninety\\ttimes\\tfaster\\tthan\\tbefore\\tbut\\texperiencing\\tlittle\\tpleasure\\tover\\tit.\\tIt\\twasn’t\\nuntil\\ta\\tfew\\tdays\\tlater\\tthat\\tI\\trealized\\thow\\tabsurd\\tit\\twas\\tthat\\tI\\twasn’t\\tcelebrating\\nsomething\\tthat\\twould\\thave\\tseemed\\tlike\\ta\\tpipe\\tdream\\tjust\\ta\\tfew\\tyears\\tbefore.\\nThe\\tpain\\tof\\tfailure\\tcorrelates\\tto\\tthe\\theight\\tof\\texpectation.\\n\\tWhen\\tdesire\\tis\\nhigh,\\tit\\thurts\\tto\\tnot\\t\\nlike\\n\\tthe\\toutcome.\\tFailing\\tto\\tattain\\tsomething\\tyou\\twant\\thurts\\nmore\\tthan\\tfailing\\tto\\tattain\\tsomething\\tyou\\tdidn’t\\tthink\\tmuch\\tabout\\tin\\tthe\\tfirst\\nplace.\\tThis\\tis\\twhy\\tpeople\\tsay,\\t“I\\tdon’t\\twant\\tto\\tget\\tmy\\thopes\\tup.”\\nFeelings\\tcome\\tboth\\tbefore\\tand\\tafter\\tthe\\tbehavior.\\n\\tBefore\\tacting,\\tthere\\tis\\ta\\nfeeling\\tthat\\tmotivates\\tyou\\tto\\tact—the\\tcraving.\\tAfter\\tacting,\\t\\nthere\\tis\\ta\\tfeeling\\nthat\\tteaches\\tyou\\tto\\trepeat\\tthe\\taction\\tin\\tthe\\tfuture—the\\treward.\\nCue\\t>\\tCraving\\t(Feeling)\\t>\\tResponse\\t>\\tReward\\t(Feeling)\\nHow\\twe\\tfeel\\tinfluences\\thow\\twe\\tact,\\tand\\thow\\twe\\tact\\tinfluences\\thow\\twe\\tfeel.\\nDesire\\tinitiates.\\tPleasure\\tsustains.\\n\\tWanting\\tand\\tliking\\tare\\tthe\\ttwo\\tdrivers\\tof\\nbehavior.\\tIf\\tit’s\\tnot\\tdesirable,\\tyou\\thave\\tno\\treason\\tto\\tdo\\tit.\\tDesire\\tand\\tcraving\\tare\\nwhat\\tinitiate\\ta\\tbehavior.\\tBut\\tif\\tit’s\\tnot\\tenjoyable,\\tyou\\thave\\tno\\treason\\tto\\trepeat\\tit.\\nPleasure\\tand\\tsatisfaction\\tare\\twhat\\tsustain\\ta\\tbehavior.\\tFeeling\\tmotivated\\tgets\\tyou\\nto\\tact.\\tFeeling\\tsuccessful\\tgets\\tyou\\tto\\trepeat.\\nHope\\tdeclines\\twith\\texperience\\tand\\tis\\treplaced\\tby\\tacceptance.\\n\\tThe\\tfirst\\ntime\\tan\\topportunity\\tarises,\\tthere\\tis\\thope\\tof\\twhat\\tcould\\tbe.\\tYour\\texpectation\\n(cravings)\\tis\\tbased\\tsolely\\ton\\t\\npromise\\n.\\tThe\\tsecond\\ttime\\taround,\\tyour\\texpectation\\nis\\tgrounded\\tin\\treality.\\tYou\\tbegin\\tto\\tunderstand\\thow\\tthe\\tprocess\\tworks\\tand\\tyour\\nhope\\tis\\tgradually\\ttraded\\tfor\\ta\\tmore\\taccurate\\tprediction\\tand\\tacceptance\\tof\\tthe\\nlikely\\toutcome.\\nThis\\tis\\tone\\treason\\twhy\\twe\\tcontinually\\tgrasp\\tfor\\tthe\\tlatest\\tget-rich-quick\\tor', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 200}), Document(page_content='weight-loss\\tscheme.\\tNew\\tplans\\toffer\\thope\\tbecause\\twe\\tdon’t\\thave\\tany\\nexperiences\\tto\\tground\\tour\\texpectations.\\tNew\\tstrategies\\tseem\\tmore\\tappealing\\nthan\\told\\tones\\tbecause\\tthey\\tcan\\thave\\tunbounded\\thope.\\t\\nAs\\tAristotle\\tnoted,\\n“Youth\\tis\\teasily\\tdeceived\\tbecause\\tit\\tis\\tquick\\tto\\thope.”\\tPerhaps\\tthis\\tcan\\tbe\\nrevised\\tto\\t“Youth\\tis\\teasily\\tdeceived\\tbecause\\tit\\tonly\\thopes.”\\tThere\\tis\\tno\\nexperience\\tto\\troot\\tthe\\texpectation\\tin.\\tIn\\tthe\\tbeginning,\\thope\\tis\\tall\\tyou\\thave.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 201}), Document(page_content='How\\tto\\tApply\\tThese\\tIdeas\\tto\\tBusiness\\nO\\nVER\\tTHE\\tYEARS\\n,\\tI’ve\\tspoken\\tat\\tFortune\\t500\\tcompanies\\tand\\tgrowing\\tstart-ups\\tabout\\nhow\\tto\\tapply\\tthe\\tscience\\tof\\tsmall\\thabits\\tto\\trun\\tmore\\teffective\\tbusinesses\\tand\\nbuild\\tbetter\\tproducts.\\tI’ve\\tcompiled\\tmany\\tof\\tthe\\tmost\\tpractical\\tstrategies\\tinto\\ta\\nshort\\tbonus\\tchapter.\\tI\\tthink\\tyou’ll\\tfind\\tit\\tto\\tbe\\tan\\tincredibly\\tuseful\\taddition\\tto\\nthe\\tmain\\tideas\\tmentioned\\tin\\t\\nAtomic\\tHabits\\n.\\nYou\\tcan\\tdownload\\tthis\\tchapter\\tat:\\t\\natomichabits.com/business', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 202}), Document(page_content='How\\tto\\tApply\\tThese\\tIdeas\\tto\\tParenting\\nO\\nNE\\tOF\\tTHE\\t\\nmost\\tcommon\\tquestions\\tI\\thear\\tfrom\\treaders\\tis\\tsomething\\talong\\tthe\\nlines\\tof,\\t“How\\tcan\\tI\\tget\\tmy\\tkids\\tto\\tdo\\tthis\\tstuff?”\\tThe\\tideas\\tin\\t\\nAtomic\\tHabits\\nare\\tintended\\tto\\tapply\\tbroadly\\tto\\tall\\tof\\thuman\\tbehavior\\t(teenagers\\tare\\thumans,\\ntoo),\\twhich\\tmeans\\tyou\\tshould\\tfind\\tplenty\\tof\\tuseful\\tstrategies\\tin\\tthe\\tmain\\ttext.\\nThat\\tsaid,\\tparenting\\tdoes\\tface\\tits\\town\\tset\\tof\\tchallenges.\\tAs\\ta\\tbonus\\tchapter,\\tI’ve\\nput\\ttogether\\ta\\tbrief\\tguide\\ton\\thow\\tto\\tapply\\tthese\\tideas\\tspecifically\\tto\\tparenting.\\nYou\\tcan\\tdownload\\tthis\\tchapter\\tat:\\t\\natomichabits.com/parenting', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 203}), Document(page_content='Acknowledgments\\nI\\n\\t\\nHAVE\\tRELIED\\tHEAVILY\\t\\non\\tothers\\tduring\\tthe\\tcreation\\tof\\tthis\\tbook.\\tBefore\\tanyone\\telse,\\tI\\nmust\\tthank\\tmy\\twife,\\tKristy,\\twho\\thas\\tbeen\\tindispensable\\tthroughout\\tthis\\tprocess.\\nShe\\thas\\tplayed\\tevery\\trole\\ta\\tperson\\tcan\\tplay\\tin\\tthe\\twriting\\tof\\ta\\tbook:\\tspouse,\\nfriend,\\tfan,\\tcritic,\\teditor,\\tresearcher,\\ttherapist.\\tIt\\tis\\tno\\texaggeration\\tto\\tsay\\tthis\\nbook\\twould\\tnot\\tbe\\tthe\\tsame\\twithout\\ther.\\tIt\\tmight\\tnot\\texist\\tat\\tall.\\tLike\\neverything\\tin\\tour\\tlife,\\twe\\tdid\\tit\\ttogether.\\nSecond,\\tI\\tam\\tgrateful\\tto\\tmy\\tfamily,\\tnot\\tonly\\tfor\\ttheir\\tsupport\\tand\\nencouragement\\ton\\tthis\\tbook\\tbut\\talso\\tfor\\tbelieving\\tin\\tme\\tno\\tmatter\\twhat\\tproject\\tI\\nhappen\\tto\\tbe\\tworking\\ton.\\tI\\thave\\tbenefited\\tfrom\\tmany\\tyears\\tof\\tsupport\\tfrom\\tmy\\nparents,\\tgrandparents,\\tand\\tsiblings.\\tIn\\tparticular,\\tI\\twant\\tmy\\tmom\\tand\\tdad\\tto\\nknow\\tthat\\tI\\tlove\\tthem.\\tIt\\tis\\ta\\tspecial\\tfeeling\\tto\\tknow\\tthat\\tyour\\tparents\\tare\\tyour\\ngreatest\\tfans.\\nThird,\\tto\\tmy\\tassistant,\\tLyndsey\\tNuckols.\\tAt\\tthis\\tpoint,\\ther\\tjob\\tdefies\\ndescription\\tas\\tshe\\thas\\tbeen\\tasked\\tto\\tdo\\tnearly\\teverything\\tone\\tcould\\timagine\\tfor\\na\\tsmall\\tbusiness.\\tThankfully,\\ther\\tskills\\tand\\ttalents\\tare\\tmore\\tpowerful\\tthan\\tmy\\nquestionable\\tmanagement\\tstyle.\\tSome\\tsections\\tof\\tthis\\tbook\\tare\\tas\\tmuch\\thers\\tas\\nthey\\tare\\tmine.\\tI\\tam\\tdeeply\\tgrateful\\tfor\\ther\\thelp.\\nAs\\tfor\\tthe\\tcontent\\tand\\twriting\\tof\\tthe\\tbook,\\tI\\thave\\ta\\tlong\\tlist\\tof\\tpeople\\tto\\nthank.\\tTo\\tstart,\\tthere\\tare\\ta\\tfew\\tpeople\\tfrom\\twhom\\tI\\thave\\tlearned\\tso\\tmuch\\tthat\\tit\\nwould\\tbe\\ta\\tcrime\\tto\\tnot\\tmention\\tthem\\tby\\tname.\\tLeo\\tBabauta,\\tCharles\\tDuhigg,\\nNir\\tEyal,\\tand\\tBJ\\tFogg\\thave\\teach\\tinfluenced\\tmy\\tthoughts\\ton\\thabits\\tin\\nmeaningful\\tways.\\tTheir\\twork\\tand\\tideas\\tcan\\tbe\\tfound\\tsprinkled\\tthroughout\\tthis\\ntext.\\tIf\\tyou\\tenjoyed\\tthis\\tbook,\\tI’d\\tencourage\\tyou\\tto\\tread\\ttheir\\twriting\\tas\\twell.\\nAt\\tvarious\\tstages\\tof\\twriting,\\tI\\tbenefited\\tfrom\\tthe\\tguidance\\tof\\tmany\\tfine\\neditors.\\tThanks\\tto\\tPeter\\tGuzzardi\\tfor\\twalking\\tme\\tthrough\\tthe\\tearly\\tstages\\tof\\tthe\\nwriting\\tprocess\\tand\\tfor\\ta\\tkick\\tin\\tthe\\tpants\\twhen\\tI\\treally\\tneeded\\tit.\\tI\\tam\\tindebted\\nto\\tBlake\\tAtwood\\tand\\tRobin\\tDellabough\\tfor\\ttransforming\\tmy\\tugly\\tand\\tinsanely\\nlong\\tfirst\\tdrafts\\tinto\\ta\\ttight,\\treadable\\tmanuscript.\\tAnd\\tI\\tam\\tthankful\\tto\\tAnne\\nBarngrover\\tfor\\ther\\tability\\tto\\tadd\\ta\\tlittle\\tclass\\tand\\tpoetic\\tstyle\\tto\\tmy\\twriting.\\nI’d\\tlike\\tto\\tthank\\tthe\\tmany\\tpeople\\twho\\tread\\tearly\\tversions\\tof\\tthe\\tmanuscript,\\nincluding\\tBruce\\tAmmons,\\tDarcey\\tAnsell,\\tTim\\tBallard,\\tVishal\\tBhardwaj,\\nCharlotte\\tBlank,\\tJerome\\tBurt,\\tSim\\tCampbell,\\tAl\\tCarlos,\\tNicky\\tCase,\\tJulie\\nChang,\\tJason\\tCollins,\\tDebra\\tCroy,\\tRoger\\tDooley,\\tTiago\\tForte,\\tMatt\\tGartland,', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 204}), Document(page_content='Andrew\\tGierer,\\tRandy\\tGiffen,\\tJon\\tGiganti,\\tAdam\\tGilbert,\\tStephan\\tGuyenet,\\nJeremy\\tHendon,\\tJane\\tHorvath,\\tJoakim\\tJansson,\\tJosh\\tKaufman,\\tAnne\\tKavanagh,\\nChris\\tKlaus,\\tZeke\\tLopez,\\tCady\\tMacon,\\tCyd\\tMadsen,\\tKiera\\tMcGrath,\\tAmy\\nMitchell,\\tAnna\\tMoise,\\tStacey\\tMorris,\\tTara-Nicholle\\tNelson,\\tTaylor\\tPearson,\\nMax\\tShank,\\tTrey\\tShelton,\\tJason\\tShen,\\tJacob\\tZangelidis,\\tand\\tAri\\tZelmanow.\\nThe\\tbook\\tbenefited\\tgreatly\\tfrom\\tyour\\tfeedback.\\nTo\\tthe\\tteam\\tat\\tAvery\\tand\\tPenguin\\tRandom\\tHouse\\twho\\tmade\\tthis\\tbook\\ta\\nreality,\\tthank\\tyou.\\tI\\towe\\ta\\tdebt\\tof\\tspecial\\tthanks\\tto\\tmy\\tpublisher,\\tMegan\\nNewman,\\tfor\\ther\\tendless\\tpatience\\tas\\tI\\tcontinually\\tpushed\\tback\\tdeadlines.\\tShe\\ngave\\tme\\tthe\\tspace\\tI\\tneeded\\tto\\tcreate\\ta\\tbook\\tI\\twas\\tproud\\tof\\tand\\tchampioned\\tmy\\nideas\\tat\\tevery\\tstep.\\tTo\\tNina,\\tfor\\ther\\tability\\tto\\ttransform\\tmy\\twriting\\twhile\\tstill\\nretaining\\tmy\\toriginal\\tmessage.\\tTo\\t\\nLindsay,\\tFarin,\\tCasey,\\tand\\tthe\\trest\\tof\\tthe\\nPRH\\tteam\\tfor\\tspreading\\tthe\\tmessage\\tof\\tthis\\tbook\\tto\\tmore\\tpeople\\tthan\\tI\\tcould\\never\\treach\\ton\\tmy\\town.\\tTo\\tPete\\tGarceau,\\tfor\\tdesigning\\ta\\tbeautiful\\tcover\\tfor\\tthis\\nbook.\\nAnd\\tto\\tmy\\tagent,\\tLisa\\tDiMona,\\tfor\\ther\\tguidance\\tand\\tinsight\\tat\\tevery\\tstep\\tof\\nthe\\tpublishing\\tprocess.\\nTo\\tthe\\tmany\\tfriends\\tand\\tfamily\\tmembers\\twho\\tasked\\t“How’s\\tthe\\tbook\\ngoing?”\\tand\\toffered\\ta\\tword\\tof\\tencouragement\\twhen\\tI\\tinevitably\\treplied\\n“Slowly”—thank\\tyou.\\tEvery\\tauthor\\tfaces\\ta\\tfew\\tdark\\tmoments\\twhen\\twriting\\ta\\nbook,\\tand\\tone\\tkind\\tword\\tcan\\tbe\\tenough\\tto\\tget\\tyou\\tto\\tshow\\tup\\tagain\\tthe\\tnext\\nday.\\nI\\tam\\tsure\\tthere\\tare\\tpeople\\tI\\thave\\tforgotten,\\tbut\\tI\\tkeep\\tan\\tupdated\\tlist\\tof\\nanyone\\twho\\thas\\tinfluenced\\tmy\\tthinking\\tin\\tmeaningful\\tways\\tat\\njamesclear.com/thanks\\n.\\nAnd\\tfinally,\\tto\\tyou.\\tLife\\tis\\tshort\\tand\\tyou\\thave\\tshared\\tsome\\tof\\tyour\\tprecious\\ntime\\twith\\tme\\tby\\treading\\tthis\\tbook.\\tThank\\tyou.\\n—May\\t\\n2018', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 205}), Document(page_content='Notes\\nI\\nN\\tTHIS\\tSECTION\\n,\\tI\\thave\\tincluded\\ta\\tdetailed\\tlist\\tof\\tnotes,\\treferences,\\tand\\tcitations\\tfor\\neach\\tchapter\\tin\\tthe\\tbook.\\tI\\ttrust\\tthat\\tmost\\treaders\\twill\\tfind\\tthis\\tlist\\tto\\tbe\\nsufficient.\\tHowever,\\tI\\talso\\trealize\\tthat\\tscientific\\tliterature\\tchanges\\tover\\ttime\\tand\\nthe\\treferences\\tfor\\tthis\\tbook\\tmay\\tneed\\tto\\tbe\\tupdated.\\tFurthermore,\\tI\\tfully\\texpect\\nthat\\tI\\thave\\tmade\\ta\\tmistake\\tsomewhere\\tin\\tthis\\tbook—either\\tin\\tattributing\\tan\\tidea\\nto\\tthe\\twrong\\tperson\\tor\\tnot\\tgiving\\tcredit\\tto\\tsomeone\\twhere\\tit\\tis\\tdue.\\t(If\\tyou\\nbelieve\\tthis\\tto\\tbe\\tthe\\tcase,\\tplease\\temail\\tme\\tat\\t\\njames@jamesclear.com\\n\\tso\\tI\\tcan\\nfix\\tthe\\tissue\\tas\\tsoon\\tas\\tpossible.)\\nIn\\taddition\\tto\\tthe\\tnotes\\tbelow,\\tyou\\tcan\\tfind\\ta\\tfull\\tlist\\tof\\tupdated\\tendnotes\\tand\\ncorrections\\tat\\t\\natomichabits.com/endnotes\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 206}), Document(page_content='INTRODUCTION\\nWe\\tall\\tdeal\\twith\\tsetbacks\\n:\\t\\nWhat\\tabout\\tluck,\\tyou\\tmight\\task?\\tLuck\\tmatters,\\tcertainly.\\tHabits\\tare\\tnot\\tthe\\tonly\\tthing\\tthat\\tinfluence\\tyour\\tsuccess,\\tbut\\tthey\\tare\\tprobably\\tthe\\tmost\\timportant\\tfactor\\tthat\\tis\\nwithin\\tyour\\tcontrol.\\tAnd\\tthe\\tonly\\tselfimprovement\\tstrategy\\tthat\\tmakes\\tany\\tsense\\tis\\tto\\tfocus\\ton\\twhat\\tyou\\tcan\\tcontrol.\\nThe\\tentrepreneur\\tand\\tinvestor\\tNaval\\tRavikant\\n:\\n\\tNaval\\tRavikant\\t(@naval),\\t“To\\twrite\\ta\\tgreat\\tbook,\\tyou\\tmust\\tfirst\\tbecome\\tthe\\tbook,”\\tTwitter,\\tMay\\t15,\\t2018,\\nhttps://twitter.com/naval/status/996460948029362176\\n.\\n“stimulus,\\tresponse,\\treward”\\n:\\n\\tB.\\tF.\\tSkinner,\\t\\nThe\\tBehavior\\tof\\tOrganisms\\n\\t(New\\tYork:\\tAppleton-Century-Crofts,\\t1938).\\n“cue,\\troutine,\\treward”\\n:\\t\\nCharles\\tDuhigg,\\t\\nThe\\tPower\\tof\\tHabit:\\tWhy\\tWe\\tDo\\tWhat\\tWe\\tDo\\tin\\tLife\\tand\\tBusiness\\n\\t(New\\tYork:\\tRandom\\tHouse,\\t2014).', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 207}), Document(page_content='CHAPTER\\t1\\njust\\ta\\tsingle\\tgold\\tmedal\\tat\\tthe\\tOlympic\\tGames\\n:\\t\\nMatt\\tSlater,\\t“How\\tGB\\tCycling\\tWent\\tfrom\\tTragic\\tto\\tMagic,”\\tBBC\\tSport,\\tApril\\t14,\\t2008,\\nhttp://news.bbc.co.uk/sport2/hi/olympics/cycling/7534073.stm\\n.\\nthe\\tTour\\tde\\tFrance\\n:\\t\\nTom\\tFordyce,\\t“Tour\\tde\\tFrance\\t2017:\\tIs\\tChris\\tFroome\\tBritain’s\\tLeast\\tLoved\\tGreat\\tSportsman?”\\tBBC\\tSport,\\tJuly\\t23,\\t2017,\\t\\nhttps://www.bbc.com/sport/cycling/40692045\\n.\\none\\tof\\tthe\\ttop\\tbike\\tmanufacturers\\tin\\tEurope\\trefused\\tto\\tsell\\tbikes\\n:\\n\\tRichard\\tMoore,\\t\\nMastermind:\\tHow\\tDave\\tBrailsford\\tReinvented\\tthe\\tWheel\\n\\t(Glasgow:\\tBackPage\\tPress,\\t2013).\\n“The\\twhole\\tprinciple\\tcame\\tfrom\\tthe\\tidea”\\n:\\t\\nMatt\\tSlater,\\t“Olympics\\tCycling:\\tMarginal\\tGains\\tUnderpin\\tTeam\\tGB\\tDominance,”\\tBBC,\\tAugust\\t8,\\t2012,\\t\\nhttps://www.bbc.com/sport/olympics/19174302\\n.\\nBrailsford\\tand\\this\\tcoaches\\tbegan\\tby\\tmaking\\tsmall\\tadjustments\\n:\\n\\tTim\\tHarford,\\t“Marginal\\tGains\\tMatter\\tbut\\tGamechangers\\tTransform,”\\tTim\\tHarford,\\tApril\\t2017,\\nhttp://timharford.com/2017/04/marginal-gains-matter-but-gamechangers-transform\\n.\\nthey\\teven\\tpainted\\tthe\\tinside\\tof\\tthe\\tteam\\ttruck\\twhite\\n:\\t\\nEben\\tHarrell,\\t“How\\t1%\\tPerformance\\tImprovements\\tLed\\tto\\tOlympic\\tGold,”\\t\\nHarvard\\tBusiness\\tReview\\n,\\tOctober\\t30,\\t2015,\\nhttps://hbr.org/2015/10/how-1-performance-improvements-led-to-olympic-gold\\n;\\tKevin\\tClark,\\t“How\\ta\\tCycling\\tTeam\\tTurned\\tthe\\tFalcons\\tInto\\tNFC\\tChampions,”\\tThe\\tRinger,\\tSeptember\\t12,\\n2017,\\t\\nhttps://www.theringer.com/nfl/2017/9/12/16293216/atlanta-falcons-thomas-dimitroff-cyclingteam-sky\\n.\\nJust\\tfive\\tyears\\tafter\\tBrailsford\\ttook\\tover\\n:\\n\\tTechnically,\\tthe\\tBritish\\triders\\twon\\t57\\tpercent\\tof\\tthe\\troad\\tand\\ttrack\\tcycling\\tmedals\\tat\\tthe\\t2008\\tOlympics.\\tFourteen\\tgold\\tmedals\\twere\\tavailable\\tin\\troad\\tand\\ntrack\\tcycling\\tevents.\\tThe\\tBrits\\twon\\teight\\tof\\tthem.\\nthe\\tBrits\\traised\\tthe\\tbar\\n:\\n\\t“World\\tand\\tOlympic\\tRecords\\tSet\\tat\\tthe\\t2012\\tSummer\\tOlympics,”\\tWikipedia,\\tDecember\\t8,\\t2017,\\nhttps://en.wikipedia.org/wiki/World_and_Olympic_records_set_at_the_2012_Summer_Olympics#Cycling\\n.\\nBradley\\tWiggins\\tbecame\\tthe\\tfirst\\tBritish\\tcyclist\\n:\\t\\nAndrew\\tLongmore,\\t“Bradley\\tWiggins,”\\t\\nEncyclopaedia\\tBritannica\\n,\\t\\nhttps://www.britannica.com/biography/Bradley-Wiggins\\n,\\tlast\\tmodified\\tApril\\t21,\\n2018.\\nChris\\tFroome\\twon\\n:\\t\\nKaren\\tSparks,\\t“Chris\\tFroome,”\\t\\nEncyclopaedia\\tBritannica\\n,\\t\\nhttps://www.britannica.com/biography/Chris-Froome\\n,\\tlast\\tmodified\\tOctober\\t23,\\t2017.\\nDuring\\tthe\\tten-year\\tspan\\tfrom\\t2007\\tto\\t2017\\n:\\t\\n“Medals\\twon\\tby\\tthe\\tGreat\\tBritain\\tCycling\\tTeam\\tat\\tworld\\tchampionships,\\tOlympic\\tGames\\tand\\tParalympic\\tGames\\tsince\\t2000,”\\tBritish\\tCycling,\\nhttps://www.britishcycling.org.uk/gbcyclingteam/article/Gbrst_gb-cyclingteam-GBCycling-Team-Medal-History—0?c=EN#K0dWAPjq84CV8Wzw.99\\n,\\taccessed\\tJune\\t8,\\t2018.\\nyou’ll\\tend\\tup\\tthirty-seven\\ttimes\\tbetter\\n:\\t\\nJason\\tShen,\\tan\\tentrepreneur\\tand\\twriter,\\treceived\\tan\\tearly\\tlook\\tat\\tthis\\tbook.\\tAfter\\treading\\tthis\\tchapter,\\the\\tremarked:\\t“If\\tthe\\tgains\\twere\\tlinear,\\tyou’d\\tpredict\\tto\\tbe\\n3.65x\\tbetter\\toff.\\tBut\\tbecause\\tit\\tis\\texponential,\\tthe\\timprovement\\tis\\tactually\\t10x\\tgreater.”\\tApril\\t3,\\t2018.\\nHabits\\tare\\tthe\\tcompound\\tinterest\\n:\\t\\nMany\\tpeople\\thave\\tnoted\\thow\\thabits\\tmultiply\\tover\\ttime.\\tHere\\tare\\tsome\\tof\\tmy\\tfavorite\\tarticles\\tand\\tbooks\\ton\\tthe\\tsubject:\\tLeo\\tBabauta,\\t“The\\tPower\\tof\\tHabit\\nInvestments,”\\tZen\\tHabits,\\tJanuary\\t28,\\t2013,\\t\\nhttps://zenhabits.net/bank\\n;\\tMorgan\\tHousel,\\t“The\\tFreakishly\\tStrong\\tBase,”\\tCollaborative\\tFund,\\tOctober\\t31,\\t2017,\\nhttp://www.collaborativefund.com/blog/the-freakishly-strong-base\\n;\\tDarren\\tHardy,\\t\\nThe\\tCompound\\tEffect\\n\\t(New\\tYork:\\tVanguard\\tPress,\\t2012).\\nAccomplishing\\tone\\textra\\ttask\\n:\\t\\nAs\\tSam\\tAltman\\tsays,\\t“A\\tsmall\\tproductivity\\tgain,\\tcompounded\\tover\\t50\\tyears,\\tis\\tworth\\ta\\tlot.”\\t“Productivity,”\\tSam\\tAltman.\\tApril\\t10,\\t2018,\\nhttp://blog.samaltman.com/productivity\\n.\\nHabits\\tare\\ta\\tdouble-edged\\tsword\\n:\\t\\nI’d\\tlike\\tto\\tcredit\\tJason\\tHreha\\twith\\toriginally\\tdescribing\\thabits\\tto\\tme\\tin\\tthis\\tway.\\tJason\\tHreha\\t(@jhreha),\\t“They’re\\ta\\tdouble\\tedged\\tsword,”\\tTwitter,\\tFebruary\\t21,\\n2018,\\t\\nhttps://twitter.com/jhreha/status/966430907371433984\\n.\\nThe\\tmore\\ttasks\\tyou\\tcan\\thandle\\twithout\\tthinking\\n:\\n\\tMichael\\t(@mmay3r),\\t“The\\tfoundation\\tof\\tproductivity\\tis\\thabits.\\tThe\\tmore\\tyou\\tdo\\tautomatically,\\tthe\\tmore\\tyou’re\\tsubsequently\\tfreed\\tto\\tdo.\\tThis\\teffect\\ncompounds,”\\tTwitter,\\tApril\\t10,\\t2018,\\t\\nhttps://twitter.com/mmay3r/status/983837519274889216\\n.\\neach\\tbook\\tyou\\tread\\tnot\\tonly\\tteaches\\n:\\n\\tThis\\tidea—that\\tlearning\\tnew\\tideas\\tincreases\\tthe\\tvalue\\tof\\tyour\\told\\tideas—is\\tsomething\\tI\\tfirst\\theard\\tabout\\tfrom\\tPatrick\\tO’Shaughnessy,\\twho\\twrites,\\t“This\\tis\\twhy\\nknowledge\\tcompounds.\\tOld\\tstuff\\tthat\\twas\\ta\\t4/10\\tin\\tvalue\\tcan\\tbecome\\ta\\t10/10,\\tunlocked\\tby\\tanother\\tbook\\tin\\tthe\\tfuture.”\\t\\nhttp://investorfieldguide.com/reading-tweet-storm\\n.\\nCancer\\tspends\\t80\\tpercent\\tof\\tits\\tlife\\tundetectable\\n:\\n\\t“How\\tto\\tLive\\ta\\tLonger,\\tHigher\\tQuality\\tLife,\\twith\\tPeter\\tAttia,\\tM.D.,”\\tInvestor’s\\tField\\tGuide,\\tMarch\\t7,\\t2017,\\t\\nhttp://investorfieldguide.com/attia\\n.\\nThe\\tSan\\tAntonio\\tSpurs\\n:\\t\\nMatt\\tMoore,\\t“NBA\\tFinals:\\tA\\tRock,\\tHammer\\tand\\tCracking\\tof\\tSpurs’\\tMajesty\\tin\\tGame\\t7,”\\tCBS\\tSports,\\tJune\\t21,\\t2013,\\t\\nhttps://www.cbssports.com/nba/news/nba-finals-a-rock-\\nhammer-and-cracking-of-spurs-majesty-in-game-7\\n.\\nInspiration\\tfor\\t\\nthis\\tdrawing\\n\\tcame\\tfrom\\ta\\ttweet\\ttitled\\t“Deception\\tof\\tlinear\\tvs\\texponential”\\tby\\t@MlichaelW.\\tMay\\t19,\\t2018.\\t\\nhttps://twitter.com/MlichaelW/status/997878086132817920\\n.\\nThe\\tseed\\tof\\tevery\\thabit\\n:\\n\\tThis\\tparagraph\\twas\\tinspired\\tby\\ta\\tquote\\tfrom\\tMr.\\tMircea,\\tan\\taccount\\ton\\tTwitter,\\twho\\twrote,\\t“each\\thabit\\tbegan\\tits\\tlife\\tas\\ta\\tsingle\\tdecision.”\\t\\nhttps://twitter.com/mistermircea\\n.\\nthe\\tgoal\\tcannot\\tbe\\twhat\\tdifferentiates\\tthe\\twinners\\tfrom\\tthe\\tlosers\\n:\\n\\tHat\\ttip\\tto\\tCrossFit\\tcoach\\tBen\\tBergeron\\tfor\\tinspiring\\tthis\\tquote\\tduring\\ta\\tconversation\\tI\\thad\\twith\\thim\\ton\\tFebruary\\t28,\\t2017.\\nYou\\tfall\\tto\\tthe\\tlevel\\tof\\tyour\\tsystems\\n:\\n\\tThis\\tline\\twas\\tinspired\\tby\\tthe\\tfollowing\\tquote\\tfrom\\tArchilochus:\\t“We\\tdon’t\\trise\\tto\\tthe\\tlevel\\tof\\tour\\texpectations,\\twe\\tfall\\tto\\tthe\\tlevel\\tof\\tour\\ttraining.”', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 208}), Document(page_content='CHAPTER\\t2\\nYou\\tcan\\timagine\\tthem\\tlike\\tthe\\tlayers\\tof\\tan\\tonion\\n:\\n\\tHat\\ttip\\tto\\tSimon\\tSinek.\\tHis\\t“Golden\\tCircle”\\tframework\\tis\\tsimilar\\tin\\tdesign,\\tbut\\tdiscusses\\tdifferent\\ttopics.\\tFor\\tmore,\\tsee\\tSimon\\tSinek,\\t\\nStart\\twith\\nWhy:\\tHow\\tGreat\\tLeaders\\tInspire\\tEveryone\\tto\\tTake\\tAction\\n\\t(London:\\tPortfolio/Penguin,\\t2013),\\t37.\\nI\\tresolved\\tto\\tstop\\tchewing\\tmy\\tnails\\n:\\n\\tThe\\tquotes\\tused\\tin\\tthis\\tsection\\tare\\tpresented\\tas\\ta\\tconversation\\tfor\\treading\\tclarity,\\tbut\\twere\\toriginally\\twritten\\tby\\tClark.\\tSee:\\tBrian\\tClark,\\t“The\\tPowerful\\nPsychological\\tBoost\\tthat\\tHelps\\tYou\\tMake\\tand\\tBreak\\tHabits,”\\tFurther,\\tNovember\\t14,\\t2017,\\t\\nhttps://further.net/pride-habits\\n.\\nResearch\\thas\\tshown\\tthat\\tonce\\ta\\tperson\\n:\\t\\nChristopher\\tJ.\\tBryan\\tet\\tal.,\\t“Motivating\\tVoter\\tTurnout\\tby\\tInvoking\\tthe\\tSelf,”\\t\\nProceedings\\tof\\tthe\\tNational\\tAcademy\\tof\\tSciences\\n\\t108,\\tno.\\t31\\t(2011):\\t12653–\\n12656.\\nThere\\tis\\tinternal\\tpressure\\n:\\t\\nLeon\\tFestinger,\\t\\nA\\tTheory\\tof\\tCognitive\\tDissonance\\n\\t(Stanford,\\tCA:\\tStanford\\tUniversity\\tPress,\\t1957).\\nYour\\tidentity\\tis\\tliterally\\tyour\\t“repeated\\tbeingness”\\n:\\n\\tTechnically,\\t\\nidentidem\\n\\tis\\ta\\tword\\tbelonging\\tto\\tthe\\tLate\\tLatin\\tlanguage.\\tAlso,\\tthanks\\tto\\tTamar\\tShippony,\\ta\\treader\\tof\\tjamesclear.com,\\twho\\noriginally\\ttold\\tme\\tabout\\tthe\\tetymology\\tof\\tthe\\tword\\t\\nidentity\\n,\\twhich\\tshe\\tlooked\\tup\\tin\\tthe\\tAmerican\\tHeritage\\tDictionary.\\nWe\\tchange\\tbit\\tby\\tbit\\n:\\n\\tThis\\tis\\tanother\\treason\\tatomic\\thabits\\tare\\tsuch\\tan\\teffective\\tform\\tof\\tchange.\\tIf\\tyou\\tchange\\tyour\\tidentity\\ttoo\\tquickly\\tand\\tbecome\\tsomeone\\tradically\\tdifferent\\tovernight,\\tthen\\tyou\\tfeel\\nas\\tif\\tyou\\tlose\\tyour\\tsense\\tof\\tself.\\tBut\\tif\\tyou\\tupdate\\tand\\texpand\\tyour\\tidentity\\tgradually,\\tyou\\twill\\tfind\\tyourself\\treborn\\tinto\\tsomeone\\ttotally\\tnew\\tand\\tyet\\tstill\\tfamiliar.\\tSlowly—habit\\tby\\thabit,\\nvote\\tby\\tvote—you\\tbecome\\taccustomed\\tto\\tyour\\tnew\\tidentity.\\tAtomic\\thabits\\tand\\tgradual\\timprovement\\tare\\tthe\\tkeys\\tto\\tidentity\\tchange\\twithout\\tidentity\\tloss.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 209}), Document(page_content='CHAPTER\\t3\\nEdward\\tThorndike\\tconducted\\tan\\texperiment\\n:\\t\\nPeter\\tGray,\\t\\nPsychology\\n,\\t6th\\ted.\\t(New\\tYork:\\tWorth,\\t2011),\\t108–109.\\n“by\\tsome\\tsimple\\tact,\\tsuch\\tas\\tpulling\\tat\\ta\\tloop\\tof\\tcord”\\n:\\n\\tEdward\\tL.\\tThorndike,\\t“Animal\\tIntelligence:\\tAn\\tExperimental\\tStudy\\tof\\tthe\\tAssociative\\tProcesses\\tin\\tAnimals,”\\t\\nPsychological\\tReview:\\nMonograph\\tSupplements\\n\\t2,\\tno.\\t4\\t(1898),\\tdoi:10.1037/h0092987.\\n“behaviors\\tfollowed\\tby\\tsatisfying\\tconsequences”\\n:\\n\\tThis\\tis\\tan\\tabbreviated\\tversion\\tof\\tthe\\toriginal\\tquote\\tfrom\\tThorndike,\\twhich\\treads:\\t“responses\\tthat\\tproduce\\ta\\tsatisfying\\teffect\\tin\\ta\\tparticular\\tsituation\\nbecome\\tmore\\tlikely\\tto\\toccur\\tagain\\tin\\tthat\\tsituation,\\tand\\tresponses\\tthat\\tproduce\\ta\\tdiscomforting\\teffect\\tbecome\\tless\\tlikely\\tto\\toccur\\tagain\\tin\\tthat\\tsituation.”\\tFor\\tmore,\\tsee\\tPeter\\tGray,\\nPsychology\\n,\\t6th\\ted.\\t(New\\tYork:\\tWorth,\\t2011),\\t108–109.\\nNeurological\\tactivity\\tin\\tthe\\tbrain\\tis\\thigh\\n:\\n\\tCharles\\tDuhigg,\\t\\nThe\\tPower\\tof\\tHabit:\\tWhy\\tWe\\tDo\\tWhat\\tWe\\tDo\\tin\\tLife\\tand\\tBusiness\\n\\t(New\\tYork:\\tRandom\\tHouse,\\t2014),\\t15;\\tAnn\\tM.\\tGraybiel,\\t“Network-\\nLevel\\tNeuroplasticity\\tin\\tCortico-Basal\\tGanglia\\tPathways,”\\t\\nParkinsonism\\tand\\tRelated\\tDisorders\\n\\t10,\\tno.\\t5\\t(2004),\\tdoi:10.1016/j.parkreldis.2004.03.007.\\n“Habits\\tare,\\tsimply,\\treliable\\tsolutions”\\n:\\n\\tJason\\tHreha,\\t“Why\\tOur\\tConscious\\tMinds\\tAre\\tSuckers\\tfor\\tNovelty,”\\t\\nRevue\\n,\\t\\nhttps://www.getrevue.co/profile/jason/issues/why-our-conscious-minds-are-\\nsuckers-for-novelty-54131\\n,\\taccessed\\tJune\\t8,\\t2018.\\nAs\\thabits\\tare\\tcreated\\n:\\t\\nJohn\\tR.\\tAnderson,\\t“Acquisition\\tof\\tCognitive\\tSkill,”\\t\\nPsychological\\tReview\\n\\t89,\\tno.\\t4\\t(1982),\\tdoi:10.1037/0033–295X.89.4.369.\\nthe\\tbrain\\tremembers\\tthe\\tpast\\n:\\t\\nShahram\\tHeshmat,\\t“Why\\tDo\\tWe\\tRemember\\tCertain\\tThings,\\tBut\\tForget\\tOthers,”\\t\\nPsychology\\tToday\\n,\\tOctober\\t8,\\t2015,\\nhttps://www.psychologytoday.com/us/blog/science-choice/201510/why-do-we-remember-certain-things-forget-others\\n.\\nthe\\tconscious\\tmind\\tis\\tthe\\tbottleneck\\n:\\t\\nWilliam\\tH.\\tGladstones,\\tMichael\\tA.\\tRegan,\\tand\\tRobert\\tB.\\tLee,\\t“Division\\tof\\tAttention:\\tThe\\tSingle-Channel\\tHypothesis\\tRevisited,”\\t\\nQuarterly\\tJournal\\tof\\nExperimental\\tPsychology\\tSection\\tA\\n\\t41,\\tno.\\t1\\t(1989),\\tdoi:10.1080/14640748908402350.\\nthe\\tconscious\\tmind\\tlikes\\tto\\tpawn\\toff\\ttasks\\n:\\n\\tDaniel\\tKahneman,\\t\\nThinking,\\tFast\\tand\\tSlow\\n\\t(New\\tYork:\\tFarrar,\\tStraus\\tand\\tGiroux,\\t2015).\\nHabits\\treduce\\tcognitive\\tload\\n:\\n\\tJohn\\tR.\\tAnderson,\\t“Acquisition\\tof\\tCognitive\\tSkill,”\\t\\nPsychological\\tReview\\n\\t89,\\tno.\\t4\\t(1982),\\tdoi:10.1037/0033–295X.89.4.369.\\nFeelings\\tof\\tpleasure\\tand\\tdisappointment\\n:\\t\\nAntonio\\tR.\\tDamasio,\\t\\nThe\\tStrange\\tOrder\\tof\\tThings:\\tLife,\\tFeeling,\\tand\\tthe\\tMaking\\tof\\tCultures\\n\\t(New\\tYork:\\tPantheon\\tBooks,\\t2018);\\tLisa\\tFeldman\\tBarrett,\\nHow\\tEmotions\\tAre\\tMade\\n\\t(London:\\tPan\\tBooks,\\t2018).', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 210}), Document(page_content='CHAPTER\\t4\\nThe\\tpsychologist\\tGary\\tKlein\\n:\\t\\nI\\toriginally\\theard\\tabout\\tthis\\tstory\\tfrom\\tDaniel\\tKahneman,\\tbut\\tit\\twas\\tconfirmed\\tby\\tGary\\tKlein\\tin\\tan\\temail\\ton\\tMarch\\t30,\\t2017.\\tKlein\\talso\\tcovers\\tthe\\tstory\\tin\\this\\town\\tbook,\\nwhich\\tuses\\tslightly\\tdifferent\\tquotes:\\tGary\\tA.\\tKlein,\\t\\nSources\\tof\\tPower:\\tHow\\tPeople\\tMake\\tDecisions\\n\\t(Cambridge,\\tMA:\\tMIT\\tPress,\\t1998),\\t43–44.\\nmilitary\\tanalysts\\tcan\\tidentify\\twhich\\tblip\\ton\\ta\\tradar\\tscreen\\n:\\t\\nGary\\tA.\\tKlein,\\t\\nSources\\tof\\tPower:\\tHow\\tPeople\\tMake\\tDecisions\\n\\t(Cambridge,\\tMA:\\tMIT\\tPress,\\t1998),\\t38–40.\\nMuseum\\tcurators\\thave\\tbeen\\tknown\\tto\\tdiscern\\n:\\t\\nThe\\tstory\\tof\\tthe\\tGetty\\tkouros,\\tcovered\\tin\\tMalcolm\\tGladwell’s\\tbook\\t\\nBlink\\n,\\tis\\ta\\tfamous\\texample.\\tThe\\tsculpture,\\tinitially\\tbelieved\\tto\\tbe\\tfrom\\tancient\\nGreece,\\twas\\tpurchased\\tfor\\t$10\\tmillion.\\tThe\\tcontroversy\\tsurrounding\\tthe\\tsculpture\\thappened\\tlater\\twhen\\tone\\texpert\\tidentified\\tit\\tas\\ta\\tforgery\\tupon\\tfirst\\tglance.\\nExperienced\\tradiologists\\tcan\\tlook\\tat\\ta\\tbrain\\tscan\\n:\\n\\tSiddhartha\\tMukherjee,\\t“The\\tAlgorithm\\tWill\\tSee\\tYou\\tNow,”\\t\\nNew\\tYorker\\n,\\tApril\\t3,\\t2017,\\t\\nhttps://www.newyorker.com/magazine/2017/04/03/ai-\\nversus-md\\n.\\nThe\\thuman\\tbrain\\tis\\ta\\tprediction\\tmachine\\n:\\n\\tThe\\tGerman\\tphysician\\tHermann\\tvon\\tHelmholtz\\tdeveloped\\tthe\\tidea\\tof\\tthe\\tbrain\\tbeing\\ta\\t“prediction\\tmachine.”\\nthe\\tclerk\\tswiped\\tthe\\tcustomer’s\\tactual\\tcredit\\tcard\\n:\\n\\tHelix\\tvan\\tBoron,\\t“What’s\\tthe\\tDumbest\\tThing\\tYou’ve\\tDone\\tWhile\\tYour\\tBrain\\tIs\\ton\\tAutopilot,”\\tReddit,\\tAugust\\t21,\\t2017,\\nhttps://www.reddit.com/r/AskReddit/comments/6v1t91/whats_the_dumbest_thing_youve_done_while_your/dlxa5y9\\n.\\nshe\\tkept\\tasking\\tcoworkers\\tif\\tthey\\thad\\twashed\\ttheir\\thands\\n:\\n\\tSwordOfTheLlama,\\t“What\\tStrange\\tHabits\\tHave\\tYou\\tPicked\\tUp\\tfrom\\tYour\\tLine\\tof\\tWork,”\\tReddit,\\tJanuary\\t4,\\t2016,\\nhttps://www.reddit.com/r/AskReddit/comments/3zckq6/what_strange_habits_have_you_picked_up_from_your/cyl3nta\\n.\\nstory\\tof\\ta\\tman\\twho\\thad\\tspent\\tyears\\tworking\\tas\\ta\\tlifeguard\\n:\\t\\nSwearImaChick,\\t“What\\tStrange\\tHabits\\tHave\\tYou\\tPicked\\tUp\\tfrom\\tYour\\tLine\\tof\\tWork,”\\tReddit,\\tJanuary\\t4,\\t2016,\\nhttps://www.reddit.com/r/AskReddit/comments/3zckq6/what_strange_habits_have_you_picked_up_from_your/cyl681q\\n.\\n“Until\\tyou\\tmake\\tthe\\tunconscious\\tconscious”\\n:\\n\\tAlthough\\tthis\\tquote\\tby\\tJung\\tis\\tpopular,\\tI\\thad\\ttrouble\\ttracking\\tdown\\tthe\\toriginal\\tsource.\\tIt’s\\tprobably\\ta\\tparaphrase\\tof\\tthis\\tpassage:\\t“The\\tpsychological\\nrule\\tsays\\tthat\\twhen\\tan\\tinner\\tsituation\\tis\\tnot\\tmade\\tconscious,\\tit\\thappens\\toutside,\\tas\\tfate.\\tThat\\tis\\tto\\tsay,\\twhen\\tthe\\tindividual\\tremains\\tundivided\\tand\\tdoes\\tnot\\tbecome\\tconscious\\tof\\this\\tinner\\nopposite,\\tthe\\tworld\\tmust\\tperforce\\tact\\tout\\tthe\\tconflict\\tand\\tbe\\ttorn\\tinto\\topposing\\thalves.”\\tFor\\tmore,\\tsee\\tC.\\tG.\\tJung,\\t\\nAion:\\tResearches\\tinto\\tthe\\tPhenomenology\\tof\\tthe\\tSelf\\n\\t(Princeton,\\tNJ:\\nPrinceton\\tUniversity\\tPress,\\t1959),\\t71.\\nPointing-and-Calling\\treduces\\terrors\\n:\\n\\tAlice\\tGordenker,\\t“JR\\tGestures,”\\t\\nJapan\\tTimes\\n,\\tOctober\\t21,\\t2008,\\t\\nhttps://www.japantimes.co.jp/news/2008/10/21/reference/jr-gestures/#.WvIG49Mvzu1\\n.\\nThe\\tMTA\\tsubway\\tsystem\\tin\\tNew\\tYork\\tCity\\n:\\t\\nAllan\\tRicharz,\\t“Why\\tJapan’s\\tRail\\tWorkers\\tCan’t\\tStop\\tPointing\\tat\\tThings,”\\t\\nAtlas\\tObscura\\n,\\tMarch\\t29,\\t2017,\\nhttps://www.atlasobscura.com/articles/pointing-and-calling-japan-trains\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 211}), Document(page_content='CHAPTER\\t5\\nresearchers\\tin\\tGreat\\tBritain\\tbegan\\tworking\\n:\\n\\tSarah\\tMilne,\\tSheina\\tOrbell,\\tand\\tPaschal\\tSheeran,\\t“Combining\\tMotivational\\tand\\tVolitional\\tInterventions\\tto\\tPromote\\tExercise\\tParticipation:\\tProtection\\nMotivation\\tTheory\\tand\\tImplementation\\tIntentions,”\\t\\nBritish\\tJournal\\tof\\tHealth\\tPsychology\\n\\t7\\t(May\\t2002):\\t163–184.\\nimplementation\\tintentions\\tare\\teffective\\n:\\n\\tPeter\\tGollwitzer\\tand\\tPaschal\\tSheeran,\\t“Implementation\\tIntentions\\tand\\tGoal\\tAchievement:\\tA\\tMeta-Analysis\\tof\\tEffects\\tand\\tProcesses,”\\t\\nAdvances\\tin\\nExperimental\\tSocial\\tPsychology\\n\\t38\\t(2006):\\t69–119.\\nwriting\\tdown\\tthe\\texact\\ttime\\tand\\tdate\\tof\\twhen\\tyou\\twill\\tget\\ta\\tflu\\tshot\\n:\\n\\tKatherine\\tL.\\tMilkman,\\tJohn\\tBeshears,\\tJames\\tJ.\\tChoi,\\tDavid\\tLaibson,\\tand\\tBrigitte\\tC.\\tMadrian,\\t“Using\\tImplementation\\tIntentions\\nPrompts\\tto\\tEnhance\\tInfluenza\\tVaccination\\tRates,”\\t\\nProceedings\\tof\\tthe\\tNational\\tAcademy\\tof\\tSciences\\n\\t108,\\tno.\\t26\\t(June\\t2011):\\t10415–10420.\\nrecording\\tthe\\ttime\\tof\\tyour\\tcolonoscopy\\tappointment\\n:\\n\\tKatherine\\tL.\\tMilkman,\\tJohn\\tBeshears,\\tJames\\tJ.\\tChoi,\\tDavid\\tLaibson,\\tand\\tBrigitte\\tC.\\tMadrian,\\t“Planning\\tPrompts\\tas\\ta\\tMeans\\tof\\tIncreasing\\nPreventive\\tScreening\\tRates,”\\t\\nPreventive\\tMedicine\\n\\t56,\\tno.\\t1\\t(January\\t2013):\\t92–93.\\nvoter\\tturnout\\tincreases\\n:\\n\\tDavid\\tW.\\tNickerson\\tand\\tTodd\\tRogers,\\t“Do\\tYou\\tHave\\ta\\tVoting\\tPlan?\\tImplementation\\tIntentions,\\tVoter\\tTurnout,\\tand\\tOrganic\\tPlan\\tMaking,”\\t\\nPsychological\\tScience\\n\\t21,\\tno.\\t2\\n(2010):\\t194–199.\\nOther\\tsuccessful\\tgovernment\\tprograms\\n:\\t\\n“Policymakers\\taround\\tthe\\tWorld\\tAre\\tEmbracing\\tBehavioural\\tScience,”\\t\\nThe\\tEconomist\\n,\\tMay\\t18,\\t2017,\\nhttps://www.economist.com/news/international/21722163-experimental-iterative-data-driven-approach-gaining-ground-policymakers-around\\n.\\npeople\\twho\\tmake\\ta\\tspecific\\tplan\\tfor\\twhen\\tand\\twhere\\n:\\t\\nEdwin\\tLocke\\tand\\tGary\\tLatham,\\t“Building\\ta\\tPractically\\tUseful\\tTheory\\tof\\tGoal\\tSetting\\tand\\tTask\\tMotivation:\\tA\\t35-Year\\tOdyssey,”\\t\\nAmerican\\nPsychologist\\n\\t57,\\tno.\\t9\\t(2002):\\t705–717,\\tdoi:10.1037//0003–066x.57.9.705.\\nhope\\tis\\tusually\\thigher\\n:\\n\\tHengchen\\tDai,\\tKatherine\\tL.\\tMilkman,\\tand\\tJason\\tRiis,\\t“The\\tFresh\\tStart\\tEffect:\\tTemporal\\tLandmarks\\tMotivate\\tAspirational\\tBehavior,”\\t\\nPsycEXTRA\\tDataset\\n,\\t2014,\\ndoi:10.1037/e513702014–058.\\nwriter\\tJason\\tZweig\\tnoted\\n:\\t\\nJason\\tZweig,\\t“Elevate\\tYour\\tFinancial\\tIQ:\\tA\\tValue\\tPacked\\tDiscussion\\twith\\tJason\\tZweig,”\\tinterview\\tby\\tShane\\tParrish,\\t\\nThe\\tKnowledge\\tProject\\n,\\tFarnam\\tStreet,\\taudio,\\nhttps://www.fs.blog/2015/10/jason-zweig-knowledge-project\\n.\\nmany\\tways\\tto\\tuse\\timplementation\\tintentions\\n:\\t\\nFor\\tthe\\tterm\\t\\nhabit\\tstacking\\n,\\tI\\tam\\tindebted\\tto\\tS.\\tJ.\\tScott,\\twho\\twrote\\ta\\tbook\\tby\\tthe\\tsame\\tname.\\tFrom\\twhat\\tI\\tunderstand,\\this\\tconcept\\tis\\tslightly\\tdifferent,\\nbut\\tI\\tlike\\tthe\\tterm\\tand\\tthought\\tit\\tappropriate\\tto\\tuse\\tin\\tthis\\tchapter.\\tPrevious\\twriters\\tsuch\\tas\\tCourtney\\tCarver\\tand\\tJulien\\tSmith\\thave\\talso\\tused\\tthe\\tterm\\t\\nhabit\\tstacking\\n,\\tbut\\tin\\tdifferent\\ncontexts.\\nThe\\tFrench\\tphilosopher\\tDenis\\tDiderot\\n:\\t\\n“Denis\\tDiderot,”\\t\\nNew\\tWorld\\tEncyclopedia\\n,\\t\\nhttp://www.newworldencyclopedia.org/entry/Denis_Diderot\\n,\\tlast\\tmodified\\tOctober\\t26,\\t2017.\\nacquired\\ta\\tscarlet\\trobe\\n:\\n\\t\\nEncyclopædia\\tBritannica\\n,\\tvol.\\t8\\t(1911),\\ts.v.\\t“Denis\\tDiderot.”\\tDiderot’s\\tscarlet\\trobe\\tis\\tfrequently\\tdescribed\\tas\\ta\\tgift\\tfrom\\ta\\tfriend.\\tHowever,\\tI\\tcould\\tfind\\tno\\toriginal\\tsource\\nclaiming\\tit\\twas\\ta\\tgift\\tnor\\tany\\tmention\\tof\\tthe\\tfriend\\twho\\tsupplied\\tthe\\trobe.\\tIf\\tyou\\thappen\\tto\\tknow\\tany\\thistorians\\tspecializing\\tin\\trobe\\tacquisitions,\\tfeel\\tfree\\tto\\tpoint\\tthem\\tmy\\tway\\tso\\twe\\tcan\\nclarify\\tthe\\tmystery\\tof\\tthe\\tsource\\tof\\tDiderot’s\\tfamous\\tscarlet\\trobe.\\n“no\\tmore\\tcoordination,\\tno\\tmore\\tunity,\\tno\\tmore\\tbeauty”\\n:\\n\\tDenis\\tDiderot,\\t“Regrets\\tfor\\tMy\\tOld\\tDressing\\tGown,”\\ttrans.\\tMitchell\\tAbidor,\\t2005,\\nhttps://www.marxists.org/reference/archive/diderot/1769/regrets.htm\\n.\\nThe\\tDiderot\\tEffect\\tstates\\n:\\t\\nJuliet\\tSchor,\\t\\nThe\\tOverspent\\tAmerican:\\tWhy\\tWe\\tWant\\tWhat\\tWe\\tDon’t\\tNeed\\n\\t(New\\tYork:\\tHarperPerennial,\\t1999).\\nwhich\\twas\\tcreated\\tby\\tBJ\\tFogg\\n:\\n\\tIn\\tthis\\tchapter,\\tI\\tused\\tthe\\tterm\\t\\nhabit\\tstacking\\n\\tto\\trefer\\tto\\tlinking\\ta\\tnew\\thabit\\tto\\tan\\told\\tone.\\tFor\\tthis\\tidea,\\tI\\tgive\\tcredit\\tto\\tBJ\\tFogg.\\tIn\\this\\twork,\\tFogg\\tuses\\tthe\\tterm\\nanchoring\\n\\tto\\tdescribe\\tthis\\tapproach\\tbecause\\tyour\\told\\thabit\\tacts\\tas\\tan\\t“anchor”\\tthat\\tkeeps\\tthe\\tnew\\tone\\tin\\tplace.\\tNo\\tmatter\\twhat\\tterm\\tyou\\tprefer,\\tI\\tbelieve\\tit\\tis\\ta\\tvery\\teffective\\tstrategy.\\tYou\\ncan\\tlearn\\tmore\\tabout\\tFogg’s\\twork\\tand\\this\\tTiny\\tHabits\\tMethod\\tat\\t\\nhttps://www.tinyhabits.com\\n.\\n“One\\tin,\\tone\\tout”\\n:\\n\\tDev\\tBasu\\t(@devbasu),\\t“Have\\ta\\tone-in-one-out\\tpolicy\\twhen\\tbuying\\tthings,”\\tTwitter,\\tFebruary\\t11,\\t2018,\\t\\nhttps://twitter.com/devbasu/status/962778141965000704\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 212}), Document(page_content='CHAPTER\\t6\\nAnne\\tThorndike\\n:\\t\\nAnne\\tN.\\tThorndike\\tet\\tal.,\\t“A\\t2-Phase\\tLabeling\\tand\\tChoice\\tArchitecture\\tIntervention\\tto\\tImprove\\tHealthy\\tFood\\tand\\tBeverage\\tChoices,”\\t\\nAmerican\\tJournal\\tof\\tPublic\\tHealth\\n\\t102,\\tno.\\t3\\n(2012),\\tdoi:10.2105/ajph.2011.300391.\\nchoose\\tproducts\\tnot\\tbecause\\tof\\t\\nwhat\\n\\tthey\\tare\\n:\\t\\nMultiple\\tresearch\\tstudies\\thave\\tshown\\tthat\\tthe\\tmere\\tsight\\tof\\tfood\\tcan\\tmake\\tus\\tfeel\\thungry\\teven\\twhen\\twe\\tdon’t\\thave\\tactual\\tphysiological\\thunger.\\nAccording\\tto\\tone\\tresearcher,\\t“dietary\\tbehaviors\\tare,\\tin\\tlarge\\tpart,\\tthe\\tconsequence\\tof\\tautomatic\\tresponses\\tto\\tcontextual\\tfood\\tcues.”\\tFor\\tmore,\\tsee\\tD.\\tA.\\tCohen\\tand\\tS.\\tH.\\tBabey,\\n“Contextual\\tInfluences\\ton\\tEating\\tBehaviours:\\tHeuristic\\tProcessing\\tand\\tDietary\\tChoices,”\\t\\nObesity\\tReviews\\n\\t13,\\tno.\\t9\\t(2012),\\tdoi:10.1111/j.1467–789x.2012.01001.x;\\tand\\tAndrew\\tJ.\\tHill,\\nLynn\\tD.\\tMagson,\\tand\\tJohn\\tE.\\tBlundell,\\t“Hunger\\tand\\tPalatability:\\tTracking\\tRatings\\tof\\tSubjective\\tExperience\\tBefore,\\tduring\\tand\\tafter\\tthe\\tConsumption\\tof\\tPreferred\\tand\\tLess\\tPreferred\\nFood,”\\t\\nAppetite\\n\\t5,\\tno.\\t4\\t(1984),\\tdoi:10.1016/s0195–6663(84)80008–2.\\nBehavior\\tis\\ta\\tfunction\\tof\\tthe\\tPerson\\tin\\ttheir\\tEnvironment\\n:\\t\\nKurt\\tLewin,\\t\\nPrinciples\\tof\\tTopological\\tPsychology\\n\\t(New\\tYork:\\tMcGraw-Hill,\\t1936).\\nSuggestion\\tImpulse\\tBuying\\n:\\t\\nHawkins\\tStern,\\t“The\\tSignificance\\tof\\tImpulse\\tBuying\\tToday,”\\t\\nJournal\\tof\\tMarketing\\n\\t26,\\tno.\\t2\\t(1962),\\tdoi:10.2307/1248439.\\n45\\tpercent\\tof\\tCoca-Cola\\tsales\\n:\\n\\tMichael\\tMoss,\\t“Nudged\\tto\\tthe\\tProduce\\tAisle\\tby\\ta\\tLook\\tin\\tthe\\tMirror,”\\t\\nNew\\tYork\\tTimes,\\t\\nAugust\\t27,\\t2013,\\t\\nhttps://www.nytimes.com/2013/08/28/dining/wooing-us-\\ndown-the-produce-aisle.html?_r=0\\n.\\nPeople\\tdrink\\tBud\\tLight\\tbecause\\n:\\n\\tThe\\tmore\\texposure\\tpeople\\thave\\tto\\tfood,\\tthe\\tmore\\tlikely\\tthey\\tare\\tto\\tpurchase\\tit\\tand\\teat\\tit.\\tT.\\tBurgoine\\tet\\tal.,\\t“Associations\\tbetween\\tExposure\\tto\\tTakeaway\\tFood\\nOutlets,\\tTakeaway\\tFood\\tConsumption,\\tand\\tBody\\tWeight\\tin\\tCambridgeshire,\\tUK:\\tPopulation\\tBased,\\tCross\\tSectional\\tStudy,”\\t\\nBritish\\tMedical\\tJournal\\n\\t348,\\tno.\\t5\\t(2014),\\ndoi:10.1136/bmj.g1464.\\nThe\\thuman\\tbody\\thas\\tabout\\televen\\tmillion\\tsensory\\treceptors\\n:\\t\\nTimothy\\tD.\\tWilson,\\t\\nStrangers\\tto\\tOurselves:\\tDiscovering\\tthe\\tAdaptive\\tUnconscious\\n\\t(Cambridge,\\tMA:\\tBelknap\\tPress,\\t2004),\\t24.\\nhalf\\tof\\tthe\\tbrain’s\\tresources\\tare\\tused\\ton\\tvision\\n:\\n\\tB.\\tR.\\tSheth\\tet\\tal.,\\t“Orientation\\tMaps\\tof\\tSubjective\\tContours\\tin\\tVisual\\tCortex,”\\t\\nScience\\n\\t274,\\tno.\\t5295\\t(1996),\\tdoi:10.1126/science.274.5295.2110.\\nWhen\\ttheir\\tenergy\\tuse\\twas\\tobvious\\tand\\teasy\\tto\\ttrack\\n:\\t\\nThis\\tstory\\twas\\ttold\\tto\\tDonella\\tMeadows\\tat\\ta\\tconference\\tin\\tKollekolle,\\tDenmark,\\tin\\t1973.\\tFor\\tmore,\\tsee\\tDonella\\tMeadows\\tand\\tDiana\\tWright,\\nThinking\\tin\\tSystems:\\tA\\tPrimer\\n\\t(White\\tRiver\\tJunction,\\tVT:\\tChelsea\\tGreen,\\t2015),\\t109.\\nthe\\tstickers\\tcut\\tbathroom\\tcleaning\\tcosts\\n:\\n\\tThe\\tactual\\testimate\\twas\\t8\\tpercent,\\tbut\\tgiven\\tthe\\tvariables\\tused,\\tanywhere\\tbetween\\t5\\tpercent\\tand\\t10\\tpercent\\tsavings\\tannually\\tis\\ta\\treasonable\\tguess.\\tBlake\\nEvans-Pritchard,\\t“Aiming\\tto\\tReduce\\tCleaning\\tCosts,”\\t\\nWorks\\tThat\\tWork\\n,\\tWinter\\t2013,\\t\\nhttps://worksthatwork.com/1/urinal-fly\\n.\\nsleeping\\t.\\t.\\t.\\twas\\tthe\\tonly\\taction\\tthat\\thappened\\tin\\tthat\\troom\\n:\\n\\t“Techniques\\tinvolving\\tstimulus\\tcontrol\\thave\\teven\\tbeen\\tsuccessfully\\tused\\tto\\thelp\\tpeople\\twith\\tinsomnia.\\tIn\\tshort,\\tthose\\twho\\thad\\ttrouble\\nfalling\\tasleep\\twere\\ttold\\tto\\tonly\\tgo\\tto\\ttheir\\troom\\tand\\tlie\\tin\\ttheir\\tbed\\twhen\\tthey\\twere\\ttired.\\tIf\\tthey\\tcouldn’t\\tfall\\tasleep,\\tthey\\twere\\ttold\\tto\\tget\\tup\\tand\\tchange\\trooms.\\tStrange\\tadvice,\\tbut\\tover\\ntime,\\tresearchers\\tfound\\tthat\\tby\\tassociating\\tthe\\tbed\\twith\\t‘It’s\\ttime\\tto\\tgo\\tto\\tsleep’\\tand\\tnot\\twith\\tother\\tactivities\\t(reading\\ta\\tbook,\\tjust\\tlying\\tthere,\\tetc.),\\tparticipants\\twere\\teventually\\table\\tto\\nquickly\\tfall\\tasleep\\tdue\\tto\\tthe\\trepeated\\tprocess:\\tit\\tbecame\\talmost\\tautomatic\\tto\\tfall\\tasleep\\tin\\ttheir\\tbed\\tbecause\\ta\\tsuccessful\\ttrigger\\thad\\tbeen\\tcreated.”\\tFor\\tmore,\\tsee\\tCharles\\tM.\\tMorin\\tet\\tal.,\\n“Psychological\\tand\\tBehavioral\\tTreatment\\tof\\tInsomnia:\\tUpdate\\tof\\tthe\\tRecent\\tEvidence\\t(1998–2004),”\\t\\nSleep\\n\\t29,\\tno.\\t11\\t(2006),\\tdoi:10.1093/sleep/29.11.1398;\\tand\\tGregory\\tCiotti,\\t“The\\nBest\\tWay\\tto\\tChange\\tYour\\tHabits?\\tControl\\tYour\\tEnvironment,”\\tSparring\\tMind,\\t\\nhttps://www.sparringmind.com/changing-habits\\n.\\nhabits\\tcan\\tbe\\teasier\\tto\\tchange\\tin\\ta\\tnew\\tenvironment\\n:\\n\\tS.\\tThompson,\\tJ.\\tMichaelson,\\tS.\\tAbdallah,\\tV.\\tJohnson,\\tD.\\tMorris,\\tK.\\tRiley,\\tand\\tA.\\tSimms,\\t‘\\nMoments\\tof\\tChange’\\tas\\tOpportunities\\tfor\\tInfluencing\\nBehaviour:\\tA\\tReport\\tto\\tthe\\tDepartment\\tfor\\tEnvironment,\\tFood\\tand\\tRural\\tAffairs\\n\\t(London:\\tDefra,\\t2011),\\t\\nhttp://randd.defra.gov.uk/Document.aspx?\\nDocument=MomentsofChangeEV0506FinalReport\\n\\tNov2011(2).pdf.\\nwhen\\tyou\\tstep\\toutside\\tyour\\tnormal\\tenvironment\\n:\\t\\nVarious\\tresearch\\tstudies\\thave\\tfound\\tthat\\tit\\tis\\teasier\\tto\\tchange\\tyour\\tbehavior\\twhen\\tyour\\tenvironment\\tchanges.\\tFor\\texample,\\tstudents\\tchange\\ttheir\\ntelevision\\twatching\\thabits\\twhen\\tthey\\ttransfer\\tschools.\\tWendy\\tWood\\tand\\tDavid\\tT.\\tNeal,\\t“Healthy\\tthrough\\tHabit:\\tInterventions\\tfor\\tInitiating\\tand\\tMaintaining\\tHealth\\tBehavior\\tChange,”\\nBehavioral\\tScience\\tand\\tPolicy\\n\\t2,\\tno.\\t1\\t(2016),\\tdoi:10.1353/bsp.2016.0008;\\tW.\\tWood,\\tL.\\tTam,\\tand\\tM.\\tG.\\tWitt,\\t“Changing\\tCircumstances,\\tDisrupting\\tHabits,”\\t\\nJournal\\tof\\tPersonality\\tand\\nSocial\\tPsychology\\n\\t88,\\tno.\\t6\\t(2005),\\tdoi:10.1037/0022–3514.88.6.918\\nYou\\taren’t\\tbattling\\told\\tenvironmental\\tcues\\n:\\n\\tPerhaps\\tthis\\tis\\twhy\\t36\\tpercent\\tof\\tsuccessful\\tchanges\\tin\\tbehavior\\twere\\tassociated\\twith\\ta\\tmove\\tto\\ta\\tnew\\tplace.\\tMelissa\\tGuerrero-Witt,\\tWendy\\tWood,\\tand\\nLeona\\tTam,\\t“Changing\\tCircumstances,\\tDisrupting\\tHabits,”\\t\\nPsycEXTRA\\tDataset\\n\\t88,\\tno.\\t6\\t(2005),\\tdoi:10.1037/e529412014–144.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 213}), Document(page_content='CHAPTER\\t7\\nFollow-up\\tresearch\\trevealed\\tthat\\t35\\tpercent\\tof\\tservice\\tmembers\\n:\\n\\tLee\\tN.\\tRobins\\tet\\tal.,\\t“Vietnam\\tVeterans\\tThree\\tYears\\tafter\\tVietnam:\\tHow\\tOur\\tStudy\\tChanged\\tOur\\tView\\tof\\tHeroin,”\\t\\nAmerican\\nJournal\\ton\\tAddictions\\n\\t19,\\tno.\\t3\\t(2010),\\tdoi:10.1111/j.1521–0391.2010.00046.x.\\nthe\\tcreation\\tof\\tthe\\tSpecial\\tAction\\tOffice\\tof\\tDrug\\tAbuse\\tPrevention\\n:\\n\\t“Excerpts\\tfrom\\tPresident’s\\tMessage\\ton\\tDrug\\tAbuse\\tControl,”\\t\\nNew\\tYork\\tTimes\\n,\\tJune\\t18,\\t1971,\\nhttps://www.nytimes.com/1971/06/18/archives/excerpts-from-presidents-message-on-drug-abuse-control.html\\n.\\nnine\\tout\\tof\\tten\\tsoldiers\\twho\\tused\\theroin\\tin\\tVietnam\\n:\\n\\tLee\\tN.\\tRobins,\\tDarlene\\tH.\\tDavis,\\tand\\tDavid\\tN.\\tNurco,\\t“How\\tPermanent\\tWas\\tVietnam\\tDrug\\tAddiction?”\\t\\nAmerican\\tJournal\\tof\\tPublic\\tHealth\\n\\t64,\\nno.\\t12\\t(suppl.)\\t(1974),\\tdoi:10.2105/ajph.64.12_suppl.38.\\n90\\tpercent\\tof\\theroin\\tusers\\tbecome\\treaddicted\\n:\\n\\tBobby\\tP.\\tSmyth\\tet\\tal.,\\t“Lapse\\tand\\tRelapse\\tfollowing\\tInpatient\\tTreatment\\tof\\tOpiate\\tDependence,”\\t\\nIrish\\tMedical\\tJournal\\n\\t103,\\tno.\\t6\\t(June\\t2010).\\n“disciplined”\\tpeople\\tare\\tbetter\\tat\\tstructuring\\ttheir\\tlives\\n:\\n\\tWilhelm\\tHofmann\\tet\\tal.,\\t“Everyday\\tTemptations:\\tAn\\tExperience\\tSampling\\tStudy\\ton\\tHow\\tPeople\\tControl\\tTheir\\tDesires,”\\t\\nPsycEXTRA\\nDataset\\n\\t102,\\tno.\\t6\\t(2012),\\tdoi:10.1037/e634112013–146.\\nIt’s\\teasier\\tto\\tpractice\\tself-restraint\\twhen\\tyou\\tdon’t\\thave\\tto\\tuse\\tit\\n:\\n\\t“Our\\tprototypical\\tmodel\\tof\\tself-control\\tis\\tangel\\ton\\tone\\tside\\tand\\tdevil\\ton\\tthe\\tother,\\tand\\tthey\\tbattle\\tit\\tout.\\t.\\t.\\t.\\tWe\\ttend\\tto\\tthink\\tof\\npeople\\twith\\tstrong\\twillpower\\tas\\tpeople\\twho\\tare\\table\\tto\\tfight\\tthis\\tbattle\\teffectively.\\tActually,\\tthe\\tpeople\\twho\\tare\\treally\\tgood\\tat\\tself-control\\tnever\\thave\\tthese\\tbattles\\tin\\tthe\\tfirst\\tplace.”\\tFor\\nmore,\\tsee\\tBrian\\tResnick,\\t“The\\tMyth\\tof\\tSelf-Control,”\\t\\nVox\\n,\\tNovember\\t24,\\t2016,\\t\\nhttps://www.vox.com/science-and-health/2016/11/3/13486940/self-control-psychology-myth\\n.\\nA\\thabit\\tthat\\thas\\tbeen\\tencoded\\tin\\tthe\\tmind\\tis\\tready\\tto\\tbe\\tused\\n:\\n\\tWendy\\tWood\\tand\\tDennis\\tRünger,\\t“Psychology\\tof\\tHabit,”\\t\\nAnnual\\tReview\\tof\\tPsychology\\n\\t67,\\tno.\\t1\\t(2016),\\tdoi:10.1146/annurev-psych-\\n122414–033417.\\nThe\\tcues\\twere\\tstill\\tinternalized\\n:\\n\\t“The\\tBiology\\tof\\tMotivation\\tand\\tHabits:\\tWhy\\tWe\\tDrop\\tthe\\tBall,”\\t\\nTherapist\\tUncensored)\\n,\\t20:00,\\t\\nhttp://www.therapistuncensored.com/biology-of-motivation-habits\\n,\\naccessed\\tJune\\t8,\\t2018.\\nShaming\\tobese\\tpeople\\twith\\tweight-loss\\tpresentations\\n:\\n\\tSarah\\tE.\\tJackson,\\tRebecca\\tJ.\\tBeeken,\\tand\\tJane\\tWardle,\\t“Perceived\\tWeight\\tDiscrimination\\tand\\tChanges\\tin\\tWeight,\\tWaist\\tCircumference,\\tand\\nWeight\\tStatus,”\\t\\nObesity\\n,\\t2014,\\tdoi:10.1002/oby.20891.\\nShowing\\tpictures\\tof\\tblackened\\tlungs\\tto\\tsmokers\\n:\\n\\tKelly\\tMcGonigal,\\t\\nThe\\tUpside\\tof\\tStress:\\tWhy\\tStress\\tIs\\tGood\\tfor\\tYou,\\tand\\tHow\\tto\\tGet\\tGood\\tat\\tIt\\n\\t(New\\tYork:\\tAvery,\\t2016),\\txv.\\nshowing\\taddicts\\ta\\tpicture\\tof\\tcocaine\\tfor\\tjust\\tthirty-three\\tmilliseconds\\n:\\n\\tFran\\tSmith,\\t“How\\tScience\\tIs\\tUnlocking\\tthe\\tSecrets\\tof\\tAddiction,”\\t\\nNational\\tGeographic\\n,\\tSeptember\\t2017,\\nhttps://www.nationalgeographic.com/magazine/2017/09/the-addicted-brain\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 214}), Document(page_content='CHAPTER\\t8\\nNiko\\tTinbergen\\tperformed\\ta\\tseries\\tof\\texperiments\\n:\\n\\tNikolaas\\tTinbergen,\\t\\nThe\\tHerring\\tGull’s\\tWorld\\n\\t(London:\\tCollins,\\t1953);\\t“Nikolaas\\tTinbergen,”\\t\\nNew\\tWorld\\tEncyclopedia\\n,\\nhttp://www.newworldencyclopedia.org/entry/Nikolaas_Tinbergen\\n,\\tlast\\tmodified\\tSeptember\\t30,\\t2016.\\nthe\\tgoose\\twill\\tpull\\t\\nany\\n\\tnearby\\tround\\tobject\\n:\\n\\tJames\\tL.\\tGould,\\t\\nEthology:\\tThe\\tMechanisms\\tand\\tEvolution\\tof\\tBehavior\\n\\t(New\\tYork:\\tNorton,\\t1982),\\t36–41.\\nthe\\tmodern\\tfood\\tindustry\\trelies\\ton\\tstretching\\n:\\n\\tSteven\\tWitherly,\\t\\nWhy\\tHumans\\tLike\\tJunk\\tFood\\n\\t(New\\tYork:\\tIUniverse,\\t2007).\\nNearly\\tevery\\tfood\\tin\\ta\\tbag\\n:\\n\\t“Tweaking\\tTastes\\tand\\tCreating\\tCravings,”\\t\\n60\\tMinutes\\n,\\tNovember\\t27,\\t2011.\\t\\nhttps://www.youtube.com/watch?v=a7Wh3uq1yTc\\n.\\nFrench\\tfries\\t.\\t.\\t.\\tare\\ta\\tpotent\\tcombination\\n:\\n\\tSteven\\tWitherly,\\t\\nWhy\\tHumans\\tLike\\tJunk\\tFood\\n\\t(New\\tYork:\\tIUniverse,\\t2007).\\nsuch\\tstrategies\\tenable\\tfood\\tscientists\\tto\\tfind\\tthe\\t“bliss\\tpoint”\\n:\\t\\nMichael\\tMoss,\\t\\nSalt,\\tSugar,\\tFat:\\tHow\\tthe\\tFood\\tGiants\\tHooked\\tUs\\n\\t(London:\\tAllen,\\t2014).\\n“We’ve\\tgotten\\ttoo\\tgood\\tat\\tpushing\\tour\\town\\tbuttons”\\n:\\n\\tThis\\tquote\\toriginally\\tappeared\\tin\\tStephan\\tGuyenet,\\t“Why\\tAre\\tSome\\tPeople\\t‘Carboholics’?”\\tJuly\\t26,\\t2017,\\nhttp://www.stephanguyenet.com/why-are-some-people-carboholics\\n.\\tThe\\tadapted\\tversion\\tis\\tgiven\\twith\\tpermission\\tgranted\\tin\\tan\\temail\\texchange\\twith\\tthe\\tauthor\\tin\\tApril\\t2018.\\nThe\\timportance\\tof\\tdopamine\\n:\\t\\n“The\\timportance\\tof\\tdopamine\\twas\\tdiscovered\\tby\\taccident.\\tIn\\t1954,\\tJames\\tOlds\\tand\\tPeter\\tMilner,\\ttwo\\tneuroscientists\\tat\\tMcGill\\tUniversity,\\tdecided\\tto\\timplant\\tan\\nelectrode\\tdeep\\tinto\\tthe\\tcenter\\tof\\ta\\trat’s\\tbrain.\\tThe\\tprecise\\tplacement\\tof\\tthe\\telectrode\\twas\\tlargely\\thappenstance;\\tat\\tthe\\ttime,\\tthe\\tgeography\\tof\\tthe\\tmind\\tremained\\ta\\tmystery.\\tBut\\tOlds\\tand\\nMilner\\tgot\\tlucky.\\tThey\\tinserted\\tthe\\tneedle\\tright\\tnext\\tto\\tthe\\tnucleus\\taccumbens\\t(NAcc),\\ta\\tpart\\tof\\tthe\\tbrain\\tthat\\tgenerates\\tpleasurable\\tfeelings.\\tWhenever\\tyou\\teat\\ta\\tpiece\\tof\\tchocolate\\tcake,\\nor\\tlisten\\tto\\ta\\tfavorite\\tpop\\tsong,\\tor\\twatch\\tyour\\tfavorite\\tteam\\twin\\tthe\\tWorld\\tSeries,\\tit\\tis\\tyour\\tNAcc\\tthat\\thelps\\tyou\\tfeel\\tso\\thappy.\\tBut\\tOlds\\tand\\tMilner\\tquickly\\tdiscovered\\tthat\\ttoo\\tmuch\\npleasure\\tcan\\tbe\\tfatal.\\tThey\\tplaced\\tthe\\telectrodes\\tin\\tseveral\\trodents’\\tbrains\\tand\\tthen\\tran\\ta\\tsmall\\tcurrent\\tinto\\teach\\twire,\\tmaking\\tthe\\tNAccs\\tcontinually\\texcited.\\tThe\\tscientists\\tnoticed\\tthat\\tthe\\nrodents\\tlost\\tinterest\\tin\\teverything.\\tThey\\tstopped\\teating\\tand\\tdrinking.\\tAll\\tcourtship\\tbehavior\\tceased.\\tThe\\trats\\twould\\tjust\\thuddle\\tin\\tthe\\tcorners\\tof\\ttheir\\tcages,\\ttransfixed\\tby\\ttheir\\tbliss.\\tWithin\\ndays,\\tall\\tof\\tthe\\tanimals\\thad\\tperished.\\tThey\\tdied\\tof\\tthirst.\\tFor\\tmore,\\tsee\\tJonah\\tLehrer,\\t\\nHow\\tWe\\tDecide\\n\\t(Boston:\\tHoughton\\tMifflin\\tHarcourt,\\t2009).\\nneurological\\tprocesses\\tbehind\\tcraving\\tand\\tdesire\\n:\\t\\nJames\\tOlds\\tand\\tPeter\\tMilner,\\t“Positive\\tReinforcement\\tProduced\\tby\\tElectrical\\tStimulation\\tof\\tSeptal\\tArea\\tand\\tOther\\tRegions\\tof\\tRat\\tBrain,”\\t\\nJournal\\nof\\tComparative\\tand\\tPhysiological\\tPsychology\\n\\t47,\\tno.\\t6\\t(1954),\\tdoi:10.1037/h0058775.\\nrats\\tlost\\tall\\twill\\tto\\tlive\\n:\\t\\nQun-Yong\\tZhou\\tand\\tRichard\\tD.\\tPalmiter,\\t“Dopamine-Deficient\\tMice\\tAre\\tSeverely\\tHypoactive,\\tAdipsic,\\tand\\tAphagic,”\\t\\nCell\\n\\t83,\\tno.\\t7\\t(1995),\\tdoi:10.1016/0092–\\n8674(95)90145–0.\\nwithout\\tdesire,\\taction\\tstopped\\n:\\n\\tKent\\tC.\\tBerridge,\\tIsabel\\tL.\\tVenier,\\tand\\tTerry\\tE.\\tRobinson,\\t“Taste\\tReactivity\\tAnalysis\\tof\\t6-Hydroxydopamine-Induced\\tAphagia:\\tImplications\\tfor\\tArousal\\tand\\nAnhedonia\\tHypotheses\\tof\\tDopamine\\tFunction,”\\t\\nBehavioral\\tNeuroscience\\n\\t103,\\tno.\\t1\\t(1989),\\tdoi:10.1037//0735–7044.103.1.36.\\nthe\\tmice\\tdeveloped\\ta\\tcraving\\tso\\tstrong\\n:\\n\\tRoss\\tA.\\tMcdevitt\\tet\\tal.,\\t“Serotonergic\\tversus\\tNonserotonergic\\tDorsal\\tRaphe\\tProjection\\tNeurons:\\tDifferential\\tParticipation\\tin\\tReward\\tCircuitry,”\\t\\nCell\\tReports\\n8,\\tno.\\t6\\t(2014),\\tdoi:10.1016/j.cel\\trep.2014.08.037.\\nthe\\taverage\\tslot\\tmachine\\tplayer\\n:\\t\\nNatasha\\tDow\\tSchüll,\\t\\nAddiction\\tby\\tDesign:\\tMachine\\tGambling\\tin\\tLas\\tVegas\\n\\t(Princeton,\\tNJ:\\tPrinceton\\tUniversity\\tPress,\\t2014),\\t55.\\nHabits\\tare\\ta\\tdopamine-driven\\tfeedback\\tloop\\n:\\n\\tI\\tfirst\\theard\\tthe\\tterm\\t\\ndopamine-driven\\tfeedback\\tloop\\n\\tfrom\\tChamath\\tPalihapitiya.\\tFor\\tmore,\\tsee\\t“Chamath\\tPalihapitiya,\\tFounder\\tand\\tCEO\\tSocial\\tCapital,\\non\\tMoney\\tas\\tan\\tInstrument\\tof\\tChange,”\\tStanford\\tGraduate\\tSchool\\tof\\tBusiness,\\tNovember\\t13,\\t2017,\\t\\nhttps://www.youtube.com/watch?v=PMotykw0SIk\\n.\\ndopamine\\t.\\t.\\t.\\tplays\\ta\\tcentral\\trole\\tin\\tmany\\tneurological\\tprocesses\\n:\\n\\tResearchers\\tlater\\tdiscovered\\tthat\\tendorphins\\tand\\topioids\\twere\\tresponsible\\tfor\\tpleasure\\tresponses.\\tFor\\tmore,\\tsee\\tV.\\tS.\\tChakravarthy,\\nDenny\\tJoseph,\\tand\\tRaju\\tS.\\tBapi,\\t“What\\tDo\\tthe\\tBasal\\tGanglia\\tDo?\\tA\\tModeling\\tPerspective,”\\t\\nBiological\\tCybernetics\\n\\t103,\\tno.\\t3\\t(2010),\\tdoi:10.1007/s00422–010–0401-y.\\ndopamine\\tis\\treleased\\tnot\\tonly\\twhen\\tyou\\t\\nexperience\\n\\tpleasure\\n:\\t\\nWolfram\\tSchultz,\\t“Neuronal\\tReward\\tand\\tDecision\\tSignals:\\tFrom\\tTheories\\tto\\tData,”\\t\\nPhysiological\\tReviews\\n\\t95,\\tno.\\t3\\t(2015),\\ndoi:10.1152/physrev.00023.2014,\\tfig.\\t8;\\tFran\\tSmith,\\t“How\\tScience\\tIs\\tUnlocking\\tthe\\tSecrets\\tof\\tAddiction,”\\t\\nNational\\tGeographic\\n,\\tSeptember\\t2017,\\nhttps://www.nationalgeographic.com/magazine/2017/09/the-addicted-brain\\n.\\nwhenever\\tdopamine\\trises,\\tso\\tdoes\\tyour\\tmotivation\\n:\\n\\tDopamine\\tcompels\\tyou\\tto\\tseek,\\texplore,\\tand\\ttake\\taction:\\t“Dopamine-energized,\\tthis\\tmesolimbic\\tSEEKING\\tsystem,\\tarising\\tfrom\\tthe\\tventral\\ntegmental\\tarea\\t(VTA),\\tencourages\\tforaging,\\texploration,\\tinvestigation,\\tcuriosity,\\tinterest\\tand\\texpectancy.\\tDopamine\\tfires\\teach\\ttime\\tthe\\trat\\t(or\\thuman)\\texplores\\tits\\tenvironment.\\t.\\t.\\t.\\tI\\tcan\\nlook\\tat\\tthe\\tanimal\\tand\\ttell\\twhen\\tI\\tam\\ttickling\\tits\\tSEEKING\\tsystem\\tbecause\\tit\\tis\\texploring\\tand\\tsniffing.”\\tFor\\tmore,\\tsee\\tKarin\\tBadt,\\t“Depressed?\\tYour\\t‘SEEKING’\\tSystem\\tMight\\tNot\\tBe\\nWorking:\\tA\\tConversation\\twith\\tNeuroscientist\\tJaak\\tPanksepp,”\\tHuffington\\tPost,\\tDecember\\t6,\\t2017,\\t\\nhttp://www.huffingtonpost.com/karin-badt/depressed-your-seeking-\\nsy_b_3616967.html\\n.\\nthe\\treward\\tsystem\\tthat\\tis\\tactivated\\tin\\tthe\\tbrain\\n:\\n\\tWolfram\\tSchultz,\\t“Multiple\\tReward\\tSignals\\tin\\tthe\\tBrain,”\\t\\nNature\\tReviews\\tNeuroscience\\n\\t1,\\tno.\\t3\\t(2000),\\tdoi:10.1038/35044563.\\n100\\tpercent\\tof\\tthe\\tnucleus\\taccumbens\\tis\\tactivated\\tduring\\twanting\\n:\\n\\tKent\\tBerridge,\\tconversation\\twith\\tauthor,\\tMarch\\t8,\\t2017.\\nByrne\\thacked\\this\\tstationary\\tbike\\n:\\n\\tHackster\\tStaff,\\t“Netflix\\tand\\tCycle!,”\\tHackster,\\tJuly\\t12,\\t2017,\\t\\nhttps://blog.hackster.io/netflix-and-cycle-1734d0179deb\\n.\\n“eliminating\\tobesity\\tone\\tNetflix\\tbinge\\tat\\ta\\ttime”\\n:\\n\\t“Cycflix:\\tExercise\\tPowered\\tEntertainment,”\\tRoboro,\\tJuly\\t8,\\t2017,\\t\\nhttps://www.youtube.com/watch?v=-nc0irLB-iY\\n.\\n“We\\tsee\\tThursday\\tnight\\tas\\ta\\tviewership\\topportunity”\\n:\\n\\tJeanine\\tPoggi,\\t“Shonda\\tRhimes\\tLooks\\tBeyond\\tABC’s\\tNighttime\\tSoaps,”\\t\\nAdAge\\n,\\tMay\\t16,\\t2016,\\t\\nhttp://adage.com/article/special-report-tv-\\nupfront/shonda-rhimes-abc-soaps/303996\\n.\\n“more\\tprobable\\tbehaviors\\twill\\treinforce\\tless\\tprobable\\tbehaviors”\\n:\\n\\tJon\\tE.\\tRoeckelein,\\t\\nDictionary\\tof\\tTheories,\\tLaws,\\tand\\tConcepts\\tin\\tPsychology\\n\\t(Westport,\\tCT:\\tGreenwood\\tPress,\\t1998),\\t384.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 215}), Document(page_content='CHAPTER\\t9\\n“A\\tgenius\\tis\\tnot\\tborn,\\tbut\\tis\\teducated\\tand\\ttrained”\\n:\\n\\tHarold\\tLundstrom,\\t“Father\\tof\\t3\\tProdigies\\tSays\\tChess\\tGenius\\tCan\\tBe\\tTaught,”\\t\\nDeseret\\tNews\\n,\\tDecember\\t25,\\t1992,\\nhttps://www.deseretnews.com/article/266378/FATHER-OF-3-PRODIGIES-SAYS-CHESS-GENIUS-CAN-BE-TAUGHT.html?pg=all\\n.\\nWe\\timitate\\tthe\\thabits\\tof\\tthree\\tgroups\\n:\\n\\tPeter\\tJ.\\tRicherson\\tand\\tRobert\\tBoyd,\\t\\nNot\\tby\\tGenes\\tAlone:\\tHow\\tCulture\\tTransformed\\tHuman\\tEvolution\\n\\t(Chicago:\\tUniversity\\tof\\tChicago\\tPress,\\t2006).\\n“a\\tperson’s\\tchances\\tof\\tbecoming\\tobese\\tincreased\\tby\\t57\\tpercent”\\n:\\n\\tNicholas\\tA.\\tChristakis\\tand\\tJames\\tH.\\tFowler,\\t“The\\tSpread\\tof\\tObesity\\tin\\ta\\tLarge\\tSocial\\tNetwork\\tover\\t32\\tYears,”\\t\\nNew\\tEngland\\nJournal\\tof\\tMedicine\\n\\t357,\\tno.\\t4\\t(2007),\\tdoi:10.1056/nejmsa066082.\\tJ.\\tA.\\tStockman,\\t“The\\tSpread\\tof\\tObesity\\tin\\ta\\tLarge\\tSocial\\tNetwork\\tover\\t32\\tYears,”\\t\\nYearbook\\tof\\tPediatrics\\t2009\\n(2009),\\tdoi:10.1016/s0084–3954(08)79134–6.\\nif\\tone\\tperson\\tin\\ta\\trelationship\\tlost\\tweight\\n:\\n\\tAmy\\tA.\\tGorin\\tet\\tal.,\\t“Randomized\\tControlled\\tTrial\\tExamining\\tthe\\tRipple\\tEffect\\tof\\ta\\tNationally\\tAvailable\\tWeight\\tManagement\\tProgram\\ton\\tUntreated\\nSpouses,”\\t\\nObesity\\n\\t26,\\tno.\\t3\\t(2018),\\tdoi:10.1002/oby.22098.\\nOf\\tthe\\tten\\tpeople\\tin\\tthe\\tclass,\\t\\nfour\\n\\tbecame\\tastronauts\\n:\\n\\tMike\\tMassimino,\\t“Finding\\tthe\\tDifference\\tBetween\\t‘Improbable’\\tand\\t‘Impossible,’”\\tinterview\\tby\\tJames\\tAltucher,\\t\\nThe\\tJames\\tAltucher\\tShow\\n,\\nJanuary\\t2017,\\t\\nhttps://jamesaltucher.com/2017/01/mike-massimino-i-am-not-good-enough\\n.\\nthe\\thigher\\tyour\\tbest\\tfriend’s\\tIQ\\tat\\tage\\televen\\tor\\ttwelve\\n:\\n\\tRyan\\tMeldrum,\\tNicholas\\tKavish,\\tand\\tBrian\\tBoutwell,\\t“On\\tthe\\tLongitudinal\\tAssociation\\tBetween\\tPeer\\tand\\tAdolescent\\tIntelligence:\\tCan\\tOur\\nFriends\\tMake\\tUs\\tSmarter?,”\\t\\nPsyArXiv\\n,\\tFebruary\\t10,\\t2018,\\tdoi:10.17605/OSF.IO/TVJ9Z.\\nSolomon\\tAsch\\tconducted\\ta\\tseries\\tof\\texperiments\\n:\\t\\nHarold\\tSteere\\tGuetzkow,\\t\\nGroups,\\tLeadership\\tand\\tMen:\\tResearch\\tin\\tHuman\\tRelations\\n\\t(Pittsburgh,\\tPA:\\tCarnegie\\tPress,\\t1951),\\t177–190.\\nBy\\tthe\\tend\\tof\\tthe\\texperiment,\\tnearly\\t75\\tpercent\\tof\\tthe\\tsubjects\\n:\\n\\tFollow-up\\tstudies\\tshow\\tthat\\tif\\tthere\\twas\\tjust\\tone\\tactor\\tin\\tthe\\tgroup\\twho\\tdisagreed\\twith\\tthe\\tgroup,\\tthen\\tthe\\tsubject\\twas\\tfar\\tmore\\tlikely\\nto\\tstate\\ttheir\\ttrue\\tbelief\\tthat\\tthe\\tlines\\twere\\tdifferent\\tlengths.\\tWhen\\tyou\\thave\\tan\\topinion\\tthat\\tdissents\\tfrom\\tthe\\ttribe,\\tit\\tis\\tmuch\\teasier\\tto\\tstand\\tby\\tit\\tif\\tyou\\thave\\tan\\tally.\\tWhen\\tyou\\tneed\\tthe\\nstrength\\tto\\tstand\\tup\\tto\\tthe\\tsocial\\tnorm,\\tfind\\ta\\tpartner.\\tFor\\tmore,\\tsee\\tSolomon\\tE.\\tAsch,\\t“Opinions\\tand\\tSocial\\tPressure,”\\t\\nScientific\\tAmerican\\n\\t193,\\tno.\\t5\\t(1955),\\ndoi:10.1038/scientificamerican1155–31;\\tand\\tWilliam\\tN.\\tMorris\\tand\\tRobert\\tS.\\tMiller,\\t“The\\tEffects\\tof\\tConsensus-Breaking\\tand\\tConsensus-Preempting\\tPartners\\ton\\tReduction\\tof\\nConformity,”\\t\\nJournal\\tof\\tExperimental\\tSocial\\tPsychology\\n\\t11,\\tno.\\t3\\t(1975),\\tdoi:10.1016/s0022–1031(75)80023–0.\\nNearly\\t75\\tpercent\\tof\\tsubjects\\tmade\\tthe\\tincorrect\\tchoice\\tat\\tleast\\tonce.\\tHowever,\\tconsidering\\tthe\\ttotal\\tnumber\\tof\\tresponses\\tthroughout\\tthe\\texperiment,\\tabout\\ttwo\\tthirds\\twere\\tcorrect.\\tEither\\nway,\\tthe\\tpoint\\tstands:\\tgroup\\tpressure\\tcan\\tsignificantly\\talter\\tour\\tability\\tto\\tmake\\taccurate\\tdecisions.\\na\\tchimpanzee\\tlearns\\tan\\teffective\\tway\\n:\\n\\tLydia\\tV.\\tLuncz,\\tGiulia\\tSirianni,\\tRoger\\tMundry,\\tand\\tChristophe\\tBoesch.\\t“Costly\\tculture:\\tdifferences\\tin\\tnut-cracking\\tefficiency\\tbetween\\twild\\tchimpanzee\\ngroups.”\\t\\nAnimal\\tBehaviour\\n\\t137\\t(2018):\\t63–73.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 216}), Document(page_content='CHAPTER\\t10\\nI\\twouldn’t\\tsay,\\t“Because\\tI\\tneed\\tfood\\tto\\tsurvive”\\n:\\t\\nI\\theard\\ta\\tsimilar\\texample\\tfrom\\tthe\\tTwitter\\taccount,\\tsimpolism\\t(@simpolism),\\t“Let’s\\textend\\tthis\\tmetaphor.\\tIf\\tsociety\\tis\\ta\\thuman\\tbody,\\tthen\\tthe\\tstate\\nis\\tthe\\tbrain.\\tHumans\\tare\\tunaware\\tof\\ttheir\\tmotives.\\tIf\\tasked\\t‘why\\tdo\\tyou\\teat?’\\tyou\\tmight\\tsay\\t‘bc\\tfood\\ttastes\\tgood’\\tand\\tnot\\t‘bc\\tI\\tneed\\tfood\\tto\\tsurvive.’\\tWhat\\tmight\\ta\\tstate’s\\tfood\\tbe?\\t(hint:\\nare\\tpills\\tfood?),”\\tTwitter,\\tMay\\t7,\\t2018,\\t\\nhttps://twitter.com/simpolism/status/993632142700826624\\n.\\nwhen\\temotions\\tand\\tfeelings\\tare\\timpaired\\n:\\n\\tAntoine\\tBechara\\tet\\tal.,\\t“Insensitivity\\tto\\tFuture\\tConsequences\\tfollowing\\tDamage\\tto\\tHuman\\tPrefrontal\\tCortex,”\\t\\nCognition\\n\\t50,\\tno.\\t1–3\\t(1994),\\ndoi:10.1016/0010–0277(94)90018–3.\\nAs\\tthe\\tneuroscientist\\tAntonio\\tDamasio\\n:\\t“\\nWhen\\tEmotions\\tMake\\tBetter\\tDecisions—Antonio\\tDamasio,”\\tAugust\\t11,\\t2009.\\t\\nhttps://www.youtube.com/watch?v=1wup_K2WN0I\\nYou\\tdon’t\\t“have”\\tto.\\tYou\\t“get”\\tto\\n:\\t\\nI\\tam\\tindebted\\tto\\tmy\\tcollege\\tstrength\\tand\\tconditioning\\tcoach,\\tMark\\tWatts,\\twho\\toriginally\\tshared\\tthis\\tsimple\\tmind-set\\tshift\\twith\\tme.\\n“\\nI’m\\tnot\\tconfined\\tto\\tmy\\twheelchair”\\n:\\n\\tRedheadBanshee,\\t“What\\tIs\\tSomething\\tSomeone\\tSaid\\tThat\\tForever\\tChanged\\tYour\\tWay\\tof\\tThinking,”\\tReddit,\\tOctober\\t22,\\t2014,\\nhttps://www.reddit.com/r/AskReddit/comments/2jzn0j/what_is_something_someone_said_that_forever/clgm4s2\\n.\\n“It’s\\ttime\\tto\\tbuild\\tendurance\\tand\\tget\\tfast”\\n:\\n\\tWingedAdventurer,\\t“Instead\\tof\\tThinking\\t‘Go\\tRun\\tin\\tthe\\tMorning,’\\tThink\\t‘Go\\tBuild\\tEndurance\\tand\\tGet\\tFast.’\\tMake\\tYour\\tHabit\\ta\\tBenefit,\\tNot\\ta\\tTask,”\\nReddit,\\tJanuary\\t19,\\t2017,\\t\\nhttps://www.reddit.com/r/selfimprovement/comments/5ovrqf/instead_of_thinking_go_run_in_the_morning_think/?st=izmz9pks&sh=059312db\\n.\\n“I’m\\tgetting\\tan\\tadrenaline\\trush\\tto\\thelp\\tme\\tconcentrate”\\n:\\n\\tAlison\\tWood\\tBrooks,\\t“Get\\tExcited:\\tReappraising\\tPre-Performance\\tAnxiety\\tas\\tExcitement\\twith\\tMinimal\\tCues,”\\t\\nPsycEXTRA\\tDataset\\n,\\tJune\\n2014,\\tdoi:10.1037/e578192014–321;\\tCaroline\\tWebb,\\t\\nHow\\tto\\tHave\\ta\\tGood\\tDay\\n\\t(London:\\tPan\\tBooks,\\t2017),\\t238.\\t“Wendy\\tBerry\\tMendes\\tand\\tJeremy\\tJamieson\\thave\\tconducted\\ta\\tnumber\\nof\\tstudies\\t[that]\\tshow\\tthat\\tpeople\\tperform\\tbetter\\twhen\\tthey\\tdecide\\tto\\tinterpret\\ttheir\\tfast\\theartbeat\\tand\\tbreathing\\tas\\t‘a\\tresource\\tthat\\taids\\tperformance.’”\\nEd\\tLatimore,\\ta\\tboxer\\tand\\twriter\\n:\\t\\nEd\\tLatimore\\t(@EdLatimore),\\t“Odd\\trealization:\\tMy\\tfocus\\tand\\tconcentration\\tgoes\\tup\\tjust\\tby\\tputting\\tmy\\theadphones\\t[on]\\twhile\\twriting.\\tI\\tdon’t\\teven\\thave\\tto\\tplay\\tany\\nmusic,”\\tTwitter,\\tMay\\t7,\\t2018,\\t\\nhttps://twitter.com/EdLatimore/status/993496493171662849\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 217}), Document(page_content='CHAPTER\\t11\\nIn\\tthe\\tend,\\tthey\\thad\\tlittle\\tto\\tshow\\tfor\\ttheir\\tefforts\\n:\\n\\tThis\\tstory\\tcomes\\tfrom\\tpage\\t29\\tof\\t\\nArt\\t&\\tFear\\n\\tby\\tDavid\\tBayles\\tand\\tTed\\tOrland.\\tIn\\tan\\temail\\tconversation\\twith\\tOrland\\ton\\tOctober\\t18,\\t2016,\\the\\nexplained\\tthe\\torigins\\tof\\tthe\\tstory.\\t“Yes,\\tthe\\t‘ceramics\\tstory’\\tin\\t‘Art\\t&\\tFear’\\tis\\tindeed\\ttrue,\\tallowing\\tfor\\tsome\\tliterary\\tlicense\\tin\\tthe\\tretelling.\\tIts\\treal-world\\torigin\\twas\\tas\\ta\\tgambit\\temployed\\nby\\tphotographer\\tJerry\\tUelsmann\\tto\\tmotivate\\this\\tBeginning\\tPhotography\\tstudents\\tat\\tthe\\tUniversity\\tof\\tFlorida.\\tAs\\tretold\\tin\\t‘Art\\t&\\tFear’\\tit\\tfaithfully\\tcaptures\\tthe\\tscene\\tas\\tJerry\\ttold\\tit\\tto\\tme\\n—except\\tI\\treplaced\\tphotography\\twith\\tceramics\\tas\\tthe\\tmedium\\tbeing\\texplored.\\tAdmittedly,\\tit\\twould’ve\\tbeen\\teasier\\tto\\tretain\\tphotography\\tas\\tthe\\tart\\tmedium\\tbeing\\tdiscussed,\\tbut\\tDavid\\nBayles\\t(co-author)\\t&\\tI\\tare\\tboth\\tphotographers\\tourselves,\\tand\\tat\\tthe\\ttime\\twe\\twere\\tconsciously\\ttrying\\tto\\tbroaden\\tthe\\trange\\tof\\tmedia\\tbeing\\treferenced\\tin\\tthe\\ttext.\\tThe\\tintriguing\\tthing\\tto\\tme\\nis\\tthat\\tit\\thardly\\tmatters\\twhat\\tart\\tform\\twas\\tinvoked—the\\tmoral\\tof\\tthe\\tstory\\tappears\\tto\\thold\\tequally\\ttrue\\tstraight\\tacross\\tthe\\twhole\\tart\\tspectrum\\t(and\\teven\\toutside\\tthe\\tarts,\\tfor\\tthat\\tmatter).”\\nLater\\tin\\tthat\\tsame\\temail,\\tOrland\\tsaid,\\t“You\\thave\\tour\\tpermission\\tto\\treprint\\tany\\tor\\tall\\tof\\tthe\\t‘ceramics’\\tpassage\\tin\\tyour\\tforthcoming\\tbook.”\\tIn\\tthe\\tend,\\tI\\tsettled\\ton\\tpublishing\\tan\\tadapted\\nversion,\\twhich\\tcombines\\ttheir\\ttelling\\tof\\tthe\\tceramics\\tstory\\twith\\tfacts\\tfrom\\tthe\\toriginal\\tsource\\tof\\tUelsmann’s\\tphotography\\tstudents.\\tDavid\\tBayles\\tand\\tTed\\tOrland,\\t\\nArt\\t&\\tFear:\\nObservations\\ton\\tthe\\tPerils\\t(and\\tRewards)\\tof\\tArtmaking\\n\\t(Santa\\tCruz,\\tCA:\\tImage\\tContinuum\\tPress,\\t1993),\\t29.\\nAs\\tVoltaire\\tonce\\twrote\\n:\\t\\nVoltaire,\\t\\nLa\\tBégueule.\\tConte\\tMoral\\n\\t(1772).\\nlong-term\\tpotentiation\\n:\\n\\tLong-term\\tpotentiation\\twas\\tdiscovered\\tby\\tTerje\\tLømo\\tin\\t1966.\\tMore\\tprecisely,\\the\\tdiscovered\\tthat\\twhen\\ta\\tseries\\tof\\tsignals\\twas\\trepeatedly\\ttransmitted\\tby\\tthe\\tbrain,\\tthere\\twas\\ta\\npersistent\\teffect\\tthat\\tlasted\\tafterward\\tthat\\tmade\\tit\\teasier\\tfor\\tthose\\tsignals\\tto\\tbe\\ttransmitted\\tin\\tthe\\tfuture.\\n“Neurons\\tthat\\tfire\\ttogether\\twire\\ttogether”\\n:\\n\\tDonald\\tO.\\tHebb,\\t\\nThe\\tOrganization\\tof\\tBehavior:\\tA\\tNeuropsychological\\tTheory\\n\\t(New\\tYork:\\tWiley,\\t1949).\\nIn\\tmusicians,\\tthe\\tcerebellum\\n:\\n\\tS.\\tHutchinson,\\t“Cerebellar\\tVolume\\tof\\tMusicians,”\\t\\nCerebral\\tCortex\\n\\t13,\\tno.\\t9\\t(2003),\\tdoi:10.1093/cercor/13.9.943.\\nMathematicians,\\tmeanwhile,\\thave\\tincreased\\tgray\\tmatter\\n:\\n\\tA.\\tVerma,\\t“Increased\\tGray\\tMatter\\tDensity\\tin\\tthe\\tParietal\\tCortex\\tof\\tMathematicians:\\tA\\tVoxel-Based\\tMorphometry\\tStudy,”\\t\\nYearbook\\tof\\nNeurology\\tand\\tNeurosurgery\\t2008\\n\\t(2008),\\tdoi:10.1016/s0513–5117(08)79083–5.\\nWhen\\tscientists\\tanalyzed\\tthe\\tbrains\\tof\\ttaxi\\tdrivers\\tin\\tLondon\\n:\\n\\tEleanor\\tA.\\tMaguire\\tet\\tal.,\\t“Navigation-Related\\tStructural\\tChange\\tin\\tthe\\tHippocampi\\tof\\tTaxi\\tDrivers,”\\t\\nProceedings\\tof\\tthe\\tNational\\nAcademy\\tof\\tSciences\\n\\t97,\\tno.\\t8\\t(2000),\\tdoi:10.1073/pnas.070039597;\\tKatherine\\tWoollett\\tand\\tEleanor\\tA.\\tMaguire,\\t“Acquiring\\t‘the\\tKnowledge’\\tof\\tLondon’s\\tLayout\\tDrives\\tStructural\\tBrain\\nChanges,”\\t\\nCurrent\\tBiology\\n\\t21,\\tno.\\t24\\t(December\\t2011),\\tdoi:10.1016/j.cub.2011.11.018;\\tEleanor\\tA.\\tMaguire,\\tKatherine\\tWoollett,\\tand\\tHugo\\tJ.\\tSpiers,\\t“London\\tTaxi\\tDrivers\\tand\\tBus\\nDrivers:\\tA\\tStructural\\tMRI\\tand\\tNeuropsychological\\tAnalysis,”\\t\\nHippocampus\\n\\t16,\\tno.\\t12\\t(2006),\\tdoi:10.1002/hipo.20233.\\n“the\\tactions\\tbecome\\tso\\tautomatic”\\n:\\n\\tGeorge\\tHenry\\tLewes,\\t\\nThe\\tPhysiology\\tof\\tCommon\\tLife\\n\\t(Leipzig:\\tTauchnitz,\\t1860).\\nrepetition\\tis\\ta\\tform\\tof\\tchange\\n:\\n\\tApparently,\\tBrian\\tEno\\tsays\\tthe\\tsame\\tthing\\tin\\this\\texcellent,\\tcreatively\\tinspiring\\tOblique\\tStrategies\\tcard\\tset,\\twhich\\tI\\tdidn’t\\tknow\\twhen\\tI\\twrote\\tthis\\tline!\\tGreat\\tminds\\tand\\nall\\tthat.\\nAutomaticity\\tis\\tthe\\tability\\tto\\tperform\\ta\\tbehavior\\n:\\n\\tPhillippa\\tLally\\tet\\tal.,\\t“How\\tAre\\tHabits\\tFormed:\\tModelling\\tHabit\\tFormation\\tin\\tthe\\tReal\\tWorld,”\\t\\nEuropean\\tJournal\\tof\\tSocial\\tPsychology\\n\\t40,\\tno.\\t6\\n(2009),\\tdoi:10.1002/ejsp.674.\\nhabits\\tform\\tbased\\ton\\tfrequency,\\tnot\\ttime\\n:\\n\\tHermann\\tEbbinghaus\\twas\\tthe\\tfirst\\tperson\\tto\\tdescribe\\tlearning\\tcurves\\tin\\this\\t1885\\tbook\\t\\nÜber\\tdas\\tGedächtnis\\n.\\tHermann\\tEbbinghaus,\\t\\nMemory:\\tA\\tContribution\\nto\\tExperimental\\tPsychology\\n\\t(United\\tStates:\\tScholar\\tSelect,\\t2016).', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 218}), Document(page_content='CHAPTER\\t12\\nthis\\tdifference\\tin\\tshape\\tplayed\\ta\\tsignificant\\trole\\tin\\tthe\\tspread\\tof\\tagriculture\\n:\\n\\tJared\\tDiamond,\\t\\nGuns,\\tGerms,\\tand\\tSteel:\\tThe\\tFates\\tof\\tHuman\\tSocieties\\n\\t(New\\tYork:\\tNorton,\\t1997).\\nIt\\tis\\thuman\\tnature\\tto\\tfollow\\tthe\\tLaw\\tof\\tLeast\\tEffort\\n:\\n\\tDeepak\\tChopra\\tuses\\tthe\\tphrase\\t“law\\tof\\tleast\\teffort”\\tto\\tdescribe\\tone\\tof\\this\\tSeven\\tSpiritual\\tLaws\\tof\\tYoga.\\tThis\\tconcept\\tis\\tnot\\trelated\\tto\\tthe\\nprinciple\\tI\\tam\\tdiscussing\\there.\\na\\tgarden\\those\\tthat\\tis\\tbent\\tin\\tthe\\tmiddle\\n:\\n\\tThis\\tanalogy\\tis\\ta\\tmodified\\tversion\\tof\\tan\\tidea\\tJosh\\tWaitzkin\\tmentioned\\tin\\this\\tinterview\\twith\\tTim\\tFerriss.\\t“The\\tTim\\tFerriss\\tShow,\\tEpisode\\t2:\\tJosh\\tWaitzkin,”\\nMay\\t2,\\t2014,\\taudio,\\t\\nhttps://soundcloud.com/tim-ferriss/the-tim-ferriss-show-episode-2-josh-waitzkin\\n.\\n“it\\ttook\\tAmerican\\tworkers\\tthree\\ttimes\\tas\\tlong\\tto\\tassemble\\ttheir\\tsets”\\n:\\n\\tJames\\tSurowiecki,\\t“Better\\tAll\\tthe\\tTime,”\\t\\nNew\\tYorker\\n,\\tNovember\\t10,\\t2014,\\nhttps://www.newyorker.com/magazine/2014/11/10/better-time\\n.\\naddition\\tby\\tsubtraction\\n:\\n\\tAddition\\tby\\tsubtraction\\tis\\tan\\texample\\tof\\ta\\tlarger\\tprinciple\\tknown\\tas\\tinversion,\\twhich\\tI\\thave\\twritten\\tabout\\tpreviously\\tat\\t\\nhttps://jamesclear.com/inversion\\n.\\tI’m\\tindebted\\tto\\tShane\\nParrish\\tfor\\tpriming\\tmy\\tthoughts\\ton\\tthis\\ttopic\\tby\\twriting\\tabout\\twhy\\t“avoiding\\tstupidity\\tis\\teasier\\tthan\\tseeking\\tbrilliance.”\\tShane\\tParrish,\\t“Avoiding\\tStupidity\\tIs\\tEasier\\tThan\\tSeeking\\nBrilliance,”\\tFarnam\\tStreet,\\tJune\\t2014,\\t\\nhttps://www.fs.blog/2014/06/avoiding-stupidity\\n.\\nthose\\tpercentage\\tpoints\\trepresent\\tmillions\\tin\\ttax\\trevenue\\n:\\n\\tOwain\\tService\\tet\\tal.,\\t“East:\\tFour\\tSimple\\tWays\\tto\\tApply\\tBehavioural\\tInsights,”\\tBehavioural\\tInsights\\tTeam,\\t2015,\\nhttp://38r8om2xjhhl25mw24492dir.wpengine.netdna-cdn.com/wp-content/uploads/2015/07/BIT-Publication-EAST_FA_WEB.pdf\\n.\\nNuckols\\tdialed\\tin\\this\\tcleaning\\thabits\\n:\\n\\tOswald\\tNuckols\\tis\\tan\\talias,\\tused\\tby\\trequest.\\n“perfect\\ttime\\tto\\tclean\\tthe\\ttoilet”\\n:\\t\\nSaul_Panzer_NY,\\t“[Question]\\tWhat\\tOne\\tHabit\\tLiterally\\tChanged\\tYour\\tLife?”\\tReddit,\\tJune\\t5,\\t2017,\\t\\nhttps://www.reddit.com/r/get\\ndisciplined/comments/6fgqbv/question_what_one_habit_literally_changed_your/diieswq.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 219}), Document(page_content='CHAPTER\\t13\\n“arsenal\\tof\\troutines”\\n:\\t\\nTwyla\\tTharp\\tand\\tMark\\tReiter,\\t\\nThe\\tCreative\\tHabit:\\tLearn\\tIt\\tand\\tUse\\tIt\\tfor\\tLife:\\tA\\tPractical\\tGuide\\n\\t(New\\tYork:\\tSimon\\tand\\tSchuster,\\t2006).\\n40\\tto\\t50\\tpercent\\tof\\tour\\tactions\\ton\\tany\\tgiven\\tday\\tare\\tdone\\tout\\tof\\thabit\\n:\\n\\tWendy\\tWood,\\t“Habits\\tAcross\\tthe\\tLifespan,”\\t2006,\\nhttps://www.researchgate.net/publication/315552294_Habits_Across_the_Lifespan\\n.\\nhabits\\tyou\\tfollow\\twithout\\tthinking\\n:\\n\\tBenjamin\\tGardner,\\t“A\\tReview\\tand\\tAnalysis\\tof\\tthe\\tUse\\tof\\t‘Habit’\\tin\\tUnderstanding,\\tPredicting\\tand\\tInfluencing\\tHealth-Related\\tBehaviour,”\\t\\nHealth\\tPsychology\\nReview\\n\\t9,\\tno.\\t3\\t(2014),\\tdoi:10.1080/17437199.2013.876238.\\ndecisive\\tmoments\\n:\\n\\tShoutout\\tto\\tHenri\\tCartier-Bresson,\\tone\\tof\\tthe\\tgreatest\\tstreet\\tphotographers\\tof\\tall\\ttime,\\twho\\tcoined\\tthe\\tterm\\t\\ndecisive\\tmoment\\n,\\tbut\\tfor\\tan\\tentirely\\tdifferent\\tpurpose:\\tcapturing\\tamazing\\nimages\\tat\\tjust\\tthe\\tright\\ttime.\\nthe\\n\\tTwo-Minute\\tRule\\n:\\t\\nHat\\ttip\\tto\\tDavid\\tAllen,\\twhose\\tversion\\tof\\tthe\\tTwo-Minute\\tRule\\tstates,\\n\\t“\\nIf\\tit\\ttakes\\tless\\tthan\\ttwo\\tminutes,\\tthen\\tdo\\tit\\tnow.”\\tFor\\tmore,\\tsee\\tDavid\\tAllen,\\t\\nGetting\\tThings\\tDone\\n\\t(New\\nYork:\\tPenguin,\\t2015).\\npower-down\\thabit\\n:\\t\\nAuthor\\tCal\\tNewport\\tuses\\ta\\tshutdown\\tritual\\tin\\twhich\\the\\tdoes\\ta\\tlast\\temail\\tinbox\\tcheck,\\tprepares\\this\\tto-do\\tlist\\tfor\\tthe\\tnext\\tday,\\tand\\tsays\\t“shutdown\\tcomplete”\\tto\\tend\\twork\\tfor\\tthe\\tday.\\nFor\\tmore,\\tsee\\tCal\\tNewport,\\t\\nDeep\\tWork\\t\\n(Boston:\\tLittle,\\tBrown,\\t2016).\\nHe\\talways\\tstopped\\tjournaling\\tbefore\\tit\\tseemed\\tlike\\ta\\thassle\\n:\\n\\tGreg\\tMcKeown,\\t\\nEssentialism:\\tThe\\tDisciplined\\tPursuit\\tof\\tLess\\n\\t(New\\tYork:\\tCrown,\\t2014),\\t78.\\nhabit\\tshaping\\n:\\n\\tGail\\tB.\\tPeterson,\\t“A\\tDay\\tof\\tGreat\\tIllumination:\\tB.\\tF.\\tSkinner’s\\tDiscovery\\tof\\tShaping,”\\t\\nJournal\\tof\\tthe\\tExperimental\\tAnalysis\\tof\\tBehavior\\n\\t82,\\tno.\\t3\\t(2004),\\tdoi:10.1901/jeab.2004.82–317.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 220}), Document(page_content='CHAPTER\\t14\\nhe\\tremained\\tin\\this\\tstudy\\tand\\twrote\\tfuriously\\n:\\n\\tAdèle\\tHugo\\tand\\tCharles\\tE.\\tWilbour,\\t\\nVictor\\tHugo,\\tby\\ta\\tWitness\\tof\\tHis\\tLife\\n\\t(New\\tYork:\\tCarleton,\\t1864).\\nA\\tcommitment\\tdevice\\tis\\ta\\tchoice\\tyou\\tmake\\tin\\tthe\\tpresent\\n:\\n\\tGharad\\tBryan,\\tDean\\tKarlan,\\tand\\tScott\\tNelson,\\t“Commitment\\tDevices,”\\t\\nAnnual\\tReview\\tof\\tEconomics\\n\\t2,\\tno.\\t1\\t(2010),\\ndoi:10.1146/annurev.economics.102308.124324.\\noutlet\\ttimer\\tcuts\\toff\\tthe\\tpower\\tto\\tthe\\trouter\\n:\\n\\t“Nir\\tEyal:\\tAddictive\\tTech,\\tKilling\\tBad\\tHabits\\t&\\tApps\\tfor\\tLife\\tHacking—#260,”\\tinterview\\tby\\tDave\\tAsprey,\\tBulletproof,\\tNovember\\t13,\\t2015,\\nhttps://blog.bulletproof.com/nir-eyal-life-hacking-260/\\n.\\nThis\\tis\\talso\\treferred\\tto\\tas\\ta\\t“Ulysses\\tpact”\\n:\\t\\nPeter\\tUbel,\\t“The\\tUlysses\\tStrategy,”\\t\\nThe\\tNew\\tYorker\\n,\\tDecember\\t11,\\t2014,\\t\\nhttps://www.newyorker.com/business/currency/ulysses-strategy-self-control\\n.\\nPatterson’s\\tbusiness\\twent\\tfrom\\tlosing\\tmoney\\tto\\tmaking\\t$5,000\\tin\\tprofit\\n:\\n\\t“John\\tH.\\tPatterson—Ringing\\tUp\\tSuccess\\twith\\tthe\\tIncorruptible\\tCashier,”\\tDayton\\tInnovation\\tLegacy,\\nhttp://www.daytoninnovationlegacy.org/patterson.html\\n,\\taccessed\\tJune\\t8,\\t2016.\\nonetime\\tactions\\tthat\\tlead\\tto\\tbetter\\tlong-term\\thabits\\n:\\n\\tJames\\tClear\\t(@james_clear),\\t“What\\tare\\tonetime\\tactions\\tthat\\tpay\\toff\\tagain\\tand\\tagain\\tin\\tthe\\tfuture?”\\tTwitter,\\tFebruary\\t11,\\t2018,\\nhttps://twitter.com/james_clear/status/962694722702790659\\n“Civilization\\tadvances\\tby\\textending\\tthe\\tnumber\\tof\\toperations”\\n:\\n\\tAlfred\\tNorth\\tWhitehead,\\t\\nIntroduction\\tto\\tMathematics\\n\\t(Cambridge,\\tUK:\\tCambridge\\tUniversity\\tPress,\\t1911),\\t166.\\nThe\\taverage\\tperson\\tspends\\tover\\ttwo\\thours\\tper\\tday\\ton\\tsocial\\tmedia\\n:\\n\\t“GWI\\tSocial,”\\tGlobalWebIndex,\\t2017,\\tQ3,\\nhttps://cdn2.hubspot.net/hubfs/304927/Downloads/GWI%20Social%20Summary%20Q3%202017.pdf\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 221}), Document(page_content='CHAPTER\\t15\\nover\\tnine\\tmillion\\tpeople\\tcalled\\tit\\thome\\n:\\n\\t“Population\\tSize\\tand\\tGrowth\\tof\\tMajor\\tCities,\\t1998\\tCensus,”\\tPopulation\\tCensus\\tOrganization,\\nhttp://www.pbs.gov.pk/sites/default/files//tables/POPULATION%20SIZE%20AND%20GROWTH%20OF%20MAJOR%20CITIES.pdf\\n.\\nOver\\t60\\tpercent\\tof\\tKarachi’s\\tresidents\\n:\\n\\tSabiah\\tAskari,\\t\\nStudies\\ton\\tKarachi:\\tPapers\\tPresented\\tat\\tthe\\tKarachi\\tConference\\t2013\\n\\t(Newcastle\\tupon\\tTyne,\\tUK:\\tCambridge\\tScholars,\\t2015).\\nIt\\twas\\tthis\\tpublic\\thealth\\tcrisis\\tthat\\thad\\tbrought\\tStephen\\tLuby\\tto\\tPakistan\\n:\\n\\tAtul\\tGawande,\\t\\nThe\\tChecklist\\tManifesto:\\tHow\\tto\\tGet\\tThings\\tRight\\n\\t(Gurgaon,\\tIndia:\\tPenguin\\tRandom\\tHouse,\\t2014).\\n“In\\tPakistan,\\tSafeguard\\twas\\ta\\tpremium\\tsoap”\\n:\\t\\nAll\\tquotes\\tin\\tthis\\tsection\\tare\\tfrom\\tan\\temail\\tconversation\\twith\\tStephen\\tLuby\\ton\\tMay\\t28,\\t2018.\\nThe\\trate\\tof\\tdiarrhea\\tfell\\tby\\t52\\tpercent\\n:\\n\\tStephen\\tP.\\tLuby\\tet\\tal.,\\t“Effect\\tof\\tHandwashing\\ton\\tChild\\tHealth:\\tA\\tRandomised\\tControlled\\tTrial,”\\t\\nLancet\\n\\t366,\\tno.\\t9481\\t(2005),\\tdoi:10.1016/s0140–\\n6736(05)66912–7.\\n“Over\\t95\\tpercent\\tof\\thouseholds”\\n:\\n\\tAnna\\tBowen,\\tMubina\\tAgboatwalla,\\tTracy\\tAyers,\\tTimothy\\tTobery,\\tMaria\\tTariq,\\tand\\tStephen\\tP.\\tLuby.\\t“Sustained\\timprovements\\tin\\thandwashing\\tindicators\\tmore\\tthan\\n5\\tyears\\tafter\\ta\\tcluster-randomised,\\tcommunity-based\\ttrial\\tof\\thandwashing\\tpromotion\\tin\\tKarachi,\\tPakistan,”\\t\\nTropical\\tMedicine\\t&\\tInternational\\tHealth\\n\\t18,\\tno.\\t3\\t(2013):\\t259–267.\\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC4626884/\\nChewing\\tgum\\thad\\tbeen\\tsold\\tcommercially\\tthroughout\\tthe\\t1800s\\n:\\n\\tMary\\tBellis,\\t“How\\tWe\\tHave\\tBubble\\tGum\\tToday,”\\tThoughtCo,\\tOctober\\t16,\\t2017,\\t\\nhttps://www.thoughtco.com/history-of-bubble-\\nand-chewing-gum-1991856\\n.\\nWrigley\\trevolutionized\\tthe\\tindustry\\n:\\n\\tJennifer\\tP.\\tMathews,\\t\\nChicle:\\tThe\\tChewing\\tGum\\tof\\tthe\\tAmericas,\\tfrom\\tthe\\tAncient\\tMaya\\tto\\tWilliam\\tWrigley\\n\\t(Tucson:\\tUniversity\\tof\\tArizona\\tPress,\\t2009),\\t44–46.\\nWrigley\\tbecame\\tthe\\tlargest\\tchewing\\tgum\\tcompany\\n:\\n\\t“William\\tWrigley,\\tJr.,”\\t\\nEncyclopædia\\tBritannica\\n,\\t\\nhttps://www.britannica.com/biography/William-Wrigley-Jr\\n,\\taccessed\\tJune\\t8,\\t2018.\\nToothpaste\\thad\\ta\\tsimilar\\ttrajectory\\n:\\n\\tCharles\\tDuhigg,\\t\\nThe\\tPower\\tof\\tHabit:\\tWhy\\tWe\\tDo\\tWhat\\tWe\\tDo\\tin\\tLife\\tand\\tBusiness\\t\\n(New\\tYork:\\tRandom\\tHouse,\\t2014),\\tchap.\\t2.\\nhe\\n\\tstarted\\tavoiding\\t\\nher\\n:\\n\\tSparkly_alpaca,\\t“What\\tAre\\tthe\\tCoolest\\tPsychology\\tTricks\\tThat\\tYou\\tKnow\\tor\\tHave\\tUsed?”\\tReddit,\\tNovember\\t11,\\t2016,\\nhttps://www.reddit.com/r/AskReddit/comments/5cgqbj/what_are_the_coolest_psychology_tricks_that_you/d9wcqsr/\\n.\\nThe\\tearliest\\tremains\\tof\\tmodern\\thumans\\n:\\t\\nIan\\tMcdougall,\\tFrancis\\tH.\\tBrown,\\tand\\tJohn\\tG.\\tFleagle,\\t“Stratigraphic\\tPlacement\\tand\\tAge\\tof\\tModern\\tHumans\\tfrom\\tKibish,\\tEthiopia,”\\t\\nNature\\n\\t433,\\tno.\\t7027\\n(2005),\\tdoi:10.1038/nature03258.\\nthe\\tneocortex\\t.\\t.\\t.\\twas\\troughly\\tthe\\tsame\\n:\\n\\tSome\\tresearch\\tindicates\\tthat\\tthe\\tsize\\tof\\tthe\\thuman\\tbrain\\treached\\tmodern\\tproportions\\taround\\tthree\\thundred\\tthousand\\tyears\\tago.\\tEvolution\\tnever\\tstops,\\tof\\ncourse,\\tand\\tthe\\tshape\\tof\\tthe\\tstructure\\tappears\\tto\\thave\\tcontinued\\tto\\tevolve\\tin\\tmeaningful\\tways\\tuntil\\tit\\treached\\tboth\\tmodern\\tsize\\tand\\tshape\\tsometime\\tbetween\\tone\\thundred\\tthousand\\tand\\nthirty-five\\tthousand\\tyears\\tago.\\tSimon\\tNeubauer,\\tJean-Jacques\\tHublin,\\tand\\tPhilipp\\tGunz,\\t“The\\tEvolution\\tof\\tModern\\tHuman\\tBrain\\tShape,”\\t\\nScience\\tAdvances\\n\\t4,\\tno.\\t1\\t(2018):\\teaao5961.\\nsociety\\thas\\tshifted\\tto\\ta\\tpredominantly\\tdelayed-return\\tenvironment\\n:\\n\\tThe\\toriginal\\tresearch\\ton\\tthis\\ttopic\\tused\\tthe\\tterms\\t\\ndelayed-return\\tsocieties\\n\\tand\\t\\nimmediate-return\\tsocieties\\n.\\tJames\\tWoodburn,\\n“Egalitarian\\tSocieties,”\\t\\nMan\\n\\t17,\\tno.\\t3\\t(1982),\\tdoi:10.2307/2801707.\\tI\\tfirst\\theard\\tof\\tthe\\tdifference\\tbetween\\timmediate-return\\tenvironments\\tand\\tdelayed-return\\tenvironments\\tin\\ta\\tlecture\\nfrom\\tMark\\tLeary.\\tMark\\tLeary,\\t\\nUnderstanding\\tthe\\tMysteries\\tof\\tHuman\\tBehavior\\n\\t(Chantilly,\\tVA:\\tTeaching,\\t2012).\\nThe\\tworld\\thas\\tchanged\\tmuch\\tin\\trecent\\tyears\\n:\\n\\tThe\\trapid\\tenvironmental\\tchanges\\tof\\trecent\\tcenturies\\thave\\tfar\\toutpaced\\tour\\tbiological\\tability\\tto\\tadapt.\\tOn\\taverage,\\tit\\ttakes\\tabout\\ttwenty-five\\tthousand\\nyears\\tfor\\tmeaningful\\tgenetic\\tchanges\\tto\\tbe\\tselected\\tfor\\tin\\ta\\thuman\\tpopulation.\\tFor\\tmore,\\tsee\\tEdward\\tO.\\tWilson,\\t\\nSociobiology\\n\\t(Cambridge,\\tMA:\\tBelknap\\tPress,\\t1980),\\t151.\\nour\\tbrains\\tevolved\\tto\\tprefer\\tquick\\tpayoffs\\tto\\tlong-term\\tones\\n:\\n\\tDaniel\\tGilbert,\\t“Humans\\tWired\\tto\\tRespond\\tto\\tShort-Term\\tProblems,”\\tinterview\\tby\\tNeal\\tConan,\\t\\nTalk\\tof\\tthe\\tNation\\n,\\tNPR,\\tJuly\\t3,\\t2006,\\nhttps://www.npr.org/templates/story/story.php?storyId=5530483\\n.\\nDisease\\tand\\tinfection\\twon’t\\tshow\\tup\\tfor\\tdays\\tor\\tweeks,\\teven\\tyears\\n:\\n\\tThe\\ttopics\\tof\\tirrational\\tbehavior\\tand\\tcognitive\\tbiases\\thave\\tbecome\\tquite\\tpopular\\tin\\trecent\\tyears.\\tHowever,\\tmany\\tactions\\tthat\\t\\nseem\\nirrational\\ton\\tthe\\twhole\\thave\\trational\\torigins\\tif\\tyou\\tconsider\\ttheir\\timmediate\\toutcome.\\nFrédéric\\tBastiat\\n:\\n\\tFrédéric\\tBastiat\\tand\\tW.\\tB.\\tHodgson,\\t\\nWhat\\tIs\\tSeen\\tand\\tWhat\\tIs\\tNot\\tSeen:\\tOr\\tPolitical\\tEconomy\\tin\\tOne\\tLesson\\t\\n(London:\\tSmith,\\t1859).\\nFuture\\tYou\\n:\\t\\nHat\\ttip\\tto\\tbehavioral\\teconomist\\tDaniel\\tGoldstein,\\twho\\tsaid,\\t“It’s\\tan\\tunequal\\tbattle\\tbetween\\tthe\\tpresent\\tself\\tand\\tthe\\tfuture\\tself.\\tI\\tmean,\\tlet’s\\tface\\tit,\\tthe\\tpresent\\tself\\tis\\tpresent.\\tIt’s\\tin\\tcontrol.\\nIt’s\\tin\\tpower\\tright\\tnow.\\tIt\\thas\\tthese\\tstrong,\\theroic\\tarms\\tthat\\tcan\\tlift\\tdoughnuts\\tinto\\tyour\\tmouth.\\tAnd\\tthe\\tfuture\\tself\\tis\\tnot\\teven\\taround.\\tIt’s\\toff\\tin\\tthe\\tfuture.\\tIt’s\\tweak.\\tIt\\tdoesn’t\\teven\\thave\\na\\tlawyer\\tpresent.\\tThere’s\\tnobody\\tto\\tstick\\tup\\tfor\\tthe\\tfuture\\tself.\\tAnd\\tso\\tthe\\tpresent\\tself\\tcan\\ttrounce\\tall\\tover\\tits\\tdreams.”\\tFor\\tmore,\\tsee\\tDaniel\\tGoldstein,\\t“The\\tBattle\\tbetween\\tYour\\tPresent\\nand\\tFuture\\tSelf,”\\tTEDSalon\\tNY2011,\\tNovember\\t2011,\\tvideo,\\t\\nhttps://www.ted.com/talks/daniel_goldstein_the_battle_between_your_present_and_future_self\\n.\\nPeople\\twho\\tare\\tbetter\\tat\\tdelaying\\tgratification\\thave\\thigher\\tSAT\\tscores\\n:\\n\\tWalter\\tMischel,\\tEbbe\\tB.\\tEbbesen,\\tand\\tAntonette\\tRaskoff\\tZeiss,\\t“Cognitive\\tand\\tAttentional\\tMechanisms\\tin\\tDelay\\tof\\nGratification,”\\t\\nJournal\\tof\\tPersonality\\tand\\tSocial\\tPsychology\\n\\t21,\\tno.\\t2\\t(1972),\\tdoi:10.1037/h0032198;\\tW.\\tMischel,\\tY.\\tShoda,\\tand\\tM.\\tRodriguez,\\t“Delay\\tof\\tGratification\\tin\\tChildren,”\\nScience\\n\\t244,\\tno.\\t4907\\t(1989),\\tdoi:10.1126/science.2658056;\\tWalter\\tMischel,\\tYuichi\\tShoda,\\tand\\tPhilip\\tK.\\tPeake,\\t“The\\tNature\\tof\\tAdolescent\\tCompetencies\\tPredicted\\tby\\tPreschool\\tDelay\\nof\\tGratification,”\\t\\nJournal\\tof\\tPersonality\\tand\\tSocial\\tPsychology\\n\\t54,\\tno.\\t4\\t(1988),\\tdoi:10.1037//0022–3514.54.4.687;\\tYuichi\\tShoda,\\tWalter\\tMischel,\\tand\\tPhilip\\tK.\\tPeake,\\t“Predicting\\nAdolescent\\tCognitive\\tand\\tSelf-Regulatory\\tCompetencies\\tfrom\\tPreschool\\tDelay\\tof\\tGratification:\\tIdentifying\\tDiagnostic\\tConditions,”\\t\\nDevelopmental\\tPsychology\\n\\t26,\\tno.\\t6\\t(1990),\\ndoi:10.1037//0012–1649.26.6.978.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 222}), Document(page_content='CHAPTER\\t16\\n“I\\twould\\tstart\\twith\\t120\\tpaper\\tclips\\tin\\tone\\tjar”\\n:\\n\\tTrent\\tDyrsmid,\\temail\\tto\\tauthor,\\tApril\\t1,\\t2015.\\nBenjamin\\tFranklin\\n:\\n\\tBenjamin\\tFranklin\\tand\\tFrank\\tWoodworth\\tPine,\\t\\nAutobiography\\tof\\tBenjamin\\tFranklin\\n\\t(New\\tYork:\\tHolt,\\t1916),\\t148.\\nDon’t\\tbreak\\tthe\\tchain\\tof\\tcreating\\tevery\\tday\\n:\\n\\tShoutout\\tto\\tmy\\tfriend\\tNathan\\tBarry,\\twho\\toriginally\\tinspired\\tme\\twith\\tthe\\tmantra,\\t“Create\\tEvery\\tDay.”\\npeople\\twho\\ttrack\\ttheir\\tprogress\\ton\\tgoals\\tlike\\tlosing\\tweight\\n:\\n\\tBenjamin\\tHarkin\\tet\\tal.,\\t“Does\\tMonitoring\\tGoal\\tProgress\\tPromote\\tGoal\\tAttainment?\\tA\\tMeta-analysis\\tof\\tthe\\tExperimental\\tEvidence,”\\nPsychological\\tBulletin\\n\\t142,\\tno.\\t2\\t(2016),\\tdoi:10.1037/bul0000025.\\nthose\\twho\\tkept\\ta\\tdaily\\tfood\\tlog\\tlost\\ttwice\\tas\\tmuch\\tweight\\tas\\tthose\\twho\\tdid\\tnot\\n:\\n\\tMiranda\\tHitti,\\t“Keeping\\tFood\\tDiary\\tHelps\\tLose\\tWeight,”\\tWebMD,\\tJuly\\t8,\\t2008,\\nhttp://www.webmd.com/diet/news/20080708/keeping-food-diary-helps-lose-weight\\n;\\tKaiser\\tPermanente,\\t“Keeping\\ta\\tFood\\tDiary\\tDoubles\\tDiet\\tWeight\\tLoss,\\tStudy\\tSuggests,”\\tScience\\nDaily,\\tJuly\\t8,\\t2008,\\t\\nhttps://www.sciencedaily.com/releases/2008/07/080708080738.htm\\n;\\tJack\\tF.\\tHollis\\tet\\tal.,\\t“Weight\\tLoss\\tduring\\tthe\\tIntensive\\tIntervention\\tPhase\\tof\\tthe\\tWeight-Loss\\nMaintenance\\tTrial,”\\t\\nAmerican\\tJournal\\tof\\tPreventive\\tMedicine\\n\\t35,\\tno.\\t2\\t(2008),\\tdoi:10.1016/j.amepre.2008.04.013;\\tLora\\tE.\\tBurke,\\tJing\\tWang,\\tand\\tMary\\tAnn\\tSevick,\\t“Self-Monitoring\\tin\\nWeight\\tLoss:\\tA\\tSystematic\\tReview\\tof\\tthe\\tLiterature,”\\t\\nJournal\\tof\\tthe\\tAmerican\\tDietetic\\tAssociation\\n\\t111,\\tno.\\t1\\t(2011),\\tdoi:10.1016/j.jada.2010.10.008.\\nThe\\tmost\\teffective\\tform\\tof\\tmotivation\\tis\\tprogress\\n:\\t\\nThis\\tline\\tis\\tparaphrased\\tfrom\\tGreg\\tMcKeown,\\twho\\twrote,\\t“Research\\thas\\tshown\\tthat\\tof\\tall\\tforms\\tof\\thuman\\tmotivation\\tthe\\tmost\\teffective\\tone\\tis\\nprogress.”\\tGreg\\tMcKeown,\\t\\nEssentialism:\\tThe\\tDisciplined\\tPursuit\\tof\\tLess\\n\\t(Currency,\\t2014).\\nThe\\tfirst\\tmistake\\tis\\tnever\\tthe\\tone\\tthat\\truins\\tyou\\n:\\n\\tIn\\tfact,\\tresearch\\thas\\tshown\\tthat\\tmissing\\ta\\thabit\\tonce\\thas\\tvirtually\\tno\\timpact\\ton\\tthe\\todds\\tof\\tdeveloping\\ta\\thabit\\tover\\tthe\\tlong-term,\\tregardless\\tof\\twhen\\nthe\\tmistake\\toccurs.\\tAs\\tlong\\tas\\tyou\\tget\\tback\\ton\\ttrack,\\tyou’re\\tfine.\\tSee:\\tPhillippa\\tLally\\tet\\tal.,\\t“How\\tAre\\tHabits\\tFormed:\\tModelling\\tHabit\\tFormation\\tin\\tthe\\tReal\\tWorld,”\\t\\nEuropean\\tJournal\\nof\\tSocial\\tPsychology\\n\\t40,\\tno.\\t6\\t(2009),\\tdoi:10.1002/ejsp.674.\\nMissing\\tonce\\tis\\tan\\taccident\\n:\\n\\t“Missing\\tonce\\tis\\tan\\taccident.\\tMissing\\ttwice\\tis\\tthe\\tstart\\tof\\ta\\tnew\\thabit.”\\tI\\tswear\\tI\\tread\\tthis\\tline\\tsomewhere\\tor\\tperhaps\\tparaphrased\\tit\\tfrom\\tsomething\\tsimilar,\\tbut\\tdespite\\tmy\\nbest\\tefforts\\tall\\tof\\tmy\\tsearches\\tfor\\ta\\tsource\\tare\\tcoming\\tup\\tempty.\\tMaybe\\tI\\tcame\\tup\\twith\\tit,\\tbut\\tmy\\tbest\\tguess\\tis\\tit\\tbelongs\\tto\\tan\\tunidentified\\tgenius\\tinstead.\\n“When\\ta\\tmeasure\\tbecomes\\ta\\ttarget”\\n:\\n\\tThis\\tdefinition\\tof\\tGoodhart’s\\tLaw\\twas\\tactually\\tformulated\\tby\\tthe\\tBritish\\tanthropologist\\tMarilyn\\tStrathern.\\t“‘Improving\\tRatings’:\\tAudit\\tin\\tthe\\tBritish\\tUniversity\\nSystem,”\\t\\nEuropean\\t Review\\n\\t5\\t(1997):\\t305–321,\\t\\nhttps://www.cambridge.org/core/journals/european-review/article/improving-ratings-audit-in-the-british-university-\\nsystem/FC2EE640C0C44E3DB87C29FB666E9AAB\\n.\\tGoodhart\\thimself\\treportedly\\tadvanced\\tthe\\tidea\\tsometime\\taround\\t1975\\tand\\tput\\tit\\tformally\\tinto\\twriting\\tin\\t1981.\\tCharles\\tGoodhart,\\n“Problems\\tof\\tMonetary\\tManagement:\\tThe\\tU.K.\\tExperience,”\\tin\\tAnthony\\tS.\\tCourakis\\t(ed.),\\t\\nInflation,\\tDepression,\\tand\\tEconomic\\tPolicy\\tin\\tthe\\tWest\\n\\t(London:\\tRowman\\tand\\tLittlefield,\\n1981),\\t111–146.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 223}), Document(page_content='CHAPTER\\t17\\n“When\\tI\\tsuggested\\tthis\\tto\\tfriends\\tin\\tthe\\tPentagon”\\n:\\n\\tRoger\\tFisher,\\t“Preventing\\tNuclear\\tWar,”\\t\\nBulletin\\tof\\tthe\\tAtomic\\tScientists\\n\\t37,\\tno.\\t3\\t(1981),\\tdoi:10.1080/00963402.1981.11458828.\\nThe\\tfirst\\tseat\\tbelt\\tlaw\\n:\\n\\tMichael\\tGoryl\\tand\\tMichael\\tCynecki,\\t“Restraint\\tSystem\\tUsage\\tin\\tthe\\tTraffic\\tPopulation,”\\t\\nJournal\\tof\\tSafety\\tResearch\\n\\t17,\\tno.\\t2\\t(1986),\\tdoi:10.1016/0022–4375(86)90107–6.\\nwearing\\ta\\tseat\\tbelt\\tis\\tenforceable\\tby\\tlaw\\n:\\n\\tNew\\tHampshire\\tis\\tthe\\tlone\\texception,\\twhere\\tseat\\tbelts\\tare\\tonly\\trequired\\tfor\\tchildren.\\t“New\\tHampshire,”\\tGovernors\\tHighway\\tSafety\\tAssociation,\\nhttps://www.ghsa.org/state-laws/states/new%20hampshire\\n,\\taccessed\\tJune\\t8,\\t2016.\\nover\\t88\\tpercent\\tof\\tAmericans\\tbuckled\\tup\\n:\\n\\t“Seat\\tBelt\\tUse\\tin\\tU.S.\\tReaches\\tHistoric\\t90\\tPercent,”\\tNational\\tHighway\\tTraffic\\tSafety\\tAdministration,\\tNovember\\t21,\\t2016,\\t\\nhttps://www.nhtsa.gov/press-\\nreleases/seat-belt-use-us-reaches-historic-90-percent\\n.\\nBryan\\tHarris\\n:\\n\\tBryan\\tHarris,\\temail\\tconversation\\twith\\tauthor,\\tOctober\\t24,\\t2017.\\nShe\\tdoes\\tthe\\t“song\\ta\\tday”\\tchallenge\\n:\\n\\tCourtney\\tShea,\\t“Comedian\\tMargaret\\tCho’s\\tTips\\tfor\\tSuccess:\\tIf\\tYou’re\\tFunny,\\tDon’t\\tDo\\tComedy,”\\t\\nGlobe\\tand\\tMail\\n,\\tJuly\\t1,\\t2013,\\nhttps://www.theglobeandmail.com/life/comedian-margaret-chos-tips-for-success-if-youre-funny-dont-do-comedy/article12902304/?service=mobile\\n.\\nThomas\\tFrank,\\tan\\tentrepreneur\\tin\\tBoulder,\\tColorado\\n:\\n\\tThomas\\tFrank,\\t“How\\tBuffer\\tForces\\tMe\\tto\\tWake\\tUp\\tat\\t5:55\\tAM\\tEvery\\tDay,”\\tCollege\\tInfo\\tGeek,\\tJuly\\t2,\\t2014,\\nhttps://collegeinfogeek.com/early-waking-with-buffer/\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 224}), Document(page_content='CHAPTER\\t18\\nPhelps\\thas\\twon\\tmore\\tOlympic\\tmedals\\n:\\n\\t“Michael\\tPhelps\\tBiography,”\\tBiography,\\t\\nhttps://www.biography.com/people/michael-phelps-345192\\n,\\tlast\\tmodified\\tMarch\\t29,\\t2018.\\nEl\\tGuerrouj\\n:\\n\\tDoug\\tGillan,\\t“El\\tGuerrouj:\\tThe\\tGreatest\\tof\\tAll\\tTime,”\\tIAFF,\\tNovember\\t15,\\t2004,\\t\\nhttps://www.iaaf.org/news/news/el-guerrouj-the-greatest-of-all-time\\n.\\nthey\\tdiffer\\tsignificantly\\tin\\theight\\n:\\n\\tHeights\\tand\\tweights\\tfor\\tMichael\\tPhelps\\tand\\tHicham\\tEl\\tGuerrouj\\twere\\tpulled\\tfrom\\ttheir\\tathlete\\tprofiles\\tduring\\tthe\\t2008\\tSummer\\tOlympics.\\t“Michael\\tPhelps,”\\tESPN,\\n2008,\\t\\nhttp://www.espn.com/olympics/summer08/fanguide/athlete?athlete=29547l\\n;\\t“Hicham\\tEl\\tGuerrouj,”\\tESPN,\\t2008,\\t\\nhttp://www.espn.com/oly/summer08/fanguide/athlete?\\nathlete=29886\\n.\\nsame\\tlength\\tinseam\\ton\\ttheir\\tpants\\n:\\n\\tDavid\\tEpstein,\\t\\nThe\\tSports\\tGene:\\tInside\\tthe\\tScience\\tof\\tExtraordinary\\tAthletic\\tPerformance\\n\\t(St.\\tLouis,\\tMO:\\tTurtleback\\tBooks,\\t2014).\\naverage\\theight\\tof\\tOlympic\\tgold\\tmedalists\\tin\\tthe\\tmen’s\\t1,500-meter\\trun\\n:\\n\\tAlex\\tHutchinson,\\t“The\\tIncredible\\tShrinking\\tMarathoner,”\\t\\nRunner’s\\tWorld\\n,\\tNovember\\t12,\\t2013,\\nhttps://www.runnersworld.com/sweat-science/the-incredible-shrinking-marathoner\\n.\\naverage\\theight\\tof\\tOlympic\\tgold\\tmedalists\\tin\\tthe\\tmen’s\\t100-meter\\n:\\n\\tAlvin\\tChang,\\t“Want\\tto\\tWin\\tOlympic\\tGold?\\tHere’s\\tHow\\tTall\\tYou\\tShould\\tBe\\tfor\\tArchery,\\tSwimming,\\tand\\tMore,”\\t\\nVox\\n,\\tAugust\\t9,\\n2016,\\t\\nhttp://www.vox.com/2016/8/9/12387684/olympic-heights\\n.\\n“Genes\\tcan\\tpredispose,\\tbut\\tthey\\tdon’t\\tpredetermine”\\n:\\n\\tGabor\\tMaté,\\t“Dr.\\tGabor\\tMaté—New\\tParadigms,\\tAyahuasca,\\tand\\tRedefining\\tAddiction,”\\t\\nThe\\tTim\\tFerriss\\tShow\\n,\\tFebruary\\t20,\\t2018,\\nhttps://tim.blog/2018/02/20/gabor-mate/\\n.\\nGenes\\thave\\tbeen\\tshown\\tto\\tinfluence\\teverything\\n:\\n\\t“All\\ttraits\\tare\\theritable”\\tis\\ta\\tbit\\tof\\tan\\texaggeration,\\tbut\\tnot\\tby\\tmuch.\\tConcrete\\tbehavioral\\ttraits\\tthat\\tpatently\\tdepend\\ton\\tcontent\\tprovided\\tby\\tthe\\thome\\nor\\tculture\\tare,\\tof\\tcourse,\\tnot\\theritable\\tat\\tall;\\twhich\\tlanguage\\tyou\\tspeak,\\twhich\\treligion\\tyou\\tworship\\tin,\\twhich\\tpolitical\\tparty\\tyou\\tbelong\\tto.\\tBut\\tbehavioral\\ttraits\\tthat\\treflect\\tthe\\tunderlying\\ntalents\\tand\\ttemperaments\\tare\\theritable:\\thow\\tproficient\\twith\\tlanguage\\tyou\\tare,\\thow\\treligious,\\thow\\tliberal\\tor\\tconservative.\\tGeneral\\tintelligence\\tis\\theritable,\\tand\\tso\\tare\\tthe\\tfive\\tmajor\\tways\\tin\\nwhich\\tpersonality\\tcan\\tvary\\t.\\t.\\t.\\topenness\\tto\\texperience,\\tconscientiousness,\\textroversion-introversion,\\tantagonism-agreeableness,\\tand\\tneuroticism.\\tAnd\\ttraits\\tthat\\tare\\tsurprisingly\\tspecific\\nturn\\tout\\tto\\tbe\\theritable,\\ttoo,\\tsuch\\tas\\tdependence\\ton\\tnicotine\\tor\\talcohol,\\tnumber\\tof\\thours\\tof\\ttelevision\\twatched,\\tand\\tlikelihood\\tof\\tdivorcing.\\tThomas\\tJ.\\tBouchard,\\t“Genetic\\tInfluence\\ton\\nHuman\\tPsychological\\tTraits,”\\t\\nCurrent\\tDirections\\tin\\tPsychological\\tScience\\n\\t13,\\tno.\\t4\\t(2004),\\tdoi:10.1111/j.0963–7214.2004.00295.x;\\tRobert\\tPlomin,\\t\\nNature\\tand\\tNurture:\\tAn\\tIntroduction\\nto\\tHuman\\tBehavioral\\tGenetics\\n\\t(Stamford,\\tCT:\\tWadsworth,\\t1996);\\tRobert\\tPlomin,\\t“Why\\tWe’re\\tDifferent,”\\tEdge,\\tJune\\t29,\\t2016,\\t\\nhttps://soundcloud.com/edgefoundationinc/edge2016-\\nrobert-plomin\\n.\\nThere’s\\ta\\tstrong\\tgenetic\\tcomponent\\n:\\n\\tDaniel\\tGoleman,\\t“Major\\tPersonality\\tStudy\\tFinds\\tThat\\tTraits\\tAre\\tMostly\\tInherited,”\\t\\nNew\\tYork\\tTimes\\n,\\tDecember\\t2,\\t1986,\\nhttp://www.nytimes.com/1986/12/02/science/major-personality-study-finds-that-traits-are-mostly-inherited.html?pagewanted=all\\n.\\nRobert\\tPlomin\\n:\\n\\tRobert\\tPlomin,\\tphone\\tcall\\twith\\tthe\\tauthor,\\tAugust\\t9,\\t2016.\\nmore\\tlikely\\tto\\tbecome\\tintroverts\\n:\\n\\tJerome\\tKagan\\tet\\tal.,\\t“Reactivity\\tin\\tInfants:\\tA\\tCross-National\\tComparison,”\\t\\nDevelopmental\\tPsychology\\n\\t30,\\tno.\\t3\\t(1994),\\tdoi:10.1037//0012–1649.30.3.342;\\tMichael\\nV.\\tEllis\\tand\\tErica\\tS.\\tRobbins,\\t“In\\tCelebration\\tof\\tNature:\\tA\\tDialogue\\twith\\tJerome\\tKagan,”\\t\\nJournal\\tof\\tCounseling\\tand\\tDevelopment\\n\\t68,\\tno.\\t6\\t(1990),\\tdoi:10.1002/j.1556–\\n6676.1990.tb01426.x;\\tBrian\\tR.\\tLittle,\\t\\nMe,\\tMyself,\\tand\\tUs:\\tThe\\tScience\\tof\\tPersonality\\tand\\tthe\\tArt\\tof\\tWell-Being\\n\\t(New\\tYork:\\tPublic\\tAffairs,\\t2016);\\tSusan\\tCain,\\t\\nQuiet:\\tThe\\tPower\\tof\\nIntroverts\\tin\\ta\\tWorld\\tThat\\tCan’t\\tStop\\tTalking\\n\\t(London:\\tPenguin,\\t2013),\\t99–100.\\nPeople\\twho\\tare\\thigh\\tin\\tagreeableness\\n:\\n\\tW.\\tG.\\tGraziano\\tand\\tR.\\tM.\\tTobin,\\t“The\\tCognitive\\tand\\tMotivational\\tFoundations\\tUnderlying\\tAgreeableness,”\\tin\\tM.\\tD.\\tRobinson,\\tE.\\tWatkins,\\tand\\tE.\\tHarmon-\\nJones,\\teds.,\\t\\nHandbook\\tof\\tCognition\\tand\\tEmotion\\n\\t(New\\tYork:\\tGuilford,\\t2013),\\t347–364.\\nThey\\talso\\ttend\\tto\\thave\\thigher\\tnatural\\toxytocin\\tlevels\\n:\\n\\tMitsuhiro\\tMatsuzaki\\tet\\tal.,\\t“Oxytocin:\\tA\\tTherapeutic\\tTarget\\tfor\\tMental\\tDisorders,”\\t\\nJournal\\tof\\tPhysiological\\tSciences\\n\\t62,\\tno.\\t6\\t(2012),\\ndoi:10.1007/s12576–012–0232–9;\\tAngeliki\\tTheodoridou\\tet\\tal.,\\t“Oxytocin\\tand\\tSocial\\tPerception:\\tOxytocin\\tIncreases\\tPerceived\\tFacial\\tTrustworthiness\\tand\\tAttractiveness,”\\t\\nHormones\\tand\\nBehavior\\n\\t56,\\tno.\\t1\\t(2009),\\tdoi:10.1016/j.yhbeh.2009.03.019;\\tAnthony\\tLane\\tet\\tal.,\\t“Oxytocin\\tIncreases\\tWillingness\\tto\\tSocially\\tShare\\tOne’s\\tEmotions,”\\t\\nInternational\\tJournal\\tof\\nPsychology\\n\\t48,\\tno.\\t4\\t(2013),\\tdoi:10.1080/00207594.2012.677540;\\tChristopher\\tCardoso\\tet\\tal.,\\t“Stress-Induced\\tNegative\\tMood\\tModerates\\tthe\\tRelation\\tbetween\\tOxytocin\\tAdministration\\nand\\tTrust:\\tEvidence\\tfor\\tthe\\tTend-and-Befriend\\tResponse\\tto\\tStress?”\\t\\nPsychoneuroendocrinology\\n\\t38,\\tno.\\t11\\t(2013),\\tdoi:10.1016/j.psyneuen.2013.05.006.\\nhypersensitivity\\tof\\tthe\\tamygdala\\n:\\n\\tJ.\\tOrmel,\\tA.\\tBastiaansen,\\tH.\\tRiese,\\tE.\\tH.\\tBos,\\tM.\\tServaas,\\tM.\\tEllenbogen,\\tJ.\\tG.\\tRosmalen,\\tand\\tA.\\tAleman,\\t“The\\tBiological\\tand\\tPsychological\\tBasis\\tof\\tNeuroticism:\\nCurrent\\tStatus\\tand\\tFuture\\tDirections,”\\t\\nNeuroscience\\tand\\tBiobehavioral\\tReviews\\n\\t37,\\tno.\\t1\\t(2013),\\tdoi:10.1016/j.neu\\tbiorev.2012.09.004.\\tPMID\\t23068306;\\tR.\\tA.\\tDepue\\tand\\tY.\\tFu,\\n“Neurogenetic\\tand\\tExperiential\\tProcesses\\tUnderlying\\tMajor\\tPersonality\\tTraits:\\tImplications\\tfor\\tModelling\\tPersonality\\tDisorders,”\\t\\nInternational\\tReview\\tof\\tPsychiatry\\n\\t23,\\tno.\\t3\\t(2011),\\ndoi:10.3109/09540261.2011.599315.\\nOur\\tdeeply\\trooted\\tpreferences\\tmake\\tcertain\\tbehaviors\\teasier\\n:\\n\\t“For\\texample,\\tall\\tpeople\\thave\\tbrain\\tsystems\\tthat\\trespond\\tto\\trewards,\\tbut\\tin\\tdifferent\\tindividuals\\tthese\\tsystems\\twill\\trespond\\twith\\ndifferent\\tdegrees\\tof\\tvigor\\tto\\ta\\tparticular\\treward,\\tand\\tthe\\tsystems’\\taverage\\tlevel\\tof\\tresponse\\tmay\\tbe\\tassociated\\twith\\tsome\\tpersonality\\ttrait.”\\tFor\\tmore,\\tsee\\tColin\\tG.\\tDeyoung,\\t“Personality\\nNeuroscience\\tand\\tthe\\tBiology\\tof\\tTraits,”\\t\\nSocial\\tand\\tPersonality\\tPsychology\\tCompass\\n\\t4,\\tno.\\t12\\t(2010),\\tdoi:10.1111/j.1751–9004.2010.00327.x.\\nIf\\tyour\\tfriend\\tfollows\\ta\\tlow-carb\\tdiet\\n:\\n\\tResearch\\tconducted\\tin\\tmajor\\trandomized\\tclinical\\ttrials\\tshows\\tno\\tdifference\\tin\\tlow-carb\\tversus\\tlow-fat\\tdiets\\tfor\\tweight\\tloss.\\tAs\\twith\\tmany\\thabits,\\tthere\\tare\\tmany\\nways\\tto\\tthe\\tsame\\tdestination\\tif\\tyou\\tstick\\twith\\tit.\\tFor\\tmore,\\tsee\\tChristopher\\tD.\\tGardner\\tet\\tal.,\\t“Effect\\tof\\tLow-Fat\\tvs\\tLow-Carbohydrate\\tDiet\\ton\\t12-Month\\tWeight\\tLoss\\tin\\tOverweight\\nAdults\\tand\\tthe\\tAssociation\\twith\\tGenotype\\tPattern\\tor\\tInsulin\\tSecretion,”\\t\\nJournal\\tof\\tthe\\tAmerican\\tMedical\\tAssociation\\n\\t319,\\tno.\\t7\\t(2018),\\tdoi:10.1001/jama.2018.0245.\\nexplore/exploit\\ttrade-off\\n:\\n\\tM.\\tA.\\tAddicott\\tet\\tal.,\\t“A\\tPrimer\\ton\\tForaging\\tand\\tthe\\tExplore/Exploit\\tTrade-Off\\tfor\\tPsychiatry\\tResearch,”\\t\\nNeuropsychopharmacology\\n\\t42,\\tno.\\t10\\t(2017),\\ndoi:10.1038/npp.2017.108.\\nGoogle\\tfamously\\tasks\\temployees\\n:\\n\\tBharat\\tMediratta\\tand\\tJulie\\tBick,\\t“The\\tGoogle\\tWay:\\tGive\\tEngineers\\tRoom,”\\t\\nNew\\tYork\\tTimes\\n,\\tOctober\\t21,\\t2007,\\nhttps://www.nytimes.com/2007/10/21/jobs/21pre.html\\n.\\n“Flow\\tis\\tthe\\tmental\\tstate”\\n:\\n\\tMihaly\\tCsikszentmihalyi,\\t\\nFinding\\tFlow:\\tThe\\tPsychology\\tof\\tEngagement\\twith\\tEveryday\\tLife\\n\\t(New\\tYork:\\tBasic\\tBooks,\\t2008).\\n“Everyone\\thas\\tat\\tleast\\ta\\tfew\\tareas”\\n:\\n\\tScott\\tAdams,\\t“Career\\tAdvice,”\\tDilbert\\tBlog,\\tJuly\\t20,\\t2007,\\t\\nhttp://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 225}), Document(page_content='CHAPTER\\t19\\nmost\\tsuccessful\\tcomedians\\n:\\n\\tSteve\\tMartin,\\t\\nBorn\\tStanding\\tUp:\\tA\\tComic’s\\tLife\\n\\t(Leicester,\\tUK:\\tCharnwood,\\t2008).\\n“4\\tyears\\tas\\ta\\twild\\tsuccess”\\n:\\n\\tSteve\\tMartin,\\t\\nBorn\\tStanding\\tUp:\\tA\\tComic’s\\tLife\\n\\t(Leicester,\\tUK:\\tCharnwood,\\t2008),\\t1.\\n“just\\tmanageable\\tdifficulty”\\n:\\n\\tNicholas\\tHobbs,\\t“The\\tPsychologist\\tas\\tAdministrator,”\\t\\nJournal\\tof\\tClinical\\tPsychology\\n\\t15,\\tno.\\t3\\t(1959),\\tdoi:10.1002/1097–4679(195907)15:33.0.co;\\t2–4;\\tGilbert\\tBrim,\\nAmbition:\\tHow\\tWe\\tManage\\tSuccess\\tand\\tFailure\\tThroughout\\tOur\\tLives\\n\\t(Lincoln,\\tNE:\\tIUniverse.com,\\t2000);\\tMihaly\\tCsikszentmihalyi,\\t\\nFinding\\tFlow:\\tThe\\tPsychology\\tof\\tEngagement\\twith\\nEveryday\\tLife\\n\\t(New\\tYork:\\tBasic\\tBooks,\\t2008).\\nIn\\tpsychology\\tresearch\\tthis\\tis\\tknown\\tas\\tthe\\tYerkes-Dodson\\tlaw\\n:\\n\\tRobert\\tYerkes\\tand\\tJohn\\tDodson,\\t“The\\tRelation\\tof\\tStrength\\tof\\tStimulus\\tto\\tRapidity\\tof\\tHabit\\tFormation,”\\t\\nJournal\\tof\\tComparative\\nNeurology\\tand\\tPsychology\\n\\t18\\t(1908):\\t459–482.\\n4\\tpercent\\tbeyond\\tyour\\tcurrent\\tability\\n:\\n\\tSteven\\tKotler,\\t\\nThe\\tRise\\tof\\tSuperman:\\tDecoding\\tthe\\tScience\\tof\\tUltimate\\tHuman\\tPerformance\\n\\t(Boston:\\tNew\\tHarvest,\\t2014).\\tIn\\this\\tbook,\\tKotler\\tcites:\\t“Chip\\nConley,\\tAI,\\tSeptember\\t2013.\\tThe\\treal\\tratio,\\taccording\\tto\\tcalculations\\tperformed\\tby\\t[Mihaly]\\tCsikszentmihalyi,\\tis\\t1:96.”\\n“Men\\tdesire\\tnovelty\\tto\\tsuch\\tan\\textent”\\n:\\n\\tNiccolò\\tMachiavelli,\\tPeter\\tBondanella,\\tand\\tMark\\tMusa,\\t\\nThe\\tPortable\\tMachiavelli\\n\\t(London:\\tPenguin,\\t2005).\\nvariable\\treward\\n:\\n\\tC.\\tB.\\tFerster\\tand\\tB.\\tF.\\tSkinner,\\t“Schedules\\tof\\tReinforcement,”\\t1957,\\tdoi:10.1037/10627–000.\\tFor\\tmore,\\tsee\\tB.\\tF.\\tSkinner,\\t“A\\tCase\\tHistory\\tin\\tScientific\\tMethod,”\\t\\nAmerican\\nPsychologist\\n\\t11,\\tno.\\t5\\t(1956):\\t226,\\tdoi:10.1037/h0047662.\\nThis\\tvariance\\tleads\\tto\\tthe\\tgreatest\\tspike\\tof\\tdopamine\\n:\\n\\tMatching\\tLaw\\tshows\\tthat\\tthe\\trate\\tof\\tthe\\treward\\tschedule\\timpacts\\tbehavior:\\t“Matching\\tLaw,”\\tWikipedia,\\nhttps://en.wikipedia.org/wiki/Matching_law\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 226}), Document(page_content='CHAPTER\\t20\\nthere\\tis\\tusually\\ta\\tslight\\t\\ndecline\\n\\tin\\tperformance\\n:\\n\\tK.\\tAnders\\tEricsson\\tand\\tRobert\\tPool,\\t\\nPeak:\\tSecrets\\tfrom\\tthe\\tNew\\tScience\\tof\\tExpertise\\n\\t(Boston:\\tMariner\\tBooks,\\t2017),\\t13.\\n“The\\tpundits\\twere\\tsaying”\\n:\\n\\tPat\\tRiley\\tand\\tByron\\tLaursen,\\t“Temporary\\tInsanity\\tand\\tOther\\tManagement\\tTechniques:\\tThe\\tLos\\tAngeles\\tLakers’\\tCoach\\tTells\\tAll,”\\t\\nLos\\tAngeles\\tTimes\\tMagazine,\\n\\tApril\\t19,\\n1987,\\t\\nhttp://articles.latimes.com/1987–04–19/magazine/tm-1669_1_lakers\\n.\\na\\tsystem\\tthat\\the\\tcalled\\tthe\\tCareer\\tBest\\tEffort\\tprogram\\tor\\tCBE\\n:\\n\\tMacMullan’s\\tbook\\tclaims\\tthat\\tRiley\\tbegan\\this\\tCBE\\tprogram\\tduring\\tthe\\t1984–1985\\tNBA\\tseason.\\tMy\\tresearch\\tshows\\tthat\\tthe\\tLakers\\nbegan\\ttracking\\tstatistics\\tof\\tindividual\\tplayers\\tat\\tthat\\ttime,\\tbut\\tthe\\tCBE\\tprogram\\tas\\tit\\tis\\tdescribed\\there\\twas\\tfirst\\tused\\tin\\t1986–1987.\\nIf\\tthey\\tsucceeded,\\tit\\twould\\tbe\\ta\\tCBE\\n:\\n\\tLarry\\tBird,\\tEarvin\\tJohnson,\\tand\\tJackie\\tMacMullan,\\t\\nWhen\\tthe\\tGame\\tWas\\tOurs\\n\\t(Boston:\\tHoughton\\tMifflin\\tHarcourt,\\t2010).\\n“Sustaining\\tan\\teffort”\\n:\\n\\tPat\\tRiley\\tand\\tByron\\tLaursen,\\t“Temporary\\tInsanity\\tand\\tOther\\tManagement\\tTechniques:\\tThe\\tLos\\tAngeles\\tLakers’\\tCoach\\tTells\\tAll,”\\t\\nLos\\tAngeles\\tTimes\\tMagazine,\\n\\tApril\\t19,\\n1987,\\t\\nhttp://articles.latimes.com/1987–04–19/magazine/tm-1669_1_lakers\\n.\\nEliud\\tKipchoge\\n:\\n\\tCathal\\tDennehy,\\t“The\\tSimple\\tLife\\tof\\tOne\\tof\\tthe\\tWorld’s\\tBest\\tMarathoners,”\\t\\nRunner’s\\tWorld\\n,\\tApril\\t19,\\t2016,\\t\\nhttps://www.runnersworld.com/elite-runners/the-simple-life-of-one-of-\\nthe-worlds-best-marathoners\\n.\\t“Eliud\\tKipchoge:\\tFull\\tTraining\\tLog\\tLeading\\tUp\\tto\\tMarathon\\tWorld\\tRecord\\tAttempt,”\\tSweat\\tElite,\\t2017,\\t\\nhttp://www.sweatelite.co/eliud-kipchoge-full-\\ntraining-log-leading-marathon-world-record-attempt/\\n.\\nher\\tcoach\\tgoes\\tover\\ther\\tnotes\\tand\\tadds\\this\\tthoughts\\n:\\n\\tYuri\\tSuguiyama,\\t“Training\\tKatie\\tLedecky,”\\tAmerican\\tSwimming\\tCoaches\\tAssociation,\\tNovember\\t30,\\t2016,\\nhttps://swimmingcoach.org/training-katie-ledecky-by-yuri-suguiyama-curl-burke-swim-club-2012/\\n.\\nWhen\\tcomedian\\tChris\\tRock\\tis\\tpreparing\\tfresh\\tmaterial\\n:\\n\\tPeter\\tSims,\\t“Innovate\\tLike\\tChris\\tRock,”\\t\\nHarvard\\tBusiness\\tReview\\n,\\tJanuary\\t26,\\t2009,\\t\\nhttps://hbr.org/2009/01/innovate-like-chris-rock\\n.\\nAnnual\\tReview\\n:\\n\\tI’d\\tlike\\tto\\tthank\\tChris\\tGuillebeau,\\twho\\tinspired\\tme\\tto\\tstart\\tmy\\town\\tannual\\treview\\tprocess\\tby\\tpublicly\\tsharing\\this\\tannual\\treview\\teach\\tyear\\tat\\t\\nhttps://chrisguillebeau.com\\n.\\n“keep\\tyour\\tidentity\\tsmall”\\n:\\n\\tPaul\\tGraham,\\t“Keep\\tYour\\tIdentity\\tSmall,”\\tFebruary\\t2009,\\t\\nhttp://www.paulgraham.com/identity.html\\n.\\nCONCLUSION\\nNo\\tone\\tcan\\tbe\\trich\\tunless\\tone\\tcoin\\tcan\\tmake\\thim\\tor\\ther\\tso\\n:\\n\\tDesiderius\\tErasmus\\tand\\tVan\\tLoon\\tHendrik\\tWillem,\\t\\nThe\\tPraise\\tof\\tFolly\\n\\t(New\\tYork:\\tBlack,\\t1942),\\t31.\\tHat\\ttip\\tto\\tGretchen\\tRubin.\\tI\\tfirst\\nread\\tabout\\tthis\\tparable\\tin\\ther\\tbook,\\t\\nBetter\\tThan\\tBefore,\\n\\tand\\tthen\\ttracked\\tdown\\tthe\\torigin\\tstory.\\tFor\\tmore,\\tsee\\tGretchen\\tRubin,\\t\\nBetter\\tThan\\tBefore\\n\\t(New\\tYork:\\tHodder,\\t2016).\\nLITTLE\\tLESSONS\\tFROM\\tTHE\\tFOUR\\tLAWS\\n“Happiness\\tis\\tthe\\tspace\\tbetween\\tone\\tdesire”\\n:\\n\\tCaed\\t(@caedbudris),\\t“Happiness\\tis\\tthe\\tspace\\tbetween\\tdesire\\tbeing\\tfulfilled\\tand\\ta\\tnew\\tdesire\\tforming,”\\tTwitter,\\tNovember\\t10,\\t2017,\\nhttps://twitter.com/caedbudris/status/929042389930594304\\n.\\nhappiness\\tcannot\\tbe\\tpursued,\\tit\\tmust\\tensue\\n:\\n\\tFrankl’s\\tfull\\tquotation\\tis\\tas\\tfollows:\\t“Don’t\\taim\\tat\\tsuccess.\\tThe\\tmore\\tyou\\taim\\tat\\tit\\tand\\tmake\\tit\\ta\\ttarget,\\tthe\\tmore\\tyou\\tare\\tgoing\\tto\\tmiss\\tit.\\tFor\\tsuccess,\\tlike\\nhappiness,\\tcannot\\tbe\\tpursued;\\tit\\tmust\\tensue,\\tand\\tit\\tonly\\tdoes\\tso\\tas\\tthe\\tunintended\\tside\\teffect\\tof\\tone’s\\tpersonal\\tdedication\\tto\\ta\\tcause\\tgreater\\tthan\\toneself\\tor\\tas\\tthe\\tby-product\\tof\\tone’s\\nsurrender\\tto\\ta\\tperson\\tother\\tthan\\toneself.”\\tFor\\tmore,\\tsee\\tViktor\\tE.\\tFrankl,\\t\\nMan’s\\tSearch\\tfor\\tMeaning:\\tAn\\tIntroduction\\tto\\tLogotherapy\\n\\t(Boston:\\tBeacon\\tPress,\\t1962).\\n“He\\twho\\thas\\ta\\twhy\\tto\\tlive\\tfor\\tcan\\tbear\\talmost\\tany\\thow”\\n:\\n\\tFriedrich\\tNietzsche\\tand\\tOscar\\tLevy,\\t\\nThe\\tTwilight\\tof\\tthe\\tIdols\\n\\t(Edinburgh:\\tFoulis,\\t1909).\\nThe\\tfeeling\\tcomes\\tfirst\\t(System\\t1)\\n:\\n\\tDaniel\\tKahneman,\\t\\nThinking,\\tFast\\tand\\tSlow\\n\\t(New\\tYork:\\tFarrar,\\tStraus\\tand\\tGiroux,\\t2015).\\nappealing\\tto\\temotion\\tis\\ttypically\\tmore\\tpowerful\\tthan\\tappealing\\tto\\treason\\n:\\n\\t“If\\tyou\\twish\\tto\\tpersuade,\\tappeal\\tto\\tinterest,\\trather\\tthan\\treason”\\t(Benjamin\\tFranklin).\\nSatisfaction\\t=\\tLiking\\t−\\tWanting\\n:\\n\\tThis\\tis\\tsimilar\\tto\\tDavid\\tMeister’s\\tfifth\\tlaw\\tof\\tservice\\tbusinesses:\\tSatisfaction\\t=\\tperception\\t−\\texpectation.\\n“Being\\tpoor\\tis\\tnot\\thaving\\ttoo\\tlittle,\\tit\\tis\\twanting\\tmore”\\n:\\n\\tLucius\\tAnnaeus\\tSeneca\\tand\\tAnna\\tLydia\\tMotto,\\t\\nMoral\\tEpistles\\n\\t(Chico,\\tCA:\\tScholars\\tPress,\\t1985).\\nAs\\tAristotle\\tnoted\\n:\\n\\tIt\\tis\\tdebated\\twhether\\tAristotle\\tactually\\tsaid\\tthis.\\tThe\\tquote\\thas\\tbeen\\tattributed\\tto\\thim\\tfor\\tcenturies,\\tbut\\tI\\tcould\\tfind\\tno\\tprimary\\tsource\\tfor\\tthe\\tphrase.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 227}), Document(page_content='A\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\nL\\nM\\nN\\nO\\nP\\nQ\\nR\\nS\\nT\\nU\\nV\\nW\\nX\\nY\\nZ\\nIndex\\nThe\\tpage\\tnumbers\\tin\\tthis\\tindex\\trefer\\tto\\tthe\\tprinted\\tversion\\tof\\tthis\\tbook.\\tThe\\tlink\\tprovided\\twill\\ttake\\tyou\\tto\\tthe\\tbeginning\\tof\\tthat\\tprint\\tpage.\\tYou\\tmay\\tneed\\tto\\tscroll\\tforward\\tfrom\\tthat\\tlocation\\tto\\tfind\\tthe\\ncorresponding\\treference\\ton\\tyour\\te-reader.\\naccepting\\tthat\\tyou\\thave\\tparticular\\tabilities,\\t\\n218\\n–19\\naccountability,\\t\\n209\\n–10\\naction\\t\\nvs.\\n\\tmotion,\\t\\n142\\n–43\\nAdams,\\tScott,\\t\\n23\\n,\\t\\n225\\naddiction\\neffect\\tof\\tenvironment\\ton\\treaddiction,\\t\\n92\\nsmoking,\\t\\n125\\n–26\\nVietnam\\tWar\\theroin\\tproblem,\\t\\n91\\n–92\\naddition\\tby\\tsubtraction\\tstrategy,\\t\\n154\\n“the\\taggregation\\tof\\tmarginal\\tgains,”\\t\\n13\\n–14\\nagricultural\\texpansion\\texample\\tof\\tdoing\\tthat\\twhich\\trequires\\tthe\\tleast\\teffort,\\t\\n149\\n–51\\nAllen\\tCarr’s\\tEasy\\tWay\\tto\\tStop\\tSmoking\\n\\t(Carr),\\t\\n125\\n–26\\namateurs\\t\\nvs.\\n\\tprofessionals,\\t\\n236\\nanimal\\tbehavior\\nwithin\\tan\\timmediate-return\\tenvironment,\\t\\n187\\ncat\\tescape\\tstudy,\\t\\n43\\n–44\\ngreylag\\tgeese\\tand\\tsupernormal\\tstimuli,\\t\\n102\\nherring\\tgulls\\tand\\tsupernormal\\tstimuli,\\t\\n101\\n–102\\nmethods\\tfor\\tsensing\\tand\\tunderstanding\\tthe\\tworld,\\t\\n84\\nArt\\t&\\tFear\\n\\t(Bayles\\tand\\tOrland),\\t\\n142\\nn\\nAsch,\\tSolomon,\\t\\n118\\n–20\\nathletes\\nCareer\\tBest\\tEffort\\tprogram\\t(CBE),\\t\\n242\\n–44\\ncomparing\\tchampions\\tof\\tdifferent\\tsports,\\t\\n217\\n–18\\nexamples\\tof\\treflection\\tand\\treview,\\t\\n244\\n–45\\nhandling\\tthe\\tboredom\\tof\\ttraining,\\t\\n233\\n–34\\nLos\\tAngeles\\tLakers\\texample\\tof\\treflection\\tand\\treview,\\t\\n242\\n–44\\nuse\\tof\\tmotivation\\trituals,\\t\\n132\\n–33\\natomic\\thabits\\ncumulative\\teffect\\tof\\tstacking,\\t\\n251\\n–52\\ndefined,\\t\\n27\\nautomaticity,\\t\\n144\\n–46\\nautomating\\ta\\thabit\\ncash\\tregister\\texample,\\t\\n171\\n–72\\ntable\\tof\\tonetime\\tactions\\tthat\\tlock\\tin\\tgood\\thabits,\\t\\n173\\nThomas\\tFrank\\texample\\tof\\tautomating\\ta\\thabit\\tcontract,\\t\\n210\\nusing\\ttechnology,\\t\\n173\\n–75\\nawareness\\nHabits\\tScorecard,\\t\\n64\\n–66\\nof\\tnonconscious\\thabits,\\t\\n62\\nPointing-and-Calling\\tsubway\\tsafety\\tsystem,\\t\\n62\\n–63\\nbad\\thabits\\nbreaking\\t(table),\\t\\n97\\n,\\t\\n137\\n,\\t\\n179\\n,\\t\\n213\\nreducing\\texposure\\tto\\tthe\\tcues\\tthat\\tcause\\tthem,\\t\\n94\\n–95\\nbehavior\\tchange\\nCardinal\\tRule\\tof\\tBehavior\\tChange,\\t\\n186\\n,\\t\\n189\\nfour\\tlaws\\tof,\\t\\n53\\n–55,\\t\\n186\\n,\\t\\n252\\n–53\\t(\\nsee\\talso\\n\\tspecific\\tnumbered\\tlaws)\\nlearning\\tcurves,\\t\\n145\\n–46\\nthree\\tlayers\\tof,\\t\\n29\\n–31\\nbenefits\\tof\\thabits,\\t\\n46\\n–47,\\t\\n239\\n“Better\\tAll\\tthe\\tTime”\\t(article),\\t\\n154\\nbiological\\tconsiderations\\n“Big\\tFive”\\tpersonality\\ttraits,\\t\\n220\\n–22\\ngenes,\\t\\n218\\n–21,\\t\\n226\\n–27\\nboredom,\\t\\n233\\n–36\\nBrailsford,\\tDave,\\t\\n13\\n–14\\nthe\\tbrain\\ncareer\\tchoices\\tand\\tbrain\\tdifferences,\\t\\n143\\n–44\\ndopamine-driven\\tfeedback\\tloops,\\t\\n105\\n–108\\nevolutionary\\tsimilarity\\tof,\\t\\n187\\nas\\thabits\\tare\\tcreated,\\t\\n45\\n–46\\nHebb’s\\tLaw,\\t\\n143\\ninaccurate\\tperceptions\\tof\\tthreats,\\t\\n189\\nn', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 228}), Document(page_content='long-term\\tpotentiation,\\t\\n143\\nphysical\\tchanges\\tin\\tthe\\tbrain\\tdue\\tto\\trepetition,\\t\\n143\\n–44\\nSystem\\t1\\t\\nvs.\\n\\tSystem\\t2\\tthinking,\\t\\n232\\nn,\\t\\n261\\n“wanting”\\t\\nvs.\\n\\t“liking”\\trewards,\\t\\n106\\n–108,\\t\\n263\\nbreakthrough\\tmoments\\nice\\tcube\\tmelting\\texample,\\t\\n20\\n–21\\nBritish\\tCycling,\\t\\n13\\n–15,\\t\\n25\\n,\\t\\n243\\nBudris,\\tCaed,\\t\\n260\\nbuilding\\ta\\thabit\\nfour-step\\tprocess\\n1.\\tcue,\\t\\n47\\n–48\\n2.\\tcraving,\\t\\n48\\n3.\\tresponse,\\t\\n48\\n–49\\n4.\\treward,\\t\\n49\\nproblem\\tphase\\tand\\tsolution\\tphase,\\t\\n51\\n–53\\nlessons\\tfrom,\\t\\n259\\n–64\\nbusiness\\tapplications\\tof\\thabit\\tstrategies,\\t\\n265\\nByrne,\\tRonan,\\t\\n108\\n–109\\ncash\\tregister\\texample\\tof\\tautomating\\ta\\thabit,\\t\\n171\\n–72\\ncat\\tescape\\tstudy,\\t\\n43\\n–44\\nchanging\\tyour\\tmind-set\\tfrom\\t“have\\tto”\\tto\\t“get\\tto,”\\t\\n130\\n–31\\nCho,\\tMargaret,\\t\\n210\\nchoosing\\tthe\\tright\\topportunities\\ncombining\\tyour\\tskills\\tto\\treduce\\tthe\\tcompetition,\\t\\n225\\n–26\\nexplore/exploit\\ttrade-off,\\t\\n223\\n–25\\nimportance\\tof,\\t\\n222\\n–23\\nspecialization,\\t\\n226\\nClark,\\tBrian,\\t\\n33\\ncommitment\\tdevices,\\t\\n170\\n–71\\ncompounding\\teffect\\tof\\tsmall\\tchanges\\nairplane\\troute\\texample,\\t\\n17\\nauthor’s\\tcollege\\texperiences,\\t\\n6\\n–7\\nnegative\\tresults,\\t\\n19\\n1\\tpercent\\tchanges,\\t\\n15\\n–16,\\t\\n17\\n–18\\npositive\\tresults,\\t\\n19\\nconditioning,\\t\\n132\\n–33\\nconsequences\\tof\\tgood\\tand\\tbad\\thabits,\\t\\n188\\n–90,\\t\\n206\\n–207\\ncontext,\\t\\n87\\n–90\\ncravings\\nas\\tthe\\tsense\\tthat\\tsomething\\tis\\tmissing,\\t\\n129\\ntiming\\tof,\\t\\n259\\n,\\t\\n263\\n–64\\nand\\tunderlying\\tmotives,\\t\\n127\\n–28,\\t\\n130\\ncue-induced\\twanting,\\t\\n93\\n–94\\ncues\\nautomatically\\tpicking\\tup,\\t\\n59\\n–62\\nmaking\\tpredictions\\tafter\\tperceiving,\\t\\n128\\n–29\\nobvious\\tvisual\\tcues,\\t\\n85\\n–87\\nas\\tpart\\tof\\tthe\\tfour-step\\tprocess\\tof\\tbuilding\\ta\\thabit,\\t\\n47\\n–48\\nselecting\\tcues\\tfor\\thabit\\tstacking,\\t\\n77\\n–79\\nculture\\nimitation\\tof\\tcommunity\\thabits\\tand\\tstandards,\\t\\n115\\n–18\\nNerd\\tFitness\\texample\\tof\\tsimilarity\\twithin\\ta\\tgroup,\\t\\n117\\n–18\\nPolgar\\tfamily\\tchess\\texample\\tof\\tthe\\trole\\tof,\\t\\n113\\n–14,\\t\\n122\\ncuriosity,\\t\\n261\\nDamasio,\\tAntonio,\\t\\n130\\nDarwin,\\tCharles,\\t\\n115\\ndecision\\tjournal,\\t\\n245\\ndecisive\\tmoments,\\t\\n160\\n–62\\ndesire,\\t\\n129\\n–30,\\t\\n263\\n–64\\nDiderot,\\tDenis,\\t\\n72\\n–73\\nDiderot\\tEffect,\\t\\n73\\n“don’t\\tbreak\\tthe\\tchain,”\\t\\n196\\n–97\\ndopamine-driven\\tfeedback\\tloops,\\t\\n105\\n–108\\ndownside\\tof\\thabits,\\t\\n239\\n–40\\nDyrsmid,\\tTrent,\\t\\n195\\nemotions,\\t\\n129\\n–30,\\t\\n261\\n–62,\\t\\n263\\n–64\\nenergy\\tand\\tlikelihood\\tof\\taction,\\t\\n151\\n–52\\nenvironment\\nand\\tcontext,\\t\\n87\\n–90\\ncreating\\tan\\tenvironment\\twhere\\tdoing\\tthe\\tright\\tthing\\tis\\tas\\teasy\\tas\\tpossible,\\t\\n155\\ndedicated\\tspaces\\tfor\\tdifferent\\tactivities,\\t\\n87\\n–90\\ndelayed-return,\\t\\n187\\n–90\\nDutch\\telectrical\\tmeter\\texample\\tof\\tobvious\\tcues,\\t\\n85\\neffect\\tof\\tenvironment\\ton\\tan\\taddiction,\\t\\n92\\nimmediate-return,\\t\\n187\\n–90\\nLewin’s\\tEquation\\tfor\\thuman\\tbehavior,\\t\\n83\\nMassachusetts\\tGeneral\\tHospital\\tcafeteria\\texample\\tof\\tdesign\\tchange,\\t\\n81\\n–82', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 229}), Document(page_content='priming\\tyour\\tenvironment,\\t\\n156\\n–58\\nredesigning\\tyour\\tenvironment,\\t\\n86\\n–87\\nsuggestion\\timpulse\\tbuying,\\t\\n83\\nVietnam\\tWar\\theroin\\taddiction\\tproblem\\texample,\\t\\n91\\n–92\\nexercise\\tstudy\\tof\\timplementation\\tintention,\\t\\n69\\n–70\\nexpectations,\\t\\n262\\n–63,\\t\\n264\\nexplore/exploit\\ttrade-off,\\t\\n223\\n–25\\nEyal,\\tNir,\\t\\n170\\nfailure,\\t\\n263\\nfeedback\\tloops\\nin\\tall\\thuman\\tbehavior,\\t\\n45\\ndopamine-driven,\\t\\n105\\n–108\\nformation\\tof\\tall\\thabits\\tthat\\tshape\\tone’s\\tidentity,\\t\\n40\\nhabit,\\t\\n49\\n–51\\nfeelings,\\t\\n129\\n–30,\\t\\n261\\n–62,\\t\\n263\\n–64\\n1st\\tLaw\\tof\\tBehavior\\tChange\\t(Make\\tIt\\tObvious)\\nHabits\\tScorecard,\\t\\n64\\n–66\\nhabit\\tstacking,\\t\\n74\\n–79,\\t\\n110\\n–11\\nhabit\\ttracking,\\t\\n197\\nimplementation\\tintention,\\t\\n69\\n–72\\nmaking\\tthe\\tcues\\tof\\tbad\\thabits\\tinvisible,\\t\\n94\\n–95\\nFisher,\\tRoger,\\t\\n205\\n–206\\nflow\\tstate,\\t\\n224\\n,\\t\\n232\\n–33\\nFogg,\\tBJ,\\t\\n72\\n,\\t\\n74\\nfood\\tscience\\n“bliss\\tpoint”\\tfor\\teach\\tproduct,\\t\\n103\\ncravings\\tfor\\tjunk\\tfood,\\t\\n102\\n–103\\ndynamic\\tcontrast\\tof\\tprocessed\\tfoods,\\t\\n103\\norosensation,\\t\\n103\\nfour\\tlaws\\tof\\tbehavior\\tchange,\\t\\n53\\n–55,\\t\\n186\\n,\\t\\n252\\n–53.\\t\\nSee\\talso\\n\\tspecific\\tnumbered\\tlaws\\nfour-step\\tprocess\\tof\\tbuilding\\ta\\thabit\\n1.\\tcue,\\t\\n47\\n–48\\n2.\\tcraving,\\t\\n48\\n3.\\tresponse,\\t\\n48\\n–49\\n4.\\treward,\\t\\n49\\nhabit\\tloop,\\t\\n49\\n–51\\nlessons\\tfrom,\\t\\n259\\n–64\\nproblem\\tphase\\tand\\tsolution\\tphase,\\t\\n51\\n–53\\n4th\\tLaw\\tof\\tBehavior\\tChange\\t(Make\\tIt\\tSatisfying)\\nhabit\\tcontract,\\t\\n207\\n–10\\nhabit\\ttracking,\\t\\n198\\n–99\\ninstant\\tgratification,\\t\\n188\\n–93\\nmaking\\tthe\\tcues\\tof\\tbad\\thabits\\tunsatisfying,\\t\\n205\\n–206\\nSafeguard\\tsoap\\tin\\tPakistan\\texample,\\t\\n184\\n–85\\nFrankl,\\tVictor,\\t\\n260\\nFranklin,\\tBenjamin,\\t\\n196\\nfrequency’s\\teffect\\ton\\thabits,\\t\\n145\\n–47\\nfriction\\nassociated\\twith\\ta\\tbehavior,\\t\\n152\\n–58\\ngarden\\those\\texample\\tof\\treducing,\\t\\n153\\nJapanese\\tfactory\\texample\\tof\\teliminating\\twasted\\ttime\\tand\\teffort,\\t\\n154\\n–55\\nto\\tprevent\\tunwanted\\tbehavior,\\t\\n157\\n–58\\n“gateway\\thabit,”\\t\\n163\\ngenes,\\t\\n218\\n–21,\\t\\n226\\n–27\\ngoals\\neffect\\ton\\thappiness,\\t\\n26\\nfleeting\\tnature\\tof,\\t\\n25\\nshared\\tby\\twinners\\tand\\tlosers,\\t\\n24\\n–25\\nshort-term\\teffects\\tof,\\t\\n26\\n–27\\nvs.\\n\\tsystems,\\t\\n23\\n–24\\nthe\\tGoldilocks\\tRule\\nflow\\tstate,\\t\\n224\\n,\\t\\n232\\n–33\\nthe\\tGoldilocks\\tZone,\\t\\n232\\ntennis\\texample,\\t\\n231\\ngood\\thabits\\ncreating\\t(table),\\t\\n96\\n,\\t\\n136\\n,\\t\\n178\\n,\\t\\n212\\nTwo-Minute\\tRule,\\t\\n162\\n–67\\nGoodhart,\\tCharles,\\t\\n203\\nGoodhart’s\\tLaw,\\t\\n203\\nGraham,\\tPaul,\\t\\n247\\n–48\\ngreylag\\tgeese\\tand\\tsupernormal\\tstimuli,\\t\\n102\\nGuerrouj,\\tHicham\\tEl,\\t\\n217\\n–18,\\t\\n225\\nGuns,\\tGerms,\\tand\\tSteel\\n\\t(Diamond),\\t\\n149\\n–51\\nhabit\\tcontract\\nBryan\\tHarris\\tweight\\tloss\\texample,\\t\\n208\\n–209\\ndefined,\\t\\n208\\nseat\\tbelt\\tlaw\\texample,\\t\\n207\\n–208', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 230}), Document(page_content='Thomas\\tFrank\\talarm\\texample,\\t\\n210\\nhabit\\tline,\\t\\n145\\n–47\\nhabit\\tloop,\\t\\n49\\n–51\\nhabits\\nof\\tavoidance,\\t\\n191\\n–92\\nbenefits\\tof,\\t\\n46\\n–47,\\t\\n239\\nbreaking\\tbad\\thabits\\t(table),\\t\\n97\\n,\\t\\n137\\n,\\t\\n179\\n,\\t\\n213\\nin\\tthe\\tbusiness\\tworld,\\t\\n265\\nchanging\\tyour\\tmind-set\\tabout,\\t\\n130\\n–31\\ncreating\\tgood\\thabits\\t(table),\\t\\n96\\n,\\t\\n136\\n,\\t\\n178\\n,\\t\\n212\\ndownside\\tof,\\t\\n239\\n–40\\neffect\\ton\\tthe\\trest\\tof\\tyour\\tday,\\t\\n160\\n,\\t\\n162\\neliminating\\tbad\\thabits,\\t\\n94\\n–95\\nas\\tthe\\tembodiment\\tof\\tidentity,\\t\\n36\\n–38\\nformation\\tof,\\t\\n44\\n–46,\\t\\n145\\n–47\\nfour-step\\tprocess\\tof\\tbuilding\\ta\\thabit,\\t\\n47\\n–53,\\t\\n259\\n–64\\n“gateway\\thabit,”\\t\\n163\\nidentity-based,\\t\\n31\\n,\\t\\n39\\n–40\\nimitation\\tof\\tothers’\\thabits\\nthe\\tclose,\\t\\n116\\n–18\\nthe\\tmany,\\t\\n118\\n–21\\nthe\\tpowerful,\\t\\n121\\n–22\\nimportance\\tof,\\t\\n40\\n–41\\noutcome-based,\\t\\n31\\nand\\tparenting,\\t\\n267\\nreframing\\thabits\\tto\\thighlight\\ttheir\\tbenefits,\\t\\n131\\n–32\\nshort-term\\tand\\tlong-term\\tconsequences\\tof,\\t\\n188\\n–90\\nsticking\\twith,\\t\\n230\\n–31\\nsuitability\\tfor\\tyour\\tpersonality,\\t\\n221\\n–22\\nTwo-Minute\\tRule,\\t\\n162\\n–67\\nusing\\timplementation\\tintention\\tto\\tstart,\\t\\n71\\n–72\\nHabits\\tAcademy,\\t\\n8\\nhabit\\tshaping,\\t\\n165\\n–67\\nHabits\\tScorecard,\\t\\n64\\n–66\\nhabit\\tstacking\\ncombining\\ttemptation\\tbundling\\twith,\\t\\n110\\n–11\\nexplained,\\t\\n74\\n–79\\nhabit\\ttracking,\\t\\n196\\n–200,\\t\\n202\\n–204\\nhandwashing\\tin\\tPakistan\\texample\\tof\\ta\\tsatisfying\\tbehavior\\tchange,\\t\\n184\\n–85\\nhappiness\\nas\\tthe\\tabsence\\tof\\tdesire,\\t\\n259\\n–60\\nand\\tgoals,\\t\\n26\\nrelativity\\tof,\\t\\n263\\nHarris,\\tBryan,\\t\\n208\\n–209\\nHebb,\\tDonald,\\t\\n143\\nHebb’s\\tLaw,\\t\\n143\\nherring\\tgulls\\tand\\tsupernormal\\tstimuli,\\t\\n101\\n–102\\nhope,\\t\\n264\\nHreha,\\tJason,\\t\\n45\\nHugo,\\tVictor,\\t\\n169\\n–70\\nThe\\tHunchback\\tof\\tNotre\\tDame\\n\\t(Hugo),\\t\\n169\\n–70\\nhyperbolic\\tdiscounting\\t(time\\tinconsistency),\\t\\n188\\n–89\\nidentity\\naccepting\\tblanket\\tpersonal\\tstatements\\tas\\tfacts,\\t\\n35\\nand\\tbehavior\\tchange,\\t\\n29\\n–32,\\t\\n34\\n–36\\nbehavior\\tthat\\tis\\tat\\todds\\twith\\tthe\\tself,\\t\\n32\\n–33\\nhabits\\tas\\tthe\\tembodiment\\tof,\\t\\n36\\n–38,\\t\\n247\\n–49\\nidentity-based\\thabits,\\t\\n31\\n,\\t\\n39\\n–40\\nletting\\ta\\tsingle\\tbelief\\tdefine\\tyou,\\t\\n247\\n–49\\npride\\tin\\ta\\tparticular\\taspect\\tof\\tone’s\\tidentity,\\t\\n33\\n–34\\nreinforcing\\tyour\\tdesired\\tidentity\\tby\\tusing\\tthe\\tTwo-Minute\\tRule,\\t\\n165\\ntwo-step\\tprocess\\tof\\tchanging\\tyour\\tidentity,\\t\\n39\\n–40\\nimplementation\\tintention,\\t\\n69\\n–72\\nimprovements,\\tmaking\\tsmall,\\t\\n231\\n–32,\\t\\n233\\n,\\t\\n253\\ninstant\\tgratification,\\t\\n188\\n–93\\nJohnson,\\tMagic,\\t\\n243\\n–44\\njournaling,\\t\\n165\\nJung,\\tCarl,\\t\\n62\\nKamb,\\tSteve,\\t\\n117\\n–18\\nKubitz,\\tAndrew,\\t\\n109\\nLao\\tTzu,\\t\\n249\\nTao\\tTe\\tChing\\n,\\t\\n249\\nLatimore,\\tEd,\\t\\n132', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 231}), Document(page_content='Lewes,\\tGeorge\\tH.,\\t\\n144\\nlong-term\\tpotentiation,\\t\\n143\\nLos\\tAngeles\\tLakers\\texample\\tof\\treflection\\tand\\treview,\\t\\n242\\n–44\\nLuby,\\tStephen,\\t\\n183\\n–85\\nMacMullan,\\tJackie,\\t\\n243\\n–44\\nMartin,\\tSteve,\\t\\n229\\n–30,\\t\\n231\\nMassachusetts\\tGeneral\\tHospital\\tcafeteria\\texample\\tof\\tenvironment\\tdesign\\tchange,\\t\\n81\\n–82\\nMassimino,\\tMike,\\t\\n117\\nmastery,\\t\\n240\\n–42\\nMate,\\tGabor,\\t\\n219\\nMcKeown,\\tGreg,\\t\\n165\\nmeasurements\\nusefulness\\tof,\\t\\n202\\n–204\\nvisual,\\t\\n195\\n–96\\nMike\\t(Turkish\\ttravel\\tguide/ex-smoker),\\t\\n125\\n–26\\nMilner,\\tPeter,\\t\\n105\\nmind-set\\tshifts\\nfrom\\t“have\\tto”\\tto\\t“get\\tto,”\\t\\n130\\n–31\\nmotivation\\trituals,\\t\\n132\\n–33\\nreframing\\thabits\\tto\\thighlight\\ttheir\\tbenefits,\\t\\n131\\n–32\\nmotion\\t\\nvs.\\n\\taction,\\t\\n142\\n–43\\nmotivation\\nthe\\tGoldilocks\\tRule,\\t\\n231\\n–33\\nmaximum\\tmotivation,\\t\\n232\\nrituals,\\t\\n132\\n–33\\nand\\ttaking\\taction,\\t\\n260\\n–61\\nMurphy,\\tMorgan,\\t\\n91\\nnegative\\tcompounding,\\t\\n19\\nNietzsche,\\tFriedrich,\\t\\n260\\nnonconscious\\tactivities,\\t\\n34\\nn\\nnonscale\\tvictories,\\t\\n203\\n–204\\nnovelty,\\t\\n234\\nNuckols,\\tOswald,\\t\\n156\\nobservations,\\t\\n260\\nobstacles\\tto\\tgetting\\twhat\\tyou\\twant,\\t\\n152\\nOlds,\\tJames,\\t\\n105\\nOlwell,\\tPatty,\\t\\n93\\n1\\tpercent\\tchanges\\nCareer\\tBest\\tEffort\\tprogram\\t(CBE),\\t\\n242\\n–44\\ncompounding\\teffect\\tof\\tmaking\\tchanges,\\t\\n15\\n–16,\\t\\n17\\n–18\\nSorites\\tParadox,\\t\\n251\\n–52\\noperant\\tconditioning,\\t\\n9\\n–10\\nopportunities,\\tchoosing\\tthe\\tright\\ncombining\\tyour\\tskills\\tto\\treduce\\tthe\\tcompetition,\\t\\n225\\n–26\\nexplore/exploit\\ttrade-off,\\t\\n223\\n–25\\nimportance\\tof,\\t\\n222\\n–23\\nspecialization,\\t\\n226\\noutcomes\\nand\\tbehavior\\tchange,\\t\\n29\\n–31\\noutcome-based\\thabits,\\t\\n31\\npain,\\t\\n206\\n–207\\nPaper\\tClip\\tStrategy\\tof\\tvisual\\tprogress\\tmeasurements,\\t\\n195\\n–96\\nparenting\\tapplications\\tof\\thabit\\tstrategies,\\t\\n267\\nPatterson,\\tJohn\\tHenry,\\t\\n171\\n–72\\nPhelps,\\tMichael,\\t\\n217\\n–18,\\t\\n225\\nphotography\\tclass\\texample\\tof\\tactive\\tpractice,\\t\\n141\\n–42,\\t\\n144\\nPlateau\\tof\\tLatent\\tPotential,\\t\\n21\\n–23\\npleasure\\nanticipating\\t\\nvs.\\n\\texperiencing,\\t\\n106\\n–108\\nimage\\tof,\\t\\n260\\nrepeating\\ta\\tbehavior\\twhen\\tit’s\\ta\\tsatisfying\\tsensory\\texperience,\\t\\n184\\n–86,\\t\\n264\\nSafeguard\\tsoap\\texample,\\t\\n184\\n–85\\nPlomin,\\tRobert,\\t\\n220\\nPointing-and-Calling\\tsubway\\tsafety\\tsystem,\\t\\n62\\n–63\\npositive\\tcompounding,\\t\\n19\\nThe\\tPower\\tof\\tHabit\\n\\t(Duhigg),\\t\\n9\\n,\\t\\n47\\nn\\npredictions,\\tmaking\\nafter\\tperceiving\\tcues,\\t\\n128\\n–29\\nthe\\thuman\\tbrain\\tas\\ta\\tprediction\\tmachine,\\t\\n60\\n–61\\nPremack,\\tDavid,\\t\\n110\\nPremack’s\\tPrinciple,\\t\\n110\\npride\\nmanicure\\texample,\\t\\n33', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 232}), Document(page_content='in\\ta\\tparticular\\taspect\\tof\\tone’s\\tidentity,\\t\\n33\\n–34\\npriming\\tyour\\tenvironment\\tto\\tmake\\tthe\\tnext\\taction\\teasy,\\t\\n156\\n–58\\nproblem\\tphase\\tof\\ta\\thabit\\tloop,\\t\\n51\\n–53\\nprocess\\tand\\tbehavior\\tchange,\\t\\n30\\n–31\\nprofessionals\\t\\nvs.\\n\\tamateurs,\\t\\n236\\nprogress,\\t\\n262\\nproximity’s\\teffect\\ton\\tbehavior,\\t\\n116\\n–18\\nquitting\\tsmoking,\\t\\n32\\n,\\t\\n125\\n–26\\nreading\\tresources\\nAtomic\\tHabits\\tnewsletter,\\t\\n257\\nbusiness\\tapplications\\tof\\thabit\\tstrategies,\\t\\n265\\nparenting\\tapplications\\tof\\thabit\\tstrategies,\\t\\n267\\nrecovering\\twhen\\thabits\\tbreak\\tdown,\\t\\n200\\n–202\\nreflection\\tand\\treview\\nauthor’s\\tAnnual\\tReview\\tand\\tIntegrity\\tReport,\\t\\n245\\n–46\\nbenefits\\tof,\\t\\n246\\n–47\\nCareer\\tBest\\tEffort\\tprogram\\t(CBE)\\texample,\\t\\n242\\n–44\\nChris\\tRock\\texample,\\t\\n245\\nEliud\\tKipchoge\\texample,\\t\\n244\\n–45\\nflexibility\\tand\\tadaptation,\\t\\n247\\n–49\\nimportance\\tof,\\t\\n244\\n–45\\nKatie\\tLedecky\\texample,\\t\\n245\\nreframing\\thabits\\tto\\thighlight\\ttheir\\tbenefits,\\t\\n131\\n–32\\nreinforcement,\\t\\n191\\n–93\\nrepetition\\nas\\tactive\\tpractice\\tof\\ta\\tnew\\thabit,\\t\\n144\\nautomaticity,\\t\\n144\\n–46\\nto\\tmaster\\ta\\thabit,\\t\\n143\\nphotography\\tclass\\texample\\tof\\tactive\\tpractice,\\t\\n141\\n–42,\\t\\n144\\nresponding\\tto\\tthings\\tbased\\ton\\temotions,\\t\\n261\\n–62\\nrewards\\nafter\\tsacrifice,\\t\\n262\\nimmediate\\t\\nvs.\\n\\tdelayed,\\t\\n187\\n–90\\npurpose\\tof,\\t\\n49\\nreinforcement,\\t\\n191\\n–93\\ntraining\\tyourself\\tto\\tdelay\\tgratification,\\t\\n190\\n–93\\nvariable\\trewards,\\t\\n235\\n“wanting”\\t\\nvs.\\n\\t“liking,”\\t\\n106\\n–108,\\t\\n263\\nRiis,\\tJacob,\\t\\n21\\nRiley,\\tMichael,\\t\\n60\\nRiley,\\tPat,\\t\\n242\\n–44\\nRitty,\\tJames,\\t\\n171\\n–72\\nRobins,\\tLee,\\t\\n91\\n–92\\nsacrifice,\\t\\n262\\nsatisfaction\\nas\\tthe\\tcompletion\\tof\\tthe\\thabit\\tloop,\\t\\n186\\nand\\texpectations,\\t\\n262\\n–63\\npleasurable\\tsensory\\texperiences,\\t\\n184\\n–86\\n2nd\\tLaw\\tof\\tBehavior\\tChange\\t(Make\\tIt\\tAttractive)\\nABC\\tThursday\\tnight\\tTV\\tlineup\\texample,\\t\\n109\\ndesire\\tfor\\tapproval,\\trespect,\\tand\\tpraise,\\t\\n121\\n–22\\nhabit\\ttracking,\\t\\n198\\nhighly\\tengineered\\tversions\\tof\\treality,\\t\\n104\\nmaking\\tthe\\tcues\\tof\\tbad\\thabits\\tunattractive,\\t\\n126\\nsupernormal\\tstimuli,\\t\\n102\\ntemptation\\tbundling,\\t\\n108\\n–11\\nSeinfeld,\\tJerry,\\t\\n196\\n–97\\nself-control\\ncontrolling\\tthe\\tenvironment\\tto\\tachieve,\\t\\n92\\n–93\\ncue-induced\\twanting,\\t\\n93\\n–94\\ndifficulty\\tof,\\t\\n262\\nriding\\tand\\tsmoking\\texample\\tof\\tcontrolling\\tyour\\tenvironment,\\t\\n93\\nas\\ta\\tshort-term\\tstrategy,\\t\\n95\\nthe\\tsenses\\nSafeguard\\tsoap\\texample,\\t\\n184\\n–85\\ntoothpaste\\texample\\tof\\ta\\tsatisfying\\tbehavior\\tchange,\\t\\n186\\nvision,\\t\\n84\\n,\\t\\n85\\n–87\\nWrigley\\tchewing\\tgum\\texample,\\t\\n185\\nshowing\\tup,\\tmastering\\tthe\\tart\\tof,\\t\\n163\\n–64,\\t\\n201\\n–202,\\t\\n236\\nSkinner,\\tB.\\tF.,\\t\\n9\\n–10,\\t\\n235\\nn\\nsmoking,\\tquitting,\\t\\n32\\n,\\t\\n125\\n–26\\nsocial\\tmedia,\\t\\n174\\n–75\\nsocial\\tnorms\\nAsch’s\\tsocial\\tconformity\\tline\\texperiments,\\t\\n118\\n–20\\ndownside\\tof\\tgoing\\talong\\twith\\tthe\\tgroup,\\t\\n120\\n–21\\nherd\\tmentality,\\t\\n115\\nimitation\\tof\\tothers’\\thabits', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 233}), Document(page_content='the\\tclose,\\t\\n116\\n–18\\nthe\\tmany,\\t\\n118\\n–21\\nthe\\tpowerful,\\t\\n121\\n–22\\nsolution\\tphase\\tof\\ta\\thabit\\tloop,\\t\\n51\\n–53\\nSorites\\tParadox,\\t\\n251\\n–52\\nstarting\\ta\\thabit,\\t\\n71\\n–72\\nSteele,\\tRobert,\\t\\n91\\nStern,\\tHawkins,\\t\\n83\\nsuccess\\naccepting\\twhere\\tyour\\tstrengths\\tare,\\t\\n218\\n–19\\nimportance\\tof\\tfeeling\\tsuccessful,\\t\\n190\\nsuffering,\\t\\n262\\nsuggestion\\timpulse\\tbuying,\\t\\n83\\nsupernormal\\tstimuli,\\t\\n102\\nSuroweicki,\\tJames,\\t\\n154\\nSystem\\t1\\t\\nvs.\\n\\tSystem\\t2\\tthinking,\\t\\n232\\nn,\\t\\n261\\nsystems\\nchanges\\tto\\tsolve\\tproblems,\\t\\n25\\nas\\ta\\tcycle\\tof\\tcontinuous\\timprovement,\\t\\n26\\n–27\\nvs.\\n\\tgoals,\\t\\n23\\n–24\\ntechnology\\nfor\\tautomating\\ta\\thabit,\\t\\n173\\n–75\\nsocial\\tmedia,\\t\\n174\\n–75\\ntemptation\\tbundling,\\t\\n108\\n–11\\n3rd\\tLaw\\tof\\tBehavior\\tChange\\t(Make\\tIt\\tEasy)\\nagricultural\\texpansion\\texample\\tof\\tusing\\tthe\\tleast\\teffort,\\t\\n149\\n–51\\nenergy\\trequirements\\tand\\tlikelihood\\tof\\taction,\\t\\n151\\n–52\\nfriction\\tassociated\\twith\\ta\\tbehavior,\\t\\n152\\n–58\\ngarden\\those\\texample\\tof\\treducing\\tfriction,\\t\\n153\\n“gateway\\thabit,”\\t\\n163\\nJapanese\\tfactory\\texample\\tof\\taddition\\tby\\tsubtraction,\\t\\n154\\n–55\\nmaking\\tthe\\tcues\\tof\\tbad\\thabits\\tdifficult,\\t\\n169\\n–70\\nonetime\\tactions\\tthat\\tlead\\tto\\tbetter\\thabits,\\t\\n172\\n–74\\nPrinciple\\tof\\tLeast\\tAction,\\t\\n151\\nn\\nrepetition\\tas\\tthe\\tkey\\tto\\thabit\\tformation,\\t\\n146\\n–47\\nTwo-Minute\\tRule,\\t\\n162\\n–67\\nTwyla\\tTharp\\texample\\tof\\ta\\tdaily\\tritual,\\t\\n159\\n–60\\nThorndike,\\tAnne,\\t\\n81\\n–82\\nThorndike,\\tEdward,\\t\\n43\\n–44\\ntime\\tinconsistency,\\t\\n188\\n–89\\nTinbergen,\\tNiko,\\t\\n101\\n–102\\ntoothpaste\\texample\\tof\\ta\\tsatisfying\\tbehavior\\tchange,\\t\\n186\\ntracking\\ta\\thabit\\nautomated,\\t\\n199\\ncombining\\thabit\\tstacking\\twith\\thabit\\ttracking,\\t\\n200\\nmanual,\\t\\n199\\n–200\\nusefulness\\tof,\\t\\n202\\n–204\\ntrajectory\\tof\\tyour\\tcurrent\\tpath,\\t\\n18\\ntwo-step\\tprocess\\tof\\tchanging\\tyour\\tidentity,\\t\\n39\\n–40\\nUelsmann,\\tJerry,\\t\\n141\\n–42\\nUlysses\\tpact\\t(Ulysses\\tcontract),\\t\\n170\\nn\\nunderlying\\tmotives\\tand\\tcravings,\\t\\n127\\n–28,\\t\\n130\\nValley\\tof\\tDisappointment,\\t\\n20\\n,\\t\\n22\\nvariable\\trewards,\\t\\n235\\nVietnam\\tWar\\theroin\\taddiction\\tproblem,\\t\\n91\\n–92\\nvision\\nimpact\\ton\\thuman\\tbehavior,\\t\\n84\\nobvious\\tvisual\\tcues,\\t\\n85\\n–87\\nvisual\\tmeasurements,\\t\\n195\\n–96\\nweight\\tloss\\nnonscale\\tvictories,\\t\\n203\\n–204\\nusing\\ta\\thabit\\tcontract\\tto\\tensure,\\t\\n208\\n–209\\nYerkes-Dodson\\tlaw,\\t\\n232\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\nL\\nM\\nN\\nO\\nP\\nQ\\nR\\nS\\nT\\nU\\nV\\nW\\nX\\nY\\nZ', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 234}), Document(page_content=\"About\\tthe\\tAuthor\\nJames\\tClear\\n's\\twork\\thas\\tappeared\\tin\\tthe\\t\\nNew\\tYork\\tTimes\\n,\\t\\nTime\\n,\\tand\\nEntrepreneur\\n,\\tand\\ton\\t\\nCBS\\tThis\\tMorning\\n,\\tand\\tis\\ttaught\\tin\\tcolleges\\taround\\tthe\\nworld.\\tHis\\twebsite,\\tjamesclear.com,\\treceives\\tmillions\\tof\\tvisitors\\teach\\tmonth,\\nand\\thundreds\\tof\\tthousands\\tsubscribe\\tto\\this\\temail\\tnewsletter.\\tHe\\tis\\tthe\\tcreator\\tof\\nThe\\tHabits\\tAcademy,\\tthe\\tpremier\\ttraining\\tplatform\\tfor\\torganizations\\tand\\nindividuals\\tthat\\tare\\tinterested\\tin\\tbuilding\\tbetter\\thabits\\tin\\tlife\\tand\\twork.\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 235}), Document(page_content='What’s\\tnext\\ton\\nyour\\treading\\tlist?\\nDiscover\\tyour\\tnext\\ngreat\\tread!\\nGet\\tpersonalized\\tbook\\tpicks\\tand\\tup-to-date\\tnews\\tabout\\tthis\\tauthor.\\nSign\\tup\\tnow.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 236}), Document(page_content='*\\n\\tInterested\\treaders\\tcan\\tlearn\\tmore\\tat\\thabitsacademy.com.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 237}), Document(page_content='*\\n\\tAs\\tthis\\tbook\\twas\\tgoing\\tto\\tprint,\\tnew\\tinformation\\tabout\\tthe\\tBritish\\tCycling\\nteam\\thas\\tcome\\tout.\\tYou\\tcan\\tsee\\tmy\\tthoughts\\tat\\t\\natomichabits.com/cycling\\n.\\n\\t\\n*\\n\\tI\\tgeeked\\tout\\tand\\tactually\\tcalculated\\tthis.\\tWashington,\\tD.C.,\\tis\\tabout\\t225\\tmiles\\nfrom\\tNew\\tYork\\tCity.\\tAssuming\\tyou\\tare\\tflying\\ton\\ta\\t747\\tor\\tan\\tAirbus\\tA380,\\nchanging\\tthe\\theading\\tby\\t3.5\\tdegrees\\tas\\tyou\\tleave\\tLos\\tAngeles\\tlikely\\tcauses\\tthe\\nnose\\tof\\tthe\\tairplane\\tto\\tshift\\tbetween\\t7.2\\tto\\t7.6\\tfeet,\\tor\\tabout\\t86\\tto\\t92\\tinches.\\tA\\nvery\\tsmall\\tshift\\tin\\tdirection\\tcan\\tlead\\tto\\ta\\tvery\\tmeaningful\\tchange\\tin\\tdestination.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 238}), Document(page_content='*\\n\\tThe\\tterms\\t\\nunconscious\\n,\\t\\nnonconscious\\n,\\tand\\t\\nsubconscious\\n\\tcan\\tall\\tbe\\tused\\tto\\ndescribe\\tthe\\tabsence\\tof\\tawareness\\tor\\tthought.\\tEven\\tin\\tacademic\\tcircles,\\tthese\\nwords\\tare\\toften\\tused\\tinterchangeably\\twithout\\tmuch\\tnitpicking\\t(for\\tonce).\\nNonconscious\\n\\tis\\tthe\\tterm\\tI’m\\tgoing\\tto\\tuse\\tbecause\\tit\\tis\\tbroad\\tenough\\tto\\nencompass\\tboth\\tthe\\tprocesses\\tof\\tthe\\tmind\\twe\\tcould\\tnever\\tconsciously\\taccess\\nand\\tthe\\tmoments\\twhen\\twe\\tare\\tsimply\\tnot\\tpaying\\tattention\\tto\\twhat\\tsurrounds\\tus.\\nNonconscious\\n\\tis\\ta\\tdescription\\tof\\tanything\\tyou\\tare\\tnot\\tconsciously\\tthinking\\nabout.\\n\\t\\n*\\n\\tCertainly,\\tthere\\tare\\tsome\\taspects\\tof\\tyour\\tidentity\\tthat\\ttend\\tto\\tremain\\nunchanged\\tover\\ttime—like\\tidentifying\\tas\\tsomeone\\twho\\tis\\ttall\\tor\\tshort.\\tBut\\teven\\nfor\\tmore\\tfixed\\tqualities\\tand\\tcharacteristics,\\twhether\\tyou\\tview\\tthem\\tin\\ta\\tpositive\\nor\\tnegative\\tlight\\tis\\tdetermined\\tby\\tyour\\texperiences\\tthroughout\\tlife.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 239}), Document(page_content='*\\n\\tReaders\\tof\\n\\tThe\\tPower\\tof\\tHabit\\n\\tby\\tCharles\\tDuhigg\\twill\\trecognize\\tthese\\tterms.\\nDuhigg\\twrote\\ta\\tgreat\\tbook\\tand\\tmy\\tintention\\tis\\tto\\tpick\\tup\\twhere\\the\\tleft\\toff\\tby\\nintegrating\\tthese\\tstages\\tinto\\tfour\\tsimple\\tlaws\\tyou\\tcan\\tapply\\tto\\tbuild\\tbetter\\thabits\\nin\\tlife\\tand\\twork.\\n\\t\\n*\\n\\tCharles\\tDuhigg\\tand\\tNir\\tEyal\\tdeserve\\tspecial\\trecognition\\tfor\\ttheir\\tinfluence\\ton\\nthis\\timage.\\tThis\\trepresentation\\tof\\tthe\\thabit\\tloop\\tis\\ta\\tcombination\\tof\\tlanguage\\nthat\\twas\\tpopularized\\tby\\tDuhigg’s\\tbook,\\t\\nThe\\tPower\\tof\\tHabit\\n,\\tand\\ta\\tdesign\\tthat\\nwas\\tpopularized\\tby\\tEyal’s\\tbook,\\t\\nHooked\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 240}), Document(page_content='*\\n\\tWhen\\tI\\tvisited\\tJapan,\\tI\\tsaw\\tthis\\tstrategy\\tsave\\ta\\twoman’s\\tlife.\\tHer\\tyoung\\tson\\nstepped\\tonto\\tthe\\tShinkansen,\\tone\\tof\\tJapan’s\\tfamous\\tbullet\\ttrains\\tthat\\ttravel\\tat\\nover\\ttwo\\thundred\\tmiles\\tper\\thour,\\tjust\\tas\\tthe\\tdoors\\twere\\tclosing.\\tShe\\twas\\tleft\\noutside\\ton\\tthe\\tplatform\\tand\\tjammed\\ther\\tarm\\tthrough\\tthe\\tdoor\\tto\\tgrab\\thim.\\tWith\\nher\\tarm\\tstuck\\tin\\tthe\\tdoor,\\tthe\\ttrain\\twas\\tabout\\tto\\ttake\\toff,\\tbut\\tright\\tbefore\\tit\\npulled\\taway\\tan\\temployee\\tperformed\\ta\\tsafety\\tcheck\\tby\\tPointing-and-Calling\\tup\\nand\\tdown\\tthe\\tplatform.\\tIn\\tless\\tthan\\tfive\\tseconds,\\the\\tnoticed\\tthe\\twoman\\tand\\nmanaged\\tto\\tstop\\tthe\\ttrain\\tfrom\\tleaving.\\tThe\\tdoor\\topened,\\tthe\\twoman—now\\tin\\ntears—ran\\tto\\ther\\tson,\\tand\\ta\\tminute\\tlater\\tthe\\ttrain\\tdeparted\\tsafely.\\n\\t\\n*\\n\\tInterested\\treaders\\tcan\\tget\\ta\\ttemplate\\tto\\tcreate\\ttheir\\town\\tHabits\\tScorecard\\tat\\natomichabits.com/scorecard\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 241}), Document(page_content=\"*\\n\\tIn\\taddition\\tto\\ther\\tpayment\\tfor\\tthe\\tlibrary,\\tCatherine\\tthe\\tGreat\\tasked\\tDiderot\\tto\\nkeep\\tthe\\tbooks\\tuntil\\tshe\\tneeded\\tthem\\tand\\toffered\\tto\\tpay\\thim\\ta\\tyearly\\tsalary\\tto\\nact\\tas\\ther\\tlibrarian.\\n\\t\\n*\\n\\tFogg\\trefers\\tto\\tthis\\tstrategy\\tas\\tthe\\t“Tiny\\tHabits\\trecipe,”\\tbut\\tI'll\\tcall\\tit\\tthe\\thabit\\nstacking\\tformula\\tthroughout\\tthe\\tbook.\", metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 242}), Document(page_content='*\\n\\tIf\\tyou’re\\tlooking\\tfor\\tmore\\texamples\\tand\\tguidance,\\tyou\\tcan\\tdownload\\ta\\tHabit\\nStacking\\ttemplate\\tat\\t\\natomichabits.com/habitstacking\\n.\\n\\t\\n*\\n\\tDopamine\\tis\\tnot\\tthe\\t\\nonly\\n\\tchemical\\tthat\\tinfluences\\tyour\\thabits.\\tEvery\\tbehavior\\ninvolves\\tmultiple\\tbrain\\tregions\\tand\\tneurochemicals,\\tand\\tanyone\\twho\\tclaims\\tthat\\n“habits\\tare\\tall\\tabout\\tdopamine”\\tis\\tskipping\\tover\\tmajor\\tportions\\tof\\tthe\\tprocess.\\tIt\\nis\\tjust\\tone\\tof\\tthe\\timportant\\trole\\tplayers\\tin\\thabit\\tformation.\\tHowever,\\tI\\twill\\nsingle\\tout\\tthe\\tdopamine\\tcircuit\\tin\\tthis\\tchapter\\tbecause\\tit\\tprovides\\ta\\twindow\\tinto\\nthe\\tbiological\\tunderpinnings\\tof\\tdesire,\\tcraving,\\tand\\tmotivation\\tthat\\tare\\tbehind\\nevery\\thabit.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 243}), Document(page_content='*\\n\\tI’m\\tso\\thappy\\tI\\twas\\table\\tto\\tfit\\ta\\t\\nGame\\tof\\tThrones\\n\\treference\\tinto\\tthis\\tbook.\\n\\t\\n*\\n\\tThis\\tis\\tjust\\ta\\tpartial\\tlist\\tof\\tunderlying\\tmotives.\\tI\\toffer\\ta\\tmore\\tcomplete\\tlist\\tand\\nmore\\texamples\\tof\\thow\\tto\\tapply\\tthem\\tto\\tbusiness\\tat\\t\\natomichabits.com/business\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 244}), Document(page_content='*\\n\\tA\\tsimilar\\tstory\\tis\\ttold\\tin\\tthe\\tbook\\t\\nArt\\t&\\tFear\\n\\tby\\tDavid\\tBayles\\tand\\tTed\\nOrland.\\tIt\\thas\\tbeen\\tadapted\\there\\twith\\tpermission.\\tSee\\tthe\\tendnotes\\tfor\\ta\\tfull\\nexplanation.\\n\\t\\n*\\n\\tThis\\tis\\ta\\tfoundational\\tprinciple\\tin\\tphysics,\\twhere\\tit\\tis\\tknown\\tas\\tthe\\tPrinciple\\nof\\tLeast\\tAction.\\tIt\\tstates\\tthat\\tthe\\tpath\\tfollowed\\tbetween\\tany\\ttwo\\tpoints\\twill\\nalways\\tbe\\tthe\\tpath\\trequiring\\tthe\\tleast\\tenergy.\\tThis\\tsimple\\tprinciple\\tunderpins\\nthe\\tlaws\\tof\\tthe\\tuniverse.\\tFrom\\tthis\\tone\\tidea,\\tyou\\tcan\\tdescribe\\tthe\\tlaws\\tof\\tmotion\\nand\\trelativity.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 245}), Document(page_content='*\\n\\tThe\\tphrase\\t\\naddition\\tby\\tsubtraction\\n\\tis\\talso\\tused\\tby\\tteams\\tand\\tbusinesses\\tto\\ndescribe\\tremoving\\tpeople\\tfrom\\ta\\tgroup\\tin\\torder\\tto\\tmake\\tthe\\tteam\\tstronger\\noverall.\\n\\t\\n*\\n\\tTo\\tbe\\tfair,\\tthis\\tstill\\tsounds\\tlike\\tan\\tamazing\\tnight.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 246}), Document(page_content='*\\n\\tI\\tdesigned\\ta\\thabit\\tjournal\\tspecifically\\tto\\tmake\\tjournaling\\teasier.\\tIt\\tincludes\\ta\\n“One\\tLine\\tPer\\tDay”\\tsection\\twhere\\tyou\\tsimply\\twrite\\tone\\tsentence\\tabout\\tyour\\nday.\\tYou\\tcan\\tlearn\\tmore\\tat\\t\\natomichabits.com/journal\\n.\\n\\t\\n*\\n\\tThe\\tirony\\tof\\thow\\tclosely\\tthis\\tstory\\tmatches\\tmy\\tprocess\\tof\\twriting\\tthis\\tbook\\tis\\nnot\\tlost\\ton\\tme.\\tAlthough\\tmy\\tpublisher\\twas\\tmuch\\tmore\\taccommodating,\\tand\\tmy\\ncloset\\tremained\\tfull,\\tI\\tdid\\tfeel\\tlike\\tI\\thad\\tto\\tplace\\tmyself\\ton\\thouse\\tarrest\\tto\\tfinish\\nthe\\tmanuscript.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 247}), Document(page_content='*\\n\\t\\nThis\\tis\\talso\\treferred\\tto\\tas\\ta\\t“Ulysses\\tpact”\\tor\\ta\\t“Ulysses\\tcontract.”\\tNamed\\nafter\\tUlysses,\\tthe\\thero\\tof\\t\\nThe\\tOdyssey\\n,\\twho\\ttold\\this\\tsailors\\tto\\ttie\\thim\\tto\\tthe\\tmast\\nof\\tthe\\tship\\tso\\tthat\\the\\tcould\\thear\\tthe\\tenchanting\\tsong\\tof\\tthe\\tSirens\\tbut\\twouldn’t\\nbe\\table\\tto\\tsteer\\tthe\\tship\\ttoward\\tthem\\tand\\tcrash\\ton\\tthe\\trocks.\\tUlysses\\trealized\\tthe\\nbenefits\\tof\\tlocking\\tin\\tyour\\tfuture\\tactions\\twhile\\tyour\\tmind\\tis\\tin\\tthe\\tright\\tplace\\nrather\\tthan\\twaiting\\tto\\tsee\\twhere\\tyour\\tdesires\\ttake\\tyou\\tin\\tthe\\tmoment.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 248}), Document(page_content='*\\n\\tThe\\tshift\\tto\\ta\\tdelayed-return\\tenvironment\\tlikely\\tbegan\\taround\\tthe\\tadvent\\tof\\nagriculture\\tten\\tthousand\\tyears\\tago\\twhen\\tfarmers\\tbegan\\tplanting\\tcrops\\tin\\nanticipation\\tof\\ta\\tharvest\\tmonths\\tlater.\\tHowever,\\tit\\twas\\tnot\\tuntil\\trecent\\tcenturies\\nthat\\tour\\tlives\\tbecame\\tfilled\\twith\\tdelayed-return\\tchoices:\\tcareer\\tplanning,\\nretirement\\tplanning,\\tvacation\\tplanning,\\tand\\teverything\\telse\\tthat\\toccupies\\tour\\ncalendars.\\n\\t\\n*\\n\\tTime\\tinconsistency\\tis\\talso\\treferred\\tto\\tas\\t\\nhyperbolic\\tdiscounting\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 249}), Document(page_content='*\\n\\tThis\\tcan\\tderail\\tour\\tdecision\\tmaking\\tas\\twell.\\tThe\\tbrain\\toverestimates\\tthe\\ndanger\\tof\\tanything\\tthat\\tseems\\tlike\\tan\\timmediate\\tthreat\\tbut\\thas\\talmost\\tno\\nlikelihood\\tof\\tactually\\toccurring:\\tyour\\tplane\\tcrashing\\tduring\\ta\\tbit\\tof\\tturbulence,\\ta\\nburglar\\tbreaking\\tin\\twhile\\tyou’re\\thome\\talone,\\ta\\tterrorist\\tblowing\\tup\\tthe\\tbus\\nyou’re\\ton.\\tMeanwhile,\\tit\\tunderestimates\\twhat\\tappears\\tto\\tbe\\ta\\tdistant\\tthreat\\tbut\\tis\\nactually\\tvery\\tlikely:\\tthe\\tsteady\\taccumulation\\tof\\tfat\\tfrom\\teating\\tunhealthy\\tfood,\\nthe\\tgradual\\tdecay\\tof\\tyour\\tmuscles\\tfrom\\tsitting\\tat\\ta\\tdesk,\\tthe\\tslow\\tcreep\\tof\\nclutter\\twhen\\tyou\\tfail\\tto\\ttidy\\tup.\\n\\t\\n*\\n\\tInterested\\treaders\\tcan\\tfind\\ta\\thabit\\ttracker\\ttemplate\\tat\\natomichabits.com/tracker\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 250}), Document(page_content='*\\n\\tYou\\tcan\\tsee\\tthe\\tactual\\tHabit\\tContracts\\tused\\tby\\tBryan\\tHarris\\tand\\tget\\ta\\tblank\\ntemplate\\tat\\t\\natomichabits.com/contract\\n.\\n\\t\\n*\\n\\tIf\\tyou\\tare\\tinterested\\tin\\ttaking\\ta\\tpersonality\\ttest,\\tyou\\tcan\\tfind\\tlinks\\tto\\tthe\\tmost\\nreliable\\ttests\\there:\\t\\natomichabits.com/personality\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 251}), Document(page_content='*\\n\\tIf\\tit’s\\tHarry\\tPotter\\ton\\trepeat,\\tI\\tfeel\\tyou.\\n\\t\\n*\\n\\tI\\thave\\ta\\tpet\\ttheory\\tabout\\twhat\\thappens\\twhen\\twe\\tachieve\\ta\\tflow\\tstate.\\tThis\\nisn’t\\tconfirmed.\\tIt’s\\tjust\\tmy\\tguess.\\tPsychologists\\tcommonly\\trefer\\tto\\tthe\\tbrain\\tas\\noperating\\tin\\ttwo\\tmodes:\\tSystem\\t1\\tand\\tSystem\\t2.\\tSystem\\t1\\tis\\tfast\\tand\\tinstinctual.\\nGenerally\\tspeaking,\\tprocesses\\tyou\\tcan\\tperform\\tvery\\tquickly\\t(like\\thabits)\\tare\\ngoverned\\tby\\tSystem\\t1.\\tMeanwhile,\\tSystem\\t2\\tcontrols\\tthinking\\tprocesses\\tthat\\tare\\nmore\\teffortful\\tand\\tslow—like\\tcalculating\\tthe\\tanswer\\tto\\ta\\tdifficult\\tmath\\tproblem.\\nWith\\tregard\\tto\\tflow,\\tI\\tlike\\tto\\timagine\\tSystem\\t1\\tand\\tSystem\\t2\\tas\\tresiding\\ton\\nopposite\\tends\\tof\\tthe\\tspectrum\\tof\\tthinking.\\tThe\\tmore\\tautomatic\\ta\\tcognitive\\nprocess\\tis,\\tthe\\tmore\\tit\\tslides\\ttoward\\tthe\\tSystem\\t1\\tside\\tof\\tthe\\tspectrum.\\tThe\\tmore\\neffortful\\ta\\ttask\\tis,\\tthe\\tmore\\tit\\tslides\\ttoward\\tSystem\\t2.\\tFlow,\\tI\\tbelieve,\\tresides\\ton\\nthe\\trazor’s\\tedge\\tbetween\\tSystem\\t1\\tand\\tSystem\\t2.\\tYou\\tare\\tfully\\tusing\\tall\\tof\\tyour\\nautomatic\\tand\\timplicit\\tknowledge\\trelated\\tto\\tthe\\ttask\\twhile\\talso\\tworking\\thard\\tto\\nrise\\tto\\ta\\tchallenge\\tbeyond\\tyour\\tability.\\tBoth\\tbrain\\tmodes\\tare\\tfully\\tengaged.\\tThe\\nconscious\\tand\\tnonconscious\\tare\\tworking\\tperfectly\\tin\\tsync.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 252}), Document(page_content='*\\n\\tThe\\tdiscovery\\tof\\tvariable\\trewards\\thappened\\tby\\taccident.\\tOne\\tday\\tin\\tthe\\tlab,\\nthe\\tfamous\\tHarvard\\tpsychologist\\tB.\\tF.\\tSkinner\\twas\\trunning\\tlow\\ton\\tfood\\tpellets\\nduring\\tone\\texperiment\\tand\\tmaking\\tmore\\twas\\ta\\ttime-consuming\\tprocess\\tbecause\\nhe\\thad\\tto\\tmanually\\tpress\\tthe\\tpellets\\tin\\ta\\tmachine.\\tThis\\tsituation\\tled\\thim\\tto\\t“ask\\nmyself\\twhy\\tevery\\tpress\\tof\\tthe\\tlever\\thad\\tto\\tbe\\treinforced.”\\tHe\\tdecided\\tto\\tonly\\ngive\\ttreats\\tto\\tthe\\trats\\tintermittently\\tand,\\tto\\this\\tsurprise,\\tvarying\\tthe\\tdelivery\\tof\\nfood\\tdid\\tnot\\tdecrease\\tbehavior,\\tbut\\tactually\\tincreased\\tit.\\n\\t\\n*\\n\\tI\\tcreated\\ta\\ttemplate\\tfor\\treaders\\tinterested\\tin\\tkeeping\\ta\\tdecision\\tjournal.\\tIt\\tis\\nincluded\\tas\\tpart\\tof\\tthe\\thabit\\tjournal\\tat\\t\\natomichabits.com/journal\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 253}), Document(page_content='*\\n\\tYou\\tcan\\tsee\\tmy\\tprevious\\tAnnual\\tReviews\\tat\\t\\njamesclear.com/annual-review\\n.\\n\\t\\n*\\n\\tYou\\tcan\\tsee\\tmy\\tprevious\\tIntegrity\\tReports\\tat\\t\\njamesclear.com/integrity\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 254}), Document(page_content='*\\n\\tSorites\\tis\\tderived\\tfrom\\tthe\\tGreek\\tword\\t\\nsorós\\n,\\twhich\\tmeans\\t\\nheap\\n\\tor\\t\\npile\\n.', metadata={'source': '/content/drive/MyDrive/RAG_DATA/Atomichabits.pdf', 'page': 255})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the extracted data into text chunks using the text_splitter, which splits the text based on the specified number of characters and overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
        "text_chunks = text_splitter.split_documents(data)\n",
        "# print the number of chunks obtained\n",
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOmHGFYUNJSZ",
        "outputId": "f5e195f2-8034-4fc3-863f-1129e8507d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=text_chunks, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
        "\n",
        "retriever1 = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "lhfRlY6KNaya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcOl9N4JNdgB",
        "outputId": "c30237f0-a659-435b-f537-d5f17fe244df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\",\n",
        "                 temperature=0.5, top_p=0.85)"
      ],
      "metadata": {
        "id": "cz0obVs9No9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer \"\n",
        "    \"the question. If you don't know the answer, say that you \"\n",
        "    \"don't know. Use three sentences maximum and keep the \"\n",
        "    \"answer concise.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever1, question_answer_chain)\n",
        "\n",
        "results = rag_chain.invoke({\"input\": \" what are the atomic habits which i can implement when im learning deep learning?\"})\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3aACEULNqa5",
        "outputId": "88652b51-e9c2-499f-b9a0-31db535c6e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': ' what are the atomic habits which i can implement when im learning deep learning?',\n",
              " 'context': [Document(page_content='learning) or Keras (for deep le arning). So you’ll fit right in! By participating in a few\\ncompetitions, maybe as part of a team, you’ll  become more familiar  with the practical\\nside of some of the advanced best practice s described in this book, especially hyperpa-\\nrameter tuning, avoiding validation-set  overfitting, and model ensembling. \\n9.4.2 Read about the latest  developments on arXiv\\nDeep-learning research, in cont rast with some other scientif ic fields, takes places com-\\npletely in the open. Papers are made publicly  and freely accessible as soon as they’re\\nfinalized, and a lot of related software is open source. arXiv ( https:/ /arxiv.org )—pro-\\nnounced “archive” (the X stands for the Greek chi)—is an open-access preprint server\\nfor physics, mathematics, and computer sc ience research papers. It has become the\\nde facto way to stay up to date on the bl eeding edge of machine learning and deep', metadata={'page': 359, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='learning) or Keras (for deep le arning). So you’ll fit right in! By participating in a few\\ncompetitions, maybe as part of a team, you’ll  become more familiar  with the practical\\nside of some of the advanced best practice s described in this book, especially hyperpa-\\nrameter tuning, avoiding validation-set  overfitting, and model ensembling. \\n9.4.2 Read about the latest  developments on arXiv\\nDeep-learning research, in cont rast with some other scientif ic fields, takes places com-\\npletely in the open. Papers are made publicly  and freely accessible as soon as they’re\\nfinalized, and a lot of related software is open source. arXiv ( https:/ /arxiv.org )—pro-\\nnounced “archive” (the X stands for the Greek chi)—is an open-access preprint server\\nfor physics, mathematics, and computer sc ience research papers. It has become the\\nde facto way to stay up to date on the bl eeding edge of machine learning and deep', metadata={'page': 359, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='learning) or Keras (for deep le arning). So you’ll fit right in! By participating in a few\\ncompetitions, maybe as part of a team, you’ll  become more familiar  with the practical\\nside of some of the advanced best practice s described in this book, especially hyperpa-\\nrameter tuning, avoiding validation-set  overfitting, and model ensembling. \\n9.4.2 Read about the latest  developments on arXiv\\nDeep-learning research, in cont rast with some other scientif ic fields, takes places com-\\npletely in the open. Papers are made publicly  and freely accessible as soon as they’re\\nfinalized, and a lot of related software is open source. arXiv ( https:/ /arxiv.org )—pro-\\nnounced “archive” (the X stands for the Greek chi)—is an open-access preprint server\\nfor physics, mathematics, and computer sc ience research papers. It has become the\\nde facto way to stay up to date on the bl eeding edge of machine learning and deep', metadata={'page': 359, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'}),\n",
              "  Document(page_content='264 CHAPTER  7Advanced deep-learning best practices\\nin the right direction. Updating hyperpar ameters, on the other hand, is extremely\\nchallenging. Consider the following:\\n\\uf0a1Computing the feedback signal (does th is set of hyperparameters lead to a\\nhigh-performing model on this task?) ca n be extremely expensive: it requires\\ncreating and training a new mode l from scratch on your dataset.\\n\\uf0a1The hyperparameter space is typically made  of discrete decisions and thus isn’t\\ncontinuous or differentiable. Hence, yo u typically can’t do gradient descent in\\nhyperparameter space. Inst ead, you must rely on gradient-free optimization\\ntechniques, which naturally are far le ss efficient than gradient descent.\\nBecause these challenges are difficult and th e field is still young, we currently only\\nhave access to very limited tools to optimi ze models. Often, it turns out that random\\nsearch (choosing hyperparameters to evaluate  at random, repeatedly) is the best solu-', metadata={'page': 286, 'source': '/content/drive/MyDrive/deeplearningwithpython.pdf'})],\n",
              " 'answer': \"The provided text doesn't directly address atomic habits for deep learning. However, it does mention some key practices that can be turned into atomic habits:\\n\\n* **Read about the latest developments on arXiv:** Make it a habit to regularly check arXiv for new research papers in deep learning. This keeps you updated on the latest advancements and helps you stay ahead of the curve.\\n* **Participate in competitions:**  Join Kaggle or other machine learning competitions to gain practical experience and learn from others. This can be a regular activity, even if it's just for a few hours a week.\\n* **Experiment with hyperparameter tuning:**  Make it a habit to experiment with different hyperparameters when training your models. This will help you understand how different settings affect performance and improve your model optimization skills. \\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ysd6ZtxhN8th"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}